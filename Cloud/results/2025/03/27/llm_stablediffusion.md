---
title: "Stable Diffusion Subreddit"
date: "2025-03-27"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] o4 image generator releases. The internet the next day:](https://i.redd.it/nfuspw67v9re1.jpeg) (Score: 136)
    *   Discussing the release of the o4 image generator and its impact, comparing it to other models and expressing concerns about censorship and open source implications.
2.  [Wan2.1-Fun Control Models! Demos at the Beginning + Full Guide & Workflows](https://youtu.be/hod6VGCLufg) (Score: 46)
    *   A video showcasing and guiding users on using Wan2.1-Fun Control Models, with viewers asking questions about compatibility, functionality, and performance.
3.  [Part 1 of a dramatic short film about space travel. Did I bite off more than I could chew? Probably. Made with Wan 2.1 I2V.](https://v.redd.it/o1gghqztp9re1) (Score: 30)
    *   The creator shared the first part of their AI-generated space travel short film made with Wan 2.1 I2V, receiving positive feedback and questions about the tools and process.
4.  [can't recreate image on the left with image on the right, everything is the same settings wise except for the seed value. I created the left image on my Mac in (Draw things), the right image on pc (Forge UI). Why are they so different & how do I fix this difference?](https://www.reddit.com/gallery/1jl88xi) (Score: 21)
    *   Users are troubleshooting why they can't recreate an image across different platforms (Mac/Draw Things vs PC/Forge UI) despite using the same settings, focusing on seed values and hardware differences.
5.  [When a story somehow lurks in a set of SDXL images. Can share WF if interested.](https://www.reddit.com/gallery/1jl5xcq) (Score: 15)
    *   User shared a set of SDXL images that tell a story and offered to share the workflow if there's interest. The images are noted for their unique and consistent style.
6.  [Controlnet help request…](https://www.reddit.com/r/StableDiffusion/comments/1jlblm8/controlnet_help_request/) (Score: 2)
    *   A user is asking for assistance with ControlNet. Users suggested using GIMP or Blender to create retail-ready images from print images.
7.  [Wrote a song and made an anime music video from Fairy Tail - Wan 2.1 and Suno AI.](https://www.youtube.com/watch?v=lpWWdO3aZgM) (Score: 2)
    *   A user created a song and anime music video from Fairy Tail using Wan 2.1 and Suno AI. They put everything together in Shotcut and shared their process.
8.  [Image upscale / enhancement](https://i.redd.it/jlim6iw1d9re1.jpeg) (Score: 0)
    *   A user is requesting help with upscaling and enhancing an image. Other users are asking for more details about what has been tried and offering suggestions like using SD 1.5 tile controlnet.
9.  [What is the best Images to Video generator using API call](https://www.reddit.com/r/StableDiffusion/comments/1jl5f7m/what_is_the_best_images_to_video_generator_using/) (Score: 0)
    *   A user is asking about the best images to video generator using API call. Users suggested kling and modal.com.
10. [Switching from Laptop to Desktop](https://www.reddit.com/r/StableDiffusion/comments/1jl5vee/switching_from_laptop_to_desktop/) (Score: 0)
    *   Users are discussing the best GPU options for a desktop setup for stable diffusion, with recommendations against AMD and discussion of used 3090s and 4060ti.
11. [Free Images to Video using API tools. Can someone please share free tools with API.](https://www.reddit.com/r/StableDiffusion/comments/1jl6jq4/free_images_to_video_using_api_tools_can_someone/) (Score: 0)
    *   A user is looking for free images-to-video tools with APIs, but others are pointing out that such tools are rare due to the high compute costs.
12. [Mismatching Lora and model](https://www.reddit.com/r/StableDiffusion/comments/1jl7xjp/mismatching_lora_and_model/) (Score: 0)
    *   A user is discussing the implications of mismatching a Lora and a model. Another user explained that Lora adjusts AI model's numeric weights to a point, at which it's able to output images similar to Lora dataset.
13. [AI Generated Short Film Doubt](https://www.reddit.com/r/StableDiffusion/comments/1jl86m1/ai_generated_short_film_doubt/) (Score: 0)
    *   A user is asking about whether I2V, Kling or Wan(480p)+Topaz would be a better approach for an AI Generated short film.
14. [Recommended Tools for 12gb?](https://www.reddit.com/r/StableDiffusion/comments/1jl8zbo/recommended_tools_for_12gb/) (Score: 0)
    *   A user is asking for recommended tools for 12gb. Another user mentioned that they found several guide/workflow for i2v on civitai due to wan2.1 release.
15. [What is today's best way to turn my own pictures into professional ones ?](https://www.reddit.com/r/StableDiffusion/comments/1jla2od/what_is_todays_best_way_to_turn_my_own_pictures/) (Score: 0)
    *   A user is asking what is today's best way to turn their own pictures into professional ones. Another user suggested Adobe Lightroom and Topaz photo ai.
16. [unsubscribe stablediffusionweb](https://www.reddit.com/r/StableDiffusion/comments/1jlak4p/unsubscribe_stablediffusionweb/) (Score: 0)
    *   A user is asking how to unsubscribe from stablediffusionweb. Another user suggested that they block the payments from their card.
17. [Control the direction of gaze on SD 1.5 or XL](https://www.reddit.com/r/StableDiffusion/comments/1jlatuk/control_the_direction_of_gaze_on_sd_15_or_xl/) (Score: 0)
    *   A user is asking how to control the direction of gaze on SD 1.5 or XL.

# Detailed Analysis by Thread
**[[D] o4 image generator releases. The internet the next day: (Score: 136)](https://i.redd.it/nfuspw67v9re1.jpeg)**
*   **Summary:** The thread discusses the release of the o4 image generator and its perceived impact. Comments range from humorous takes on the internet's reaction to concerns about censorship, open-source development, and comparisons to other models like Google Gemini.
*   **Emotion:** The overall emotional tone is Neutral, with a mix of humor, concern, and technical discussion. While some comments express negativity regarding censorship, others are simply observational or humorous. A single comment had a negative sentiment score.
*   **Top 3 Points of View:**
    *   The release of o4 is a paradigm shift for native multimodal image generation.
    *   The model is heavily censored, limiting its capabilities.
    *   Open-source models may be at risk due to this release.

**[Wan2.1-Fun Control Models! Demos at the Beginning + Full Guide & Workflows (Score: 46)](https://youtu.be/hod6VGCLufg)**
*   **Summary:** This thread is centered around a video demonstrating Wan2.1-Fun Control Models. Users are asking questions about its features, compatibility with other models like T2V, and how to achieve specific effects like character animation.
*   **Emotion:** The overall emotional tone is Positive, with users expressing interest, appreciation, and asking clarifying questions.
*   **Top 3 Points of View:**
    *   The Wan2.1 models are interesting and show promise.
    *   Users are seeking guidance on specific functionalities and integrations.
    *   Some users feel the result quality is still rough.

**[Part 1 of a dramatic short film about space travel. Did I bite off more than I could chew? Probably. Made with Wan 2.1 I2V. (Score: 30)](https://v.redd.it/o1gghqztp9re1)**
*   **Summary:** The thread features the first part of an AI-generated short film created with Wan 2.1 I2V. The creator shares details of their process, including the tools and models used. Responses are overwhelmingly positive, with viewers praising the work and asking for more.
*   **Emotion:** The overall emotional tone is Positive. Viewers are impressed and excited about the project.
*   **Top 3 Points of View:**
    *   The short film is a promising demonstration of AI video generation.
    *   Viewers are eager for the next installment.
    *   The creator shared the tools and workflow that he used, including the 480p model and voice acting via ElevenLabs.

**[can't recreate image on the left with image on the right, everything is the same settings wise except for the seed value. I created the left image on my Mac in (Draw things), the right image on pc (Forge UI). Why are they so different & how do I fix this difference? (Score: 21)](https://www.reddit.com/gallery/1jl88xi)**
*   **Summary:** The user is trying to reproduce an image created on a Mac (Draw Things) on a PC (Forge UI) but is getting different results despite using the same settings. Users offered suggestions and solutions.
*   **Emotion:** The overall emotional tone is Neutral, focusing on problem-solving and technical explanations. There's a mix of offering help and stating preferences for one image over the other.
*   **Top 3 Points of View:**
    *   Differences in GPU architectures and software implementations (Draw Things vs. Forge UI) cause the discrepancies.
    *   Ensuring identical settings, including the seed and noise settings, is crucial.
    *   The AI model and backend might be different, leading to different results.

**[When a story somehow lurks in a set of SDXL images. Can share WF if interested. (Score: 15)](https://www.reddit.com/gallery/1jl5xcq)**
*   **Summary:** The user posted a set of SDXL images and offered to share the workflow.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   The images have a unique and consistent style.
    *   The workflow could be interesting to other users.

**[Controlnet help request… (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jlblm8/controlnet_help_request/)**
*   **Summary:** The user is asking for assistance with ControlNet.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   GIMP is the easiest way to create a retail-ready image from a print image.
    *   Blender is better, but if all you need is a quick mockup, GIMP can do it.

**[Wrote a song and made an anime music video from Fairy Tail - Wan 2.1 and Suno AI. (Score: 2)](https://www.youtube.com/watch?v=lpWWdO3aZgM)**
*   **Summary:** The user created a song and anime music video from Fairy Tail using Wan 2.1 and Suno AI.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   The user had an idea for a song in their head. Suno AI made that real.
    *   They put everything together in Shotcut.
    *   It's rougher than they like but was still fun to put together.

**[Image upscale / enhancement (Score: 0)](https://i.redd.it/jlim6iw1d9re1.jpeg)**
*   **Summary:** The user is requesting help with upscaling and enhancing an image.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   The user asked a vague question.
    *   Users suggested that they try a denoise of 0.55 using Flux img2img.
    *   Sd 1.5 tile controlnet

**[What is the best Images to Video generator using API call (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jl5f7m/what_is_the_best_images_to_video_generator_using/)**
*   **Summary:** The user is asking about the best images to video generator using API call.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Users suggested kling
    *   Another user suggested using modal.com to host your workflow as app and access it via api endpoint

**[Switching from Laptop to Desktop (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jl5vee/switching_from_laptop_to_desktop/)**
*   **Summary:** Users are discussing the best GPU options for a desktop setup for stable diffusion.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   Users recommended against AMD.
    *   The used 3090 is probably the best deal for VRAM/$.
    *   There are good deals for 4060ti out there that's probably your cheapest option for decent vram size.

**[Free Images to Video using API tools. Can someone please share free tools with API. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jl6jq4/free_images_to_video_using_api_tools_can_someone/)**
*   **Summary:** The user is looking for free images-to-video tools with APIs.
*   **Emotion:** The overall emotional tone is Negative.
*   **Top 3 Points of View:**
    *   Such tools are rare due to the high compute costs.
    *   Users can rent a cloud GPU for $0.50 an hour.
    *   Users can host your workflow on modal dot com , they provide option to host your workflow and vai api endpoint you can access it.

**[Mismatching Lora and model (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jl7xjp/mismatching_lora_and_model/)**
*   **Summary:** The user is discussing the implications of mismatching a Lora and a model.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Lora adjusts AI model's numeric weights to a point, at which it's able to output images similar to Lora dataset.
    *   Numeric adjustments contained in Lora stay exactly the same even if you switch the AI model.

**[AI Generated Short Film Doubt (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jl86m1/ai_generated_short_film_doubt/)**
*   **Summary:** A user is asking about whether I2V, Kling or Wan(480p)+Topaz would be a better approach for an AI Generated short film.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   It takes 10 minutes to generate a 4 second clip at 720p at 16 fps on Wan 2.1 720p image2video on my 14900K w/ 96GB of ram and a RTX 441.
    *   If you don't have a machine like this, you may need to pay for a service.
    *   Paid services like Kling support 10s, some open sourse free models too.

**[Recommended Tools for 12gb? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jl8zbo/recommended_tools_for_12gb/)**
*   **Summary:** A user is asking for recommended tools for 12gb.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   I found several guide/workflow for i2v on civitai due to wan2.1 release, works great by default, now to relearn prompt

**[What is today's best way to turn my own pictures into professional ones ? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jla2od/what_is_todays_best_way_to_turn_my_own_pictures/)**
*   **Summary:** A user is asking what is today's best way to turn their own pictures into professional ones.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   If all you're looking for is a professional *vibe* then shoot raw on your phone and use Adobe light room.
    *   Topaz photo ai for the *** pictures.
    *   If you already have a crisp picture, then you need to post-process it to your linking I guess.

**[unsubscribe stablediffusionweb (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jlak4p/unsubscribe_stablediffusionweb/)**
*   **Summary:** A user is asking how to unsubscribe from stablediffusionweb.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Just block the payments from your card.

**[Control the direction of gaze on SD 1.5 or XL (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jlatuk/control_the_direction_of_gaze_on_sd_15_or_xl/)**
*   **Summary:** A user is asking how to control the direction of gaze on SD 1.5 or XL.
*   **Emotion:** The overall emotional tone is Negative.
*   **Top 3 Points of View:**
    *   This is a problem that isn't really solved yet.
    *   The only thing that really works for me are using specific tags in a booru based checkpoint such as Pony or Illustrious.

