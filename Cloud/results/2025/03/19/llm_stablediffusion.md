---
title: "Stable Diffusion Subreddit"
date: "2025-03-19"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [I don't have a computer powerful enough, and i can't afford a payed version of an image generator, because i don't own my own bankaccount( i'm mentally disabled) but is there someone with a powerful computer wanting to turn this oc of mine into an anime picture?](https://i.redd.it/o9woljrtcope1.jpeg) (Score: 339)
    *   A user requests help generating an anime picture of their OC because they lack the resources. Other users provide AI-generated images based on the OC.
2.  [MCP Claude and blender are just magic. Fully automatic to generate 3d scene](https://v.redd.it/p3imerepvope1) (Score: 74)
    *   A user showcases a fully automatic process to generate 3D scenes using MCP Claude and Blender.
3.  [Wan2.1 In RTX 5090 32GB](https://v.redd.it/fux8uk15bope1) (Score: 30)
    *   A user tests Wan2.1 on an RTX 5090, highlighting the impact of GPU RAM on resolution.
4.  [Do anybody know how could I achieve this? (vid 2 vid + style transfer)](https://www.reddit.com/r/StableDiffusion/comments/1jf1o3c/do_anybody_know_how_could_i_achieve_this_vid_2/) (Score: 5)
    *   A user asks for guidance on achieving a specific video-to-video style transfer effect.
5.  [(silly WanVideo 2.1  experiment) This happened if you keep passing the last frame of the video as the first frame of the next input](https://youtu.be/_4CfVfwCExI) (Score: 5)
    *   A user shares a WanVideo 2.1 experiment where the last frame of a video is used as the first frame of the next input, resulting in a looping effect.
6.  [Wan 2.1 image to video introduces weird blur and VHS/scramble-like color shifts and problems.](https://www.reddit.com/r/StableDiffusion/comments/1jez3k8/wan_21_image_to_video_introduces_weird_blur_and/) (Score: 3)
    *   A user reports blur and color shift issues with Wan 2.1 image-to-video.
7.  [Magic_ILL](https://civitai.com/models/1346879/magicill) (Score: 1)
    *   A user shares their custom model merge and seeks community feedback.
8.  [Can inpainting be used to blend photo montages?](https://www.reddit.com/r/StableDiffusion/comments/1jf1d4s/can_inpainting_be_used_to_blend_photo_montages/) (Score: 1)
    *   A user asks if inpainting can be used to blend photo montages.
9.  [Flux ControlNet Issues: What am I doing wrong?](https://i.redd.it/gmxd8g6dgope1.jpeg) (Score: 0)
    *   A user seeks help with Flux ControlNet issues, struggling to generate realistic images despite using various workflows and settings.
10. [I'm not getting any answers on Kohya's github-page, so I'm trying here instead. I keep getting these kind of errors when trying to extract SDXL LoRAs. I can extract some, but most gives errors like this. Anyone know what needs to be fixed? I don't understand anything.](https://i.redd.it/z767gby4vnpe1.png) (Score: 0)
    *   A user is encountering errors while extracting SDXL LoRAs using Kohya and seeks assistance.
11. [Reelaborate famous old pictures](https://www.reddit.com/r/StableDiffusion/comments/1jf3dwp/reelaborate_famous_old_pictures/) (Score: 0)
    *   A user discusses re-elaborating famous old pictures.
12. [budget laptop for AI image generator recommendations](https://www.reddit.com/r/StableDiffusion/comments/1jf3nor/budget_laptop_for_ai_image_generator/) (Score: 0)
    *   A user requests budget laptop recommendations for AI image generation.
13. [Where can I find sources that explain how to build image generator from scratch](https://www.reddit.com/r/StableDiffusion/comments/1jf4jlu/where_can_i_find_sources_that_explain_how_to/) (Score: 0)
    *   A user asks where to find resources for building an image generator from scratch.
14. [Help: Setup for SD?](https://www.reddit.com/r/StableDiffusion/comments/1jf5azo/help_setup_for_sd/) (Score: 0)
    *   A user seeks help with setting up Stable Diffusion (SD).
15. [Best way to generate text 2 image via scripts instead of GUI](https://www.reddit.com/r/StableDiffusion/comments/1jf5r4n/best_way_to_generate_text_2_image_via_scripts/) (Score: 0)
    *   A user inquires about the best way to generate text-to-image via scripts instead of a GUI.

# Detailed Analysis by Thread
**[I don't have a computer powerful enough, and i can't afford a payed version of an image generator, because i don't own my own bankaccount( i'm mentally disabled) but is there someone with a powerful computer wanting to turn this oc of mine into an anime picture? (Score: 339)](https://i.redd.it/o9woljrtcope1.jpeg)**
*  **Summary:** A user with limited resources (due to lack of a powerful computer, financial constraints, and disability) requests assistance from the community to generate an anime-style image of their original character (OC). Several users respond by providing AI-generated images.
*  **Emotion:** The overall emotion is positive, driven by the community's helpfulness and the positive sentiment expressed in some of the replies.
*  **Top 3 Points of View:**
    *   The user needs help generating an image of their OC due to resource limitations.
    *   Several users are willing to use their resources to fulfill the request by creating AI generated images.
    *   Some users offer suggestions about free services that the original poster can use.

**[MCP Claude and blender are just magic. Fully automatic to generate 3d scene (Score: 74)](https://v.redd.it/p3imerepvope1)**
*  **Summary:** A user showcases a fully automatic 3D scene generation process using MCP Claude and Blender. They share a GitHub link for others to test the setup.
*  **Emotion:** The overall emotional tone is neutral, driven by informational and inquisitive comments. There is a hint of positivity from users impressed by the results. A small amount of negativity is shown by users being confused with the scene.
*  **Top 3 Points of View:**
    *   The user is demonstrating a new, automated workflow for 3D scene generation.
    *   Other users are curious about the process and ask for more details and explanations.
    *   Some users compare this workflow to other AI tools for 3D modeling and texturing, questioning its efficiency.

**[Wan2.1 In RTX 5090 32GB (Score: 30)](https://v.redd.it/fux8uk15bope1)**
*  **Summary:** The user shares the result of Wan2.1 running on a high-end RTX 5090 GPU, emphasizing the importance of GPU RAM for higher resolutions. The test resulted in a 1280x728 image generated in 10 minutes.
*  **Emotion:** The overall tone is mixed, with neutral observations about performance and positive remarks on the result, but also negative comments about the speed.
*  **Top 3 Points of View:**
    *   The user is showcasing the performance of Wan2.1 on new hardware, highlighting the benefits of more GPU RAM.
    *   Other users inquire about performance at higher resolutions, wanting to compare.
    *   Some users believe WAN is overhyped, questioning the value of the output relative to the processing time and hardware requirements.

**[Do anybody know how could I achieve this? (vid 2 vid + style transfer) (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1jf1o3c/do_anybody_know_how_could_i_achieve_this_vid_2/)**
*  **Summary:** A user asks for advice on achieving a specific video-to-video style transfer effect. Another user provides a link to a YouTube video with a workflow.
*  **Emotion:** The thread has a neutral tone, characterized by a request for help and a straightforward solution.
*  **Top 3 Points of View:**
    *   The user is looking for specific guidance on video style transfer.
    *   Another user shares a relevant resource (YouTube video).

**[(silly WanVideo 2.1  experiment) This happened if you keep passing the last frame of the video as the first frame of the next input (Score: 5)](https://youtu.be/_4CfVfwCExI)**
*  **Summary:** The user describes their experiment with WanVideo 2.1, where they looped the video by feeding the last frame as the next input. The user is experiencing crashing issues with WanVideo 2.1 i2v. Another user sums up the video as a repetitive ballerina movement.
*  **Emotion:** The overall emotion is neutral, driven by the summarization of the video content and the technical issue.
*  **Top 3 Points of View:**
    *   The user is experimenting with a specific video looping technique using WanVideo 2.1.
    *   The user is encountering technical difficulties with the WanVideo 2.1.
    *   Another user provides a summary of the video content for those who don't want to click.

**[Wan 2.1 image to video introduces weird blur and VHS/scramble-like color shifts and problems. (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1jez3k8/wan_21_image_to_video_introduces_weird_blur_and/)**
*  **Summary:** A user reports issues with Wan 2.1 image-to-video, specifically blur and color shifts. Another user confirms experiencing the same problem.
*  **Emotion:** The emotion is mainly neutral, with slight negativity due to the reported issues.
*  **Top 3 Points of View:**
    *   The user is reporting technical problems with Wan 2.1.
    *   Another user confirms the same issue.

**[Magic_ILL (Score: 1)](https://civitai.com/models/1346879/magicill)**
*  **Summary:** A user shares their custom model merge named "Magic_ILL" and asks for feedback from the community.
*  **Emotion:** The overall tone is positive, stemming from the user's enthusiasm and desire for feedback.
*  **Top 3 Points of View:**
    *   The user is sharing their creation with the community.
    *   The user is actively soliciting feedback to improve the model.

**[Can inpainting be used to blend photo montages? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jf1d4s/can_inpainting_be_used_to_blend_photo_montages/)**
*  **Summary:** A user asks if inpainting can be used to blend photo montages. Another user confirms it's possible and suggests a combination of inpainting, ControlNet, and image-to-image with low denoise, pointing to a helpful post and tutorials.
*  **Emotion:** Positive due to a helpful response providing detailed guidance and resources.
*  **Top 3 Points of View:**
    *   The user is asking a specific question about inpainting.
    *   Another user confirms the possibility and provides technical guidance.
    *   The user points to additional resources for learning about the technique.

**[Flux ControlNet Issues: What am I doing wrong? (Score: 0)](https://i.redd.it/gmxd8g6dgope1.jpeg)**
*  **Summary:** A user is experiencing issues with Flux ControlNet, struggling to generate realistic images despite using different workflows and settings. Another user suggests adjusting the `end_percent` and `strength` parameters in the Apply ControlNet node.
*  **Emotion:** The tone is mainly neutral, with a slight hint of frustration from the user experiencing issues and helpfulness from the user offering advice.
*  **Top 3 Points of View:**
    *   The user is struggling with ControlNet settings for realistic image generation.
    *   The user specifies their hardware and software setup for troubleshooting.
    *   Another user provides specific parameter adjustments for ControlNet.

**[I'm not getting any answers on Kohya's github-page, so I'm trying here instead. I keep getting these kind of errors when trying to extract SDXL LoRAs. I can extract some, but most gives errors like this. Anyone know what needs to be fixed? I don't understand anything. (Score: 0)](https://i.redd.it/z767gby4vnpe1.png)**
*  **Summary:** A user is facing errors while extracting SDXL LoRAs using Kohya and is seeking assistance after not receiving help on GitHub. Another user suggests the models may have been created with a different tool than Kohya.
*  **Emotion:** The emotion is neutral, with a hint of frustration due to the unresolved errors.
*  **Top 3 Points of View:**
    *   The user needs help resolving errors during LoRA extraction.
    *   The user indicates a lack of understanding of the error messages.
    *   Another user offers a possible cause for the errors.

**[Reelaborate famous old pictures (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jf3dwp/reelaborate_famous_old_pictures/)**
*  **Summary:** The user discusses re-elaborating famous old pictures.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   The user wants to re-elaborate famous old pictures.
    *   The user needs help on unfinished part.

**[budget laptop for AI image generator recommendations (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jf3nor/budget_laptop_for_ai_image_generator/)**
*  **Summary:** The user wants to find a budget laptop for AI image generation.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   The user needs a recommendation for a budget laptop.

**[Where can I find sources that explain how to build image generator from scratch (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jf4jlu/where_can_i_find_sources_that_explain_how_to/)**
*  **Summary:** The user wants to find sources that explain how to build image generator from scratch. Another user shared a Github link.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    *   The user wants to build image generator from scratch.
    *   The user needs resource of building image generator.
    *   Another user suggests Github link

**[Help: Setup for SD? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jf5azo/help_setup_for_sd/)**
*  **Summary:** The user wants to setup for SD? Another user shared his setup.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   The user wants to setup for SD.
    *   The user needs setup tutorial.
    *   Another user suggests his setup

**[Best way to generate text 2 image via scripts instead of GUI (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jf5r4n/best_way_to_generate_text_2_image_via_scripts/)**
*  **Summary:** The user wants to generate text 2 image via scripts instead of GUI. Another user shared a Github link.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   The user wants to generate text 2 image via scripts instead of GUI.
    *   The user needs a tool that generate text 2 image via scripts instead of GUI.
    *   Another user suggests Github link
