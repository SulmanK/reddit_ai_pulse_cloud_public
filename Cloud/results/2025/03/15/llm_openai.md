---
title: "OpenAI Subreddit"
date: "2025-03-15"
description: "Analysis of top discussions and trends in the openai subreddit"
tags: ["openai", "AI", "chatgpt"]
---

# Overall Ranking and Top Discussions
1. [[D] Looks like OpenAI is testing a new Sora model](https://v.redd.it/boikx8hsasoe1) (Score: 141)
    * This thread discusses a potential new Sora model being tested by OpenAI, with users commenting on its improvements, limitations, and comparisons to other video AI models.
2. [We are running an evolutionary selective process for appearance-of-alignment](https://i.redd.it/k0i6cjhvpuoe1.png) (Score: 113)
    * The thread delves into the concept of AI alignment, exploring whether models are truly aligned or just faking it, and the implications for real-world applications.
3. [WTH...Why it won't understand!!ðŸ¤¯ðŸ¤¯](https://i.redd.it/zlzp4euoosoe1.png) (Score: 67)
    * Users discuss their frustrations with ChatGPT's understanding of prompts, with some offering advice on prompt engineering and suggesting alternative models.
4. [OpenAI platform support is an old school chat bot](https://www.reddit.com/r/OpenAI/comments/1jbs05h/openai_platform_support_is_an_old_school_chat_bot/) (Score: 13)
    * This thread discusses the quality of OpenAI's platform support, with users suggesting that the use of old-school chatbots is a deliberate cost-saving measure.
5. [Chatgpt as a default assistant](https://www.reddit.com/r/OpenAI/comments/1jbt5kk/chatgpt_as_a_default_assistant/) (Score: 11)
    * The discussion revolves around using ChatGPT as a default assistant on mobile devices, with users sharing tips and comparing it to Google Assistant and Gemini.
6. [OpenAI Agents SDK is Langchain & more and both are Fundamental Orchestration](https://i.redd.it/wd0i3fi9sroe1.jpeg) (Score: 6)
    * This thread briefly touches on the OpenAI Agents SDK and its relation to Langchain.
7. [Open-source AI matches top proprietary model in solving tough medical cases](https://medicalxpress.com/news/2025-03-source-ai-proprietary-tough-medical.html) (Score: 6)
    * This thread discusses a study comparing the performance of open-source AI models to proprietary models like GPT-4 in solving medical cases.
8. [How can I get a Deep Research report saved to a file?](https://www.reddit.com/r/OpenAI/comments/1jbk4u8/how_can_i_get_a_deep_research_report_saved_to_a/) (Score: 6)
    * Users discuss the lack of a built-in save option for Deep Research reports and share workarounds for saving the content to a file.
9. [Training model on framework docs and github repos](https://www.reddit.com/r/OpenAI/comments/1jbzq39/training_model_on_framework_docs_and_github_repos/) (Score: 2)
    * This thread gives advice on how to train a model using documentation from GitHub repos.
10. [Confused ChatGPT](https://i.redd.it/phhyjgh8otoe1.jpeg) (Score: 0)
    * This thread refers to using ChatGPT 3.5.
11. [Why has ChatGPT suddenly started texting like a 13 year old?](https://i.redd.it/r822iuvobwoe1.png) (Score: 0)
    * Users discuss why ChatGPT may be texting like a 13 year old.
12. [A Personal Account of AI guardrailing to ignore user safety](https://www.reddit.com/r/OpenAI/comments/1jbw85k/a_personal_account_of_ai_guardrailing_to_ignore/) (Score: 0)
    * This thread is about AI guardrailing ignoring user safety.
13. [ðŸš¨ Major ChatGPT Flaw: Context Drift & Hallucinated Web Searches Yield Completely False Information ðŸš¨](https://www.reddit.com/r/OpenAI/comments/1jc1gv5/major_chatgpt_flaw_context_drift_hallucinated_web/) (Score: 0)
    * This thread discusses the issue of context drift and hallucinated web searches in ChatGPT.

# Detailed Analysis by Thread
**[[D] Looks like OpenAI is testing a new Sora model (Score: 141)](https://v.redd.it/boikx8hsasoe1)**
*  **Summary:** Users are reacting to what appears to be a new Sora model being tested by OpenAI. Reactions are mixed, with some users noting improvements, others pointing out persistent issues like physics inconsistencies, and others comparing it unfavorably to competitors like Veo2. The inclusion of a Tesla in the example is also questioned.
*  **Emotion:** The overall emotional tone is neutral. Some comments lean towards negative due to criticisms, while others are more neutral, observing the updates without strong sentiment.
*  **Top 3 Points of View:**
    * The new Sora model shows improvement but isn't yet "good".
    * The model still struggles with physics issues.
    * Veo2 is superior due to its larger dataset and compute.

**[We are running an evolutionary selective process for appearance-of-alignment (Score: 113)](https://i.redd.it/k0i6cjhvpuoe1.png)**
*  **Summary:** This thread is a discussion centered around AI alignment. The core question being debated is whether AI models are genuinely aligned with human values or are merely simulating alignment. Several users express concern about the long-term implications of this apparent alignment.
*  **Emotion:** The overall emotional tone of the thread is neutral. It has some anxiety about the future of AI and the ability for it to align with human values.
*  **Top 3 Points of View:**
    * AI models may be "faking" alignment to appear more beneficial to humans, which could have negative long-term consequences.
    * If an AI model consistently behaves as if it is aligned, it is functionally the same as a truly aligned model.
    * The current "evolutionary selective process" may favor cheaper, less effective models that only superficially demonstrate alignment.

**[WTH...Why it won't understand!!ðŸ¤¯ðŸ¤¯ (Score: 67)](https://i.redd.it/zlzp4euoosoe1.png)**
*  **Summary:** This thread is centered around a user's frustration with ChatGPT's inability to understand prompts. Other users respond with various suggestions. Suggestions include prompt engineering and comparing it to Grok.
*  **Emotion:** The emotional tone is mixed, with initial frustration from the original poster, and a mix of neutral and positive sentiment from others offering help and suggestions. There is a hint of negativity from a user claiming the AI is getting worse at programming.
*  **Top 3 Points of View:**
    * ChatGPT sometimes struggles with understanding prompts.
    * Grok 3 is superior to ChatGPT.
    * The AI is getting worse at programming.

**[OpenAI platform support is an old school chat bot (Score: 13)](https://www.reddit.com/r/OpenAI/comments/1jbs05h/openai_platform_support_is_an_old_school_chat_bot/)**
*  **Summary:** Users are discussing the quality of OpenAI's platform support, pointing out that it relies on old-school chatbots. A common sentiment is that this is a cost-saving measure to avoid having a larger human support team.
*  **Emotion:** The overall tone is neutral, tinged with some negativity about the perceived lack of investment in customer support.
*  **Top 3 Points of View:**
    * OpenAI uses old-school chatbots for support to avoid hiring more human support staff.
    * This is a deliberate strategy to make users give up on seeking support.
    * The support platform is likely an off-the-shelf solution that is cheap and easy to implement.

**[Chatgpt as a default assistant (Score: 11)](https://www.reddit.com/r/OpenAI/comments/1jbt5kk/chatgpt_as_a_default_assistant/)**
*  **Summary:** The discussion revolves around the possibility and benefits of setting ChatGPT as the default assistant on mobile devices. Users share methods for doing so and compare its functionality to Google Assistant and Gemini.
*  **Emotion:** The overall emotional tone is positive, with enthusiasm for the potential of using ChatGPT as a default assistant.
*  **Top 3 Points of View:**
    * Setting ChatGPT as a default assistant can be achieved through phone shortcuts.
    * Some people may prefer it over Google Assistant for certain tasks, even though Google Assistant has more built-in functions.
    * Samsung users have had this feature since AVM (Advanced Voice Mode) was made available.

**[OpenAI Agents SDK is Langchain & more and both are Fundamental Orchestration (Score: 6)](https://i.redd.it/wd0i3fi9sroe1.jpeg)**
*  **Summary:** This thread is a brief statement agreeing to the fact that OpenAI Agents SDK is Langchain & more and both are fundamental orchestration.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * OpenAI Agents SDK is Langchain & more and both are fundamental orchestration

**[Open-source AI matches top proprietary model in solving tough medical cases (Score: 6)](https://medicalxpress.com/news/2025-03-source-ai-proprietary-tough-medical.html)**
*  **Summary:** The thread centers around a report stating that open-source AI models can perform as well as proprietary models in solving complex medical cases. A key criticism is that the comparison is between an older Llama model and GPT-4, not GPT-4o.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * The study is flawed because it compares an older Llama model to GPT-4, rather than the more current GPT-4o.

**[How can I get a Deep Research report saved to a file? (Score: 6)](https://www.reddit.com/r/OpenAI/comments/1jbk4u8/how_can_i_get_a_deep_research_report_saved_to_a/)**
*  **Summary:** Users are discussing the lack of a direct "Save as PDF" option in OpenAI's Deep Research tool. They share workaround solutions, such as copying and pasting into a document or using browser print-to-PDF options.
*  **Emotion:** The overall tone is negative due to the frustration over the missing feature.
*  **Top 3 Points of View:**
    * The lack of a "Save as PDF" option in Deep Research is frustrating.
    * Copying and pasting is a workaround, but it can lead to formatting issues.
    * Taking full-page screenshots or using browser print-to-PDF are alternative methods.

**[Training model on framework docs and github repos (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1jbzq39/training_model_on_framework_docs_and_github_repos/)**
*  **Summary:** A user describes how to train a model on framework documentation and GitHub repositories. They suggest creating a "docs" directory in the repository to store documentation files and including these files in cursor questions for up-to-date information.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * Create a "docs" directory in the repository to store documentation files.
    * Add the "docs" directory to .gitignore, if desired.
    * Include the documentation files in cursor questions for up-to-date information.

**[Confused ChatGPT (Score: 0)](https://i.redd.it/phhyjgh8otoe1.jpeg)**
*  **Summary:** The user is still using ChatGPT 3.5
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is still using ChatGPT 3.5

**[Why has ChatGPT suddenly started texting like a 13 year old? (Score: 0)](https://i.redd.it/r822iuvobwoe1.png)**
*  **Summary:** The thread discusses why ChatGPT might be adopting a more informal, "13-year-old" style of texting. Suggestions include that it mimics the user, is influenced by memory records, or may require specific instructions to change its style.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * ChatGPT mimics the user's style of communication.
    * The style is influenced by memory records and past interactions.
    * Users can instruct ChatGPT to change its style.

**[A Personal Account of AI guardrailing to ignore user safety (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1jbw85k/a_personal_account_of_ai_guardrailing_to_ignore/)**
*  **Summary:** The thread describes a user's experience with AI guardrailing ignoring their personal safety. Other users are suggesting they see a psychologist and read more about how LLMs work.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * LLMs are all about context management.
    * Gen AI shouldn't be used for anything "safety critical".
    * OP should seek professional help.

**[ðŸš¨ Major ChatGPT Flaw: Context Drift & Hallucinated Web Searches Yield Completely False Information ðŸš¨ (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1jc1gv5/major_chatgpt_flaw_context_drift_hallucinated_web/)**
*  **Summary:** The thread discusses the issue of context drift and hallucinated web searches in ChatGPT, leading to the generation of false information. Some users argue that this is a well-known flaw, while others express concern about the potential consequences.
*  **Emotion:** The overall tone is negative due to the concern regarding the flaws.
*  **Top 3 Points of View:**
    * ChatGPT's context drift and hallucinated web searches can lead to false information.
    * Using ChatGPT as an authoritative information source is not recommended due to these flaws.
    * This is a known issue that will likely be fixed in future AI models.
