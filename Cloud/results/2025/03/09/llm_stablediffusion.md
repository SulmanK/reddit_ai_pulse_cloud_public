---
title: "Stable Diffusion Subreddit"
date: "2025-03-09"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Plot twist: Jealous girlfriend - (Wan i2v + Rife)](https://v.redd.it/xgcdre1v7pne1) (Score: 147)
    *   A video showcasing a "plot twist" involving a jealous girlfriend, created using Wan i2v and Rife technologies.

2.  [New CLIP Text Encoder. And a giant mutated Vision Transformer that has +20M params and a modality gap of 0.4740 (was: 0.8276). Proper attention heatmaps. Code playground (including fine-tuning it yourself). [HuggingFace, GitHub]](https://www.reddit.com/gallery/1j7cr1y) (Score: 78)
    *   A post announcing a new CLIP Text Encoder and a mutated Vision Transformer, offering code and resources for experimentation.

3.  [With two animal images to one hug video](https://v.redd.it/4dqdivgl6pne1) (Score: 20)
    *   A video creation using animal images and AI, made on Eachlabs.

4.  [Here's how to activate animated previews on ComfyUi.](https://www.reddit.com/r/StableDiffusion/comments/1j7ay60/heres_how_to_activate_animated_previews_on_comfyui/) (Score: 12)
    *   A guide on enabling animated previews in ComfyUI, a popular interface for Stable Diffusion.

5.  [I haven't shut down my pc since 3 days even since I got wan2.1 to work locally. I queue generations on before going to sleep. Will this affect my gpu or my pc in any negative way?](https://www.reddit.com/r/StableDiffusion/comments/1j7cjem/i_havent_shut_down_my_pc_since_3_days_even_since/) (Score: 7)
    *   A user asks about the potential negative effects of continuously running their PC for AI image generation.

6.  [Nunchaku v0.1.4 (SVDQuant) ComfyUI Portable Instructions for Windows (NO WSL required)](https://www.reddit.com/r/StableDiffusion/comments/1j7dzhe/nunchaku_v014_svdquant_comfyui_portable/) (Score: 5)
    *   Instructions for using Nunchaku v0.1.4 with ComfyUI on Windows without WSL.

7.  [LTX Video 0.9.5 Testing on Comfy UI](https://www.reddit.com/r/StableDiffusion/comments/1j7bntb/ltx_video_095_testing_on_comfy_ui/) (Score: 4)
    *   A user tests LTX Video 0.9.5 on ComfyUI.

8.  [Nunchaku v0.1.4 LoRA Conversion (SVDQuant) ComfyUI Portable Instructions for Windows (convert Flux LoRA for use with this node set)](https://www.reddit.com/r/StableDiffusion/comments/1j7ed4w/nunchaku_v014_lora_conversion_svdquant_comfyui/) (Score: 4)
    *   Instructions for converting LoRAs using Nunchaku v0.1.4 with ComfyUI.

9.  [Started building a music player for my cloud this weekend and decided to try Wan for animating album covers. Worked perfectly, even with my setup (rtx260 6go) !](https://v.redd.it/txne7a3lrpne1) (Score: 3)
    *   A user shares their success using Wan to animate album covers for their music player project.

10. [Anyone gotten local MagicAnimate working under Python 3.12?](https://www.reddit.com/r/StableDiffusion/comments/1j7cyny/anyone_gotten_local_magicanimate_working_under/) (Score: 2)
    *   A user is asking for help getting local MagicAnimate to work.

11. [TATTOO REMOVAL WITH AI](https://www.reddit.com/r/StableDiffusion/comments/1j7cfox/tattoo_removal_with_ai/) (Score: 0)
    *   A discussion on using AI for tattoo removal.

# Detailed Analysis by Thread
**[Plot twist: Jealous girlfriend - (Wan i2v + Rife) (Score: 147)](https://v.redd.it/xgcdre1v7pne1)**
*  **Summary:** The post features a video created using Wan i2v and Rife, depicting a "plot twist" involving a jealous girlfriend.
*  **Emotion:** The overall emotional tone is Neutral, although individual comments range from positive ("This is crazy...well done") to negative ("That will not end well.").
*  **Top 3 Points of View:**
    *   The video is visually impressive and demonstrates the capabilities of AI in creating short stories.
    *   Some viewers are intrigued and express anticipation for future developments.
    *   Some users find the scenario depicted potentially problematic or foresee negative outcomes.

**[New CLIP Text Encoder. And a giant mutated Vision Transformer that has +20M params and a modality gap of 0.4740 (was: 0.8276). Proper attention heatmaps. Code playground (including fine-tuning it yourself). [HuggingFace, GitHub] (Score: 78)](https://www.reddit.com/gallery/1j7cr1y)**
*  **Summary:** This post announces a new CLIP Text Encoder and a mutated Vision Transformer, providing links to code and resources for those interested in experimenting with it. The aim is to improve CLIP's ability to process global information, leading to better image segmentation and retrieval.
*  **Emotion:** Predominantly Positive, expressing awe and appreciation for the work. Some comments exhibit confusion due to the technical nature of the content.
*  **Top 3 Points of View:**
    *   The development is impressive and represents significant progress in the field of AI image processing.
    *   Some users find the technical details difficult to understand and request simpler explanations.
    *   Users express gratitude for the sharing of code and resources, enabling further exploration and experimentation.

**[With two animal images to one hug video (Score: 20)](https://v.redd.it/4dqdivgl6pne1)**
*  **Summary:** The author used animal images and an AI prompt to create a "hug" video in Eachlabs.
*  **Emotion:** Neutral. The comments are factual.
*  **Top 3 Points of View:**
    *   The video was made on Eachlabs.
    *   The aspect ratio of the cat image broke.

**[Here's how to activate animated previews on ComfyUi. (Score: 12)](https://www.reddit.com/r/StableDiffusion/comments/1j7ay60/heres_how_to_activate_animated_previews_on_comfyui/)**
*  **Summary:** This post provides instructions on how to enable animated previews in ComfyUI.
*  **Emotion:** Mostly Positive, as users appreciate the helpful tip.
*  **Top 3 Points of View:**
    *   Animated previews can be enabled using ComfyUI-Manager.
    *   Alternatively, the feature can be enabled with a command-line flag `--preview-method taesd`.
    *   Users are interested in the performance and VRAM impact of this feature.

**[I haven't shut down my pc since 3 days even since I got wan2.1 to work locally. I queue generations on before going to sleep. Will this affect my gpu or my pc in any negative way? (Score: 7)](https://www.reddit.com/r/StableDiffusion/comments/1j7cjem/i_havent_shut_down_my_pc_since_3_days_even_since/)**
*  **Summary:**  A user inquires about potential negative impacts of running their PC continuously for AI image generation.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Maintaining consistent temperatures is crucial to avoid hardware wear.
    *   The increased power bill is a significant concern.
    *   Hard drive lifespan may be affected if the system relies heavily on swap space due to insufficient RAM.

**[Nunchaku v0.1.4 (SVDQuant) ComfyUI Portable Instructions for Windows (NO WSL required) (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1j7dzhe/nunchaku_v014_svdquant_comfyui_portable/)**
*  **Summary:** This post provides instructions for using Nunchaku v0.1.4 with ComfyUI on Windows without needing WSL (Windows Subsystem for Linux).
*  **Emotion:** Positive. A user expresses thanks for the help.
*  **Top 3 Points of View:**
    *   The instructions helped a user overcome a previous installation issue.

**[LTX Video 0.9.5 Testing on Comfy UI (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1j7bntb/ltx_video_095_testing_on_comfy_ui/)**
*  **Summary:** A user is testing LTX Video 0.9.5 within the ComfyUI environment.
*  **Emotion:** Positive. User finds the speed "incredible".
*  **Top 3 Points of View:**
    *   The user is seeking tips for improving the movement of people in generated videos, as they are noticing some distortions.

**[Nunchaku v0.1.4 LoRA Conversion (SVDQuant) ComfyUI Portable Instructions for Windows (convert Flux LoRA for use with this node set) (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1j7ed4w/nunchaku_v014_lora_conversion_svdquant_comfyui/)**
*  **Summary:** This post provides instructions for converting LoRAs for use with a specific node set using Nunchaku v0.1.4 and ComfyUI.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   A user is asking about Nunchaku wheels for Python 3.10.
    *   The user believes the tech is cool but its current requirements limit its usability.

**[Started building a music player for my cloud this weekend and decided to try Wan for animating album covers. Worked perfectly, even with my setup (rtx260 6go) ! (Score: 3)](https://v.redd.it/txne7a3lrpne1)**
*  **Summary:** A user shares their success using Wan to animate album covers for their cloud-based music player.
*  **Emotion:** Positive.
*  **Top 3 Points of View:**
    *   Wan works well for animating album covers.
    *   The user had to reduce the image resolution due to hardware limitations.
    *   The final result is considered great.

**[Anyone gotten local MagicAnimate working under Python 3.12? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1j7cyny/anyone_gotten_local_magicanimate_working_under/)**
*  **Summary:** The post is a question asking if anyone has successfully gotten MagicAnimate to work locally under Python 3.12.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   One user suggests using `uv` with a venv to try multiple Python versions.
    *   Another user recommends using Python 3.10 instead, as 3.12 may not be compatible with many useful libraries.

**[TATTOO REMOVAL WITH AI (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1j7cfox/tattoo_removal_with_ai/)**
*  **Summary:** This post is a discussion about how to remove tattoos from images using AI.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Use a model that gives a reasonable skin texture.
    *   Color over the tattoo in Photoshop or GIMP.
    *   Use inpaint Image2Image in A1111 or ComfyUI to remove the tattoo.
