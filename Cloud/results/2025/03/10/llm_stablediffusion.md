---
title: "Stable Diffusion Subreddit"
date: "2025-03-10"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stable diffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] Everyone was asking me to upload an example, so here it is: SFW quality difference in Wan2.1 when disabling blocks 20->39 vs. using them (first is default, second disabled, follow by preview pictures) Lora strength = 1, 800x800 49 frames pingpong](https://v.redd.it/pjqa74laiwne1) (Score: 44)
    * The post demonstrates the quality difference in Wan2.1 when disabling certain blocks, showcasing the impact on SFW image generation.
2.  [Just tried Runpod for the first time...](https://www.reddit.com/r/StableDiffusion/comments/1j858co/just_tried_runpod_for_the_first_time/) (Score: 10)
    * A user shares their experience using Runpod with specific configurations for Stable Diffusion, providing a guide for others.
3.  [Man, Wan 2.1 I2V is so good](https://v.redd.it/ts0nk80rxwne1) (Score: 3)
    *  The user expresses their satisfaction with Wan 2.1 I2V, highlighting its ability to create realistic images.
4.  [Problem installing SageAttention for ComfyUI](https://i.redd.it/cxa72rrjewne1.png) (Score: 1)
    * A user is seeking help with installing SageAttention for ComfyUI, encountering errors despite fulfilling the prerequisites.
5.  [ForgeUI: Sudden increase in move model time & Freezing PC](https://www.reddit.com/r/StableDiffusion/comments/1j84gy1/forgeui_sudden_increase_in_move_model_time/) (Score: 1)
    * A user reports a sudden increase in model loading time and PC freezing with ForgeUI, questioning the cause of this issue.
6.  [ComfyUI blurry, why?](https://www.reddit.com/r/StableDiffusion/comments/1j84uvp/comfyui_blurry_why/) (Score: 1)
    * The user is asking why their ComfyUI output looks blurry.
7.  [any methods for i2v but with little movement like hair slightly moving or dust particles slightly moving? basically a static image but with few elements moving very little? I have RTX 3050 4gb and even if it takes hours, it's ok](https://www.reddit.com/r/StableDiffusion/comments/1j85gnw/any_methods_for_i2v_but_with_little_movement_like/) (Score: 1)
    * A user is seeking methods for creating image-to-video animations with minimal movement, such as slight hair movement or dust particles, and is willing to wait for longer processing times.
8.  [IMG2VID on a Mac Studio.. Possible?](https://www.reddit.com/r/StableDiffusion/comments/1j87620/img2vid_on_a_mac_studio_possible/) (Score: 1)
    *  The user is inquiring about the possibility of running IMG2VID on a Mac Studio and another user wants to run Wan 2.1 on their m3 max 48gb.
9.  [Images Taking Significantly Longer with ADetailer / Inpaint Suggestions](https://www.reddit.com/r/StableDiffusion/comments/1j87959/images_taking_significantly_longer_with_adetailer/) (Score: 1)
    * A user is experiencing longer image generation times when using ADetailer and is seeking suggestions to improve performance or alternative inpainting methods.
10. [Need urgent help](https://www.reddit.com/gallery/1j87vcz) (Score: 1)
    * The user needs help with an issue and the denoise is at 1.0 meaning it gets creative / doesn't adhere to the input.
11. [I was doing I2V in WAN 2.1 and wondering is there image/video restoration tool based on WAN 2.1 which restoring photo/video via WAN 2.1 model?](https://www.reddit.com/gallery/1j8540o) (Score: 0)
    * The user is looking for an image/video restoration tool based on WAN 2.1
12. [Best Open-Source or Paid LLMs with the Largest Context Windows?](https://www.reddit.com/r/StableDiffusion/comments/1j85uha/best_opensource_or_paid_llms_with_the_largest/) (Score: 0)
    * The user is asking for recommendations on the best open-source or paid LLMs with the largest context windows.
13. [Why does SD say "Happy New Year 2021" when it goes crazy?](https://www.reddit.com/r/StableDiffusion/comments/1j86eqq/why_does_sd_say_happy_new_year_2021_when_it_goes/) (Score: 0)
    * The user is experiencing a strange behavior where Stable Diffusion outputs "Happy New Year 2021" when it malfunctions, and seeks an explanation for this phenomenon.

# Detailed Analysis by Thread
**[[D] Everyone was asking me to upload an example, so here it is: SFW quality difference in Wan2.1 when disabling blocks 20->39 vs. using them (first is default, second disabled, follow by preview pictures) Lora strength = 1, 800x800 49 frames pingpong](https://v.redd.it/pjqa74laiwne1) (Score: 44)**
*  **Summary:**  The post demonstrates the quality difference in Wan2.1 when disabling certain blocks during image generation, along with the prompt and negative prompt used to generate the images.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Demonstration of the impact of disabling specific blocks on image quality in Wan2.1.
    *   Sharing of the prompt, negative prompt, and Lora settings used.
    *   Suggestion that observed differences may be due to diffusion variance.

**[Just tried Runpod for the first time...](https://www.reddit.com/r/StableDiffusion/comments/1j858co/just_tried_runpod_for_the_first_time/) (Score: 10)**
*  **Summary:** A user shares their experience setting up and using Runpod for Stable Diffusion, providing detailed instructions on configuration, necessary software installations, and UI settings.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Detailed step-by-step guide on configuring Runpod.
    *   Listing of necessary software and dependencies.
    *   Sharing of optimal UI settings for performance.

**[Man, Wan 2.1 I2V is so good](https://v.redd.it/ts0nk80rxwne1) (Score: 3)**
*  **Summary:**  The user expresses their satisfaction with Wan 2.1 I2V, highlighting its ability to create realistic images and requests settings used on this one.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    *   Praise for the realism achieved with Wan 2.1 I2V.
    *   Request for sharing of settings.
    *   Agreement that the output is impressive and crosses the uncanny valley.

**[Problem installing SageAttention for ComfyUI](https://i.redd.it/cxa72rrjewne1.png) (Score: 1)**
*  **Summary:** A user is seeking help with installing SageAttention for ComfyUI, encountering errors despite fulfilling the prerequisites and receiving guidance on troubleshooting steps.
*  **Emotion:** Negative
*  **Top 3 Points of View:**
    *   User experiencing installation errors and seeking help.
    *   Suggestion to check installation instructions and run as admin.
    *   Recommendation to use CUDA 12.4 and specific pip install commands.

**[ForgeUI: Sudden increase in move model time & Freezing PC](https://www.reddit.com/r/StableDiffusion/comments/1j84gy1/forgeui_sudden_increase_in_move_model_time/) (Score: 1)**
*  **Summary:** A user reports a sudden increase in model loading time and PC freezing with ForgeUI, questioning the cause of this issue and receiving suggestions to check for recent updates or environment changes.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   User reporting performance issues with ForgeUI.
    *   Suggestion to check for recent Forge updates.
    *   Recommendation to use specific environments for stability.

**[ComfyUI blurry, why?](https://www.reddit.com/r/StableDiffusion/comments/1j84uvp/comfyui_blurry_why/) (Score: 1)**
*  **Summary:** The user is asking why their ComfyUI output looks blurry.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * One comment states that ComfyUI is the backend of SwarmUI.
    * Another comment says that one of ComfyUI's images has a much higher resolution than the other.

**[any methods for i2v but with little movement like hair slightly moving or dust particles slightly moving? basically a static image but with few elements moving very little? I have RTX 3050 4gb and even if it takes hours, it's ok](https://www.reddit.com/r/StableDiffusion/comments/1j85gnw/any_methods_for_i2v_but_with_little_movement_like/) (Score: 1)**
*  **Summary:** A user is seeking methods for creating image-to-video animations with minimal movement, such as slight hair movement or dust particles, and is willing to wait for longer processing times.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    *   Suggestion to use DaVinci Resolve for adding particles.
    *   Recommendation to explore ComfyUI Depthflow Nodes for parallax effects.
    *   Alternate suggestion to use cogvideox, new video models, or klingai.com

**[IMG2VID on a Mac Studio.. Possible?](https://www.reddit.com/r/StableDiffusion/comments/1j87620/img2vid_on_a_mac_studio_possible/) (Score: 1)**
*  **Summary:** The user is inquiring about the possibility of running IMG2VID on a Mac Studio and another user wants to run Wan 2.1 on their m3 max 48gb.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Inquiring about the possibility of running IMG2VID on a Mac Studio
    * Wondering if Wan 2.1 is possible to run on m3 max 48gb.

**[Images Taking Significantly Longer with ADetailer / Inpaint Suggestions](https://www.reddit.com/r/StableDiffusion/comments/1j87959/images_taking_significantly_longer_with_adetailer/) (Score: 1)**
*  **Summary:** A user is experiencing longer image generation times when using ADetailer and is seeking suggestions to improve performance or alternative inpainting methods.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  ADetailer steps should go the same speed as the regular generation, assuming they are working at similar resolutions.

**[Need urgent help](https://www.reddit.com/gallery/1j87vcz) (Score: 1)**
*  **Summary:** The user needs help with an issue and the denoise is at 1.0 meaning it gets creative / doesn't adhere to the input.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * your denoise is at 1.0 meaning it gets creative / doesn't adhere to the input

**[I was doing I2V in WAN 2.1 and wondering is there image/video restoration tool based on WAN 2.1 which restoring photo/video via WAN 2.1 model?](https://www.reddit.com/gallery/1j8540o) (Score: 0)**
*  **Summary:** The user is looking for an image/video restoration tool based on WAN 2.1.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * That image wasn’t restored. The AI hallucinated a different image.

**[Best Open-Source or Paid LLMs with the Largest Context Windows?](https://www.reddit.com/r/StableDiffusion/comments/1j85uha/best_opensource_or_paid_llms_with_the_largest/) (Score: 0)**
*  **Summary:** The user is asking for recommendations on the best open-source or paid LLMs with the largest context windows.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    *  Gemini Pro and Gemini Experimental have 2 million tokens context on OpenRouter. Gemini Flash 2.0 is amazingly cheap and fast.

**[Why does SD say "Happy New Year 2021" when it goes crazy?](https://www.reddit.com/r/StableDiffusion/comments/1j86eqq/why_does_sd_say_happy_new_year_2021_when_it_goes/) (Score: 0)**
*  **Summary:** The user is experiencing a strange behavior where Stable Diffusion outputs "Happy New Year 2021" when it malfunctions, and seeks an explanation for this phenomenon.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  Maybe you're reaching the maximum token size?
    *  If it's messed up after changing the prompt back then it sounds like something bugged out and broke, possibly your GPU or CPU maxed out and messed something up? Hard to say without screenshots or logs.
