---
title: "Stable Diffusion Subreddit"
date: "2025-03-18"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] The meta state of video generations right now](https://i.redd.it/5lmmyw0z6hpe1.png) (Score: 137)
    *   Discussion of the current state of video generation technology, including workflows and expectations from pioneers in the field.
2.  [Illustrious v3.5-pred is already trained and has raised 100% Stardust, but they will not open the model weights (at least not for 300,000 Stardust).](https://www.reddit.com/r/StableDiffusion/comments/1jec4dd/illustrious_v35pred_is_already_trained_and_has/) (Score: 43)
    *   Discussion about the Illustrious v3.5-pred model and the decision to not release the model weights despite reaching the funding goal, leading to criticism and concerns about potential scams.
3.  [Stable Virtual Camera: This multi-view diffusion model transforms 2D images into immersive 3D videos with realistic depth and perspective](https://v.redd.it/leu89mo7whpe1) (Score: 50)
    *   Announcement of Stable Virtual Camera, a diffusion model for creating immersive 3D videos from 2D images, and discussion of its capabilities and potential for local use.
4.  [Personalize Anything Training-Free with Diffusion Transformer](https://i.redd.it/rcdkkdulrhpe1.png) (Score: 5)
    *   Brief discussion about "Personalize Anything", a training-free method using diffusion transformers.
5.  [More burgers - cleaned up workflow from Pantheon3D with optimized layout + speed improvements](https://i.redd.it/skm2v9welhpe1.png) (Score: 2)
    *   Sharing and optimization of a burger-themed workflow in Pantheon3D, with a focus on improving productivity and speed.
6.  [Shortly, what models are okay with human anatomy, cause I ve tried lot of them and its harder than I suppouse to make a humanoid caracter ?](https://www.reddit.com/r/StableDiffusion/comments/1jedegi/shortly_what_models_are_okay_with_human_anatomy/) (Score: 2)
    *   Inquiry about suitable models for generating human anatomy and suggestions for improving humanoid character creation.
7.  [RTX 5090 with Triton and SageAttention!](https://www.reddit.com/r/StableDiffusion/comments/1jebu4f/rtx_5090_with_triton_and_sageattention/) (Score: 1)
    *   Discussion about setting up RTX 5090 with Triton and SageAttention, including specific steps and software versions.
8.  [Adding trigger words to hunyuan lora](https://www.reddit.com/r/StableDiffusion/comments/1je9hi6/adding_trigger_words_to_hunyuan_lora/) (Score: 0)
    *   Simple question and answer about adding trigger words to a Hunyuan LoRA model.
9.  [how to create images like these???](https://www.reddit.com/r/StableDiffusion/comments/1je9tpk/how_to_create_images_like_these/) (Score: 0)
    *   Question about creating images, but without any images provided for reference.
10. [Help! Teacache node not working!](https://www.reddit.com/r/StableDiffusion/comments/1jeaw7p/help_teacache_node_not_working/) (Score: 0)
    *   A post seeking help with a Teacache node issue.
11. [Has anyone used Wan2.1's text to image capabilities yet?](https://www.reddit.com/r/StableDiffusion/comments/1jebt35/has_anyone_used_wan21s_text_to_image_capabilities/) (Score: 0)
    *   Asking if anyone has used Wan2.1's text-to-image capabilities.
12. [Has anyone been able to use Hunyuan locally effectively?](https://www.reddit.com/r/StableDiffusion/comments/1jecdsf/has_anyone_been_able_to_use_hunyuan_locally/) (Score: 0)
    *   Asking about the experience of using Hunyuan locally.

# Detailed Analysis by Thread
**[[D] The meta state of video generations right now (Score: 137)](https://i.redd.it/5lmmyw0z6hpe1.png)**
*   **Summary:** A discussion regarding the current state of video generation, focusing on the meta aspects, workflows, and the disappointing performance of some pioneers, as well as personal experiences with hardware limitations.
*   **Emotion:** Predominantly Negative, driven by disappointment, disgust, and some sadness mixed with neutral observations.
*   **Top 3 Points of View:**
    *   Some users express disappointment in the lack of workflows and innovation from key players in video generation.
    *   Others highlight personal limitations like older hardware affecting their ability to participate.
    *   One user reflects on the emotional impact of the technology, imagining its use by people dealing with loss.

**[Illustrious v3.5-pred is already trained and has raised 100% Stardust, but they will not open the model weights (at least not for 300,000 Stardust). (Score: 43)](https://www.reddit.com/r/StableDiffusion/comments/1jec4dd/illustrious_v35pred_is_already_trained_and_has/)**
*   **Summary:** The thread discusses the controversy surrounding the Illustrious v3.5-pred model, where the developers are withholding the model weights despite reaching the initial funding goal. Users express suspicion, disappointment, and accusations of potential scams.
*   **Emotion:** Predominantly Negative, driven by disappointment, frustration, and distrust.
*   **Top 3 Points of View:**
    *   Some users believe the situation is a scam due to the raised money but withheld model.
    *   Others criticize the monetization strategy, suggesting alternative and more transparent methods.
    *   A minority defends the developers, citing miscommunication and the involvement of a single major donor.

**[Stable Virtual Camera: This multi-view diffusion model transforms 2D images into immersive 3D videos with realistic depth and perspective (Score: 50)](https://v.redd.it/leu89mo7whpe1)**
*   **Summary:** The thread introduces "Stable Virtual Camera", a diffusion model for generating 3D videos from 2D images. The discussion includes excitement about Stability AI's return, inquiries about local usage, and technical observations about the model's output.
*   **Emotion:** Predominantly Neutral with some Positive sentiment due to the excitement about the new technology.
*   **Top 3 Points of View:**
    *   Excitement about the release of the new Stable Virtual Camera model.
    *   Inquiry about the possibility of running the model locally.
    *   Technical discussion comparing the model's output to high-quality gaussian splats.

**[Personalize Anything Training-Free with Diffusion Transformer (Score: 5)](https://i.redd.it/rcdkkdulrhpe1.png)**
*   **Summary:** A brief discussion centered on a technology called "Personalize Anything", a training-free diffusion transformer, with one user indicating that the image provided sufficient context.
*   **Emotion:** Mostly Neutral with a hint of Positive sentiment.
*   **Top 3 Points of View:**
    *   Link provided to the project page.
    *   One user indicated image was sufficient context.
    *   General inquiry about what the technology is.

**[More burgers - cleaned up workflow from Pantheon3D with optimized layout + speed improvements (Score: 2)](https://i.redd.it/skm2v9welhpe1.png)**
*   **Summary:** Sharing and optimizing a burger-themed workflow in Pantheon3D, with a focus on improving productivity and speed. Gratitude expressed to the original creator.
*   **Emotion:** Predominantly Positive, expressing relaxation and enjoyment in optimizing workflows.
*   **Top 3 Points of View:**
    *   Gratitude for the shared workflow.
    *   Enjoyment in the optimization process.
    *   Link to the original workflow provided.

**[Shortly, what models are okay with human anatomy, cause I ve tried lot of them and its harder than I suppouse to make a humanoid caracter ? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jedegi/shortly_what_models_are_okay_with_human_anatomy/)**
*   **Summary:** Inquiry about suitable models for generating human anatomy, along with troubleshooting advice and specific model recommendations.
*   **Emotion:** Mostly Neutral, primarily seeking information and offering advice.
*   **Top 3 Points of View:**
    *   Question about which models are good for human anatomy.
    *   Suggestion to adjust settings for better results.
    *   Recommendation to use the "Flux" model.

**[RTX 5090 with Triton and SageAttention! (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jebu4f/rtx_5090_with_triton_and_sageattention/)**
*   **Summary:** A discussion focusing on the setup of RTX 5090 with Triton and SageAttention, including detailed steps for installing necessary components and resolving potential errors.
*   **Emotion:** Mostly Neutral, focusing on technical instructions and problem-solving.
*   **Top 3 Points of View:**
    *   Sharing setup instructions for RTX 5090 with Triton and SageAttention.
    *   Emphasis on reading error messages for troubleshooting.
    *   Reference to a specific ComfyUI build for compatibility.

**[Adding trigger words to hunyuan lora (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1je9hi6/adding_trigger_words_to_hunyuan_lora/)**
*   **Summary:** Simple question and answer regarding the process of adding trigger words to a Hunyuan LoRA model.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Instruction to add trigger words to the captions text file.
    *   Explanation of what a trigger word is.

**[how to create images like these??? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1je9tpk/how_to_create_images_like_these/)**
*   **Summary:** A question asking for guidance on how to create specific images, but lacking any reference images.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Request for guidance.
    *   Response noting the absence of reference images.

**[Help! Teacache node not working! (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jeaw7p/help_teacache_node_not_working/)**
*   **Summary:** A post seeking assistance with a malfunctioning Teacache node.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Help request for node not working

**[Has anyone used Wan2.1's text to image capabilities yet? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jebt35/has_anyone_used_wan21s_text_to_image_capabilities/)**
*   **Summary:** A question asking if anyone has experience with Wan2.1's text-to-image feature.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Looking for any response.

**[Has anyone been able to use Hunyuan locally effectively? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jecdsf/has_anyone_been_able_to_use_hunyuan_locally/)**
*   **Summary:** Question about the effectiveness of using Hunyuan locally, with responses detailing performance and hardware requirements.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Initial question regarding local Hunyuan usage.
    *   Comment on potential slowness.
    *   Experience of using HunVid Q8 model, and the usage of ComfyUI-MultiGPU.
