---
title: "Stable Diffusion Subreddit"
date: "2025-03-13"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions

1.  [[D] Google released native image generation in Gemini 2.0 Flash](https://www.reddit.com/gallery/1jaia40) (Score: 203)
    *   Users are discussing Google's new image generation in Gemini 2.0 Flash, its adherence to the subreddit's open-source rules, and testing its capabilities.
2.  [A.I. Wonderland is the first-ever immersive AI film where YOU can appear on the big screen!](https://v.redd.it/zuzpz6oeshoe1) (Score: 32)
    *   Users are impressed with the quality and theme of the first-ever immersive AI film.
3.  [Flux Dev Character LoRA -> Google Flash Gemini = One-shot Consistent Character](https://v.redd.it/kbrp6py2phoe1) (Score: 23)
    *   Users are discussing the performance and efficiency of using Flux Dev Character LoRA with Google Flash Gemini for consistent character generation, including speed and image quality considerations.
4.  [So you generate a video but 16fps (Wan) looks kinda stuttery and setting to 24fps throws the speed off. Ok, just use simple RIFE workflow to interpolate/double the fps (generates in between frames - no duplicates) then can save to 24fps and it'll be 24 unique frames w proper speed.](https://github.com/Fannovel16/ComfyUI-Frame-Interpolation) (Score: 10)
    *   Users are discussing a workflow for interpolating frames in generated videos to improve the frame rate and smoothness, along with alternative tools for better quality.
5.  [Wan2.1 14B Q5 GGUF - Upscaled Ouput](https://v.redd.it/npw3ljrjmhoe1) (Score: 10)
    *   Users are sharing their experiences with using Wan2.1 14B Q5 GGUF for upscaling images, including performance on different hardware and comparisons with other tools.
6.  [Detailed anime style images now possible also for SDXL](https://www.reddit.com/gallery/1jaf3dh) (Score: 7)
    *   Users are discussing a new LoRA for generating detailed anime-style images with SDXL, addressing the challenges of replicating the style and sharing results.
7.  [Increase Speed with Sage Attention v1 with Pytorch 2.7 (fast fp16) - Windows 11](https://www.reddit.com/r/StableDiffusion/comments/1jahks4/increase_speed_with_sage_attention_v1_with/) (Score: 6)
    *   Users are sharing and asking question about increasing speed with Sage Attention v1 with Pytorch 2.7 on Windows 11
8.  [Is Flux-Dev still the best for generating photorealistic images/realistic loras?](https://www.reddit.com/r/StableDiffusion/comments/1jahyvg/is_fluxdev_still_the_best_for_generating/) (Score: 5)
    *   Users are debating whether Flux-Dev remains the top choice for photorealistic image generation and realistic LoRAs, comparing it to other models like Pony Diffusion and discussing its strengths and weaknesses.
9.  [Anime with Wan I2V: comparison of prompt formats and negatives (longer, long, short; 3D, default, simple)](https://v.redd.it/hbmtb2b0jioe1) (Score: 1)
    *   The post details experiments with anime motion using Wan I2V, comparing different prompt formats and negatives.
10. [When creating "paintings" with stable diffusion, the brush strokes look random. Any way to solve this problem ? Another problem is that the art looks dry or scratched.](https://www.reddit.com/r/StableDiffusion/comments/1jaeiyp/when_creating_paintings_with_stable_diffusion_the/) (Score: 1)
    *   The post contains a question about how to solve the random brush strokes problem when creating paintings with stable diffusion.
11. [How to prompt 2 girls with reforge?](https://www.reddit.com/r/StableDiffusion/comments/1jaivy8/how_to_prompt_2_girls_with_reforge/) (Score: 1)
    *   The post contains a question about how to prompt 2 girls with reforge.
12. [Question for Newbie - Getting started with AI video/imagery](https://www.reddit.com/r/StableDiffusion/comments/1jak94i/question_for_newbie_getting_started_with_ai/) (Score: 1)
    *   The post contains a question about how to get started with AI video/imagery.
13. [How to deal with this??](https://www.reddit.com/r/StableDiffusion/comments/1jakkub/how_to_deal_with_this/) (Score: 1)
    *   The post contains a question about how to deal with the error.
14. [Flux is unable to generate scat, even in completely SFW contexts](https://www.reddit.com/r/StableDiffusion/comments/1jae9ir/flux_is_unable_to_generate_scat_even_in/) (Score: 0)
    *   The post discusses Flux's inability to generate scat, even in completely SFW contexts.
15. [Character Training SDXL - Tags/Captions: All the things vs some of said things? What is optimal?](https://www.reddit.com/r/StableDiffusion/comments/1jaebat/character_training_sdxl_tagscaptions_all_the/) (Score: 0)
    *   The post contains a question about Character Training SDXL - Tags/Captions: All the things vs some of said things? What is optimal?
16. [Dezgo and the Lora](https://www.reddit.com/r/StableDiffusion/comments/1jaelqk/dezgo_and_the_lora/) (Score: 0)
    *   The post contains a question about Dezgo and the Lora.
17. [Can I run Flux-dev on my laptop?](https://www.reddit.com/r/StableDiffusion/comments/1jagyki/can_i_run_fluxdev_on_my_laptop/) (Score: 0)
    *   The post contains a question about whether it's possible to run Flux-dev on a laptop.

# Detailed Analysis by Thread

**[ [D] Google released native image generation in Gemini 2.0 Flash (Score: 203)](https://www.reddit.com/gallery/1jaia40)**
*  **Summary:** Users are discussing Google's new native image generation in Gemini 2.0 Flash, with some focusing on its open-source status and whether it violates the subreddit's rules. Others are sharing examples and testing its capabilities, while some are joking about image content.
*  **Emotion:** The overall emotional tone is Neutral, with a mix of neutral observations, technical questions, and lighthearted comments. Some negative sentiment is present due to concerns about the tool's compliance with open-source rules.
*  **Top 3 Points of View:**
    *   The tool may violate the subreddit's rule about open-source AI.
    *   Users are sharing and testing image generation examples.
    *   The tool's image generation is being compared to other AI models.

**[A.I. Wonderland is the first-ever immersive AI film where YOU can appear on the big screen! (Score: 32)](https://v.redd.it/zuzpz6oeshoe1)**
*  **Summary:** Users are reacting positively to an immersive AI film called "A.I. Wonderland," praising its quality and the innovative concept of allowing viewers to appear on the big screen.
*  **Emotion:** The emotional tone is overwhelmingly Positive, with users expressing excitement and appreciation for the film's quality and concept.
*  **Top 3 Points of View:**
    *   The quality of the AI film is impressive.
    *   The theme is well-suited to the immersive experience.
    *   The concept of allowing viewers to appear in the film is exciting.

**[Flux Dev Character LoRA -> Google Flash Gemini = One-shot Consistent Character (Score: 23)](https://v.redd.it/kbrp6py2phoe1)**
*  **Summary:** The thread discusses using a Flux Dev Character LoRA in conjunction with Google Flash Gemini to achieve consistent character generation in AI images. Users are sharing links to the LoRA and a platform for testing, while also discussing the performance and limitations of the setup.
*  **Emotion:** The overall emotional tone is Neutral, with a mix of excitement about the potential of the combination and concerns about its performance and speed.
*  **Top 3 Points of View:**
    *   The combination offers potential for consistent character generation.
    *   There are concerns about the speed of image generation.
    *   Gemini may degrade image quality with each new image.

**[So you generate a video but 16fps (Wan) looks kinda stuttery and setting to 24fps throws the speed off. Ok, just use simple RIFE workflow to interpolate/double the fps (generates in between frames - no duplicates) then can save to 24fps and it'll be 24 unique frames w proper speed. (Score: 10)](https://github.com/Fannovel16/ComfyUI-Frame-Interpolation)**
*  **Summary:** The post discusses a workflow for interpolating frames in generated videos to increase the frame rate and improve smoothness. Users are also recommending alternative tools for better quality interpolation.
*  **Emotion:** The overall emotional tone is Positive, with users sharing helpful tips and expressing gratitude for the information.
*  **Top 3 Points of View:**
    *   RIFE workflow can be used to double the fps of the video.
    *   GIMM VFI has better quality than RIFE.
    *   Thanks for sharing the info.

**[Wan2.1 14B Q5 GGUF - Upscaled Ouput (Score: 10)](https://v.redd.it/npw3ljrjmhoe1)**
*  **Summary:** Users are discussing their experiences with using Wan2.1 14B Q5 GGUF for upscaling AI-generated images, particularly focusing on the performance on different hardware configurations (like a 4070ti) and comparing different quantization levels (Q4 vs Q5).
*  **Emotion:** The emotional tone is Positive, with users happy with the results.
*  **Top 3 Points of View:**
    *   Wan2.1 14B Q5 GGUF is useful for upscaling.
    *   Performance varies depending on the hardware (e.g., 4070ti).
    *   Quantization levels (Q4 vs Q5) make a slight difference in quality.

**[Detailed anime style images now possible also for SDXL (Score: 7)](https://www.reddit.com/gallery/1jaf3dh)**
*  **Summary:** The post announces the possibility of generating detailed anime-style images using SDXL with a new LoRA. Users are sharing positive feedback, expressing gratitude, and questioning the connection of the shared images to anime style.
*  **Emotion:** The overall emotional tone is Positive.
*  **Top 3 Points of View:**
    *   The new LoRA enables detailed anime-style images with SDXL.
    *   VRAM is too slow to create detailed, high contrast, sharp anime style with Flux.
    *   What do any of these images have to do with anime?

**[Increase Speed with Sage Attention v1 with Pytorch 2.7 (fast fp16) - Windows 11 (Score: 6)](https://www.reddit.com/r/StableDiffusion/comments/1jahks4/increase_speed_with_sage_attention_v1_with/)**
*  **Summary:** The post is about increasing the speed of Sage Attention v1 with Pytorch 2.7 on Windows 11.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Is python 3.12 (or 3.13) faster than python 3.10 for stable diffusion and flux ?
    *   Will you make an auto installer again later for portable?

**[Is Flux-Dev still the best for generating photorealistic images/realistic loras? (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1jahyvg/is_fluxdev_still_the_best_for_generating/)**
*  **Summary:** The thread questions whether Flux-Dev remains the best option for generating photorealistic images and realistic LoRAs. Users are comparing it to other models, particularly Pony Diffusion, and discussing its strengths and weaknesses in different contexts (SFW vs. NSFW).
*  **Emotion:** The overall emotional tone is Neutral, with a mix of agreement and disagreement regarding Flux-Dev's status as the best model.
*  **Top 3 Points of View:**
    *   Flux-Dev is still the best, especially with retro/analog LoRAs, for SFW.
    *   Pony Diffusion is better for NSFW content.
    *   Models like CogView 4 or Lumina 2 could potentially surpass Flux-Dev with further development.

**[Anime with Wan I2V: comparison of prompt formats and negatives (longer, long, short; 3D, default, simple) (Score: 1)](https://v.redd.it/hbmtb2b0jioe1)**
*  **Summary:** Tests were done on Kijai's Wan I2V workflow - 720p, 49 frames (11 blocks swapped), 30 steps; SageAttention, TorchCompile, TeaCache (0.090), Enhance-a-Video at 0 because I don't know if.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   What makes a good 2D anime video is not the same as what makes a good photoreal or 3D video, so the default recommended prompt which pulls towards cleaner motion, perhaps unsurprisingly, works against what we want for anime. Static images, duplicated frames, distortions are normal for anime, but not real-life or 3D content.
    *   Describing things that exist and should keep existing helps "ground" them in the video. New things have to be sufficiently described for them to be likely to appear.
    *   The model really, really likes "thinking" in 3D. But describing the style and throwing anime keywords into the positive seems to help. Mentioning commonly used 3D software in the negatives seems to help. This all is still not 100% effective, but it's more effective than pure luck from my tests. And asking for smoothness and all that will have the opposite effect.

**[When creating "paintings" with stable diffusion, the brush strokes look random. Any way to solve this problem ? Another problem is that the art looks dry or scratched. (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jaeiyp/when_creating_paintings_with_stable_diffusion_the/)**
*  **Summary:** The post contains a question about how to solve the random brush strokes problem when creating paintings with stable diffusion.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Make sure you notice what checkpoint model they're using and make sure you match it you can start with that.

**[How to prompt 2 girls with reforge? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jaivy8/how_to_prompt_2_girls_with_reforge/)**
*  **Summary:** The post contains a question about how to prompt 2 girls with reforge.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The typical concept bleed with AI models, you'll have to use inpaint or regional prompting of some sort to get two distinct embeddings or loras to function without blending.
    *   There was a post about 4 character generation, that also included 2 characters.

**[Question for Newbie - Getting started with AI video/imagery (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jak94i/question_for_newbie_getting_started_with_ai/)**
*  **Summary:** The post contains a question about how to get started with AI video/imagery.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Are you looking to generate locally on your own hardware or do it through an online service?

**[How to deal with this?? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jakkub/how_to_deal_with_this/)**
*  **Summary:** The post contains a question about how to deal with the error.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Since you didn't mention it on your post, did you try the "update all" option of the Manager in ComfyUI?
    *   But I think Code Crafters Corner posted a good video on YouTube about a month ago going over the PuLID install process
    *   I don't remember this guy's workflow giving much problem.

**[Flux is unable to generate scat, even in completely SFW contexts (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jae9ir/flux_is_unable_to_generate_scat_even_in/)**
*  **Summary:** The post discusses Flux's inability to generate scat, even in completely SFW contexts.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Flux is heavily sanitized through guidance distillation. The effect correlates with the embedded guidance scale. The downside is that generation artifacts increase.
    *   Just make a LoRA.
    *   WHAT'S WRONG WITH YOU?

**[Character Training SDXL - Tags/Captions: All the things vs some of said things? What is optimal? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jaebat/character_training_sdxl_tagscaptions_all_the/)**
*  **Summary:** The post contains a question about Character Training SDXL - Tags/Captions: All the things vs some of said things? What is optimal?
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Tiling and cropping can reduce noise in a dataset. Masked training can also help with this problem.
    *   if its in there, you always want to tag it.

**[Dezgo and the Lora (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jaelqk/dezgo_and_the_lora/)**
*  **Summary:** The post contains a question about Dezgo and the Lora.
*  **Emotion:** The overall emotional tone is Negative.
*  **Top 3 Points of View:**
    *   Loras only work best with the base model they were trained on. The different types of lora are meant to improve their compatibility with other lora.

**[Can I run Flux-dev on my laptop? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jagyki/can_i_run_fluxdev_on_my_laptop/)**
*  **Summary:** The post contains a question about whether it's possible to run Flux-dev on a laptop.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   It takes more than 4 minutes to generate an image on dev&t5 gguf models. If you change the model or Lora, your RAM will crash. It's better to use Google Colab.
    *   It's better to use a pay per image service or rent a GPU in the cloud.
    *   How much is shared RAM?
