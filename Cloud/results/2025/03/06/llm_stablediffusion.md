---
title: "Stable Diffusion Subreddit"
date: "2025-03-06"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Juggernaut FLUX Pro vs. FLUX Dev – Free Comparison Tool and Blog Post Live Now!](https://v.redd.it/8qziozrjc4ne1) (Score: 53)
    *   This thread discusses the release of Juggernaut FLUX, an upgraded image generation model, and a comparison tool.
2.  [Fantastic resolution with Flux and Hunyuan I2V upscaled in ComfyUI](https://v.redd.it/b750kemrd4ne1) (Score: 13)
    *   This thread is about achieving fantastic resolution with Flux and Hunyuan I2V.
3.  [How to Caption Static Images for Wan/Hunyuan Video Training?](https://www.reddit.com/r/StableDiffusion/comments/1j535cu/how_to_caption_static_images_for_wanhunyuan_video/) (Score: 2)
    *   This thread discusses methods for captioning static images for video training.
4.  [I want to make a LoRA of my pet cat, what model should I use?](https://www.reddit.com/r/StableDiffusion/comments/1j53dmh/i_want_to_make_a_lora_of_my_pet_cat_what_model/) (Score: 2)
    *   This thread is about choosing the right model for creating a LoRA of a pet cat.
5.  [My HONEST review of Hunyuan I2V](https://www.reddit.com/r/StableDiffusion/comments/1j53e2i/my_honest_review_of_hunyuan_i2v/) (Score: 2)
    *   This thread contains an honest review of Hunyuan I2V.
6.  [Another 'What card to get' post](https://www.reddit.com/r/StableDiffusion/comments/1j548fd/another_what_card_to_get_post/) (Score: 2)
    *   This thread discusses which graphics card to buy for stable diffusion.
7.  [WAN i2v vs t2v vs fp8](https://www.reddit.com/r/StableDiffusion/comments/1j52t4y/wan_i2v_vs_t2v_vs_fp8/) (Score: 1)
    *   This thread explains the difference between WAN i2v, t2v and fp8.
8.  [WAN 2.1 480P 14B 6Q GGUF....extraordinary videos within 8 minutes|| Teacache and Sageattention lossless video output || 8GB VRAM](https://www.reddit.com/r/StableDiffusion/comments/1j53fee/wan_21_480p_14b_6q_ggufextraordinary_videos/) (Score: 1)
    *   This thread discusses WAN 2.1 and its features for video output.
9.  [Which tts ai model is good, I used pinokio f5 tts, but the result is](https://www.reddit.com/r/StableDiffusion/comments/1j53mz6/which_tts_ai_model_is_good_i_used_pinokio_f5_tts/) (Score: 1)
    *   This thread discusses which TTS AI model is good.
10. [Is there a way to speed up the VAE step on a AMD GPU?](https://www.reddit.com/r/StableDiffusion/comments/1j53p5p/is_there_a_way_to_speed_up_the_vae_step_on_a_amd/) (Score: 1)
    *   This thread discusses how to speed up the VAE step on an AMD GPU.
11. [Can stable diffusion only create 3D images ?](https://i.redd.it/05uwmstke4ne1.jpeg) (Score: 0)
    *   This thread discusses if stable diffusion can only create 3D images.
12. [SD 3.5 Medium vs stock Flux / Flux loras / a Flux finetune on "generating a lady who is both conventionally attractive and middle-aged at the same time"](https://www.reddit.com/gallery/1j53v6x) (Score: 0)
    *   This thread is about comparing SD 3.5 Medium with stock Flux.
13. [Are any models besides SD 1.5 actually uncensored?](https://www.reddit.com/r/StableDiffusion/comments/1j544xd/are_any_models_besides_sd_15_actually_uncensored/) (Score: 0)
    *   This thread discusses uncensored stable diffusion models.
14. [Wan i2v vs Hunyuan i2v? Why?](https://www.reddit.com/r/StableDiffusion/comments/1j54s84/wan_i2v_vs_hunyuan_i2v_why/) (Score: 0)
    *   This thread discusses the differences between Wan i2v and Hunyuan i2v.
15. [How Chinese developers is leading in AI generated videos if they don't have access to powerfull GPU's?](https://www.reddit.com/r/StableDiffusion/comments/1j55ivk/how_chinese_developers_is_leading_in_ai_generated/) (Score: 0)
    *   This thread discusses how Chinese developers are leading in AI-generated videos.

# Detailed Analysis by Thread
**[Juggernaut FLUX Pro vs. FLUX Dev – Free Comparison Tool and Blog Post Live Now! (Score: 53)](https://v.redd.it/8qziozrjc4ne1)**
*  **Summary:** RunDiffusion released Juggernaut FLUX, an upgraded FLUX model series with sharper details, better realism, and fewer artifacts. A comparison tool is available to see the difference.
*  **Emotion:** The overall emotional tone is neutral, with some positive sentiments about the quality of the model and some negative sentiments as some users found it underwhelming.
*  **Top 3 Points of View:**
    *   Juggernaut FLUX Pro offers improved image quality compared to FLUX Dev.
    *   The performance of Juggernaut FLUX Pro is comparable to the official FLUX Pro 1.1 but at a lower cost.
    *   Some users find the improvement underwhelming compared to using Flux with realism LoRAs.

**[Fantastic resolution with Flux and Hunyuan I2V upscaled in ComfyUI (Score: 13)](https://v.redd.it/b750kemrd4ne1)**
*  **Summary:** A user showcases achieving high-resolution results using Flux and Hunyuan I2V, upscaled in ComfyUI, and other users are asking for workflow details.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Users are interested in replicating the demonstrated workflow.
    *   The combination of Flux and Hunyuan I2V can produce high-resolution images.
    *   ComfyUI is used for upscaling.

**[How to Caption Static Images for Wan/Hunyuan Video Training? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1j535cu/how_to_caption_static_images_for_wanhunyuan_video/)**
*  **Summary:** The thread discusses methods for captioning static images for Wan/Hunyuan video training, with users suggesting tools like Florence 2, Janus, and jay captioning.
*  **Emotion:** The overall emotional tone is positive as the comments are providing helpful tips.
*  **Top 3 Points of View:**
    *   Florence 2 and Janus from Deepseek can be used for captioning.
    *   The latest version of jay captioning is better than Florence or Janus.
    *   The goal is to effectively caption images for video training.

**[I want to make a LoRA of my pet cat, what model should I use? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1j53dmh/i_want_to_make_a_lora_of_my_pet_cat_what_model/)**
*  **Summary:** The thread discusses which model to use for creating a LoRA of a pet cat, with one user recommending Flux Dev.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Flux Dev is a good model for training a LoRA of a cat.
    *   The user has not tried creating an anthropomorphic version.
    *   The main goal is to create a LoRA of a pet cat.

**[My HONEST review of Hunyuan I2V (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1j53e2i/my_honest_review_of_hunyuan_i2v/)**
*  **Summary:** The thread contains an honest review of Hunyuan I2V, where users suggest interpolating to 32fps after rendering for better results.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Interpolating to 32fps can improve the look of WAN's 16fps output.
    *   Interpolated frames are less problematic than messed-up faces.
    *   Hunyuan I2V is being reviewed for its performance.

**[Another 'What card to get' post (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1j548fd/another_what_card_to_get_post/)**
*  **Summary:** The thread discusses which graphics card to buy for stable diffusion, with suggestions for 4060 Ti 16GB and recommendations for 64GB RAM.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 3 Points of View:**
    *   4060 Ti 16GB is sufficient for existing image and video models.
    *   64GB RAM is recommended for those cards.
    *   Users are interested in reviews/benchmarks of the "A" series cards.

**[WAN i2v vs t2v vs fp8 (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1j52t4y/wan_i2v_vs_t2v_vs_fp8/)**
*  **Summary:** The thread explains the difference between WAN i2v, t2v and fp8. i2v is image to video, t2v is text to video.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   i2v is short for Image to Video, and t2v is short for Text to Video.
    *   With i2v you feed it an image as a starting point, with t2v you have to write a prompt yourself.
    *   fp16 is better, but it takes up more memory.

**[WAN 2.1 480P 14B 6Q GGUF....extraordinary videos within 8 minutes|| Teacache and Sageattention lossless video output || 8GB VRAM (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1j53fee/wan_21_480p_14b_6q_ggufextraordinary_videos/)**
*  **Summary:** The thread discusses WAN 2.1 and its features for video output. One user is asking for teacache values.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   WAN 2.1 can create extraordinary videos within 8 minutes.
    *   It supports Teacache and Sageattention for lossless video output.
    *   It requires 8GB VRAM.

**[Which tts ai model is good, I used pinokio f5 tts, but the result is (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1j53mz6/which_tts_ai_model_is_good_i_used_pinokio_f5_tts/)**
*  **Summary:** The thread discusses which TTS AI model is good, with users recommending XTTS v2.0.2, kokoro, and styleTTS.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Pinokio f5 tts results are hit or miss.
    *   XTTS v2.0.2 provides some of the best intonation and emotion.
    *   More recent models that give good results are kokoro and styleTTS.

**[Is there a way to speed up the VAE step on a AMD GPU? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1j53p5p/is_there_a_way_to_speed_up_the_vae_step_on_a_amd/)**
*  **Summary:** The thread discusses how to speed up the VAE step on an AMD GPU, suggesting solutions like VAE tiling, different VAE models, and custom ROCm builds.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   There is a bottleneck with AMD GPUs when running VAE operations in video generation pipelines.
    *   VAE tiling can help speed up the VAE step.
    *   Custom ROCm builds with optimizations can also help.

**[Can stable diffusion only create 3D images ? (Score: 0)](https://i.redd.it/05uwmstke4ne1.jpeg)**
*  **Summary:** The thread discusses if stable diffusion can only create 3D images.
*  **Emotion:** The emotional tone is mixed with positive, negative and neutral emotions.
*  **Top 3 Points of View:**
    *   Stable Diffusion can also create 2D Images.
    *   Trellis and Hunyuan 3D is along the lines of what you're looking for.
    *   Some users are sarcastically saying Stable Diffusion can only create 3D images.

**[SD 3.5 Medium vs stock Flux / Flux loras / a Flux finetune on "generating a lady who is both conventionally attractive and middle-aged at the same time" (Score: 0)](https://www.reddit.com/gallery/1j53v6x)**
*  **Summary:** The thread is about comparing SD 3.5 Medium with stock Flux when generating images of conventionally attractive, middle-aged women.
*  **Emotion:** The emotional tone is negative.
*  **Top 3 Points of View:**
    *   The models don't really understand the concept of middle-aged.
    *   The checkpoints understand *****, just sayin.
    *   Users are asking why SD 3.5 Medium is used when there is 3.5 Large.

**[Are any models besides SD 1.5 actually uncensored? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1j544xd/are_any_models_besides_sd_15_actually_uncensored/)**
*  **Summary:** The thread discusses uncensored stable diffusion models.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   There are more uncensored SDXL models in Civit.ai.
    *   Flux just needs a little help from a Lora to give you boobies.
    *   Some people are sarcastic.

**[Wan i2v vs Hunyuan i2v? Why? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1j54s84/wan_i2v_vs_hunyuan_i2v_why/)**
*  **Summary:** The thread discusses the differences between Wan i2v and Hunyuan i2v.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Hunyuan is like an inbetween of ltxv and wan2.1
    *   Hunyuan changes the first frame.
    *   Users are comparing the two models.

**[How Chinese developers is leading in AI generated videos if they don't have access to powerfull GPU's? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1j55ivk/how_chinese_developers_is_leading_in_ai_generated/)**
*  **Summary:** The thread discusses how Chinese developers are leading in AI-generated videos despite GPU limitations.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   They can rent server time like everyone else or buy them in India or wherever.
    *   Innovation and optimization.
    *   They do have access to powerful gpus.
