---
title: "Stable Diffusion Subreddit"
date: "2025-03-22"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stable diffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[Project] ByteDance releases InfinateYou](https://i.redd.it/4rq1h0ijr9qe1.png) (Score: 60)
    * This thread discusses the release of ByteDance's InfinateYou project, with links to the project page, paper, code, model, and demo.
2.  [Wan 2.1 I2V (All generated with H100)](https://v.redd.it/qb8pw8cubaqe1) (Score: 46)
    * This thread showcases video generated with Wan 2.1 I2V using H100 hardware, with users discussing the resolution and realism of the generated content.
3.  [Extra long Hunyuan Image to Video with RIFLEx](https://v.redd.it/5c37uj02paqe1) (Score: 5)
    * Users discuss using Hunyuan Image to Video with RIFLEx to create longer videos, with details and workflow provided.
4.  [How do I stop this llama python thing from downloading every time I launch Comfy? Makes restarts very lengthy.](https://i.redd.it/y84y9pz1faqe1.jpeg) (Score: 4)
    * Users are trying to solve issue of llama python constantly downloading in ComfyUI and looking for advice.
5.  [Various experiments with Flux/Redux/Florence2 and Lora training - first quarter 2025.](https://www.reddit.com/gallery/1jhbmze) (Score: 4)
    * User shows experiments with different tools (Flux/Redux/Florence2) and Lora training.
6.  [run video model with multi gpu ?](https://www.reddit.com/r/StableDiffusion/comments/1jhezrt/run_video_model_with_multi_gpu/) (Score: 1)
    * User asks whether it is possible to run video model with multi gpu and receives information regarding the topic.
7.  [Has anyone successfully been able to run Joy Caption Alpha Two locally? When I try to load the model before captioning, the whole app just keeps loading forever and eventually freezes.](https://www.reddit.com/r/StableDiffusion/comments/1jhg3wo/has_anyone_successfully_been_able_to_run_joy/) (Score: 1)
    * User has issues running Joy Caption Alpha Two locally and asks for help.
8.  [Using Pony/SDXL checkpoints and loras with Hunyuan and Wan?](https://www.reddit.com/r/StableDiffusion/comments/1jhgjc7/using_ponysdxl_checkpoints_and_loras_with_hunyuan/) (Score: 1)
    * The post is about using Pony/SDXL checkpoints and loras with Hunyuan and Wan and whether this is possible.
9.  [how to install custom lora on wan2.1?](https://www.reddit.com/r/StableDiffusion/comments/1jhh06d/how_to_install_custom_lora_on_wan21/) (Score: 1)
    * The post is about installing custom lora on wan2.1.
10. [Can someone generate a picture of a man from the sketch on the right?](https://i.redd.it/fbtfwholp9qe1.jpeg) (Score: 0)
    * User asked to generate a picture of a man from the sketch.
11. [How to make this image i need prompt please](https://i.redd.it/ikjujf7iv9qe1.jpeg) (Score: 0)
    * User asks about prompt to make the image.
12. [Newbie doing this i need help (repost cuz i misflaired it before lol)](https://i.redd.it/zfzljsst3aqe1.png) (Score: 0)
    * New user needs help with something and asks for tips.
13. [Why is Open-source so far behind Gemini's image generation?](https://www.reddit.com/r/StableDiffusion/comments/1jhd0vw/why_is_opensource_so_far_behind_geminis_image/) (Score: 0)
    * The post discusses why Open-source is so far behind Gemini's image generation.
14. [Recommend me a new service provider (rant)](https://www.reddit.com/r/StableDiffusion/comments/1jhe1bs/recommend_me_a_new_service_provider_rant/) (Score: 0)
    * The post discusses recommendations for a new service provider.

# Detailed Analysis by Thread
**[[Project] ByteDance releases InfinateYou (Score: 60)](https://i.redd.it/4rq1h0ijr9qe1.png)**
*   **Summary:** ByteDance has released InfinateYou, a new project with associated resources including project page, paper, code, model, and demo. Users are discussing its performance and potential uses.
*   **Emotion:** The emotional tone is predominantly Neutral, with comments focusing on the technical aspects and performance of the software. Some negative emotions were expressed because the image doesn't look similar enough in one user's opinion.
*   **Top 3 Points of View:**
    *   The project includes a ComfyUI workflow.
    *   Links to the project page, paper, code, model, and demo are helpful for exploration.
    *   The software is reported to be slow, with one user experiencing 120 seconds per image.

**[Wan 2.1 I2V (All generated with H100) (Score: 46)](https://v.redd.it/qb8pw8cubaqe1)**
*   **Summary:** The thread showcases video generated with Wan 2.1 I2V using H100 hardware. People are impressed by the resolution and realism of the generated content, with some users seeking information on the workflow and prompts used.
*   **Emotion:** The overall emotional tone is Positive, with many expressing excitement and awe at the quality of the video.
*   **Top 3 Points of View:**
    *   The resolution is amazing.
    *   The videos are convincing and hard to distinguish from real footage.
    *   Users are interested in the prompt used to generate a specific scene.

**[Extra long Hunyuan Image to Video with RIFLEx (Score: 5)](https://v.redd.it/5c37uj02paqe1)**
*   **Summary:** The thread discusses using Hunyuan Image to Video with RIFLEx to create longer videos (up to 9 seconds). The user shares their workflow details and asks if anyone has tried RIFLEx with Wan.
*   **Emotion:** The emotional tone is Neutral and somewhat informative, with a focus on sharing technical details and seeking comparisons.
*   **Top 3 Points of View:**
    *   RIFLEx helps to create longer videos with Hunyuan Image to Video while maintaining quality.
    *   Workflow details and resources are shared for others to try.
    *   There's a curiosity regarding the comparison of RIFLEx with Wan.

**[How do I stop this llama python thing from downloading every time I launch Comfy? Makes restarts very lengthy. (Score: 4)](https://i.redd.it/y84y9pz1faqe1.jpeg)**
*   **Summary:** A user is experiencing lengthy restarts in ComfyUI due to the llama python dependency downloading every time, and is seeking solutions.
*   **Emotion:** Neutral, with a slight hint of frustration.
*   **Top 3 Points of View:**
    *   Using a venv might resolve the issue.
    *   The problem might be due to an unsuccessful installation.
    *   Custom node dependencies could be the cause.

**[Various experiments with Flux/Redux/Florence2 and Lora training - first quarter 2025. (Score: 4)](https://www.reddit.com/gallery/1jhbmze)**
*   **Summary:** The user shares results of various experiments with Flux/Redux/Florence2 and Lora training, showcasing abstract album covers.
*   **Emotion:** The overall emotion is positive due to admiration of the artwork, particularly the Nirvana cover.
*   **Top 3 Points of View:**
    *   Abstract album covers generated with AI tools are interesting.
    *   The Nirvana cover is particularly striking and evokes unique interpretations.
    *   It's unexpected to see such imagery coming from AI.

**[run video model with multi gpu ? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jhezrt/run_video_model_with_multi_gpu/)**
*   **Summary:** A user asks about running video models with multiple GPUs, and receives information about ComfyUI-MultiGPU and SwarmUI.
*   **Emotion:** Neutral, mainly informational and seeking clarification.
*   **Top 3 Points of View:**
    *   ComfyUI-MultiGPU allows to run video models with multiple GPUs.
    *   SwarmUI may have similar functionality.
    *   It's not possible to combine VRAM of multiple GPUs.

**[Has anyone successfully been able to run Joy Caption Alpha Two locally? When I try to load the model before captioning, the whole app just keeps loading forever and eventually freezes. (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jhg3wo/has_anyone_successfully_been_able_to_run_joy/)**
*   **Summary:** A user is experiencing issues with running Joy Caption Alpha Two locally and asks for help.
*   **Emotion:** Neutral, problem solving.
*   **Top 3 Points of View:**
    *   Tagui can be used to run Joy Caption.
    *   Freezing could be a VRAM issue.

**[Using Pony/SDXL checkpoints and loras with Hunyuan and Wan? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jhgjc7/using_ponysdxl_checkpoints_and_loras_with_hunyuan/)**
*   **Summary:** The post questions whether it's possible to use Pony/SDXL checkpoints and LoRAs with Hunyuan and Wan, clarifying that SDXL is architecturally different.
*   **Emotion:** Mostly Neutral, explaining technical limitations and offering alternative interpretations.
*   **Top 3 Points of View:**
    *   SDXL checkpoints and LoRAs are incompatible with Hunyuan and Wan due to architectural differences.
    *   The user is likely seeing image2video where the initial image used LoRAs.
    *   The first step is to generate the image, then the second step is to animate the image with i2v model

**[how to install custom lora on wan2.1? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jhh06d/how_to_install_custom_lora_on_wan21/)**
*   **Summary:** The post is a question regarding how to install custom lora on wan2.1, and the answer explains that using LoRA loader to the unet loader in ComfyUI or other UIs is how the lora should be loaded and no need for some documents.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Connect LoRA loader to the unet loader in ComfyUI
    *   There is no need for any extra documents

**[Can someone generate a picture of a man from the sketch on the right? (Score: 0)](https://i.redd.it/fbtfwholp9qe1.jpeg)**
*   **Summary:** User asked to generate a picture of a man from the sketch.
*   **Emotion:** Mostly neutral.
*   **Top 3 Points of View:**
    *   An user thinks that cops are using this for composite sketches and asks whether that is a side hustle.
    *   User provides the generated picture.

**[How to make this image i need prompt please (Score: 0)](https://i.redd.it/ikjujf7iv9qe1.jpeg)**
*   **Summary:** User asks about prompt to make the image.
*   **Emotion:** Neutral, informational.
*   **Top 3 Points of View:**
    *   A prompt is provided to replicate the image.
    *   It is suggested to drop this image into Joy Caption.
    *   Copy pasting might work.

**[Newbie doing this i need help (repost cuz i misflaired it before lol) (Score: 0)](https://i.redd.it/zfzljsst3aqe1.png)**
*   **Summary:** New user needs help with something and asks for tips.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   ControlNet inpaint for NoobAI is the official tool
    *   Illustrious or derivatives of Noob AI can be used with it

**[Why is Open-source so far behind Gemini's image generation? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jhd0vw/why_is_opensource_so_far_behind_geminis_image/)**
*   **Summary:** The post discusses why Open-source is so far behind Gemini's image generation.
*   **Emotion:** Neutral, debatable.
*   **Top 3 Points of View:**
    *   The Gemini images are nothing special, actually FLUX can do better ones
    *   The one thing closed models like that have though is their ties and access to the LLM capabilities of it’s system too
    *   Gemini is just inpainting and auto segment

**[Recommend me a new service provider (rant) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jhe1bs/recommend_me_a_new_service_provider_rant/)**
*   **Summary:** The post discusses recommendations for a new service provider.
*   **Emotion:** Neutral, advice.
*   **Top 3 Points of View:**
    *   A100 with comfyui installed from vastai costs 60 to 80 cents an hour of use
    *   A PC with a 3060 12GB or older card should suffice for running video generation
    *   OctaSpace offers direct and personal support via their discord server and various hardware from 30 to 50 series
