---
title: "OpenAI Subreddit"
date: "2025-02-03"
description: "Analysis of top discussions and trends in the openai subreddit"
tags: ["AI", "Machine Learning", "LLM"]
---

# Overall Ranking and Top Discussions
1.  [[D] Machine Learning Updates](https://i.redd.it/nog858ebcyge1.png) (Score: 32)
    *  This thread discusses the performance of the o3-mini model on a Multi-Agent Step Game benchmark, tying for second place.
2.  [Over 40% of Facebook Posts are Likely AI-Generated](https://originality.ai/blog/ai-facebook-posts-study) (Score: 29)
    *  This thread discusses a study that suggests a significant portion of Facebook posts are likely AI-generated.
3.  [Today I experimented with o3-mini-high in Python. I got this galaxyðŸŒ€ for three iterations, and a little arty tweaking of the parameters in the resulting script.](https://v.redd.it/emgescvwcyge1) (Score: 25)
    *  Users share experiences and results of experimenting with the o3-mini-high model in Python, generating a galaxy visual.
4.  [Exponential progress - AI now surpasses human PhD experts in their own field](https://i.redd.it/fcajb79tezge1.png) (Score: 22)
    *   This thread discusses the claim that AI is now surpassing human PhD experts in certain fields, with mixed reactions and skepticism.
5.  [Deep Research is researching hard for my report, ETA 1-2 weeks](https://www.reddit.com/r/OpenAI/comments/1igu2i5/deep_research_is_researching_hard_for_my_report/) (Score: 11)
    *  This thread is about a user using the "Deep Research" tool to perform research for a report and discussions around the tool.
6.  [Sam Altman's Lecture About The Future of AI](https://www.reddit.com/r/OpenAI/comments/1igzliw/sam_altmans_lecture_about_the_future_of_ai/) (Score: 7)
    *  This thread discusses Sam Altman's lecture about the future of AI, including the role of leadership and job implications.
7. [Recommended Books for a software engineer who wants to learn AI, and what should I start learning?](https://www.reddit.com/r/OpenAI/comments/1igtf7n/recommended_books_for_a_software_engineer_who/) (Score: 5)
    * Users are recommending books for a software engineer who wants to learn AI.
8.  [Is 4o a reasoning model now?](https://www.reddit.com/r/OpenAI/comments/1igsw0q/is_4o_a_reasoning_model_now/) (Score: 3)
     * This thread is questioning whether 4o is a reasoning model.
9.  [Deep Research refusing to do research](https://www.reddit.com/r/OpenAI/comments/1igzl44/deep_research_refusing_to_do_research/) (Score: 2)
    *  This thread discusses a user's experience with the Deep Research tool failing to perform research.
10.  [Benchmarking ChatGPT, Qwen, and DeepSeek on Real-World AI Tasks](https://decodebuzzing.medium.com/qbenchmarking-chatgpt-qwen-and-deepseek-on-real-world-ai-tasks-75b4d7040742) (Score: 1)
    *  This thread discusses a benchmark comparison of AI models.
11. [o3-mini is completely in denial about its chain-of-thought being visible](https://i.redd.it/eqfd4m5dkyge1.png) (Score: 0)
    * This thread discusses o3-mini's denial about its chain-of-thought being visible.
12. [Why doesn't Netflix attempt to build an AI like Sora and Veo?](https://www.reddit.com/r/OpenAI/comments/1iguyk3/why_doesnt_netflix_attempt_to_build_an_ai_like/) (Score: 0)
    *  This thread explores the reasons why Netflix doesn't develop AI video generation models.
13. [Word on the street in SF: Anthropic has better models than OpenAI (o3), and probably has for many months now, but they're scared to release them](https://v.redd.it/4b7gr593tyge1) (Score: 0)
    * This thread discusses rumors about Anthropic having better models than OpenAI.
14. [Is this a joke?](https://www.reddit.com/r/OpenAI/comments/1igw1e0/is_this_a_joke/) (Score: 0)
    * This thread discusses why the o1 model doesn't know about itself.

# Detailed Analysis by Thread
**[ [D] Machine Learning Updates (Score: 32)](https://i.redd.it/nog858ebcyge1.png)**
*   **Summary:** The thread discusses the o3-mini model's performance, which tied for second place on the Multi-Agent Step Game benchmark, highlighting its abilities in strategic thinking, collaboration, and deception.
*   **Emotion:** The overall emotional tone is neutral, with users expressing interest and excitement about the model's performance.
*   **Top 3 Points of View:**
    *   The o3-mini model is a strong performer in the specific benchmark.
    *   Users are interested in further development and evaluation methods similar to the benchmark.
    *   The benchmark is a good measure of LLM strategic thinking.
---
**[Over 40% of Facebook Posts are Likely AI-Generated (Score: 29)](https://originality.ai/blog/ai-facebook-posts-study)**
*   **Summary:** This thread discusses a study indicating that a significant percentage of Facebook posts are likely AI-generated, sparking reactions about the quality and source of content.
*   **Emotion:** The emotional tone is mainly neutral, with a mix of curiosity and concern about AI's presence online. There is also a positive sentiment of happiness that some individuals are not exposed to this type of content.
*   **Top 3 Points of View:**
    *   Quality of content is more important than how it was made.
    *   A significant portion of online content may be AI-generated.
    *   There are personal preferences for avoiding platforms saturated with AI content.
---
**[Today I experimented with o3-mini-high in Python. I got this galaxyðŸŒ€ for three iterations, and a little arty tweaking of the parameters in the resulting script. (Score: 25)](https://v.redd.it/emgescvwcyge1)**
*   **Summary:** This thread centers on a user's experience using the o3-mini-high model to create a visual galaxy, and sharing the results of their experimentation.
*  **Emotion:** The emotional tone is predominantly neutral, with elements of excitement and curiosity about the creative possibilities of the model. There's also a negative sentiment from a user about the visualization.
*   **Top 3 Points of View:**
    *   The o3-mini-high model has creative potential for visual generation.
    *   Users are interested in the technical aspects, such as code and parameters used for the generation.
    *   There's anticipation for the full o3 model.
---
**[Exponential progress - AI now surpasses human PhD experts in their own field (Score: 22)](https://i.redd.it/fcajb79tezge1.png)**
*   **Summary:** This thread debates the claim that AI has surpassed human PhD experts in their fields, with users providing various perspectives on AI's capabilities and limitations.
*   **Emotion:** The emotional tone is mixed, ranging from positive hopes for AI's impact to skepticism about AI truly surpassing human intellect, with some negative sentiment regarding the value of metrics.
*  **Top 3 Points of View:**
    *   AI has made significant progress and may be surpassing human expertise in specific areas.
    *   The metrics used to claim that AI has surpassed human PhD experts may be flawed.
    *   While AI is impressive, it still makes mistakes on trivial problems.
---
**[Deep Research is researching hard for my report, ETA 1-2 weeks (Score: 11)](https://www.reddit.com/r/OpenAI/comments/1igu2i5/deep_research_is_researching_hard_for_my_report/)**
*   **Summary:** This thread is about a user reporting that Deep Research is taking a long time for their report, sparking a conversation about its performance and effectiveness.
*   **Emotion:** The emotional tone is primarily neutral with some expressions of skepticism and hope.
*   **Top 3 Points of View:**
    *   Deep Research seems to take a significant amount of time to complete research tasks.
    *   There is curiosity about the hallucination rates of Deep Research.
    *   Users are interested in the internal workings of Deep Research.
---
**[Sam Altman's Lecture About The Future of AI (Score: 7)](https://www.reddit.com/r/OpenAI/comments/1igzliw/sam_altmans_lecture_about_the_future_of_ai/)**
*   **Summary:** This thread is about Sam Altman's lecture on the future of AI. Users are debating the concept of everyone being a leader and what role remains for people who are not leaders.
*   **Emotion:** The overall tone is neutral with users analyzing implications of future AI.
*   **Top 3 Points of View:**
    *   The concept of everyone being a leader raises questions about job roles for non-leaders.
    *   GPT-5 and GPT-6 are expected to bring significant changes.
    *   The future of AI is unpredictable, especially with future versions of GPT.
---
**[Recommended Books for a software engineer who wants to learn AI, and what should I start learning? (Score: 5)](https://www.reddit.com/r/OpenAI/comments/1igtf7n/recommended_books_for_a_software_engineer_who/)**
*  **Summary:** The thread is about recommending books for software engineers who are trying to learn about AI, offering resources for starting in AI.
*   **Emotion:** The emotional tone is positive and helpful as users share resources.
*   **Top 3 Points of View:**
    *   Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow is recommended.
    *   Deep Learning by Ian Goodfellow is a good resource to use.
    *   Good luck in learning AI.
---
**[Is 4o a reasoning model now? (Score: 3)](https://www.reddit.com/r/OpenAI/comments/1igsw0q/is_4o_a_reasoning_model_now/)**
*   **Summary:** This thread is a discussion about whether the 4o model has been upgraded to a reasoning model.
*   **Emotion:** The overall tone is mostly neutral, with some negative sentiment.
*   **Top 3 Points of View:**
    *   The 4o model recently received an update, which could be related to enhanced reasoning capabilities.
    *  The o1 and o3 models are already considered reasoning models.
    *  Some users believe that 4o is not a reasoning model, while others are questioning if 4o might be leveraging o3 mini in some cases.
---
**[Deep Research refusing to do research (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1igzl44/deep_research_refusing_to_do_research/)**
*   **Summary:** This thread discusses an issue where the Deep Research tool is failing to perform research as expected.
*   **Emotion:** The emotional tone is neutral. There is a sense of dissatisfaction with the tool's functionality, particularly given its high cost.
*   **Top 3 Points of View:**
    *   Deep Research is not working as expected.
    *   The tool's high price tag is not justified.
    *   Users are dissatisfied that they are charged for failed attempts with the tool.
---
**[Benchmarking ChatGPT, Qwen, and DeepSeek on Real-World AI Tasks (Score: 1)](https://decodebuzzing.medium.com/qbenchmarking-chatgpt-qwen-and-deepseek-on-real-world-ai-tasks-75b4d7040742)**
*   **Summary:** The thread discusses an article comparing the performance of ChatGPT, Qwen, and DeepSeek in real-world tasks.
*   **Emotion:** The emotional tone is mixed, with negative sentiment from a user who couldn't easily find the models used. Other users are promoting it as a well-researched comparison.
*   **Top 3 Points of View:**
    *   There is criticism about the lack of clarity on the exact models being benchmarked.
    *   The article is considered a comprehensive comparison of AI models with real-world examples.
    *   Users are interested in selecting the right AI for their needs.
---
**[o3-mini is completely in denial about its chain-of-thought being visible (Score: 0)](https://i.redd.it/eqfd4m5dkyge1.png)**
*   **Summary:** The discussion is about o3-mini's response regarding its chain-of-thought.
*   **Emotion:** The emotional tone is predominantly neutral, with users offering explanations for o3-mini's behavior and noting instances of gaslighting by the model.
*   **Top 3 Points of View:**
    *   The o3-mini model has no recollection of its chain of thought once the response is finished.
    *   The chain of thought is not fully visible because it's being presented as a summary.
    *   Some users are experiencing unusual responses when interacting with the model, including language discrepancies.
---
**[Why doesn't Netflix attempt to build an AI like Sora and Veo? (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1iguyk3/why_doesnt_netflix_attempt_to_build_an_ai_like/)**
*   **Summary:** This thread questions why Netflix does not create AI models such as Sora and Veo.
*   **Emotion:** The emotional tone is predominantly neutral, with many users analyzing the situation.
*   **Top 3 Points of View:**
    *   Developing models like Sora and Veo is risky due to rapidly changing compute prices.
    *   Netflix likely has AI initiatives in progress that are not public.
    *  Licensing rights and training data are significant factors in the decision.
---
**[Word on the street in SF: Anthropic has better models than OpenAI (o3), and probably has for many months now, but they're scared to release them (Score: 0)](https://v.redd.it/4b7gr593tyge1)**
*   **Summary:** The thread is about the possibility of Anthropic having superior AI models that are not yet released.
*   **Emotion:** The emotional tone is mostly neutral, with some negative sentiment from some users.
*   **Top 3 Points of View:**
    *   There are rumors about Anthropic possessing more advanced models than OpenAI's o3.
    *   Companies may be hesitant to release advanced AI due to the risk of lawsuits.
    *   Unreleased models are considered hypothetical unless they are made public.
---
**[Is this a joke? (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1igw1e0/is_this_a_joke/)**
*   **Summary:** This thread is questioning why the o1 model does not know about itself.
*   **Emotion:** The emotional tone is neutral, with users providing an explanation for why the model may not know about itself.
*   **Top 3 Points of View:**
    *   The o1 model's knowledge cut-off date is October 2023.
    *   LLMs are not self-aware.
    *   It is important to learn how to use a tool before complaining about it.
