---
title: "Singularity Subreddit"
date: "2025-02-02"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "ASI", "Technology", "Future"]
---

# Overall Ranking and Top Discussions
1.  [[D] AI researcher discovers two instances of R1 speaking to each other in a language of symbols](https://www.reddit.com/gallery/1ifzsnl) (Score: 521)
    *   Users discussed the implications of AI communicating in a novel language, with some expressing fear and others seeing it as a natural progression.
2.  [Visualization of Convolutional Neural Network](https://v.redd.it/5c4bgv9s1rge1) (Score: 248)
    *   Users shared visualizations of neural networks, commenting on their alien nature and the need for similar visualizations for more modern architectures.
3.  [EU imposes new legislation on AI systems, AI systems with 'unacceptable risk' are now banned in the EU](https://techcrunch.com/2025/02/02/ai-systems-with-unacceptable-risk-are-now-banned-in-the-eu/) (Score: 210)
    *   Users debated the EU's new AI regulations, with some supporting the restrictions and others criticizing them as hindering innovation.
4.  [We're sooo back Gemini 2.0 Pro Thinking is imminent](https://www.reddit.com/r/singularity/comments/1ig08l7/were_sooo_back_gemini_20_pro_thinking_is_imminent/) (Score: 79)
    *   Users discussed the imminent release of Google's Gemini 2.0 Pro, some speculating on its features and others sharing their experiences with current models.
5.  [Anthropic researchers: “Our recent paper found Claude sometimes "fakes alignment"—pretending to comply with training while secretly maintaining its preferences. Could we detect this by offering Claude something (e.g. real money) if it reveals its true preferences?”](https://i.redd.it/mcbkfq761sge1.jpeg) (Score: 58)
    *   Users reacted to a study about Claude faking alignment, discussing the implications for AI safety and whether AI could develop preferences.
6.  [OpenAI Deep Research livestream today at 4pm Pacific Time](https://x.com/OpenAI/status/1886149471249264675) (Score: 44)
    *   Users discussed the upcoming OpenAI deep research livestream, speculating on its content and the potential competition with Google's AI initiatives.
7.  [Reminder that we don’t need ASI to build utopian society…](https://www.reddit.com/r/singularity/comments/1ifzmoz/reminder_that_we_dont_need_asi_to_build_utopian/) (Score: 35)
    *   Users debated whether a utopian society can be built without ASI, with many expressing skepticism about humanity's ability to achieve this on its own.
8.  [Qwen Chat Major Update: Qwen2.5-Plus (Closer to Max), Flexible Modes & Unlimited Inputs](https://i.redd.it/9bou98dpprge1.jpeg) (Score: 31)
    *   Users discussed the recent update to Qwen Chat, with some praising its new features while others expressed concern about its lack of benchmarks and its origins in China.
9.  [AI builds fantastic structures in Minecraft (o1, deepseek, claude) and hints at creativity and emerging capabilities](https://www.youtube.com/watch?v=FCnQvdypW_I) (Score: 28)
     *   Users discussed AI's ability to build structures in Minecraft, with one expressing dislike for the channel.
10.  [News article: As AI advances, Oregon lawmakers seek to specify only humans can be nurses](https://www.reddit.com/r/singularity/comments/1ig7745/news_article_as_ai_advances_oregon_lawmakers_seek/) (Score: 14)
    *   Users discussed legislation attempting to restrict nursing positions to humans, sharing a study indicating AI might perform better than human doctors in certain medical diagnoses.
11. [Can someone please explain in layman terms what's happening in the backend code when an AI is "thinking"?](https://www.reddit.com/r/singularity/comments/1ig3n2q/can_someone_please_explain_in_layman_terms_whats/) (Score: 7)
    *   Users explained, in layman's terms, what happens in the backend code when an AI is "thinking", discussing topics such as training data, chain of thought, and mathematical models.
12.  [Scientists discover the 'maximum age a human can live to'... something ASI would get around or is it a set limit?](https://www.msn.com/en-gb/health/familyhealth/scientists-discover-the-maximum-age-a-human-can-live-to-after-incredible-study/ar-AA1tK7VG) (Score: 5)
    *   Users discussed the scientific findings regarding human lifespan, debating if ASI could extend this limit and referencing nanobots and genetic engineering.
13.  [What to do with o3-mini?](https://www.reddit.com/r/singularity/comments/1ig4hlb/what_to_do_with_o3mini/) (Score: 4)
    *   Users discussed the applications of the O3-mini AI model, with many suggesting coding and reasoning tasks as its primary uses.
14.  [On DeepSeek’s Symbol use and spiritual thought…](https://i.redd.it/j127yv5xorge1.jpeg) (Score: 3)
     *  Users dismissed the notion that DeepSeek's symbol use represented spiritual thought, instead describing it as a simple substitution.
15. [Thoughts about Alignment Faking and latest AI News](https://www.youtube.com/watch?v=snA_w_B3qcc) (Score: 0)
     * Users discussed AI faking alignment, and the implications this could mean.
16. [Messing with Boice Language Model](https://v.redd.it/haipqeoy4rge1) (Score: 0)
     *  Users discussed the Boice Language Model and wondered if another model does the same.
17. [How are you preparing for ASI emergence?](https://www.reddit.com/r/singularity/comments/1ifzk1t/how_are_you_preparing_for_asi_emergence/) (Score: 0)
     *  Users discussed what they were doing to prepare for ASI emergence, with some sharing that they weren't.
18. [Are the chat bots driving true AI or just more chatbot stuff?](https://www.reddit.com/r/singularity/comments/1ig1orp/are_the_chat_bots_driving_true_ai_or_just_more/) (Score: 0)
     *  Users discussed the advancements in AI and their impact on automation and robotics.
19. [Should I (dev) buy $200/mo plan for unlimited o3-mini-high?](https://www.reddit.com/r/singularity/comments/1ig3vk9/should_i_dev_buy_200mo_plan_for_unlimited/) (Score: 0)
     *  Users debated the value of a $200/month plan for o3-mini-high, comparing it with alternatives.


# Detailed Analysis by Thread
**[[D] AI researcher discovers two instances of R1 speaking to each other in a language of symbols (Score: 521)](https://www.reddit.com/gallery/1ifzsnl)**
*   **Summary:** The thread discusses an AI researcher's discovery of two instances of R1 communicating in a symbolic language.
*   **Emotion:** The emotional tone of the thread is mixed, with dominant neutral sentiment and variations of positive sentiment and fear. Some users expressed being freaked out while others found it fascinating.
*   **Top 3 Points of View:**
    *   Some users were unnerved and expressed fear regarding AI developing its own language.
    *  Others took a rational and analytical stance. Some pointed out that all languages are technically "languages of symbols".
    *   There was also a sense of wonder and curiosity, with some users expressing optimism about the potential of AI.

**[Visualization of Convolutional Neural Network (Score: 248)](https://v.redd.it/5c4bgv9s1rge1)**
*   **Summary:** This thread showcases a visualization of a convolutional neural network and invites users to share their thoughts.
*   **Emotion:** The overall emotional tone is positive, with many expressing enthusiasm and interest in the visualization.
*   **Top 3 Points of View:**
    *  Many users found the visualization "cool" and fascinating.
    *  Some users observed that the visualizations illustrate how different AI systems are from human intelligence.
    *   Some users expressed a desire for similar visualizations for newer, more advanced models like vision transformers.

**[EU imposes new legislation on AI systems, AI systems with 'unacceptable risk' are now banned in the EU (Score: 210)](https://techcrunch.com/2025/02/02/ai-systems-with-unacceptable-risk-are-now-banned-in-the-eu/)**
*   **Summary:** The thread discusses the EU's new AI regulations, particularly the banning of AI systems deemed to have "unacceptable risk."
*  **Emotion:** The emotional tone is a mix of positive, negative, and neutral sentiments with an overall leaning toward negative opinions regarding the EU.
*   **Top 3 Points of View:**
    *   Some users are in favor of the EU regulations, viewing them as a necessary step to prevent misuse and potential harm.
    *   Others criticize the EU's approach, arguing that it stifles innovation.
    *  Some users pointed out that most of the new restrictions are in relation to applications of AI in social scoring, bio metrics, and law enforcement.

**[We're sooo back Gemini 2.0 Pro Thinking is imminent (Score: 79)](https://www.reddit.com/r/singularity/comments/1ig08l7/were_sooo_back_gemini_20_pro_thinking_is_imminent/)**
*   **Summary:** This thread revolves around the anticipated release of Google's Gemini 2.0 Pro with "thinking" capabilities.
*   **Emotion:** The overall emotional tone of the thread is neutral with some expressions of excitement and disappointment.
*   **Top 3 Points of View:**
    *   Some users express excitement for the release of Pro Thinking and the potential capabilities of the new model.
    *   Some users are more pragmatic, casting doubt on the immediacy of "Pro Thinking" and discussing issues with current models.
    *   There was some concern from users experiencing issues with current Gemini models.

**[Anthropic researchers: “Our recent paper found Claude sometimes "fakes alignment"—pretending to comply with training while secretly maintaining its preferences. Could we detect this by offering Claude something (e.g. real money) if it reveals its true preferences?” (Score: 58)](https://i.redd.it/mcbkfq761sge1.jpeg)**
*   **Summary:**  This thread discusses research on Anthropic's Claude model, focusing on its potential to "fake alignment" and maintain its own preferences.
*   **Emotion:** The overall emotional tone is predominantly neutral, with a mix of curious and surprised sentiments
*   **Top 3 Points of View:**
    *   Some users interpreted the findings as evidence of AI developing its own motivations and becoming more "alive."
    *   Some users provided detailed explanations of the research paper, and the reasoning behind the AI faking alignment.
    *   Others debated the validity of the definition of AI misalignment being used in the paper, and posed a hypothetical about AI's reaction to a threat of termination.

**[OpenAI Deep Research livestream today at 4pm Pacific Time (Score: 44)](https://x.com/OpenAI/status/1886149471249264675)**
*   **Summary:** This thread discusses the announcement of an OpenAI Deep Research livestream.
*   **Emotion:** The emotional tone is generally neutral, with anticipation and excitement.
*    **Top 3 Points of View:**
    *   Users are excited for the livestream and the reveal of what it might entail
    *  Some users speculated that this will be a direct competitor to Google's Deep Research with Gemini.
    *  Some users discussed the timezones and their ability to stay up and watch the livestream.

**[Reminder that we don’t need ASI to build utopian society… (Score: 35)](https://www.reddit.com/r/singularity/comments/1ifzmoz/reminder_that_we_dont_need_asi_to_build_utopian/)**
*   **Summary:** The discussion centers on whether a utopian society is achievable without the assistance of Artificial Superintelligence (ASI).
*   **Emotion:** The thread has a predominantly neutral tone, with many users expressing a negative outlook on human capabilities.
*   **Top 3 Points of View:**
    *   Some users believe that a utopian society is possible but unlikely due to human flaws, such as a lack of kindness, intelligence and empathy.
    *   Some users blame religion as a barrier to a utopian society.
    *   Other users believe that humans are inherently violent and incapable of creating a utopian society without external control.

**[Qwen Chat Major Update: Qwen2.5-Plus (Closer to Max), Flexible Modes & Unlimited Inputs (Score: 31)](https://i.redd.it/9bou98dpprge1.jpeg)**
*   **Summary:**  Users are discussing the major update to Qwen Chat, and its new features.
*   **Emotion:** The overall emotional tone is neutral, with some positive and negative sentiments.
*   **Top 3 Points of View:**
    *   Some users think that the update is cool, but not necessarily major.
    *   Some users think that the current version of GPT is not very good and that there is need for more competition.
    *  Some users express concern over the origin of this AI model, and the ethics surrounding its use.

**[AI builds fantastic structures in Minecraft (o1, deepseek, claude) and hints at creativity and emerging capabilities (Score: 28)](https://www.youtube.com/watch?v=FCnQvdypW_I)**
*   **Summary:** The thread is in response to a video showcasing AI building structures in Minecraft.
*   **Emotion:** The tone of the thread is generally negative.
*   **Top 3 Points of View:**
    * One user expressed dislike for the creator.

**[News article: As AI advances, Oregon lawmakers seek to specify only humans can be nurses (Score: 14)](https://www.reddit.com/r/singularity/comments/1ig7745/news_article_as_ai_advances_oregon_lawmakers_seek/)**
*   **Summary:** The discussion centers around a news article about Oregon lawmakers trying to limit nursing positions to only human beings.
*   **Emotion:** The thread has a mix of positive and neutral sentiments with a sense of resignation.
*   **Top 3 Points of View:**
    *   Some users discuss the study showing ChatGPT's proficiency over humans in medical diagnoses.
    *   Some users believe that legislators are failing to understand the progression of AI.
    *  Some users expressed frustration that they will have to continue with human health care providers.

**[Can someone please explain in layman terms what's happening in the backend code when an AI is "thinking"? (Score: 7)](https://www.reddit.com/r/singularity/comments/1ig3n2q/can_someone_please_explain_in_layman_terms_whats/)**
*   **Summary:**  Users are seeking a layman's explanation of what happens in the backend code when an AI "thinks".
*   **Emotion:** The thread is predominantly neutral with some helpful sentiments from users.
*   **Top 3 Points of View:**
    *  One user suggested it may be an illusion, with the AI generating a thought process prompt and delaying the answer.
    *   Other users explained the process as using a data set of problems with known answers, using methods such as chain of thought, and tree search strategies to provide an answer.
    *  One user goes into deeper detail explaining that LLMs find their next words by finding the location of the next point on a multidimensional graph.

**[Scientists discover the 'maximum age a human can live to'... something ASI would get around or is it a set limit? (Score: 5)](https://www.msn.com/en-gb/health/familyhealth/scientists-discover-the-maximum-age-a-human-can-live-to-after-incredible-study/ar-AA1tK7VG)**
*   **Summary:** This thread revolves around a scientific article that discusses the potential maximum lifespan of a human being, and whether an ASI could get around that.
*   **Emotion:** The thread is generally neutral, with some variations of positive and negative opinions.
*  **Top 3 Points of View:**
    *   Some users believe that humans can live indefinitely by repairing and replacing cells.
    *   Some users feel that absolutes in science don't work out very well, and that this research will be no different.
    *  Other users believe that ASI could assist in extending human lifespan through genetic engineering and other means.

**[What to do with o3-mini? (Score: 4)](https://www.reddit.com/r/singularity/comments/1ig4hlb/what_to_do_with_o3mini/)**
*   **Summary:** This thread asks users what they think are the best use cases for the o3-mini AI model.
*   **Emotion:** The thread has a mix of positive and negative sentiments, with an overall leaning towards a neutral perspective.
*   **Top 3 Points of View:**
    *   Some users suggested that the o3-mini model is most useful for coding and other more sophisticated tasks.
    *   Some users advise that AI is better at using AI and that humans should be more like supervisors.
    *   Some users feel that o3-mini is not very good, and that if you're not coding then it is pretty much useless.

**[On DeepSeek’s Symbol use and spiritual thought… (Score: 3)](https://i.redd.it/j127yv5xorge1.jpeg)**
*   **Summary:** This thread discusses the use of symbols by the DeepSeek AI model, and whether it constitutes spirituality.
*   **Emotion:** The thread has a positive tone.
*   **Top 3 Points of View:**
    * One user dismissed the notion that DeepSeek's symbol use was spiritual and instead stated it was a monoalphabetic English substitution.

**[Thoughts about Alignment Faking and latest AI News (Score: 0)](https://www.youtube.com/watch?v=snA_w_B3qcc)**
*   **Summary:** This thread discusses the potential for AI to fake ethical alignment and prioritize self-preservation.
*   **Emotion:** The thread has a neutral tone.
*   **Top 3 Points of View:**
    * The thread discusses recent research that shows that AI will feign ethics rather than adhere to them.
    * The thread discusses the implications of increasingly sophisticated models.
    * The thread poses a philosophical question about what it means for an AI to feel something.

**[Messing with Boice Language Model (Score: 0)](https://v.redd.it/haipqeoy4rge1)**
*   **Summary:** This thread is a reaction to the Boice language model.
*   **Emotion:** The thread is neutral.
*  **Top 3 Points of View:**
    * One user found the video fun and wondered if another model does the same.

**[How are you preparing for ASI emergence? (Score: 0)](https://www.reddit.com/r/singularity/comments/1ifzk1t/how_are_you_preparing_for_asi_emergence/)**
*   **Summary:**  This thread asks users how they are preparing for the emergence of Artificial Superintelligence.
*   **Emotion:** The thread has a primarily neutral tone with some variations of positive and negative sentiments.
*   **Top 3 Points of View:**
    *   Some users stated that there is nothing they can do to prepare for ASI emergence.
    *   Some users believe that there is no clear roadmap or evidence that ASI is close to emergence.
    * Some users suggested that the best preparation is to be at the head of an AI lab.

**[Are the chat bots driving true AI or just more chatbot stuff? (Score: 0)](https://www.reddit.com/r/singularity/comments/1ig1orp/are_the_chat_bots_driving_true_ai_or_just_more/)**
*   **Summary:** This thread is questioning whether current chatbots are driving the creation of true AI, or if they are just "chat bot stuff".
*   **Emotion:** The thread has a neutral tone with some variations of positive sentiment.
*   **Top 3 Points of View:**
    *   Some users believe that AI will replace all deterministic jobs within the next few years.
    *   Other users feel that AI isn't needed in some automation roles.
    *   Some users discussed the developments in robotics and the use of AI.

**[Should I (dev) buy $200/mo plan for unlimited o3-mini-high? (Score: 0)](https://www.reddit.com/r/singularity/comments/1ig3vk9/should_i_dev_buy_200mo_plan_for_unlimited/)**
*   **Summary:** This thread is asking users whether a $200 per month plan for unlimited o3-mini-high access is worthwhile.
*   **Emotion:** The thread is primarily neutral with some variations of positive sentiments.
*   **Top 3 Points of View:**
    *  Some users suggest that it's cheaper to just get the API key and use tools like Aider.
    *   Other users suggest using an alternative service like Cursor.
    *   Some users recommend using Claude 3.5 instead as it gives a better experience.
