---
title: "Stable Diffusion Subreddit"
date: "2025-02-28"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Wan2.1 720P Local in ComfyUI I2V](https://v.redd.it/hh5n626gvwle1) (Score: 165)
    *   The thread showcases a user's successful implementation of I2V (Image-to-Video) at 720P resolution using ComfyUI and the Wan2.1 model, generating positive responses and prompting questions about the workflow.
2.  [Do you remember this?](https://i.redd.it/lvav39q3zwle1.png) (Score: 97)
    *   Users reminisce about older AI models like VQGAN-CLIP and Disco Diffusion, reflecting on the evolution of AI image generation.
3.  [Wan 2.1 – stable frames, smooth motion, no flicker](https://v.redd.it/s8se5ugk4xle1) (Score: 58)
    *   The thread discusses the quality and tools used to create a video with stable frames, smooth motion, and no flicker using Wan 2.1. Some users point out minor issues with the smoothness.
4.  [Wan2.1 i2v cow in the sky. How do i increase the length of video?](https://v.redd.it/t9rsygxpbxle1) (Score: 22)
    *   Users are discussing how to increase the length of videos generated with Wan2.1 i2v, with some humor.
5.  [Liminal Surveillance - The Break Area](https://i.redd.it/mxjycp1fywle1.jpeg) (Score: 12)
    *   A user shared an AI-generated image and mentioned the tools that they used.
6.  [Wan2.1 Performance Testing](https://v.redd.it/w76pvjpv7xle1) (Score: 6)
    *   A user shared performance testing across different GPUs for video generation.
7.  [Automatic installation of Triton and SageAttention into an existing Portable Comfy (v1.0)](https://www.reddit.com/r/StableDiffusion/comments/1j0enkx/automatic_installation_of_triton_and/) (Score: 5)
    *   The thread discusses the automatic installation of Triton and SageAttention and performance improvements.
8.  [one hour video wan 1.3b test](https://youtu.be/QqYjaHgGcWg?si=5AMAy_1D_cTW212R) (Score: 5)
    *   A user shared a one-hour video generated with wan 1.3b, prompting questions about the generation process and receiving some criticism for lack of context.
9.  [Unwanted text in the generated image is completely out of hand](https://i.redd.it/45nc0yud0xle1.jpeg) (Score: 3)
    *   A user is having issues with unwanted text appearing in their generated images and is asking for help on how to fix it.
10. [I feel I've fallen behind on SDXL due to flux, what are some new realistic, versatile checkpoints and loras that can do hands, feet, multiple characters well? Keep in mind I always use my own outlines when generating with SDXL. So I will be using t2i adapters or control net](https://www.reddit.com/r/StableDiffusion/comments/1j0fr14/i_feel_ive_fallen_behind_on_sdxl_due_to_flux_what/) (Score: 2)
    *   A user is looking for recommendations on new realistic, versatile checkpoints and loras.
11. [tongyi.aliyun.com/wanxiang I2V](https://v.redd.it/dfucgkl34xle1) (Score: 1)
    *   A user shared positive results from using I2V on the tongyi.aliyun.com/wanxiang website.
12. [Is it possible to overlay or combine two images to remove a watermark? One high-resolution file with a watermark and another low-resolution version of the same image without a watermark.](https://www.reddit.com/r/StableDiffusion/comments/1j0hf3m/is_it_possible_to_overlay_or_combine_two_images/) (Score: 1)
    *   The thread discusses methods to remove watermarks from images using Photoshop and AI upscaling, as well as the potential for Stable Diffusion methods.
13. [How to inpaint properly in Stable Diffusion so nothing sticks out when overlaying images?](https://www.reddit.com/r/StableDiffusion/comments/1j0i3dc/how_to_inpaint_properly_in_stable_diffusion_so/) (Score: 1)
    *   A user is seeking guidance on how to inpaint properly in Stable Diffusion to avoid noticeable seams when overlaying images.
14. [Chinese AI is notably superior to Western AI or is it just me?](https://www.reddit.com/r/StableDiffusion/comments/1j0dg3m/chinese_ai_is_notably_superior_to_western_ai_or/) (Score: 0)
    *   The discussion revolves around whether Chinese AI is superior to Western AI, with arguments about resources, open-source contributions, and censorship.
15. [Why is size more significant than seed?](https://www.reddit.com/r/StableDiffusion/comments/1j0f8rs/why_is_size_more_significant_than_seed/) (Score: 0)
    *   Users discuss the impact of image size and seed on the output of Stable Diffusion, with explanations on how resolution and aspect ratio influence prompt interpretation.

# Detailed Analysis by Thread
**[Wan2.1 720P Local in ComfyUI I2V (Score: 165)](https://v.redd.it/hh5n626gvwle1)**
*   **Summary:** The thread showcases a user's successful implementation of I2V (Image-to-Video) at 720P resolution using ComfyUI and the Wan2.1 model. Users inquired about the workflow, prompting the original poster to share it. Others commented positively on the video's quality and specific details like the movement of coffee in a cup.
*   **Emotion:** The overall emotional tone is positive and neutral. People are impressed with the results and asking technical questions.
*   **Top 3 Points of View:**
    *   The user successfully implemented I2V at 720P with good quality.
    *   Others are interested in the workflow used to achieve the results.
    *   Some users noticed specific details, indicating a good level of realism.

**[Do you remember this? (Score: 97)](https://i.redd.it/lvav39q3zwle1.png)**
*   **Summary:** Users reminisce about older AI models like VQGAN-CLIP and Disco Diffusion, sharing images and memories from that era. The discussion highlights the evolution of AI image generation and how far it has come.
*   **Emotion:** The overall emotional tone is nostalgic and neutral.
*   **Top 3 Points of View:**
    *   Users remember VQGAN-CLIP and Disco Diffusion fondly.
    *   The thread serves as a reminder of the progress made in AI image generation.
    *   Some users express a desire to train a flux lora with a sample of those models.

**[Wan 2.1 – stable frames, smooth motion, no flicker (Score: 58)](https://v.redd.it/s8se5ugk4xle1)**
*   **Summary:** The thread discusses the quality and tools used to create a video with stable frames, smooth motion, and no flicker using Wan 2.1. Some users point out minor issues with the smoothness, while others inquire about the creation process. A user also notes the pricing model associated with the tool.
*   **Emotion:** The overall emotional tone is mixed, with both positive and neutral sentiments. Some users are impressed, while others point out flaws.
*   **Top 3 Points of View:**
    *   The video has generally good stability and motion.
    *   Some users find the initial few seconds not entirely smooth.
    *   There's interest in the tools and processes used.

**[Wan2.1 i2v cow in the sky. How do i increase the length of video? (Score: 22)](https://v.redd.it/t9rsygxpbxle1)**
*   **Summary:** Users are discussing how to increase the length of videos generated with Wan2.1 i2v. Suggestions include increasing the frame count, using VFI, decreasing the frame rate, and merging multiple video segments. Some users make humorous comparisons to movies.
*   **Emotion:** The emotional tone is mostly neutral with a hint of humor.
*   **Top 3 Points of View:**
    *   The user wants to increase the video length.
    *   Others provide technical suggestions on how to do so.
    *   Some users make humorous references.

**[Liminal Surveillance - The Break Area (Score: 12)](https://i.redd.it/mxjycp1fywle1.jpeg)**
*   **Summary:** A user shared an AI-generated image created with Flux Pro Ultra on NightCafe. Other users comment on the image, with one noting they could spend hours doing nothing in such a space.
*   **Emotion:** The emotional tone is neutral.
*   **Top 2 Points of View:**
    *   The user shared their AI-generated image.
    *   Another user commented on the image's atmosphere.

**[Wan2.1 Performance Testing (Score: 6)](https://v.redd.it/w76pvjpv7xle1)**
*   **Summary:** The thread discusses performance testing of Wan2.1 on ComfyUI across various GPUs. The tests focused on Text-to-Video (T2V) generation at 480P and 720P, with findings indicating that the H100 was the fastest, while some GPUs struggled with 720P due to VRAM limitations.
*   **Emotion:** The emotional tone is informative and neutral.
*   **Top 1 Point of View:**
    *   The user shared performance data for Wan2.1 across different GPUs.

**[Automatic installation of Triton and SageAttention into an existing Portable Comfy (v1.0) (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1j0enkx/automatic_installation_of_triton_and/)**
*   **Summary:** The thread discusses the automatic installation of Triton and SageAttention into ComfyUI. Users shared feedback on performance improvements, bug fixes, and installation issues.
*   **Emotion:** The emotional tone is positive and neutral with problem solving.
*   **Top 3 Points of View:**
    *   The user developed an automatic installation for Triton and SageAttention.
    *   Others are testing the implementation and reporting results.
    *   Users are troubleshooting installation issues.

**[one hour video wan 1.3b test (Score: 5)](https://youtu.be/QqYjaHgGcWg?si=5AMAy_1D_cTW212R)**
*   **Summary:** A user shared a one-hour video generated with wan 1.3b, prompting questions about the generation process and receiving some criticism for lack of context.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 2 Points of View:**
    *   The user posted a video with no explanation
    *   Other users criticized the lack of context

**[Unwanted text in the generated image is completely out of hand (Score: 3)](https://i.redd.it/45nc0yud0xle1.jpeg)**
*   **Summary:** A user is having issues with unwanted text appearing in their generated images, specifically the text "score 9," and seeks help to remove it despite using negative prompts.
*   **Emotion:** The emotional tone is frustrated and neutral.
*   **Top 1 Points of View:**
    *   A user is seeking guidance to remove unwanted text in their generated images.

**[I feel I've fallen behind on SDXL due to flux, what are some new realistic, versatile checkpoints and loras that can do hands, feet, multiple characters well? Keep in mind I always use my own outlines when generating with SDXL. So I will be using t2i adapters or control net (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1j0fr14/i_feel_ive_fallen_behind_on_sdxl_due_to_flux_what/)**
*   **Summary:** A user is looking for recommendations on new realistic, versatile checkpoints and loras that can handle hands, feet, and multiple characters well for SDXL.
*   **Emotion:** The emotional tone is neutral and inquisitive.
*   **Top 1 Points of View:**
    *   The user wants recommendations on new versatile checkpoints and loras.

**[tongyi.aliyun.com/wanxiang I2V (Score: 1)](https://v.redd.it/dfucgkl34xle1)**
*   **Summary:** A user shared positive results from using I2V on the tongyi.aliyun.com/wanxiang website, noting that T2V results were less satisfactory.
*   **Emotion:** The emotional tone is positive.
*   **Top 1 Points of View:**
    *   I2V results from tongyi.aliyun.com/wanxiang are positive.

**[Is it possible to overlay or combine two images to remove a watermark? One high-resolution file with a watermark and another low-resolution version of the same image without a watermark. (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1j0hf3m/is_it_possible_to_overlay_or_combine_two_images/)**
*   **Summary:** The thread discusses methods to remove watermarks from images, with a focus on using Photoshop and AI upscaling.
*   **Emotion:** The emotional tone is neutral and informative.
*   **Top 1 Points of View:**
    *   Photoshop and AI upscaling are possible methods to remove watermarks.

**[How to inpaint properly in Stable Diffusion so nothing sticks out when overlaying images? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1j0i3dc/how_to_inpaint_properly_in_stable_diffusion_so/)**
*   **Summary:** A user is seeking guidance on how to inpaint properly in Stable Diffusion to avoid noticeable seams when overlaying images.
*   **Emotion:** The emotional tone is neutral and inquisitive.
*   **Top 1 Points of View:**
    *   The user wants to inpaint properly to avoid seams.

**[Chinese AI is notably superior to Western AI or is it just me? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1j0dg3m/chinese_ai_is_notably_superior_to_western_ai_or/)**
*   **Summary:** The discussion revolves around whether Chinese AI is superior to Western AI, with arguments about resources, open-source contributions, and censorship.
*   **Emotion:** The overall emotional tone is neutral, but there are varied sentiments within the discussion.
*   **Top 3 Points of View:**
    *   Chinese AI benefits from more resources and less censorship
    *   Chinese AI focuses on open-source releases
    *   Western AI is restricted due to censorship

**[Why is size more significant than seed? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1j0f8rs/why_is_size_more_significant_than_seed/)**
*   **Summary:** Users discuss the impact of image size and seed on the output of Stable Diffusion, with explanations on how resolution and aspect ratio influence prompt interpretation.
*   **Emotion:** The overall emotional tone is informative and neutral.
*   **Top 3 Points of View:**
    *   Resolution and aspect ratio drastically changes how the prompt is interpreted.
    *   The seed is simply the starting noise.
    *   If you want higher resolution images, you should generate at a standard rate and use some form of upscaling.
