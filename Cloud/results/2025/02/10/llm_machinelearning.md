---
title: "Machine Learning Subreddit"
date: "2025-02-10"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machine learning", "AI", "discussion"]
---

# Overall Ranking and Top Discussions
1.  [[D] Laptop for Deep Learning PhD](https://www.reddit.com/r/MachineLearning/comments/1im44wy/laptop_for_deep_learning_phd_d/) (Score: 42)
    *   This thread discusses the best laptop options for a PhD student in deep learning, considering factors like budget, GPU needs, and operating system preferences.
2.  [[P] Inviting Collaborators for a Differentiable Geometric Loss Function Library](https://www.reddit.com/r/MachineLearning/comments/1ilzqdb/p_inviting_collaborators_for_a_differentiable/) (Score: 25)
    *   This thread is an invitation for collaborators on a project involving a differentiable geometric loss function library.
3.  [[D] KL divergence as a primary reward in LLM post-training RL?](https://www.reddit.com/r/MachineLearning/comments/1im7bsb/d_kl_divergence_as_a_primary_reward_in_llm/) (Score: 10)
    *   This thread explores the use of KL divergence as a primary reward in LLM post-training reinforcement learning.
4.  [[R] Common practice when extending a workshop paper's work](https://www.reddit.com/r/MachineLearning/comments/1imaq6g/r_common_practice_when_extending_a_workshop/) (Score: 6)
    *   This thread discusses the common practice of extending a workshop paper for further publication or development.
5.  [[D] Will there be a position paper track at NeurIPS 2025?](https://www.reddit.com/r/MachineLearning/comments/1im1j39/d_will_there_be_a_position_paper_track_at_neurips/) (Score: 5)
    *   This thread discusses the possibility of a position paper track at NeurIPS 2025.
6.  People Need Education On AI... [[D]](https://www.reddit.com/r/MachineLearning/comments/1imghft/people_need_education_on_ai_d/) (Score: 2)
    *   This thread discusses the need for better public education on AI.

# Detailed Analysis by Thread
**[[D] Laptop for Deep Learning PhD (Score: 42)](https://www.reddit.com/r/MachineLearning/comments/1im44wy/laptop_for_deep_learning_phd_d/)**
*   **Summary:** The discussion centers around the best laptop for a deep learning PhD student, weighing factors like the necessity of a GPU, budget constraints, and alternative solutions like cloud computing. The debate includes Mac vs. PC, the practicality of laptop GPUs, and the importance of RAM and screen quality.
*   **Emotion:** The overall emotional tone is Neutral, with discussions focusing on practical advice and weighing different options. A few comments express stronger opinions (positive towards Macbooks, negative towards Windows), but the dominant tone is informative and neutral. A couple of Positive sentiments appear, but they are the exception rather than the norm.
*   **Top 3 Points of View:**
    *   A powerful laptop with a dedicated GPU is unnecessary; cloud computing or remote servers are better for heavy calculations.
    *   Macbooks, particularly those with M-series chips, offer the best performance and efficiency for the price, especially considering non-compute tasks.
    *   Consider a smaller, efficient laptop (like a Macbook) for everyday tasks and access powerful remote resources for computationally intensive deep learning tasks.

**[[P] Inviting Collaborators for a Differentiable Geometric Loss Function Library (Score: 25)](https://www.reddit.com/r/MachineLearning/comments/1ilzqdb/p_inviting_collaborators_for_a_differentiable/)**
*   **Summary:** The thread is a call for collaboration on a differentiable geometric loss function library. Discussions involve questions about the project's goals, potential for publication, and comparisons to existing libraries like KeOps and Geomloss.
*   **Emotion:** The overall emotional tone is Neutral. Comments are inquisitive and professional, seeking clarification and offering suggestions.
*   **Top 3 Points of View:**
    *   The project needs a clear direction and defined goals.
    *   There is interest in collaboration, especially if the project is geared towards publication or a preprint.
    *   The project should consider and potentially incorporate features from existing libraries like KeOps and Geomloss.

**[[D] KL divergence as a primary reward in LLM post-training RL? (Score: 10)](https://www.reddit.com/r/MachineLearning/comments/1im7bsb/d_kl_divergence_as_a_primary_reward_in_llm/)**
*   **Summary:** The discussion revolves around the feasibility and effectiveness of using KL divergence as a primary reward in LLM post-training reinforcement learning (RL). Participants discuss the nuances of RL, the importance of human preferences (RLHF), and potential pitfalls.
*   **Emotion:** The dominant emotion is Neutral, with users seeking clarification and offering advice. There is a hint of skepticism and caution regarding the proposed approach. Some users express a Positive sentiment.
*   **Top 3 Points of View:**
    *   Using KL divergence as a primary reward in a pure RL setting for LLMs is likely problematic without a verifiable domain or human preferences.
    *   KL divergence is more appropriately used as a regularization term in RLHF to prevent the model from deviating too far from its initial state.
    *   Consider imitation learning algorithms and explore existing research that utilizes KL divergence in similar contexts.

**[[R] Common practice when extending a workshop paper's work (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1imaq6g/r_common_practice_when_extending_a_workshop/)**
*   **Summary:** This thread discusses best practices for extending a workshop paper. The consensus is that if the workshop is non-archival, the extended work can be treated as a new paper.
*   **Emotion:** The overall emotional tone is Positive, with users sharing opinions to extending your work to fit other things is pretty huge. Most responses are supportive and informative, aiming to provide helpful advice.
*   **Top 3 Points of View:**
    *   If the workshop is non-archival, treat the extended work as a new paper.
    *   Update the arXiv version with the new and improved version.

**[[D] Will there be a position paper track at NeurIPS 2025? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1im1j39/d_will_there_be_a_position_paper_track_at_neurips/)**
*   **Summary:** This thread briefly discusses the possibility of a position paper track at NeurIPS 2025.
*   **Emotion:** The overall emotional tone is Neutral, with a user stating that they think that there are pretty high chances of the position paper track happening.
*   **Top 3 Points of View:**
    *   There's a decent possibility of a position paper track based on previous workshops.

**People Need Education On AI... [[D]](https://www.reddit.com/r/MachineLearning/comments/1imghft/people_need_education_on_ai_d/) (Score: 2)**
*   **Summary:** The thread discusses the need for increased AI education to avoid inane questions and fear-mongering.
*   **Emotion:** The overall emotional tone is Neutral, with a user stating that they people should ask the ai before they ask the gpt about it.
*   **Top 3 Points of View:**
    *   People should consult AI before asking basic questions or spreading misinformation.
