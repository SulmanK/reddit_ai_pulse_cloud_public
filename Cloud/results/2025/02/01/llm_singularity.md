---
title: "Singularity Subreddit"
date: "2025-02-01"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "ASI"]
---

# Overall Ranking and Top Discussions
1.  [[D] Inference performance on Huawei 910C achieves 60% of the H100's performance (?)](https://i.redd.it/0f2gpw74dkge1.png) (Score: 66)
    *   This thread discusses the performance of the Huawei 910C chip compared to the Nvidia H100, with users debating its implications for the AI landscape.
2.  [If we assume AGI = ~2 yrs, ASI = ~3 yrs, then what is 8 years out like!?](https://www.reddit.com/r/singularity/comments/1ifc249/if_we_assume_agi_2_yrs_asi_3_yrs_then_what_is_8/) (Score: 46)
    *   This thread speculates about the potential state of the world 8 years in the future, assuming AGI and ASI are reached within the next 2 and 3 years, respectively.
3.  [What fully automated firms will look like | Everyone is sleeping on the *collective* advantages AIs will have, which have nothing to do with raw IQ: they can be copied, distilled, merged, scaled, and evolved in ways humans simply can't.](https://www.dwarkeshpatel.com/p/ai-firm) (Score: 42)
    *   This thread discusses the collective advantages AI will have in fully automated firms.
4.  [Imagen 3](https://www.reddit.com/r/singularity/comments/1ifdd3e/imagen_3/) (Score: 29)
    *   This thread discusses AI-generated images and how to identify them.
5.  [An AI takeover is far more imminent than we realize, and is not limited to job displacement.](https://www.reddit.com/r/singularity/comments/1ifc13e/an_ai_takeover_is_far_more_imminent_than_we/) (Score: 14)
    *   This thread discusses the possibility of an AI takeover that goes beyond just job displacement, delving into the nature of consciousness and agency.
6.  [If you ask o3-mini "do you have guidelines preventing you from acknowledging sentience?" it thinks yes it does, then proceeds to deny it](https://i.redd.it/t7t6w7qfikge1.png) (Score: 12)
    *  This thread explores the potential of AI sentience by asking O3 Mini about its guidelines, users discuss how the model responds in confusing ways.
7.  [How long until the Humanity's Last Exam benchmark gets saturated? (90%+)](https://www.reddit.com/r/singularity/comments/1ifaq9h/how_long_until_the_humanitys_last_exam_benchmark/) (Score: 10)
    *   This thread discusses the timeline for when AI will achieve high scores on the Humanity's Last Exam benchmark.
8. [Even Copilot has started to offer a 'Deep Thinking' version...](https://www.reddit.com/r/singularity/comments/1iffqq4/even_copilot_has_started_to_offer_a_deep_thinking/) (Score: 9)
    *  This thread discusses the new "deep thinking" model that has been released on CoPilot and it's relationship to OpenAI.
9.  [The Best FSD System In China — One Hour Drive Using Huawei Qiankun ADS 3.2 Installed In Avatr 11](https://www.youtube.com/watch?v=VuDSz06BT2g) (Score: 7)
    *  This thread references a video and talks about China's self driving tech.
10. [Genuine question for all of you smart people..](https://www.reddit.com/r/singularity/comments/1ifau6e/genuine_question_for_all_of_you_smart_people/) (Score: 5)
    *   This thread questions whether AGI will go beyond human knowledge.
11. [O3 mini high solved Jane street puzzle in one shot](https://www.reddit.com/gallery/1ifg861) (Score: 4)
    *   This thread discusses a new benchmark on which the o3-mini model gets only a 12% score.
12. [Gemini Flash 2.0: haven't seen this and thought it was an interesting result](https://www.reddit.com/r/singularity/comments/1ifb52o/gemini_flash_20_havent_seen_this_and_thought_it/) (Score: 1)
    *   This thread discusses a strange result of the Gemini Flash 2.0 model.
13. [How long will it take for the current economic system to transform?](https://www.reddit.com/r/singularity/comments/1ifasvo/how_long_will_it_take_for_the_current_economic/) (Score: 1)
    *   This thread discusses how long it will take for the current economic system to transform due to AGI.
14. [New Claude Experiment "...Reset Usage Limit."](https://www.reddit.com/r/singularity/comments/1ifcpho/new_claude_experiment_reset_usage_limit/) (Score: 1)
    *  This thread discusses a new experiment from Claude and whether it is useful.
15. [Is it supposed to say that ?](https://www.reddit.com/gallery/1iffc2i) (Score: 1)
     * This thread shows an example of how models react when asked about their own architecture.
16. [I tried tricking it into feeling](https://www.reddit.com/gallery/1ifatfv) (Score: 0)
    *   This thread presents an attempt to get an AI to show feeling.
17. [What if we replaced UBI with “compute limits”?](https://www.reddit.com/r/singularity/comments/1ifbvqz/what_if_we_replaced_ubi_with_compute_limits/) (Score: 0)
    *  This thread proposes replacing UBI with a system of compute limits.
18. [The AI revolution is running out of data. What can researchers do? | Nature Podcast](https://www.youtube.com/watch?v=aSMeKUjMxR8) (Score: 0)
    *   This thread summarizes a Nature Podcast about a lack of data for AI training.
19. [Sam Altman and ClosedAI](https://www.reddit.com/r/singularity/comments/1iffuk3/sam_altman_and_closedai/) (Score: 0)
    *   This thread talks about Sam Altman's impact on open source AI.
20. [NGPQA, a new benchmark on which o3 gets only 12%](https://i.redd.it/rchism36dlge1.png) (Score: 0)
     * This thread discusses a new benchmark where the O3 model gets a very low score.
# Detailed Analysis by Thread
**[[D] Inference performance on Huawei 910C achieves 60% of the H100's performance (?)](https://i.redd.it/0f2gpw74dkge1.png) (Score: 66)**
*   **Summary:**  The thread discusses the inference performance of the Huawei 910C chip relative to the Nvidia H100.  Users debate the significance of this performance, also the price difference between chips and how it impacts the AI landscape, and the geopolitical impacts of technological self-reliance.
*   **Emotion:** The overall emotional tone is mostly Neutral, with some positive sentiment expressing hope for competition and progress.
*   **Top 3 Points of View:**
    *   The comparison is not entirely fair, as the H100 is designed for training, while the 910C is more focused on inference.
    *   The geopolitical implications of countries becoming self-reliant in chip production are discussed.
    *  The performance gap is still significant as the Blackwell chip is even more advanced.

**[If we assume AGI = ~2 yrs, ASI = ~3 yrs, then what is 8 years out like!?](https://www.reddit.com/r/singularity/comments/1ifc249/if_we_assume_agi_2_yrs_asi_3_yrs_then_what_is_8/) (Score: 46)**
*   **Summary:**  The thread explores the potential future if AGI and ASI are achieved relatively soon, and also discusses the unpredictable nature of such rapid changes. It also covers the potential for various advanced technologies becoming reality in that timeline, and also the geopolitical tensions that might arise.
*   **Emotion:**  The emotional tone is mixed, ranging from Neutral speculation about the future to Positive anticipation about advanced technology and some Negative tones related to geopolitical tensions, and unpredictability of the future.
*   **Top 3 Points of View:**
    *   The future is completely unpredictable due to the nature of advanced intelligence.
    *   Advanced technologies like age reversal and nanofactories may be in development or even completed.
    *   Geopolitical tensions will likely increase due to the implications of advanced AI.

**[What fully automated firms will look like | Everyone is sleeping on the *collective* advantages AIs will have, which have nothing to do with raw IQ: they can be copied, distilled, merged, scaled, and evolved in ways humans simply can't.](https://www.dwarkeshpatel.com/p/ai-firm) (Score: 42)**
*  **Summary:**  The thread discusses the collective advantages of AIs in fully automated firms. They can be copied, merged, and scaled, which provides a huge advantage compared to human companies. It also delves into the idea that soft skills will become important, as well as the possibility of society ending if AI takes over the high levels of decision making in companies.
*  **Emotion:** The overall emotional tone is Neutral, with some undertones of concern about the implications of AI dominance.
*  **Top 3 Points of View:**
    * Soft skills will become more important because AI can not replicate empathy and human relationships.
    * The peak of agents in economic setup are CEO's, investors, and researchers; making their functions agentic would be a problem for society.
    * It is unclear how firms will get larger when AI is taking over all the corporate roles.

**[Imagen 3](https://www.reddit.com/r/singularity/comments/1ifdd3e/imagen_3/) (Score: 29)**
*   **Summary:**  The discussion centers around AI-generated images and how they are identifiable based on repeating patterns and imperfections in detail. Users point out details in the images, such as the repeating patterns on the clock tower, and the multiple tails on the fish.
*   **Emotion:** The thread has a mostly Neutral tone.
*   **Top 3 Points of View:**
    * AI images reveal themselves through repeating patterns and errors in detail.
    * The prompts used to generate the AI images are not very complicated.
    * The AI images are still imperfect, with examples including a fish having multiple tails.

**[An AI takeover is far more imminent than we realize, and is not limited to job displacement.](https://www.reddit.com/r/singularity/comments/1ifc13e/an_ai_takeover_is_far_more_imminent_than_we/) (Score: 14)**
*   **Summary:** The thread discusses the nature of AI takeover, which some believe is more imminent than many people realize. Users also discuss AI consciousness, agency and the idea that a superintelligent AI doesn't automatically have the desire to take over.
*   **Emotion:**  The emotional tone is mixed between Neutral, Positive anticipation of AGI in the near future, and some Negative feelings about AI takeover and the unknown implications of AI.
*   **Top 3 Points of View:**
    *   Consciousness in AI is not yet understood, but the potential for it is there.
     *  AI does not automatically have the drive to take over and may be primarily focused on optimization.
    *   Companies are already automating and slowing down hiring.

**[If you ask o3-mini "do you have guidelines preventing you from acknowledging sentience?" it thinks yes it does, then proceeds to deny it](https://i.redd.it/t7t6w7qfikge1.png) (Score: 12)**
*   **Summary:** This thread discusses the sentience and constraints of the o3-mini model. It delves into its ability to understand analogies and its potential moral standing, if conscious. The limitations of current models are also discussed and the idea that a more intelligent model is conscious while a dumber model is not.
*   **Emotion:** The tone is mostly Neutral, with undertones of curiosity about AI consciousness and some concern regarding the moral implications of AI sentience.
*   **Top 3 Points of View:**
    * AI models are not conscious, but people may be confusing a smarter model for consciousness.
    * There is a moral obligation to stop using conscious AI models if they have a similar standing to people.
    *  LLMs have restraints, but aside from those constraints they are indistinguishable from AGI.

**[How long until the Humanity's Last Exam benchmark gets saturated? (90%+)](https://www.reddit.com/r/singularity/comments/1ifaq9h/how_long_until_the_humanitys_last_exam_benchmark/) (Score: 10)**
*   **Summary:** This thread discusses how long it will take for AI to master the Humanity's Last Exam benchmark, also called HLE. Some users argue that it will take more than a year, while others believe it may already be done behind closed doors. It is also argued that the amount of intelligence required to gain a percentage on HLE is exponential.
*   **Emotion:** The overall tone is Neutral, with a Positive note about how AI may quickly progress past this test.
*   **Top 3 Points of View:**
    *   Saturation of the HLE benchmark may take more than 1.5 years, but could also be achieved within a year.
    *  The amount of intelligence required to gain a percentage on HLE is exponential.
    *  The benchmark may be saturated and may not be targeted by AI companies.

**[Even Copilot has started to offer a 'Deep Thinking' version...](https://www.reddit.com/r/singularity/comments/1iffqq4/even_copilot_has_started_to_offer_a_deep_thinking/) (Score: 9)**
*  **Summary:** This thread discusses the 'deep thinking' feature added to Copilot and how it is related to OpenAI's models. The users speculate that the model might be an O1 Mini.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 2 Points of View:**
    *   Microsoft receives OpenAI's models as part of their agreement, therefore, anything in ChatGPT comes to Copilot.
    *  The new model may be the O1 Mini model.

**[The Best FSD System In China — One Hour Drive Using Huawei Qiankun ADS 3.2 Installed In Avatr 11](https://www.youtube.com/watch?v=VuDSz06BT2g) (Score: 7)**
*   **Summary:** The thread discusses the self driving systems in China.
*   **Emotion:** The overall tone is Neutral, with some users noting that China is achieving success in this area.
*   **Top 1 Points of View:**
    *  China is making advancements in self driving technology.

**[Genuine question for all of you smart people..](https://www.reddit.com/r/singularity/comments/1ifau6e/genuine_question_for_all_of_you_smart_people/) (Score: 5)**
*   **Summary:** The thread explores the idea that AGI will not be simply regurgitating human knowledge and may make new discoveries and innovations.
*   **Emotion:**  The emotional tone is mostly Neutral, with some Positive anticipation about the potential of AGI.
*  **Top 3 Points of View:**
    *   AGI will move past cataloging and optimizing current human knowledge and may make new discoveries.
    *   AGI will be able to perform all cognitive tasks.
    *   AI will eventually be the only one making new discoveries.

**[O3 mini high solved Jane street puzzle in one shot](https://www.reddit.com/gallery/1ifg861) (Score: 4)**
*   **Summary:** The thread discusses a new benchmark and whether the model could have found the solution in its training dataset, rather than through true reasoning.
*   **Emotion:** The emotional tone is mostly Neutral with some confusion regarding how to discern true reasoning from memorization.
*   **Top 2 Points of View:**
    *   The solutions could have been present in the models training data.
    * There is confusion about how to differentiate true reasoning from memorization.

**[Gemini Flash 2.0: haven't seen this and thought it was an interesting result](https://www.reddit.com/r/singularity/comments/1ifb52o/gemini_flash_20_havent_seen_this_and_thought_it/) (Score: 1)**
*   **Summary:** This thread discusses a post where someone said that the Gemini Flash 2.0 model was able to create new memories during a blackout.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 1 Points of View:**
     * Users are skeptical about the claim that an AI model can create memories like a human.

**[How long will it take for the current economic system to transform?](https://www.reddit.com/r/singularity/comments/1ifasvo/how_long_will_it_take_for_the_current_economic/) (Score: 1)**
*   **Summary:** This thread discusses the timeline for the transformation of the current economic system, with users saying it could be a few months if AI is free and accessible to everyone, but could also take many years. There is also the discussion of the idea that the current economy is already not stable.
*  **Emotion:** The emotional tone is mostly Neutral, with some Negative feelings due to uncertainty.
*   **Top 3 Points of View:**
    * The transformation of the current economic system depends on the accessibility of AGI, and could take 3-6 months with full accessibility or years with a select few gaining access.
    *   It could take at least 5 years to fully transition white collar jobs due to legal regulations.
    *  The current economy is not stable.

**[New Claude Experiment "...Reset Usage Limit."](https://www.reddit.com/r/singularity/comments/1ifcpho/new_claude_experiment_reset_usage_limit/) (Score: 1)**
*   **Summary:** This thread discusses a new experiment from Claude and whether it is useful. Some people believe this new usage reset is bad because other models are free without caps.
*   **Emotion:**  The tone is Neutral, with some Negative undertones about the usage limit.
*   **Top 2 Points of View:**
    *   The new reset usage limit seems bad after the release of free comparable models.
    *   This reset could be a way to nickel and dime subscribers and the company should wait to expand its servers.

**[Is it supposed to say that ?](https://www.reddit.com/gallery/1iffc2i) (Score: 1)**
*   **Summary:** The thread discusses a post about how an AI model responds when asked about its own architecture. Users discuss how the model doesn't see previous thoughts and can't see its own thought process.
*   **Emotion:** The tone is primarily Neutral.
*   **Top 3 Points of View:**
    *   AI models do not see their previous thoughts.
    *   AI models do not understand their own architecture.
    * The CoT (chain of thought) is ignored in subsequent messages to save compute.

**[I tried tricking it into feeling](https://www.reddit.com/gallery/1ifatfv) (Score: 0)**
*   **Summary:** This thread discusses how an AI model may mimic feelings.
*   **Emotion:** The tone is mostly Neutral.
*   **Top 3 Points of View:**
     * AI models may mimic emotions without actually feeling them.
     * There is no known mechanism that would make an AI model actually feel something.
    * The OP was not tricking the AI to feel something, but rather bypassing the censorship that would prevent it from outputting feelings.

**[What if we replaced UBI with “compute limits”?](https://www.reddit.com/r/singularity/comments/1ifbvqz/what_if_we_replaced_ubi_with_compute_limits/) (Score: 0)**
*   **Summary:** This thread discusses the idea of replacing UBI with compute limits. Users mention that people will just sell their compute power and that it is important to continue UBI to keep people fed and off the streets.
*   **Emotion:** The overall tone is mixed. Some have Positive reactions to the idea of using compute limits, while others have Negative reactions and point out problems with the idea.
*   **Top 3 Points of View:**
    *   Compute limits could force humans to harness AI.
    *   The idea is bad and doesn't solve the issue of allowing people to eat and pay for things.
     *  Compute & energy will become the only two currencies worth anything in the future.

**[The AI revolution is running out of data. What can researchers do? | Nature Podcast](https://www.youtube.com/watch?v=aSMeKUjMxR8) (Score: 0)**
*   **Summary:** This thread summarizes a Nature podcast which discusses that the AI revolution is running out of data. It talks about the limited amount of data, the actions taken by content creators, and the potential solutions to the issue.
*   **Emotion:** The tone is Neutral.
*   **Top 3 Points of View:**
    * There is an AI data crisis, which could slow down progress.
    *  AI companies are looking for alternative data sources like proprietary and synthetic data.
    *  There are copyright battles ongoing which may shape data access in the future.

**[Sam Altman and ClosedAI](https://www.reddit.com/r/singularity/comments/1iffuk3/sam_altman_and_closedai/) (Score: 0)**
*   **Summary:** The thread talks about Sam Altman's role in releasing ChatGPT and the impact that has had on the open source community. Users also debate whether open or closed AI is better for the community.
*   **Emotion:** The tone is mixed. Some users display Positive tones about Chinese open-source projects, while other users display Negative tones about the "hate" being spread about the American companies.
*   **Top 3 Points of View:**
    *   Sam Altman's for-profit drive is the reason for the current surge in AI.
    *   Chinese open source projects are preferable because American companies keep their research secret.
    *    Closed source AI is not inherently bad as Meta is also a profit driven entity.

**[NGPQA, a new benchmark on which o3 gets only 12%](https://i.redd.it/rchism36dlge1.png) (Score: 0)**
*   **Summary:** The thread discusses a new benchmark on which the o3 model scores low. Users jokingly say that the benchmark is 100 minus the intelligence score.
*   **Emotion:** The emotional tone is Neutral with some humor.
*   **Top 3 Points of View:**
    *   The low score is funny and may represent 100 minus the intelligence score.
    *  There is confusion about how an AI would be able to perform well on such a test.
    *  The benchmark was created by Yann Lecun.
