---
title: "Stable Diffusion Subreddit"
date: "2025-09-14"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Created a video of me aging using Nano Banana + Wan FLF](https://v.redd.it/1azvkz8tb6pf1) (Score: 41)
    *   A user created a video showcasing their aging process using Nano Banana and Wan FLF, and shared the video for community feedback.
2.  [Release Diffusion Toolkit v1.9.1 · RupertAvery/DiffusionToolkit](https://github.com/RupertAvery/DiffusionToolkit/releases/tag/v1.9.1) (Score: 29)
    *   A new version of Diffusion Toolkit was released, leading to discussions about features, requests for future updates, and general appreciation for the tool.
3.  [Yet another Flux+Wan22 clip — starring myself](https://v.redd.it/d6s9r9tv26pf1) (Score: 19)
    *   The user shared another clip using Flux+Wan22. The community asked about training tutorials and the process of creating the Lora for images or video.
4.  [Yet another Wan workflow - Raw Full resolution (no LTXV) vs Render at half-resolution(no LTXV) + 2nd stage denoise/LTXV ( save ~50% compute time)](https://v.redd.it/n1lwr09wh6pf1) (Score: 7)
    *   A user presents a workflow that balances resolution and compute time for video generation. Others are requesting render time estimations and what GPU was used for the workflow.
5.  [how do you add 2 images side by side to load?](https://www.reddit.com/r/StableDiffusion/comments/1ngvliq/how_do_you_add_2_images_side_by_side_to_load/) (Score: 2)
    *   A user asked for help to add 2 images side by side. Other users suggested using an image stitch node, ComfyUI, and QwenEdit.
6.  [Dataset for LoRA training, where to find free to use datset?](https://www.reddit.com/r/StableDiffusion/comments/1ngz9wg/dataset_for_lora_training_where_to_find_free_to/) (Score: 2)
    *   The user asked where to find a free dataset for LoRA training. Other users provided links to free datasets.
7.  [phase 2 training after flux lora on civit ai](https://www.reddit.com/r/StableDiffusion/comments/1ngrgpx/phase_2_training_after_flux_lora_on_civit_ai/) (Score: 1)
    *   A user asked about phase 2 training after flux lora on civit ai. The community provided tools like Fluxgym and Pinokio, and discussed the number of repeats with kohya.
8.  [Best option to blend a person from one photo into another?](https://www.reddit.com/r/StableDiffusion/comments/1ngrnpb/best_option_to_blend_a_person_from_one_photo_into/) (Score: 1)
    *   The user is looking for the best way to blend a person from one photo into another. Other users recommended Qwen Edit with the inscene lora.
9.  [Steps/repeats vs epoch for wan video?](https://www.reddit.com/r/StableDiffusion/comments/1ngufz1/stepsrepeats_vs_epoch_for_wan_video/) (Score: 1)
    *   The user is asking about the number of steps, repeats, and epochs for Wan video. Other users shared their personal preferences.
10. [SD rendering grey image](https://www.reddit.com/r/StableDiffusion/comments/1ngxgly/sd_rendering_grey_image/) (Score: 1)
    *   The user is experiencing grey image renders in Stable Diffusion. Other users pointed out that the user may need to use Forge for Flux finetune or Pinokio.
11. [Qwen Image is not following prompt, what could cause it?](https://www.reddit.com/r/StableDiffusion/comments/1ngzp9s/qwen_image_is_not_following_prompt_what_could/) (Score: 1)
    *   The user is having issues with Qwen Image not following the prompt. They shared an image for better understanding.
12. [Qwen Edit LoRa made for client](https://www.reddit.com/gallery/1ngy7y7) (Score: 0)
    *   The user shared a Qwen Edit LoRa made for the client. Other users questioned the training data and requested if the user will share with the community.
13. [AI cinematic video](https://www.reddit.com/r/StableDiffusion/comments/1ngr0g6/ai_cinematic_video/) (Score: 0)
    *   The user shared an AI cinematic video. Some users commented that it could be architectural rendering from 3D models.
14. [Free I2V i can use for broke people?](https://www.reddit.com/r/StableDiffusion/comments/1ngrs19/free_i2v_i_can_use_for_broke_people/) (Score: 0)
    *   A user is looking for free I2V options. The community suggested apob ai, Slop.club, Krea ai, Hailuo ai and dreamina.
15. [AI to create image based on multiple input files.](https://www.reddit.com/r/StableDiffusion/comments/1ngvltb/ai_to_create_image_based_on_multiple_input_files/) (Score: 0)
    *   A user is looking for an AI that can create images based on multiple input files. The community recommended Qwen Edit and Kontext, but acknowledged their issues with consistency.

# Detailed Analysis by Thread
**[Created a video of me aging using Nano Banana + Wan FLF (Score: 41)](https://v.redd.it/1azvkz8tb6pf1)**
*  **Summary:** A user showcased a video they created depicting their aging process using Nano Banana and Wan FLF.
*  **Emotion:** The overall sentiment is Neutral (0.967022180557251).
*  **Top 3 Points of View:**
    * The user created a video.
    * The user used Nano Banana + Wan FLF.
    * The video depicts the user aging.

**[Release Diffusion Toolkit v1.9.1 · RupertAvery/DiffusionToolkit (Score: 29)](https://github.com/RupertAvery/DiffusionToolkit/releases/tag/v1.9.1)**
*  **Summary:** This thread discusses the release of Diffusion Toolkit v1.9.1. Users are expressing appreciation for the tool and suggesting new features.
*  **Emotion:** The overall emotional tone is Positive. The sentiment scores are 0.8235942721366882, 0.5825875997543335, 0.8213346600532532.
*  **Top 3 Points of View:**
    * The community loves the tool and appreciates the developers.
    * Users are requesting the ability to read workflows from JPEG files.
    * Users are requesting support for wan2gp videos.

**[Yet another Flux+Wan22 clip — starring myself (Score: 19)](https://v.redd.it/d6s9r9tv26pf1)**
*  **Summary:** A user shared another clip using Flux+Wan22. The community asked about training tutorials and the process of creating the Lora for images or video.
*  **Emotion:** The overall emotional tone is mixed, with some positive sentiment (0.9192383289337158, 0.8074407577514648) and neutral sentiment (0.6437258124351501, 0.5799596905708313, 0.5799596905708313).
*  **Top 3 Points of View:**
    * The community finds the clips great and fun.
    * People are seeking tutorials for training Flux.
    * People are asking about creating Lora for images or wan video.

**[Yet another Wan workflow - Raw Full resolution (no LTXV) vs Render at half-resolution(no LTXV) + 2nd stage denoise/LTXV ( save ~50% compute time) (Score: 7)](https://v.redd.it/n1lwr09wh6pf1)**
*  **Summary:** A user presents a workflow that balances resolution and compute time for video generation. Others are requesting render time estimations and what GPU was used for the workflow.
*  **Emotion:** The overall sentiment is Neutral (0.7846603989601135).
*  **Top 3 Points of View:**
    * The user shared a new workflow.
    * The community is interested in render time estimations.
    * The community is interested in which GPU was used.

**[how do you add 2 images side by side to load? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1ngvliq/how_do_you_add_2_images_side_by_side_to_load/)**
*  **Summary:** A user asked for help to add 2 images side by side. Other users suggested using an image stitch node, ComfyUI, and QwenEdit.
*  **Emotion:** The overall sentiment is Neutral (0.9703521728515625, 0.9411462545394897, 0.9133898615837097).
*  **Top 3 Points of View:**
    * The user is seeking help adding 2 images side by side.
    * The community suggested using an image stitch node.
    * The community suggested ComfyUI and QwenEdit.

**[Dataset for LoRA training, where to find free to use datset? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1ngz9wg/dataset_for_lora_training_where_to_find_free_to/)**
*  **Summary:** The user asked where to find a free dataset for LoRA training. Other users provided links to free datasets.
*  **Emotion:** The overall sentiment is Neutral (0.9628728628158569).
*  **Top 3 Points of View:**
    * The user is looking for a free dataset for LoRA training.
    * The community is sharing links to free datasets.

**[phase 2 training after flux lora on civit ai (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ngrgpx/phase_2_training_after_flux_lora_on_civit_ai/)**
*  **Summary:** A user asked about phase 2 training after flux lora on civit ai. The community provided tools like Fluxgym and Pinokio, and discussed the number of repeats with kohya.
*  **Emotion:** The overall sentiment is Neutral (0.887361466884613, 0.707415759563446).
*  **Top 3 Points of View:**
    * The user needs help with phase 2 training after flux lora.
    * The community suggested Fluxgym and Pinokio.
    * The community discussed the number of repeats with kohya.

**[Best option to blend a person from one photo into another? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ngrnpb/best_option_to_blend_a_person_from_one_photo_into/)**
*  **Summary:** The user is looking for the best way to blend a person from one photo into another. Other users recommended Qwen Edit with the inscene lora.
*  **Emotion:** The overall sentiment is Neutral (0.7753672003746033, 0.6351644396781921).
*  **Top 3 Points of View:**
    * The user is looking for a way to blend a person from one photo into another.
    * Qwen Edit with the inscene lora was recommended.
    * The community suggested the civitai models.

**[Steps/repeats vs epoch for wan video? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ngufz1/stepsrepeats_vs_epoch_for_wan_video/)**
*  **Summary:** The user is asking about the number of steps, repeats, and epochs for Wan video. Other users shared their personal preferences.
*  **Emotion:** The overall sentiment is Neutral (0.6063050627708435).
*  **Top 3 Points of View:**
    * The user needs help with steps, repeats, and epochs for Wan video.
    * The community suggested to go with 1 rep.
    * The community aims for 20 to 30 epochs and 2000-3000 steps total.

**[SD rendering grey image (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ngxgly/sd_rendering_grey_image/)**
*  **Summary:** The user is experiencing grey image renders in Stable Diffusion. Other users pointed out that the user may need to use Forge for Flux finetune or Pinokio.
*  **Emotion:** The overall emotional tone is mixed, with some neutral sentiment (0.9507685303688049) and negative sentiment (0.5818614959716797).
*  **Top 3 Points of View:**
    * The user needs help with grey image renders in Stable Diffusion.
    * Other users pointed out that the user may need to use Forge for Flux finetune.
    * Sd 1.5 doesn't work very well with the 50xx series, but Forge can run it.

**[Qwen Image is not following prompt, what could cause it? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ngzp9s/qwen_image_is_not_following_prompt_what_could/)**
*  **Summary:** The user is having issues with Qwen Image not following the prompt. They shared an image for better understanding.
*  **Emotion:** The overall sentiment is Neutral (0.9603597521781921).
*  **Top 3 Points of View:**
    * The user needs help with Qwen Image not following the prompt.
    * The user shared an image for better understanding.

**[Qwen Edit LoRa made for client (Score: 0)](https://www.reddit.com/gallery/1ngy7y7)**
*  **Summary:** The user shared a Qwen Edit LoRa made for the client. Other users questioned the training data and requested if the user will share with the community.
*  **Emotion:** The overall sentiment is Neutral (0.5978712439537048, 0.4564293324947357, 0.6702777147293091).
*  **Top 3 Points of View:**
    * The user shared a Qwen Edit LoRa made for the client.
    * The community is interested in the training data.
    * The community is interested if the user will share it.

**[AI cinematic video (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ngr0g6/ai_cinematic_video/)**
*  **Summary:** The user shared an AI cinematic video. Some users commented that it could be architectural rendering from 3D models.
*  **Emotion:** The overall sentiment is Neutral (0.9658575654029846, 0.7708664536476135, 0.8765340447425842).
*  **Top 3 Points of View:**
    * The user shared an AI cinematic video.
    * The community thinks it's low quality.
    * The community thinks it's architectural rendering from 3D models.

**[Free I2V i can use for broke people? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ngrs19/free_i2v_i_can_use_for_broke_people/)**
*  **Summary:** A user is looking for free I2V options. The community suggested apob ai, Slop.club, Krea ai, Hailuo ai and dreamina.
*  **Emotion:** The overall emotional tone is mixed, with some neutral sentiment (0.9682654142379761, 0.9647013545036316, 0.9673831462860107, 0.9524220824241638, 0.9234710931777954, 0.8095413446426392, 0.8938653469085693, 0.6476778388023376, 0.9706084728240967) and positive sentiment (0.7982367277145386).
*  **Top 3 Points of View:**
    * The user is looking for free I2V options.
    * The community suggested apob ai, Slop.club, and Krea ai.
    * The community suggested Hailuo ai and dreamina.

**[AI to create image based on multiple input files. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ngvltb/ai_to_create_image_based_on_multiple_input_files/)**
*  **Summary:** A user is looking for an AI that can create images based on multiple input files. The community recommended Qwen Edit and Kontext, but acknowledged their issues with consistency.
*  **Emotion:** The overall sentiment is Neutral (0.31324297189712524).
*  **Top 3 Points of View:**
    * The user is looking for an AI that can create images based on multiple input files.
    * Qwen Edit and Kontext were recommended.
    * The community acknowledged their issues with consistency.
