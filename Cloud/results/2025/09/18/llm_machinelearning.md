---
title: "Machine Learning Subreddit"
date: "2025-09-18"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "reddit", "AI"]
---

# Overall Ranking and Top Discussions
1.  [[N] Both OpenAI and DeepMind are claiming ICPC gold-level performance](https://www.reddit.com/r/MachineLearning/comments/1njny8k/n_both_openai_and_deepmind_are_claiming_icpc/) (Score: 62)
    *   The discussion revolves around claims by OpenAI and DeepMind that their models have achieved ICPC gold-level performance in coding competitions. Users discuss the specifics of these claims, the need for reproducibility, and whether these claims are more marketing than substance.
2.  [[R] Uni-CoT: A Unified CoT Framework that Integrates Text+Image reasoning!](https://www.reddit.com/gallery/1nk0txd) (Score: 35)
    *   This thread discusses a new framework called Uni-CoT that integrates text and image reasoning. Users share links to the paper, GitHub repository, and project page. There's excitement about its potential and a desire to test it out once available.
3.  [[D] AAAI 2026: Why did some papers get 3 human reviewers in Phase 1?](https://www.reddit.com/r/MachineLearning/comments/1nk1b7o/d_aaai_2026_why_did_some_papers_get_3_human/) (Score: 10)
    *   The discussion centers around why some papers submitted to AAAI 2026 received three human reviews in the first phase. Possible explanations include emergency reviewers being recruited and original reviewers submitting late reviews.
4.  [[P] Open dataset: 40M GitHub repositories (2015 → mid-2025) — rich metadata for ML](https://www.reddit.com/r/MachineLearning/comments/1nkhqgn/p_open_dataset_40m_github_repositories_2015/) (Score: 4)
    *   This thread announces the release of an open dataset containing metadata for 40 million GitHub repositories. Links to the dataset on Hugging Face and the GitHub repository are provided.
5.  [First time submitting to a workshop - what exactly to expect? [D]](https://www.reddit.com/r/MachineLearning/comments/1nkcfgc/first_time_submitting_to_a_workshop_what_exactly/) (Score: 2)
    *   The discussion is about what to expect when submitting to a workshop, specifically regarding the rigor and depth expected compared to conference papers. Contributors discuss the purpose of workshops, the benefits of reviewer feedback, and the level of detail required for different page lengths.
6.  [[P] Built a CLI to turn PDFs and docs into fine tuning datasets](https://www.reddit.com/r/MachineLearning/comments/1nka2g3/p_built_a_cli_to_turn_pdfs_and_docs_into_fine/) (Score: 2)
    *   A CLI tool for converting PDFs and documents into fine-tuning datasets is presented. Users discuss the tool's usefulness, particularly for local fine-tuning, and express excitement about the planned Ollama integration. OCR support for scanned documents is suggested.
7.  [[D] What is the best part came this year in your opinion and why?](https://www.reddit.com/r/MachineLearning/comments/1nk0uvm/d_what_is_the_best_part_came_this_year_in_your/) (Score: 0)
    *   A user asks about the most interesting development in the field this year. One response notes the rise of reasoning models.
8.  [[D] ICLR Reproducibility statement](https://www.reddit.com/r/MachineLearning/comments/1njzuje/d_iclr_reproducibility_statement/) (Score: 0)
    *   The thread is about the ICLR reproducibility statement and page limits for submissions. One comment clarifies that ethical statements, reproducibility statements, and appendices are not included in the core page limit.
9.  [[D] Student paper?](https://www.reddit.com/r/MachineLearning/comments/1njuo8h/d_student_paper/) (Score: 0)
    *   This thread discusses the meaning of the "student paper" marker when submitting a paper and whether it is appropriate to mark it as such. One response notes that it's only relevant if the submitter is eligible for a student paper award. Another suggests looking into the "Tiny Papers" track at ICLR workshops.
10. [[R] Reproducible prompt protocol induces consistent self-referential responses across LLMs (Claude, GPT, Gemini)](https://www.reddit.com/r/MachineLearning/comments/1njp1ly/r_reproducible_prompt_protocol_induces_consistent/) (Score: 0)
    *   The thread is about a reproducible prompt protocol that induces consistent self-referential responses across LLMs. A question is asked about what a response would look like from an LLM *without* self-referential awareness.
11. [[R] PCA Isn’t Always Compression: The Yeole Ratio Tells You When It Actually Is](https://www.reddit.com/r/MachineLearning/comments/1nkgguy/r_pca_isnt_always_compression_the_yeole_ratio/) (Score: 0)
    *   This thread discusses a paper claiming PCA isn't always compression. One commenter dismisses it as a low-effort self-promotion attempt, and makes fun of the naming of the ratio.

# Detailed Analysis by Thread
**[[N] Both OpenAI and DeepMind are claiming ICPC gold-level performance (Score: 62)](https://www.reddit.com/r/MachineLearning/comments/1njny8k/n_both_openai_and_deepmind_are_claiming_icpc/)**
*   **Summary:** The thread discusses claims by OpenAI and DeepMind about achieving ICPC gold-level performance. Users debate the details, verifiability, and potential marketing aspects of these claims.
*   **Emotion:** The emotional tone is predominantly Neutral, with some expressions of Positive sentiment. There's a mix of excitement about progress in AI and skepticism about the validity and transparency of the claims.
*   **Top 3 Points of View:**
    *   OpenAI's GPT-5, possibly with an Experimental Reasoning Model, solved 12 ICPC problems. Details are needed for reproducibility.
    *   This indicates progress towards solving open problems, suggesting the possibility of self-recursive improvements in the near future.
    *   The claims are potentially marketing stunts and lack verifiability and reproducibility.

**[[R] Uni-CoT: A Unified CoT Framework that Integrates Text+Image reasoning! (Score: 35)](https://www.reddit.com/gallery/1nk0txd)**
*   **Summary:**  The thread is about a new framework, Uni-CoT, for text and image reasoning. Users share links to the paper, code repository, and project page.
*   **Emotion:** The emotional tone is generally Neutral with some instances of Positive sentiment. There is interest in the framework and eagerness to test it.
*   **Top 3 Points of View:**
    *   The Uni-CoT framework and related resources (paper, code, project page) are being shared.
    *   Existing VLM models are effective with CoT prompting, but lack reasoning capabilities.
    *   The Uni-CoT framework is impressive, and there's a desire to test it, but it requires significant GPU resources.

**[[D] AAAI 2026: Why did some papers get 3 human reviewers in Phase 1? (Score: 10)](https://www.reddit.com/r/MachineLearning/comments/1nk1b7o/d_aaai_2026_why_did_some_papers_get_3_human/)**
*   **Summary:** The thread discusses the reasons why some papers submitted to AAAI 2026 received three human reviews during Phase 1.
*   **Emotion:** The overall emotional tone is Neutral, with comments primarily focused on providing explanations and observations.
*   **Top 3 Points of View:**
    *   The most likely explanation is that ACs recruited emergency reviewers when original reviewers were late, resulting in some papers receiving three reviews.
    *   Some authors who passed Phase 1 did not see any reviews.
    *   The target was to get 3 reviews per paper.

**[[P] Open dataset: 40M GitHub repositories (2015 → mid-2025) — rich metadata for ML (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1nkhqgn/p_open_dataset_40m_github_repositories_2015/)**
*   **Summary:** This thread announces the release of a large open dataset of GitHub repository metadata for machine learning purposes.
*   **Emotion:** The emotional tone is Neutral, mainly providing information about the dataset.
*   **Top 3 Points of View:**
    *   The user provides links to the dataset on Hugging Face and the GitHub repository.

**[First time submitting to a workshop - what exactly to expect? [D] (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1nkcfgc/first_time_submitting_to_a_workshop_what_exactly/)**
*   **Summary:** This thread is a discussion about what to expect when submitting to a workshop, particularly the differences compared to submitting to a conference.
*   **Emotion:** The overall tone is Neutral, with informative responses.
*   **Top 3 Points of View:**
    *   Workshop papers are for works that may not have the rigor of conference papers but present interesting ideas that could benefit from feedback.
    *   Submitting to workshops can be a good way to get feedback before submitting to conferences.
    *   The page length dictates how deeply the experiment has to be described.

**[[P] Built a CLI to turn PDFs and docs into fine tuning datasets (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1nka2g3/p_built_a_cli_to_turn_pdfs_and_docs_into_fine/)**
*   **Summary:** A user announces the creation of a CLI tool to convert PDFs and documents into fine-tuning datasets.
*   **Emotion:** The overall tone is Neutral with some Positive sentiment. The comment expresses usefulness of the tool.
*   **Top 3 Points of View:**
    *   The CLI tool simplifies local fine-tuning by processing multiple files.
    *   The Ollama integration would enhance privacy.
    *   OCR support for scanned documents would be a valuable addition.

**[[D] What is the best part came this year in your opinion and why? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1nk0uvm/d_what_is_the_best_part_came_this_year_in_your/)**
*   **Summary:** The user asks what the best part came this year and why.
*   **Emotion:** The overall tone is Neutral.
*   **Top 3 Points of View:**
    *   The rise of reasoning models is an intriguing development.

**[[D] ICLR Reproducibility statement (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1njzuje/d_iclr_reproducibility_statement/)**
*   **Summary:** The thread discusses the ICLR reproducibility statement.
*   **Emotion:** The overall tone is Neutral.
*   **Top 3 Points of View:**
    *   The ethical statement, reproducibility statement, and appendix are not counted as part of the core paper and, therefore, are not subject to the page limit.

**[[D] Student paper? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1njuo8h/d_student_paper/)**
*   **Summary:** The thread discusses the meaning of the "student paper" marker and whether it's appropriate to check it.
*   **Emotion:** The overall tone is Neutral.
*   **Top 3 Points of View:**
    *   The student marker is to see if you are eligible for the best student paper award.
    *   ICLR has "Tiny Papers" for first time authors with other underrepresented groups.

**[[R] Reproducible prompt protocol induces consistent self-referential responses across LLMs (Claude, GPT, Gemini) (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1njp1ly/r_reproducible_prompt_protocol_induces_consistent/)**
*   **Summary:** The thread discusses a prompt protocol that induces self-referential responses in LLMs.
*   **Emotion:** The overall tone is Neutral.
*   **Top 3 Points of View:**
    *   What would a response look like for an LLM that does not have self-referential awareness?

**[[R] PCA Isn’t Always Compression: The Yeole Ratio Tells You When It Actually Is (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1nkgguy/r_pca_isnt_always_compression_the_yeole_ratio/)**
*   **Summary:** A discussion of the new ratio for the PCA.
*   **Emotion:** The overall tone is Positive.
*   **Top 3 Points of View:**
    *   The author of the new ratio is getting self-promotion for "research" paper.
