---
title: "Stable Diffusion Subreddit"
date: "2025-09-18"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [VACE 2.2 might not come instead WAN 2.5](https://www.reddit.com/r/StableDiffusion/comments/1nk73ta/vace_22_might_not_come_instead_wan_25/) (Score: 62)
    * The thread discusses the possibility of WAN 2.5 replacing VACE 2.2, with WAN 2.5 potentially offering better performance and requiring only a driving video and reference image to copy actions and adapt lighting.
2.  [Aether IN-D – Cinematic 3D LoRA for Wan 2.2 14B (Image Showcase)](https://www.reddit.com/gallery/1nkee66) (Score: 22)
    * The thread showcases images generated using the Aether IN-D LoRA for Wan 2.2, with users expressing excitement and appreciation for the results.
3.  [SDXL running fully on iOS — 2–10s per image. Would you use it? Is it worth releasing in App Store?](https://www.reddit.com/r/StableDiffusion/comments/1nkecsz/sdxl_running_fully_on_ios_210s_per_image_would/) (Score: 22)
    * The thread discusses the potential of running SDXL on iOS devices, with users debating its feasibility, usefulness, and whether it should be released on the App Store, including concerns about subscription models and comparisons to existing apps.
4.  [PSA: Don't bother with Network Volumes on Runpod](https://www.reddit.com/r/StableDiffusion/comments/1nkcgvp/psa_dont_bother_with_network_volumes_on_runpod/) (Score: 14)
    * The thread advises against using network volumes on Runpod, citing slow startup times and high costs, with users suggesting alternative methods like using shell scripts or Google Drive for storing files.
5.  [What's Qwen Video 7B?](https://www.reddit.com/r/StableDiffusion/comments/1nkbd9w/whats_qwen_video_7b/) (Score: 10)
    * The thread discusses Qwen Video 7B, a multimodal model for understanding real-world short videos, with users providing links to the GitHub repository and describing its capabilities.
6.  [[NOOB FRIENDLY] Installing the Index-TTS2 Gradio App (including Deepspeed): IMO the Most Accurate Voice Cloning Software to Date: Emotion Control is OK but What Stands Out is the Accuracy of Voice and Length of Geneartion](https://youtu.be/FG41RvPEQ-U) (Score: 3)
    * The thread discusses the Index-TTS2 Gradio App, with users asking about its multilingual capabilities.
7.  [Help! My InfiniteTalk character in ComfyUI looks like a conductor!](https://www.reddit.com/r/StableDiffusion/comments/1nk6gzr/help_my_infinitetalk_character_in_comfyui_looks/) (Score: 2)
    * The thread discusses issues with InfiniteTalk character generation in ComfyUI, with users offering suggestions for improving results.
8.  [WAN 2.2 img to video turns out blurry](https://www.reddit.com/r/StableDiffusion/comments/1nkf5v4/wan_22_img_to_video_turns_out_blurry/) (Score: 2)
    * The thread discusses the problem of blurry video output from WAN 2.2, with users suggesting solutions such as using descriptive prompts, checking LoRA settings, and adjusting resolution.
9.  [Help! InfiniteTalk making overexposed, oversaturated videos](https://www.reddit.com/r/StableDiffusion/comments/1nkcsou/help_infinitetalk_making_overexposed/) (Score: 1)
    * The thread discusses issues with overexposure and oversaturation in InfiniteTalk generated videos, with users suggesting using the VACE module.
10. [What model is this?](https://v.redd.it/slnlbnxocypf1) (Score: 0)
    * This thread asks about a specific model used, with one user providing a link and another offering a negative opinion.
11. [Nano banana is way better than I expected. It even recognized the character (Yae Miko) without stating it in my prompt.](https://www.reddit.com/gallery/1nk620b) (Score: 0)
    * This thread compares Nano Banana to other models, with users discussing prompting, LoRAs, and model quality.
12. [Looking for advice on local model](https://www.reddit.com/r/StableDiffusion/comments/1nk7xuk/looking_for_advice_on_local_model/) (Score: 0)
    * This thread seeks advice on choosing a local model, with recommendations for Flux family, WAN 2.2, and Qwen-Image.
13. [Best Free AI for Image to Video?](https://www.reddit.com/r/StableDiffusion/comments/1nk8oy3/best_free_ai_for_image_to_video/) (Score: 0)
    * This thread asks for recommendations on the best free AI for image to video generation, with suggestions including Qwen Image, Flux Dev, Stable Diffusion XL, Pollo.ai, and Pixverse.
14. [AI Imag2vid platform with unlimited generations a month?](https://www.reddit.com/r/StableDiffusion/comments/1nkbw0m/ai_imag2vid_platform_with_unlimited_generations_a/) (Score: 0)
    * This thread seeks information about AI imag2vid platforms with unlimited generations, with suggestions including Freepik AI, Kling, Runway, and Tensorart.
15. [What's the best *free* AI tool for image generation ?](https://www.reddit.com/r/StableDiffusion/comments/1nkc6f8/whats_the_best_free_ai_tool_for_image_generation/) (Score: 0)
    * This thread requests recommendations for the best free AI tool for image generation, with suggestions including Pollo.ai and Nano Banana.
16. [YouTubers or similar to go from novice to master?](https://www.reddit.com/r/StableDiffusion/comments/1nke1qh/youtubers_or_similar_to_go_from_novice_to_master/) (Score: 0)
    * This thread asks for recommendations for YouTubers or similar resources to learn image generation, with advice to search on YouTube and Civitai.
17. [I changed my GPU from RTX 3060 to 5060 ti and now i have this TORCH INDUCTOR ERROR that won't go away](https://www.reddit.com/r/StableDiffusion/comments/1nkhtap/i_changed_my_gpu_from_rtx_3060_to_5060_ti_and_now/) (Score: 0)
    * This thread discusses a TORCH INDUCTOR error encountered after upgrading a GPU, with users suggesting solutions related to ComfyUI versions, Torch versions and sage compatibility.
18. [Possible to generate multiple images with a single prompt/image?](https://www.reddit.com/r/StableDiffusion/comments/1nki4fp/possible_to_generate_multiple_images_with_a/) (Score: 0)
    * This thread asks about generating multiple images with a single prompt, with suggestions for using ComfyUI and referencing older A1111 functionality.

# Detailed Analysis by Thread
**[[VACE 2.2 might not come instead WAN 2.5](https://www.reddit.com/r/StableDiffusion/comments/1nk73ta/vace_22_might_not_come_instead_wan_25/) (Score: 62)](https://www.reddit.com/r/StableDiffusion/comments/1nk73ta/vace_22_might_not_come_instead_wan_25/)**
*  **Summary:**  The thread discusses the possibility of WAN 2.5 replacing VACE 2.2.  WAN 2.5 is described as a better replacement that needs a driving video and a reference image and the model would copy exact action, and even lightning will adapt based on the reference video.
*  **Emotion:** The overall emotional tone is positive, with users expressing hope and anticipation for the new WAN 2.5 model.
*  **Top 3 Points of View:**
    * WAN 2.5 is a significant improvement over VACE, simplifying the process of video generation.
    * Users are curious about the timeline of development, questioning the skipped versions (2.3, 2.4).
    *  There is a desire for longer video generation times and improved native frame referencing.

**[[Aether IN-D – Cinematic 3D LoRA for Wan 2.2 14B (Image Showcase)](https://www.reddit.com/gallery/1nkee66) (Score: 22)](https://www.reddit.com/gallery/1nkee66)**
*  **Summary:** The thread is a showcase of images created with the Aether IN-D LoRA for Wan 2.2, and the community responds with positivity and appreciation.
*  **Emotion:** The emotional tone is overwhelmingly positive, with users expressing excitement and admiration for the LoRA's capabilities.
*  **Top 3 Points of View:**
    * The LoRA produces impressive cinematic 3D images.
    * Users are eager to experiment with the LoRA and find creative uses for it.
    * The LoRA creates images with a strong dynamic.

**[[SDXL running fully on iOS — 2–10s per image. Would you use it? Is it worth releasing in App Store?](https://www.reddit.com/r/StableDiffusion/comments/1nkecsz/sdxl_running_fully_on_ios_210s_per_image_would/) (Score: 22)](https://www.reddit.com/r/StableDiffusion/comments/1nkecsz/sdxl_running_fully_on_ios_210s_per_image_would/)**
*  **Summary:**  This thread discusses an SDXL implementation running on iOS with impressive speed.  The post asks if users would utilize such an app and if it's worth releasing on the app store.
*  **Emotion:** The thread has a mixed emotional tone, with positive reactions to the speed and potential, but also neutral inquiries about technical details and comparisons to existing apps.
*  **Top 3 Points of View:**
    * The speed of SDXL on iOS is impressive and desirable.
    * Users are concerned about the ability to load custom checkpoints and LoRAs.
    * There are existing iOS apps that already offer similar functionality.

**[[PSA: Don't bother with Network Volumes on Runpod](https://www.reddit.com/r/StableDiffusion/comments/1nkcgvp/psa_dont_bother_with_network_volumes_on_runpod/) (Score: 14)](https://www.reddit.com/r/StableDiffusion/comments/1nkcgvp/psa_dont_bother_with_network_volumes_on_runpod/)**
*  **Summary:** The thread is a public service announcement advising against using network volumes on Runpod due to various issues, including slow speeds and unexpected charges.
*  **Emotion:** The emotional tone is mixed, ranging from negative experiences with Runpod's services to positive suggestions for alternative solutions.
*  **Top 3 Points of View:**
    * Network volumes on Runpod are not worth the cost due to slow speeds and other issues.
    *  Using a shell script to install Comfy needs is a better alternative.
    * Automating Runpod to pull and write to Google Drive is another solution.

**[[What's Qwen Video 7B?](https://www.reddit.com/r/StableDiffusion/comments/1nkbd9w/whats_qwen_video_7b/) (Score: 10)](https://www.reddit.com/r/StableDiffusion/comments/1nkbd9w/whats_qwen_video_7b/)**
*  **Summary:**  The thread discusses Qwen Video 7B, a multimodal model designed for understanding and processing real-world short videos.
*  **Emotion:** The emotional tone is primarily neutral and informative, focused on describing the model's capabilities and providing relevant links.
*  **Top 3 Points of View:**
    * Qwen Video 7B is a powerful tool for understanding real-world short videos.
    * The model is capable of multi-granularity timestamped video captioning and summarization.
    * It leverages high-quality data from an automated annotation pipeline.

**[[NOOB FRIENDLY] Installing the Index-TTS2 Gradio App (including Deepspeed): IMO the Most Accurate Voice Cloning Software to Date: Emotion Control is OK but What Stands Out is the Accuracy of Voice and Length of Geneartion](https://youtu.be/FG41RvPEQ-U) (Score: 3)](https://youtu.be/FG41RvPEQ-U)**
*  **Summary:**  The thread discusses the Index-TTS2 Gradio App and its voice cloning capabilities.
*  **Emotion:** The thread has a neutral tone, with users mainly asking questions about the app's multilingual support.
*  **Top 3 Points of View:**
    * The primary concern is whether the app supports multiple languages beyond English.
    * Some ask if it is limited to English/Chinese only.
    * N/A

**[[Help! My InfiniteTalk character in ComfyUI looks like a conductor!](https://www.reddit.com/r/StableDiffusion/comments/1nk6gzr/help_my_infinitetalk_character_in_comfyui_looks/) (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1nk6gzr/help_my_infinitetalk_character_in_comfyui_looks/)**
*  **Summary:** This thread is about a user seeking help with InfiniteTalk character generation in ComfyUI, where the generated character resembles a conductor.
*  **Emotion:**  The tone is mostly neutral with a hint of frustration from the user seeking help.
*  **Top 3 Points of View:**
    * Simpler prompts might yield better results.
    * Try v2v and make video first.
    * Consider using Unianimate with InfiniteTalk.

**[[WAN 2.2 img to video turns out blurry](https://www.reddit.com/r/StableDiffusion/comments/1nkf5v4/wan_22_img_to_video_turns_out_blurry/) (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1nkf5v4/wan_22_img_to_video_turns_out_blurry/)**
*  **Summary:** The thread addresses a user's issue with blurry video output when using WAN 2.2 for image to video conversion.
*  **Emotion:** The thread's tone is neutral, focused on providing technical suggestions to resolve the blurriness issue.
*  **Top 3 Points of View:**
    * The user's prompt may be the issue, suggesting WAN needs narrative prompts.
    * Incorrect lightx LoRAs could be causing the blurriness, suggesting checking for a14 versions.
    * Lowering the resolution might improve the video quality.

**[[Help! InfiniteTalk making overexposed, oversaturated videos](https://www.reddit.com/r/StableDiffusion/comments/1nkcsou/help_infinitetalk_making_overexposed/) (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1nkcsou/help_infinitetalk_making_overexposed/)**
*  **Summary:** A user is seeking help with InfiniteTalk videos that are coming out overexposed and oversaturated.
*  **Emotion:** The emotional tone is slightly positive, as the suggestion offered is helpful.
*  **Top 3 Points of View:**
    * The user should try the VACE module instead of first last frame, as it does a better job at generating continuous video with overlap.
    * N/A
    * N/A

**[[What model is this?](https://v.redd.it/slnlbnxocypf1) (Score: 0)](https://v.redd.it/slnlbnxocypf1)**
*   **Summary:** The thread is a simple question asking for the identification of a model used in a video.
*   **Emotion:** The emotional tone is mixed, with a neutral identification and a negative assessment of the model.
*   **Top 3 Points of View:**
    *   The model is the Nightmare Before Christmas Creator Flux.
    *   The model is considered awful.
    *   N/A

**[[Nano banana is way better than I expected. It even recognized the character (Yae Miko) without stating it in my prompt.](https://www.reddit.com/gallery/1nk620b) (Score: 0)](https://www.reddit.com/gallery/1nk620b)**
*   **Summary:** The thread is a user sharing their positive experience with Nano Banana, noting its ability to recognize a character without being prompted.
*   **Emotion:** The emotional tone is mixed, with the original post being positive but subsequent comments expressing negative sentiments or neutral observations.
*   **Top 3 Points of View:**
    *   Nano Banana performs well, even recognizing characters without specific prompts.
    *   Other AI models in the comparison have issues with rendering feet.
    *   The post is viewed by some as a biased comparison against open-source models.

**[[Looking for advice on local model](https://www.reddit.com/r/StableDiffusion/comments/1nk7xuk/looking_for_advice_on_local_model/) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1nk7xuk/)**
*   **Summary:** A user is seeking advice on which local model to use.
*   **Emotion:** The tone is neutral, providing factual recommendations.
*   **Top 3 Points of View:**
    *   Recommend the Flux family (dev, krea, colossus).
    *   Suggest trying Wan 2.2 or Qwen-Image, noting their specific strengths and weaknesses.
    * wan t2i is most realistic and knows physics better than other models

**[[Best Free AI for Image to Video?](https://www.reddit.com/r/StableDiffusion/comments/1nk8oy3/best_free_ai_for_image_to_video/) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1nk8oy3/)**
*   **Summary:** The thread asks for recommendations on the best free AI tool for generating videos from images.
*   **Emotion:** The overall tone is mixed, with suggestions ranging from neutral recommendations to slightly negative experiences.
*   **Top 3 Points of View:**
    *   Qwen Image and Flux Dev are good open-source options.
    *   Pollo.ai aggregates multiple video generators and offers affordable options.
    *   Pixverse offers a limited but high-quality free option.

**[[AI Imag2vid platform with unlimited generations a month?](https://www.reddit.com/r/StableDiffusion/comments/1nkbw0m/ai_imag2vid_platform_with_unlimited_generations_a/) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1nkbw0m/)**
*   **Summary:** The thread inquires about the existence of AI image-to-video platforms that offer unlimited generations per month.
*   **Emotion:** The thread has a slightly positive emotional tone due to recommendations for affordable alternatives.
*   **Top 3 Points of View:**
    *   Unlimited generation plans are rare due to potential for abuse.
    *   Tensorart is an affordable option with the ability to create multiple accounts.
    *   Renting a computer offers another way to generate videos with more control.

**[[What's the best *free* AI tool for image generation ?](https://www.reddit.com/r/StableDiffusion/comments/1nkc6f8/whats_the_best_free_ai_tool_for_image_generation/) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1nkc6f8/)**
*   **Summary:**  The thread is a request for the best free AI tool for image generation.
*   **Emotion:** The emotional tone is neutral with a mix of helpfulness and slight annoyance at the question.
*   **Top 3 Points of View:**
    *   Pollo.ai is a good option because it’s an index of video generators.
    *   Nano banana is good if you don’t want to buy hardware.
    *   "Best" depends on the use case.

**[[YouTubers or similar to go from novice to master?](https://www.reddit.com/r/StableDiffusion/comments/1nke1qh/youtubers_or_similar_to_go_from_novice_to_master/) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1nke1qh/)**
*   **Summary:** The thread asks for recommendations on YouTubers or similar resources to learn image generation.
*   **Emotion:** The emotional tone is neutral, providing direct advice and suggestions.
*   **Top 3 Points of View:**
    *   Search YouTube for "local image generation tutorial".
    *   Explore Civitai for popular workflows and learn from them.
    *   N/A

**[[I changed my GPU from RTX 3060 to 5060 ti and now i have this TORCH INDUCTOR ERROR that won't go away](https://www.reddit.com/r/StableDiffusion/comments/1nkhtap/i_changed_my_gpu_from_rtx_3060_to_5060_ti_and_now/) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1nkhtap/)**
*   **Summary:** The thread is about a user experiencing a TORCH INDUCTOR error after upgrading their GPU.
*   **Emotion:** The emotional tone is neutral, with users providing technical advice and troubleshooting steps.
*   **Top 3 Points of View:**
    *   Incompatibility with certain versions of Pytorch and Python can cause the error.
    *   ComfyUI versions can cause issues with SAGE compatibility.
    *   Specific Torch and Triton versions might be needed.

**[[Possible to generate multiple images with a single prompt/image?](https://www.reddit.com/r/StableDiffusion/comments/1nki4fp/possible_to_generate_multiple_images_with_a/) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1nki4fp/)**
*   **Summary:**  The thread asks if it's possible to generate multiple images with a single prompt or image.
*   **Emotion:** The emotional tone is neutral, providing suggestions and acknowledging limitations.
*   **Top 3 Points of View:**
    *   ComfyUI offers batch generation options.
    *   ComfyUI allows queing gens.
    *   A1111 used to have this function, which is missed in Comfy.
