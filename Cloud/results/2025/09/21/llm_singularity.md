---
title: "Singularity Subreddit"
date: "2025-09-21"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "singularity", "technology"]
---

# Overall Ranking and Top Discussions
1.  [[D] Goodwill CEO says he’s preparing for an influx of jobless Gen Zers because of AI—and warns, a youth unemployment crisis is already happening](https://www.yahoo.com/news/articles/goodwill-ceo-says-preparing-influx-090000273.html) (Score: 424)
    *   The discussion revolves around the Goodwill CEO's prediction about AI causing job losses for Gen Z, with various opinions on the validity of the claim, the role of corporate greed, and potential solutions like UBI.
2.  [xAI hired google deepmind core team member](https://www.reddit.com/r/singularity/comments/1nmkrwe/xai_hired_google_deepmind_core_team_member/) (Score: 157)
    *   This thread discusses xAI's hiring of a Google DeepMind team member, with comments ranging from the impact of the hire, concerns about working for Elon Musk, and the importance of data in AI development.
3.  [Release of new features for pro users](https://i.redd.it/gl6zssjeekqf1.png) (Score: 101)
    *   The thread speculates on new features being released for a pro version of a product, possibly related to AI, with some hoping for an API or improved memory.
4.  [From an outside perspective the doomers here look like paranoid traumatized people senselessly spreading mass hysteria](https://www.reddit.com/r/singularity/comments/1nmqezp/from_an_outside_perspective_the_doomers_here_look/) (Score: 94)
    *   The discussion centers on the perceived "doomer" mentality in the subreddit concerning the potential negative impacts of AI, with some arguing for a more balanced perspective while others defend the concerns.
5.  [There is a very real possibility that Google, OpenAI, Anthropic, etc. will release their own super cheap versions of Grok-4-fast!](https://www.reddit.com/r/singularity/comments/1nmzqj5/there_is_a_very_real_possibility_that_google/) (Score: 71)
    *   The thread discusses the possibility of companies releasing cheaper versions of AI models like Grok-4, comparing performance, and debating the implications of closed vs. open-source models.
6.  [New SWE-Bench Pro becnchmark  (GPT-5 & Claude 4.1 drop from 70%+ to ~23%)](https://scale.com/leaderboard/swe_bench_pro_public) (Score: 26)
    *   This thread discusses the surprising drop in performance of GPT-5 and Claude 4.1 in the SWE-Bench Pro benchmark, along with the difficulty of creating effective coding benchmarks.
7.  [We just wrapped up a huge week at Figure - here’s what we announced](https://x.com/adcock_brett/status/1969781540805914856#m) (Score: 21)
    *   The thread is about Figure's announcements. Users questioned what ‘human video collection’ is and shared opinions on the company's positioning.
8.  [Live forever as you are now - Ray Kurzweil seen by Alan Resnick](https://www.youtube.com/watch?v=xg29TuWo0Yo) (Score: 16)
    *   The thread discusses a video featuring Ray Kurzweil and asks about the current projects of Alan Resnick.
9.  [How to get  a taste what modern LLMs can do for programmers?](https://www.reddit.com/r/singularity/comments/1nmt53x/how_to_get_a_taste_what_modern_llms_can_do_for/) (Score: 13)
    *   The thread asks for ways programmers can try modern LLMs. Users recommend different services like Codex, ChatGPT, Claude and Google AI Studio.
10. [The introduction of Continual Learning will break how we evaluate models](https://www.reddit.com/r/singularity/comments/1nmynhc/the_introduction_of_continual_learning_will_break/) (Score: 11)
    *   The thread is about the impact of continual learning on how models are evaluated. Users mention privacy concerns, the opaqueness of the models and the possibility of evaluating agents individually.
11. [Magnetic activation of spherical nucleic acids](https://www.reddit.com/r/singularity/comments/1nmv4mn/magnetic_activation_of_spherical_nucleic_acids/) (Score: 22)
    *   The thread simply contains the comment "r/brandnewsentence", indicating the user found the post title to be unusual or novel.
12. ["Magical Thinking on AI"](https://www.reddit.com/r/singularity/comments/1nmuudb/magical_thinking_on_ai/) (Score: 3)
    *   The discussion is about "Magical Thinking on AI". Users express agreement with the need for less magical thinking, while one user found the read depressing and confusing.

# Detailed Analysis by Thread
**[[D] Goodwill CEO says he’s preparing for an influx of jobless Gen Zers because of AI—and warns, a youth unemployment crisis is already happening (Score: 424)](https://www.yahoo.com/news/articles/goodwill-ceo-says-preparing-influx-090000273.html)**
*   **Summary:**  The thread discusses the Goodwill CEO's warning about AI causing job losses for Gen Z. People debated the validity of the claim, the influence of corporate greed, the potential need for UBI, and the role of government and trade policies.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   AI is a real threat to employment, especially for entry-level positions, and governments should prepare for potential job losses.
    *   Corporate greed is the main driver of job losses, not AI, and companies will always seek to maximize profits regardless of technological advancements.
    *   UBI is a potential solution to address job displacement caused by AI and automation.

**[xAI hired google deepmind core team member (Score: 157)](https://www.reddit.com/r/singularity/comments/1nmkrwe/xai_hired_google_deepmind_core_team_member/)**
*   **Summary:** The discussion centers around xAI's hiring of a Google DeepMind team member. Comments varied from excitement about the hire and potential impact, to skepticism about the "core team member" label, and concerns about working for Elon Musk.
*   **Emotion:** The overall emotional tone is Neutral. Some comments also expressed Positive sentiments.
*   **Top 3 Points of View:**
    *   This is a significant hire for xAI, indicating their seriousness about AI research and development.
    *   It is ethically questionable to contribute to AI development under Elon Musk.
    *   Synthetic data and compute power are more important than algorithms for AI advancement.

**[Release of new features for pro users (Score: 101)](https://i.redd.it/gl6zssjeekqf1.png)**
*   **Summary:** The thread discusses the release of new features for pro users of a service, with users speculating on what the features might be, such as an API, improved memory, or Sora 2 integration. Concerns were also raised about additional fees.
*   **Emotion:** The overall emotional tone is Neutral, with some Positive comments expressing excitement.
*   **Top 3 Points of View:**
    *   Users hope for an API to be included in the new features.
    *   The new features will likely involve improved memory or processing capabilities.
    *   There is concern that the new features will come with additional costs on top of the existing subscription fee.

**[From an outside perspective the doomers here look like paranoid traumatized people senselessly spreading mass hysteria (Score: 94)](https://www.reddit.com/r/singularity/comments/1nmqezp/from_an_outside_perspective_the_doomers_here_look/)**
*   **Summary:** The thread is a discussion about the "doomer" perspective on the subreddit, where the original poster argues that many users are paranoid and spreading hysteria about the potential negative consequences of AI. This sparks debate about the validity of these concerns, the need for a balance between hope and realism, and the potential for negative outcomes from AI development.
*   **Emotion:** The overall emotional tone is Neutral with some Negative.
*   **Top 3 Points of View:**
    *   The "doomer" mentality is a form of mass hysteria and is comparable to poor mental health, as pessimism can be delusional.
    *   It's important to acknowledge and discuss the risks and potential negative outcomes of AI development, rather than suppressing these concerns with "toxic positivity."
    *   Both utopian and dystopian viewpoints should be avoided in favor of agnostic thinking.

**[There is a very real possibility that Google, OpenAI, Anthropic, etc. will release their own super cheap versions of Grok-4-fast! (Score: 71)](https://www.reddit.com/r/singularity/comments/1nmzqj5/there_is_a_very_real_possibility_that_google/)**
*   **Summary:** The thread discusses the possibility of companies releasing cheaper versions of AI models like Grok-4, comparing performance, and debating the implications of closed vs. open-source models.
*   **Emotion:** The overall emotional tone is Neutral, with some Positive comments on the performance of Grok-4-fast.
*   **Top 3 Points of View:**
    *   Grok-4-fast and similar models are underhyped, offering comparable performance to more expensive models.
    *   Cheap models could increase the dominance of corporations.
    *   The key factor is whether or not China launches competitive models.

**[New SWE-Bench Pro becnchmark  (GPT-5 & Claude 4.1 drop from 70%+ to ~23%) (Score: 26)](https://scale.com/leaderboard/swe_bench_pro_public)**
*   **Summary:** This thread discusses the surprising drop in performance of GPT-5 and Claude 4.1 in the SWE-Bench Pro benchmark, along with the difficulty of creating effective coding benchmarks.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 2 Points of View:**
    *   It is difficult to create coding benchmarks that are not quickly learned by AI models, leading to inflated scores.
    *   Personal experience with GPT-5 shows much worse results compared to reported benchmark scores.

**[We just wrapped up a huge week at Figure - here’s what we announced (Score: 21)](https://x.com/adcock_brett/status/1969781540805914856#m)**
*   **Summary:** The thread is about Figure's announcements. Users questioned what ‘human video collection’ is and shared opinions on the company's positioning.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 2 Points of View:**
    *   A user asks what 'human video collection' means, suggesting it could be POV videos.
    *   A user believes the company is too early and not in a sweet spot.

**[Live forever as you are now - Ray Kurzweil seen by Alan Resnick (Score: 16)](https://www.youtube.com/watch?v=xg29TuWo0Yo)**
*   **Summary:** The thread discusses a video featuring Ray Kurzweil and asks about the current projects of Alan Resnick.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 1 Point of View:**
    *   The user loves the video and inquires about the current activities of Alan Resnick.

**[How to get  a taste what modern LLMs can do for programmers? (Score: 13)](https://www.reddit.com/r/singularity/comments/1nmt53x/how_to_get_a_taste_what_modern_llms_can_do_for/)**
*   **Summary:** The thread asks for ways programmers can try modern LLMs. Users recommend different services like Codex, ChatGPT, Claude and Google AI Studio.
*   **Emotion:** The overall emotional tone is Neutral with positive comments.
*   **Top 3 Points of View:**
    *   Download cursor and use their trial. You can even try codex inside of cursor as an extension if you want to specifically try that.
    *   A $20 chatGPT subscription and play around with the Codex CLI, make sure to use the codex-high model.
    *   Claude AI is generally the best for coding.

**[The introduction of Continual Learning will break how we evaluate models (Score: 11)](https://www.reddit.com/r/singularity/comments/1nmynhc/the_introduction_of_continual_learning_will_break/)**
*   **Summary:** The thread is about the impact of continual learning on how models are evaluated. Users mention privacy concerns, the opaqueness of the models and the possibility of evaluating agents individually.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   If the model is continually adapting in ways we can't fully observe, how can you measure something inherently opaque?
    *   There are privacy issues relating to continual learning in chatbots. Many users want models to learn personal details about them.
    *   Models would be updating the weights every few days or so and would just serve the latest updated model instead.

**[Magnetic activation of spherical nucleic acids (Score: 22)](https://www.reddit.com/r/singularity/comments/1nmv4mn/magnetic_activation_of_spherical_nucleic_acids/)**
*   **Summary:** The thread simply contains the comment "r/brandnewsentence", indicating the user found the post title to be unusual or novel.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 1 Point of View:**
    *   The poster found the title to be unusual or novel.

**["Magical Thinking on AI" (Score: 3)](https://www.reddit.com/r/singularity/comments/1nmuudb/magical_thinking_on_ai/)**
*   **Summary:** The discussion is about "Magical Thinking on AI". Users express agreement with the need for less magical thinking, while one user found the read depressing and confusing.
*   **Emotion:** The overall emotional tone is Neutral with a positive and a depressing comment.
*   **Top 3 Points of View:**
    *   Friedman is an easy target to criticize.
    *   Agreed, we need less magical thinking.
    *   The article was a depressing and confusing read.
