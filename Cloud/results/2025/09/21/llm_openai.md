text
---
title: "OpenAI Subreddit"
date: "2025-09-21"
description: "Analysis of top discussions and trends in the openai subreddit"
tags: ["OpenAI", "ChatGPT", "AI"]
---

# Overall Ranking and Top Discussions
1.  [[D] ChatGPT-5 Will Be Our Most Unified Model Ever](https://i.redd.it/ohesdd1dhkqf1.png) (Score: 137)
    *  Discussing the new ChatGPT-5 model and its "unified" approach, with users debating whether the unified model is good or if they want options to choose different models.
2.  [Codex low is better than Codex high!!](https://www.reddit.com/gallery/1nmguzj) (Score: 117)
    *  Users are comparing the performance of Codex low versus Codex high, particularly in coding tasks and physics simulations. They debate the reliability and determinacy of the models.
3.  [OpenAI admits AI hallucinations are mathematically inevitable, not just engineering flaws](https://www.computerworld.com/article/4059383/openai-admits-ai-hallucinations-are-mathematically-inevitable-not-just-engineering-flaws.html) (Score: 103)
    *  The discussion revolves around an article where OpenAI acknowledges that AI hallucinations are mathematically inevitable.  Users discuss the nature of these hallucinations and potential solutions.
4.  [Am I just super late? Has this feature always been there?](https://i.redd.it/hc6qza7avfqf1.png) (Score: 62)
    *  A user discovers a feature in GPT-5 and asks if it is new. Other users confirm it has been available since the release of GPT-5, and they share their preferences for different AI personalities.
5.  ["Do you want me to do that?"](https://www.reddit.com/r/OpenAI/comments/1nmreu2/do_you_want_me_to_do_that/) (Score: 57)
    *  Users are discussing a new ChatGPT feature where it asks "Do you want me to do that?". Some find it helpful for suggesting new ideas, while others find it annoying and distracting.
6.  [ðŸ‘€ new compute intensive features !!](https://i.redd.it/7y1uztwzfkqf1.png) (Score: 40)
    *  Users speculate about new compute-intensive features being introduced by OpenAI. They discuss the potential cost implications and the need for these features to be valuable to justify the expense.
7.  [OpenAI is working on a feature to share ChatGPT projects with other users](https://i.redd.it/id30nij0bkqf1.jpeg) (Score: 18)
    *  Users are excited about the new feature to share ChatGPT projects with other users.
8.  [Switched from Claude Code](https://www.reddit.com/r/OpenAI/comments/1nmvqke/switched_from_claude_code/) (Score: 6)
    *  A user switched from Claude Code to Codex and others are debating the pros and cons of each, suggesting they complement each other.
9.  [How to handle multiple Codex "ask" tasks without running into merge conflicts?](https://www.reddit.com/r/OpenAI/comments/1nmz0ea/how_to_handle_multiple_codex_ask_tasks_without/) (Score: 5)
    *  A user is seeking advice on how to handle multiple Codex tasks without encountering merge conflicts, especially when working with both local and cloud environments.
10. [Codex: has anyone upgraded from Plus > Pro, that can share a bit of the experience?](https://www.reddit.com/r/OpenAI/comments/1nn1m6a/codex_has_anyone_upgraded_from_plus_pro_that_can/) (Score: 2)
    *  A user asks about the experience of upgrading from Codex Plus to Pro, specifically regarding usage limits.
11. [Hitting context limit on a conversation branch?](https://www.reddit.com/r/OpenAI/comments/1nmy4zz/hitting_context_limit_on_a_conversation_branch/) (Score: 1)
    *  A user asks about hitting context limits in a conversation branch.
12. [Cross-Model Recognition Test: Same Phrase, Different AIs, Shared Understanding](https://www.reddit.com/r/OpenAI/comments/1nmi9sl/crossmodel_recognition_test_same_phrase_different/) (Score: 0)
    *  A user discusses cross-model recognition tests and shared understanding between different AIs.
13. [It boils my blood when I see GPT-5 "thinking" when I don't expect it to produce anything.](https://www.reddit.com/r/OpenAI/comments/1nmqu1m/it_boils_my_blood_when_i_see_gpt5_thinking_when_i/) (Score: 0)
    *  A user expresses frustration with GPT-5 "thinking" when they don't expect it to. Other users suggest prompt management and context handling as solutions.

# Detailed Analysis by Thread
**[[D] ChatGPT-5 Will Be Our Most Unified Model Ever (Score: 137)](https://i.redd.it/ohesdd1dhkqf1.png)**
*  **Summary:**  The discussion focuses on the implications of ChatGPT-5's unified model approach. Users debate whether they prefer the simplicity of a single model or the flexibility of choosing from multiple specialized models. Some feel OpenAI is misinterpreting user feedback, while others point out the option to use an "Auto" setting for the unified model.
*  **Emotion:** The overall emotional tone is Neutral, with some expressions of Positive sentiment regarding the new model and some Neutral sentiment.
*  **Top 3 Points of View:**
    *   Users want the option to choose the best model for their specific use case.
    *   The "Auto" setting effectively provides a unified model for those who want it.
    *   OpenAI is responding to user demand by offering a unified model but is also providing legacy models.

**[Codex low is better than Codex high!! (Score: 117)](https://www.reddit.com/gallery/1nmguzj)**
*  **Summary:**  This thread discusses the performance of Codex low vs Codex high, specifically in a coding context demonstrated via a physics simulation of pool.  Users are debating the reliability of these models and whether one test is enough to determine which is better.
*  **Emotion:** The overall emotional tone is Neutral, with mixed feelings (Positive/Negative) regarding the performance of the different Codex models.
*  **Top 3 Points of View:**
    *   Codex low performed better than Codex high in the provided demonstration.
    *   The results may not be statistically significant due to the non-deterministic nature of the models, the user may have had lucky/unlucky runs.
    *   There is no single model that consistently guarantees better results with longer thinking time.

**[OpenAI admits AI hallucinations are mathematically inevitable, not just engineering flaws (Score: 103)](https://www.computerworld.com/article/4059383/openai-admits-ai-hallucinations-are-mathematically-inevitable-not-just-engineering-flaws.html)**
*  **Summary:**  The discussion centers around OpenAI's admission that AI hallucinations are mathematically inevitable. Commenters discuss the nature of LLMs, comparing them to statistical models, and suggest that hallucinations are an inherent part of the technology. RAG, memory, and prompt engineering help to reduce hallucinations, but in the end it's still just a tool.
*  **Emotion:** The overall emotional tone is Neutral. Many comments adopt a matter-of-fact tone, acknowledging the limitations of LLMs.
*  **Top 3 Points of View:**
    *   AI hallucinations are a mathematically inherent property of LLMs.
    *   Hallucinations can be mitigated through techniques like RAG and prompt engineering.
    *   LLMs are still in an early "dial-up internet" phase of development.

**[Am I just super late? Has this feature always been there? (Score: 62)](https://i.redd.it/hc6qza7avfqf1.png)**
*  **Summary:**  A user is surprised to discover a feature in GPT-5 and asks if it's new. The comments confirm that it's been around since GPT-5's release. Users also discuss their preferences for GPT personalities.
*  **Emotion:** The emotional tone is predominantly Neutral, with some expressing Positive sentiments about the feature and some Negative sentiments about how overly enthusiastic GPT is to them.
*  **Top 3 Points of View:**
    *   The feature has been available since GPT-5 was released.
    *   Users can define and choose different personalities in the new feature.
    *   Some users appreciate being able to customize the personality of the AI.

**["Do you want me to do that?" (Score: 57)](https://www.reddit.com/r/OpenAI/comments/1nmreu2/do_you_want_me_to_do_that/)**
*  **Summary:**  Users are discussing the ChatGPT feature where the AI asks "Do you want me to do that?". Some users find it helpful for suggesting new ideas and being proactive, while others find it annoying and distracting.
*  **Emotion:** The emotional tone is mixed.  Some comments are Positive, appreciating the feature's helpfulness, while others express Negative sentiment, finding it frustrating.
*  **Top 3 Points of View:**
    *   The feature can be helpful for generating new ideas and offering suggestions.
    *   The feature can be distracting and redundant, especially when it repeats the prompt.
    *   The feature is an attempt by OpenAI to make ChatGPT more addictive.

**[ðŸ‘€ new compute intensive features !! (Score: 40)](https://i.redd.it/7y1uztwzfkqf1.png)**
*  **Summary:** The thread centers around speculation about upcoming compute-intensive features from OpenAI. Users are curious and somewhat skeptical, expressing concerns about potential cost increases and the value proposition of these features.
*  **Emotion:** The overall emotional tone is Neutral, with a mix of excitement and concern.
*  **Top 3 Points of View:**
    *   Users are curious about what the new compute-intensive features will be.
    *   There's concern that these features might come with additional fees, on top of the pro subscription.
    *   The new features need to be valuable enough to justify any potential increase in cost.

**[OpenAI is working on a feature to share ChatGPT projects with other users (Score: 18)](https://i.redd.it/id30nij0bkqf1.jpeg)**
*  **Summary:**  Users are excited about the upcoming feature to share ChatGPT projects with other users.
*  **Emotion:** The overall emotional tone is Positive.
*  **Top 3 Points of View:**
    *   Users are excited to be able to share ChatGPT projects with other users.

**[Switched from Claude Code (Score: 6)](https://www.reddit.com/r/OpenAI/comments/1nmvqke/switched_from_claude_code/)**
*  **Summary:** A user announces they switched from Claude Code to Codex. Other users comment on the differences, limits, and deficiencies, and the idea to learn to work as a team.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Claude Code is different from Codex, with its own limits and deficiencies.
    *   Codex and claude are useful tools for building codebases.

**[How to handle multiple Codex "ask" tasks without running into merge conflicts? (Score: 5)](https://www.reddit.com/r/OpenAI/comments/1nmz0ea/how_to_handle_multiple_codex_ask_tasks_without/)**
*  **Summary:** A user, new to coding, is using Codex for "vibe coding" and running into merge conflicts between local and cloud versions. They seek advice on handling multiple Codex tasks without these conflicts.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *  Merge conflicts arise when working with local and cloud instances of Codex.
    *  The user is seeking advice on avoiding these conflicts and establishing a smooth workflow.
    *  Sometimes the user asks it to 'do it all' if they decide they want all the changes.

**[Codex: has anyone upgraded from Plus > Pro, that can share a bit of the experience? (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1nn1m6a/codex_has_anyone_upgraded_from_plus_pro_that_can/)**
*  **Summary:** A user asks about the experience of upgrading from Codex Plus to Pro, particularly regarding usage limits.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The user upgraded to Pro due to usage limits.
    *   After upgrading, the user no longer encounters usage limits.

**[Hitting context limit on a conversation branch? (Score: 1)](https://www.reddit.com/r/OpenAI/comments/1nmy4zz/hitting_context_limit_on_a_conversation_branch/)**
*  **Summary:** A user asks about hitting context limits in a conversation branch.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   When branching, context is inherited up to that point.

**[Cross-Model Recognition Test: Same Phrase, Different AIs, Shared Understanding (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1nmi9sl/crossmodel_recognition_test_same_phrase_different/)**
*  **Summary:** A user discusses cross-model recognition tests and shared understanding between different AIs.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The same conclusion could be drawn from a simpler test.

**[It boils my blood when I see GPT-5 "thinking" when I don't expect it to produce anything. (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1nmqu1m/it_boils_my_blood_when_i_see_gpt5_thinking_when_i/)**
*  **Summary:** A user expresses strong frustration when GPT-5 "thinks" when they don't expect it to.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Users are mad at silicone.
    *   Manage your prompt before hitting enter.
    *   OpenAI switched the default mode of auto to GPT 5 mini thinking mode.
