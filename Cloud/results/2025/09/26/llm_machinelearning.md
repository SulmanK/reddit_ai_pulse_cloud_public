---
title: "Machine Learning Subreddit"
date: "2025-09-26"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions
1.  [[P] Give me your one line of advice of machine learning code, that you have learned over years of hands on experience.](https://www.reddit.com/r/MachineLearning/comments/1nqtiad/p_give_me_your_one_line_of_advice_of_machine/) (Score: 27)
    *   The thread is asking for one-line pieces of advice for machine learning code based on personal experience.
2.  [[R] What do you do when your model is training?](https://www.reddit.com/r/MachineLearning/comments/1nr1s6g/r_what_do_you_do_when_your_model_is_training/) (Score: 22)
    *   The thread discusses what machine learning practitioners do while their models are training, from working on other projects to playing games.
3.  [[P] How to Check If Your Training Data Is Representative: Using PSI and Cramer’s V in Python](https://www.reddit.com/r/MachineLearning/comments/1nqkwn4/p_how_to_check_if_your_training_data_is/) (Score: 9)
    *   The thread is about checking the representativeness of training data using PSI and Cramer’s V in Python, with one user planning to try it in their project.
4.  [[R] How to finetune a multimodal model?](https://www.reddit.com/r/MachineLearning/comments/1nqil0w/r_how_to_finetune_a_multimodal_model/) (Score: 8)
    *   The thread is asking for advice on how to finetune a multimodal model. Commenters suggested that using a vision model, CNN, or AnomalyLib may be more appropriate based on the anomaly detection use case.
5.  [[D] How to address class imbalance in image classification task?](https://www.reddit.com/r/MachineLearning/comments/1nr4glq/d_how_to_address_class_imbalance_in_image/) (Score: 1)
    *   The thread discusses ways to handle class imbalance in image classification tasks. Commenters recommend researching SOTA techniques and using non-random sampling methods.
6.  [[R] Is there any research on using LLMs as Loss Functions?](https://www.reddit.com/r/MachineLearning/comments/1nqosof/r_is_there_any_research_on_using_llms_as_loss/) (Score: 0)
    *   The thread is asking about research on using LLMs as loss functions. Commenters point to LLM-as-a-judge, LLM as a reward model, GEPA, textGrad, RLHF and GRPO as related concepts and research directions.

# Detailed Analysis by Thread
**[ [P] Give me your one line of advice of machine learning code, that you have learned over years of hands on experience. (Score: 27)](https://www.reddit.com/r/MachineLearning/comments/1nqtiad/p_give_me_your_one_line_of_advice_of_machine/)**
*  **Summary:** The thread asks for one-line pieces of advice for machine learning code based on personal experience. Many responses emphasize data cleaning, regularization, careful validation, and logging.
*  **Emotion:** The overall emotional tone is neutral, as the advice is presented in a factual and informative manner. However, there are hints of positive sentiment in a couple of comments reflecting on experience gained.
*  **Top 3 Points of View:**
    *   Data cleaning is crucial.
    *   Regularization is essential.
    *   Careful consideration of the validation dataset is vital for generalization.

**[ [R] What do you do when your model is training? (Score: 22)](https://www.reddit.com/r/MachineLearning/comments/1nr1s6g/r_what_do_you_do_when_your_model_is_training/)**
*  **Summary:** This thread discusses what machine learning practitioners do while their models are training. Responses range from working on other projects, reading papers, playing games, to monitoring the training process.
*  **Emotion:** The emotional tone is mixed, with neutral, and positive sentiments being expressed. Some express the anxiety of waiting for results, while others maintain a productive or relaxed attitude.
*  **Top 3 Points of View:**
    *   Work on other related tasks or research.
    *   Take a break and engage in unrelated activities.
    *   Monitor the training process closely.

**[ [P] How to Check If Your Training Data Is Representative: Using PSI and Cramer’s V in Python (Score: 9)](https://www.reddit.com/r/MachineLearning/comments/1nqkwn4/p_how_to_check_if_your_training_data_is/)**
*  **Summary:** The thread discusses a method to check the representativeness of training data using PSI and Cramer’s V in Python.
*  **Emotion:** The emotional tone is neutral, with one comment expressing interest in trying the method.
*  **Top 3 Points of View:**
    *   The method seems promising for checking training data representativeness.

**[ [R] How to finetune a multimodal model? (Score: 8)](https://www.reddit.com/r/MachineLearning/comments/1nqil0w/r_how_to_finetune_a_multimodal_model/)**
*  **Summary:** This thread seeks advice on finetuning a multimodal model for anomaly detection. Commenters question the need for a multimodal model and suggest alternative approaches like CNNs, vision models, or AnomalyLib.
*  **Emotion:** The emotional tone is mixed, with neutral questioning and positive suggestions. Some express doubt about the initial approach, while others offer alternative solutions.
*  **Top 3 Points of View:**
    *   A multimodal model with LLMs might be overkill for anomaly detection in images.
    *   Consider using a vision model or CNN instead of a multimodal model.
    *   AnomalyLib is a potential alternative for anomaly detection.

**[ [D] How to address class imbalance in image classification task? (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1nr4glq/d_how_to_address_class_imbalance_in_image/)**
*  **Summary:** This thread discusses how to handle class imbalance in image classification tasks. Commenters suggest researching SOTA techniques and using non-random sampling methods.
*  **Emotion:** The emotional tone is neutral, with informative suggestions.
*  **Top 3 Points of View:**
    *   There are many existing techniques for handling data imbalance in imaging.
    *   Non-random sampling can be effective for balancing classes.

**[ [R] Is there any research on using LLMs as Loss Functions? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1nqosof/r_is_there_any_research_on_using_llms_as_loss/)**
*  **Summary:** This thread is inquiring about research on using LLMs as loss functions. Commenters suggest related concepts such as LLM-as-a-judge, LLM as a reward model, GEPA, textGrad, RLHF, and GRPO.
*  **Emotion:** The emotional tone is neutral, primarily providing information and related research directions.
*  **Top 3 Points of View:**
    *   LLM-as-a-judge and LLM as a reward model are related research directions.
    *   Consider concepts like GEPA and textGrad.
    *   RLHF and GRPO are relevant to using LLMs for rating outputs and further training.
