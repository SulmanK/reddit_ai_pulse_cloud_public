---
title: "Data Engineering Subreddit"
date: "2025-09-26"
description: "Analysis of top discussions and trends in the dataengineering subreddit"
tags: ["data engineering", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions
1.  [Reality Nowadaysâ€¦](https://i.redd.it/223ur66tmfrf1.jpeg) (Score: 419)
    * The discussion revolves around the current state of data cleaning and the challenges data engineers face with messy and unintegrated data sources.
2.  [In way over my head, feel like a fraud](https://www.reddit.com/r/dataengineering/comments/1nqsuyj/in_way_over_my_head_feel_like_a_fraud/) (Score: 45)
    * This thread discusses imposter syndrome in data engineering and seeks advice on managing a heavy workload and learning new tools.
3.  [Fastest way to generate surrogate keys in Delta table with billions of rows?](https://www.reddit.com/r/dataengineering/comments/1nqj6qk/fastest_way_to_generate_surrogate_keys_in_delta/) (Score: 28)
    * Users are brainstorming and sharing methods for efficiently generating surrogate keys in Delta tables, especially when dealing with billions of rows.
4.  [Unemployment thoughts](https://www.reddit.com/r/dataengineering/comments/1nqt4s0/unemployment_thoughts/) (Score: 27)
    * The thread reflects on the difficulties of finding a job in the current market, particularly for international workers needing visa sponsorship.
5.  [My company didn't use industry standard tools and I feel I'm way behind](https://www.reddit.com/r/dataengineering/comments/1nr3w6v/my_company_didnt_use_industry_standard_tools_and/) (Score: 22)
    * This discussion focuses on concerns about lacking experience with industry-standard tools and how to address this in job applications.
6.  [my freebies haul from big data ldn! (peep the stickers)](https://www.reddit.com/gallery/1nqzudt) (Score: 14)
    * This thread is about Big Data LDN. It discusses the poster's experience with the large crowds, booth queues, and talk queues at the conference.
7.  [How SQL queries can be optimized for analytics and massive queries](https://www.reddit.com/r/dataengineering/comments/1nr3v2l/how_sql_queries_can_be_optimized_for_analytics/) (Score: 13)
    * The thread features a write-up on SQL query optimization techniques for analytics, with a comment discussing differences in execution planners for different tools.
8.  [How to deal with non engineer people](https://www.reddit.com/r/dataengineering/comments/1nquwi3/how_to_deal_with_non_engineer_people/) (Score: 12)
    * This thread explores strategies for working with non-engineers, specifically on ML projects and how to deal with storing the data.
9.  [Any good ways to make a 300+ page PDF AI readable?](https://www.reddit.com/r/dataengineering/comments/1nqvkbr/any_good_ways_to_make_a_300_page_pdf_ai_readable/) (Score: 12)
    * The discussion centers around methods for making large PDFs AI-readable, including text layers, metadata, PDF tagging, OCR, and structured data versions.
10. [Please tell me I'm on the right path](https://www.reddit.com/r/dataengineering/comments/1nqvc08/please_tell_me_im_on_the_right_path/) (Score: 7)
    * The discussion includes normalizing data based on business needs and documenting the whole flow for future reference.
11. [We built a new geospatial DataFrame library called SedonaDB](https://www.reddit.com/r/dataengineering/comments/1nr9ciu/we_built_a_new_geospatial_dataframe_library/) (Score: 7)
    * The discussion questions if the blog was written by AI.
12. [How to replicate/mirror OLD as400 database to latest SQL databases or any compatible databases](https://www.reddit.com/r/dataengineering/comments/1nqw5c7/how_to_replicatemirror_old_as400_database_to/) (Score: 6)
    * The thread discusses how to migrate old AS400 database to the latest SQL database, using an ETL pipeline, Trino, or CDC.
13. [Kafka BQ sink connector multiple tables from MySQL](https://www.reddit.com/r/dataengineering/comments/1nqnqin/kafka_bq_sink_connector_multiple_tables_from_mysql/) (Score: 3)
    * This thread focuses on configuring a Kafka BQ sink connector for multiple tables from MySQL and why Kafka is being used.
14. [The Evolution of Search - A Brief History of Information Retrieval](https://youtu.be/ghE4gQkx2b4) (Score: 3)
    * The Evolution of Search from memory palaces to vector embeddings. This is the story of how search has evolved - how we've been trying to solve the problem of finding the right information at the right time for millennia.
15. [Iceberg based Datalake project vs a mature Data streaming service](https://www.reddit.com/r/dataengineering/comments/1nqrnpe/iceberg_based_datalake_project_vs_a_mature_data/) (Score: 2)
    * The thread discussed choosing vibes and a team. Tech doesn't matter unless it's pure cobol.
16. [Hive or Iceberg for production ?](https://www.reddit.com/r/dataengineering/comments/1nqu1v9/hive_or_iceberg_for_production/) (Score: 2)
    * This thread shows the poster finds the information to be helpful.
17. [This had to be my first post ðŸ˜‚](https://i.redd.it/bnqdd7x0ogrf1.png) (Score: 0)
    * This thread shows a meme and asks why AI was used instead of using actual movie shots.
18. [Feedback Request: Automating PDF Reporting in Data Pipelines](https://www.reddit.com/r/dataengineering/comments/1nqy2cl/feedback_request_automating_pdf_reporting_in_data/) (Score: 0)
    * The thread is about feedback on automating PDF reporting in data pipelines and provides a link to an open-source project showcase and a form to submit your own project.

# Detailed Analysis by Thread
**[Reality Nowadaysâ€¦ (Score: 419)](https://i.redd.it/223ur66tmfrf1.jpeg)**
*  **Summary:** The thread discusses the realities of data engineering, including the challenges of cleaning data, dealing with poorly integrated data sources, and the recurring issues caused by duplicated data.
*  **Emotion:** The overall emotional tone is neutral, with a hint of resignation and humor regarding the difficulties of data engineering.
*  **Top 3 Points of View:**
    * Data cleaning is a never-ending and often frustrating task.
    * Many companies have significant issues with data integration and duplicated data.
    * AI is not a magical solution for messy data, and underlying data quality issues need to be addressed.

**[In way over my head, feel like a fraud (Score: 45)](https://www.reddit.com/r/dataengineering/comments/1nqsuyj/in_way_over_my_head_feel_like_a_fraud/)**
*  **Summary:** This thread is a discussion about feeling overwhelmed and experiencing imposter syndrome in the data engineering field. Users offer advice and support, suggesting strategies for learning new skills, managing workload, and seeking help.
*  **Emotion:** The emotional tone is mixed, with initial feelings of anxiety and being overwhelmed, but ultimately leaning towards encouragement and support. There are also undertones of understanding and shared experiences among data engineers.
*  **Top 3 Points of View:**
    * Imposter syndrome is common among high achievers and is a normal part of the learning process.
    * It's crucial to communicate with your boss and team if you're struggling with your workload and to ask for support in getting up to speed.
    * AI tools like ChatGPT and Claude can be valuable resources for learning new languages and tools and for problem-solving.

**[Fastest way to generate surrogate keys in Delta table with billions of rows? (Score: 28)](https://www.reddit.com/r/dataengineering/comments/1nqj6qk/fastest_way_to_generate_surrogate_keys_in_delta/)**
*  **Summary:** This thread seeks advice on the fastest methods to generate surrogate keys in a Delta table with billions of rows, specifically requiring no gaps in the generated keys.
*  **Emotion:** The emotional tone is neutral, with a focus on problem-solving and sharing technical solutions.
*  **Top 3 Points of View:**
    * Hashing algorithms like xx64 can be faster than window functions or monotonous IDs for key generation.
    * Generating surrogate keys without gaps in a distributed system is a difficult problem.
    * Consider using spark_partition_id to parallelize the key generation process.

**[Unemployment thoughts (Score: 27)](https://www.reddit.com/r/dataengineering/comments/1nqt4s0/unemployment_thoughts/)**
*  **Summary:** This thread is about the poster's struggles with unemployment and reflects on the difficult job market, especially for international workers requiring visa sponsorship.
*  **Emotion:** The overall emotional tone is negative, with feelings of frustration, anxiety, and disappointment about the job search.
*  **Top 3 Points of View:**
    * The job market is tough, especially for those needing visa sponsorship.
    * Polishing your CV is crucial to pass through ATS tools.
    * It might be worth exploring job opportunities in the EU.

**[My company didn't use industry standard tools and I feel I'm way behind (Score: 22)](https://www.reddit.com/r/dataengineering/comments/1nr3w6v/my_company_didnt_use_industry_standard_tools_and/)**
*  **Summary:** The thread discusses the feeling of being behind due to a company not using industry-standard tools and seeks advice on how to address this in job applications and interviews.
*  **Emotion:** The emotional tone is a mix of anxiety and determination, with some negativity mixed in.
*  **Top 3 Points of View:**
    * Focus on the concepts and problem-solving skills gained from your work, rather than just the specific tools used.
    * Set up a home lab to learn and gain experience with industry-standard tools.
    * Overstating your experience with tools like Microsoft Azure could backfire if you're not prepared for in-depth questions.

**[my freebies haul from big data ldn! (Score: 14)](https://www.reddit.com/gallery/1nqzudt)**
*  **Summary:** This thread is about Big Data LDN. It discusses the poster's experience with the large crowds, booth queues, and talk queues at the conference.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    * Big Data LDN was manic and crowded.

**[How SQL queries can be optimized for analytics and massive queries (Score: 13)](https://www.reddit.com/r/dataengineering/comments/1nr3v2l/how_sql_queries_can_be_optimized_for_analytics/)**
*  **Summary:** The thread features a write-up on SQL query optimization techniques for analytics, with a comment discussing differences in execution planners for different tools.
*  **Emotion:** The overall tone is positive.
*  **Top 3 Points of View:**
    * The write-up is very good.
    * BQ execution planners are different than RDMS, they need different SQL optimizations.

**[How to deal with non engineer people (Score: 12)](https://www.reddit.com/r/dataengineering/comments/1nquwi3/how_to_deal_with_non_engineer_people/)**
*  **Summary:** This thread explores strategies for working with non-engineers, specifically regarding a machine learning project where non-engineers prefer storing model results in flat files instead of a database.
*  **Emotion:** The general emotional tone is neutral.
*  **Top 3 Points of View:**
    * It is possible to be overcomplicating the task and over-engineering.
    * A data warehouse can be a small experiment tracker. Even a simple Schema with parameters and results.
    * You can modularize code and store everything in S3.

**[Any good ways to make a 300+ page PDF AI readable? (Score: 12)](https://www.reddit.com/r/dataengineering/comments/1nqvkbr/any_good_ways_to_make_a_300_page_pdf_ai_readable/)**
*  **Summary:** The discussion centers around methods for making large PDFs AI-readable, including text layers, metadata, PDF tagging, OCR, and structured data versions.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    * Ensure the PDF has a fully machine-readable text layer, document metadata and PDF tagging for accessibility.
    * The revenue side of your company is missing an opportunity to sell subscriptions to structured versions of your data.
    * Pytessarct should be able to parse the pdf(even the ones with OCR)

**[Please tell me I'm on the right path (Score: 7)](https://www.reddit.com/r/dataengineering/comments/1nqvc08/please_tell_me_im_on_the_right_path/)**
*  **Summary:** The discussion includes normalizing data based on business needs and documenting the whole flow for future reference.
*  **Emotion:** The overall tone is positive.
*  **Top 3 Points of View:**
    * It is similar to another user's project.
    * Don't break 300 columns into too many tables.
    * It will work based on the use case for data warehouse reporting.

**[We built a new geospatial DataFrame library called SedonaDB (Score: 7)](https://www.reddit.com/r/dataengineering/comments/1nr9ciu/we_built_a_new_geospatial_dataframe_library/)**
*  **Summary:** The discussion questions if the blog was written by AI.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * The blog was written by AI.

**[How to replicate/mirror OLD as400 database to latest SQL databases or any compatible databases (Score: 6)](https://www.reddit.com/r/dataengineering/comments/1nqw5c7/how_to_replicatemirror_old_as400_database_to/)**
*  **Summary:** The thread discusses how to migrate old AS400 database to the latest SQL database, using an ETL pipeline, Trino, or CDC.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * Use an ETL pipeline if your data have metadata column (modified_at) and export to files.
    * Directly bridge using Trino.
    * Use a CDC to export modification events and then use this information to ingest in the other database.

**[Kafka BQ sink connector multiple tables from MySQL (Score: 3)](https://www.reddit.com/r/dataengineering/comments/1nqnqin/kafka_bq_sink_connector_multiple_tables_from_mysql/)**
*  **Summary:** This thread focuses on configuring a Kafka BQ sink connector for multiple tables from MySQL and why Kafka is being used.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * It is important to know if the user is using Debezium to read the MySQL.
    * Why use Kafka when tools like Spark are designed to do the same job.
    * The tables' primary key are not all "id" ?

**[The Evolution of Search - A Brief History of Information Retrieval (Score: 3)](https://youtu.be/ghE4gQkx2b4)**
*  **Summary:** The history of information retrieval starts before the written record and ends with Retrieval Augmented Generation (RAG).
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * The link provided shows information retrieval from memory palaces to vector embeddings.

**[Iceberg based Datalake project vs a mature Data streaming service (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1nqrnpe/iceberg_based_datalake_project_vs_a_mature_data/)**
*  **Summary:** The thread discussed choosing vibes and a team. Tech doesn't matter unless it's pure cobol.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * Choose for vibes and the team. Tech doesn't matter unless it's actually just pure cobol.

**[Hive or Iceberg for production ? (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1nqu1v9/hive_or_iceberg_for_production/)**
*  **Summary:** This thread shows the poster finds the information to be helpful.
*  **Emotion:** The overall tone is positive.
*  **Top 3 Points of View:**
    * The thread shows the information to be helpful.

**[This had to be my first post ðŸ˜‚ (Score: 0)](https://i.redd.it/bnqdd7x0ogrf1.png)**
*  **Summary:** This thread shows a meme and asks why AI was used instead of using actual movie shots.
*  **Emotion:** The overall tone is negative.
*  **Top 3 Points of View:**
    * The poster does not like the meme.
    * Why was there a need for AI if you could just use actual shots from the Movie and do the Subtitles with powerpoint?

**[Feedback Request: Automating PDF Reporting in Data Pipelines (Score: 0)](https://www.reddit.com/r/dataengineering/comments/1nqy2cl/feedback_request_automating_pdf_reporting_in_data/)**
*  **Summary:** The thread is about feedback on automating PDF reporting in data pipelines and provides a link to an open-source project showcase and a form to submit your own project.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * A form and open-source project link has been provided.
