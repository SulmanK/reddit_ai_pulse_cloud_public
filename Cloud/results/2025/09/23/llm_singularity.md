---
title: "Singularity Subreddit"
date: "2025-09-23"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "singularity", "technology"]
---

# Overall Ranking and Top Discussions
1.  [[D] "Immortality sucks" ? Skill issue](https://i.redd.it/1kbd290s0wqf1.jpeg) (Score: 814)
    *   This thread discusses different viewpoints on immortality, with some arguing it's a "skill issue" to not enjoy it, while others raise concerns about boredom and the loss of loved ones.
2.  [Incredible Wan 2.2 Animate model allows you to act as another person. For movies this is a game changer.](https://v.redd.it/en7lluczzsqf1) (Score: 134)
    *   The discussion revolves around the potential of the Wan 2.2 Animate model, with opinions ranging from its game-changing impact on movies to concerns about its use in scams.
3.  [Suno v5 is here and it sounds amazing!](https://v.redd.it/vbjopjq11yqf1) (Score: 85)
    *   This thread discusses the new Suno v5 AI music model, with commenters expressing both excitement about its improvements and reservations about its overall quality compared to professional music production.
4.  [Abundant Intelligence - Sam Altman blog post on automating building AI infrastructure](https://blog.samaltman.com/abundant-intelligence) (Score: 78)
    *   The conversation centers on Sam Altman's blog post about automating the building of AI infrastructure, with discussions about the scale of investment, potential benefits, and comparisons to Elon Musk's infrastructure projects.
5.  [Amazing Qwen !! 6 releases tonight](https://i.redd.it/w3jo2x7a2wqf1.png) (Score: 72)
    *   This thread is about the release of Qwen, with people speculating what the 6 releases might be.
6.  [GPT-5 Codex is now available in API with same pricing as GPT-5](https://i.redd.it/k0lxkgdbgyqf1.png) (Score: 56)
    *   Users are discussing the availability and performance of GPT-5 Codex, with some finding it underwhelming compared to other coding agents.
7.  [Waymo says “thank you” after humans clear obstruction from road](https://v.redd.it/0kwda4lbrvqf1) (Score: 36)
    *   The thread discusses a video of a Waymo self-driving car thanking humans for clearing an obstruction, with speculation on whether a remote operator was involved.
8.  [The Next Level of AI Video Games Is Here. Put in your image, any image, and a playable game results.](https://youtu.be/6Adcl7nXWuU?si=Ap84D-k89cJRX2eG) (Score: 22)
    *   Users are discussing the potential of AI to generate playable video games from images.
9.  [What kind of compute would it take to render all of human history into a playable simulation? So that you might choose when/where to visit/live.](https://www.reddit.com/r/singularity/comments/1nojgqd/what_kind_of_compute_would_it_take_to_render_all/) (Score: 19)
    *   The discussion revolves around the computational requirements for simulating all of human history, with considerations for accuracy, data storage, and potential approaches like using DNA as a template.
10. [Introducing our latest Gemini Live model](https://x.com/OfficialLoganK/status/1970546338858246255) (Score: 18)
    *   The thread is a quick discussion on the latest Gemini Live model.
11. [Joe Rogan talks about Ai deniers](https://v.redd.it/jsnypc8qqyqf1) (Score: 14)
    *   This thread discusses Joe Rogan's opinions on AI deniers.
12. [We might come to AI kids (like iPad kids)](https://www.reddit.com/r/singularity/comments/1nodmbo/we_might_come_to_ai_kids_like_ipad_kids/) (Score: 14)
    *   The discussion centers on the potential impact of AI on children, drawing parallels to "iPad kids" and considering whether AI could be a beneficial or detrimental influence on development.
13. ["The mini placentas and ovaries revealing the basics of women’s health"](https://www.reddit.com/r/singularity/comments/1nogs8r/the_mini_placentas_and_ovaries_revealing_the/) (Score: 13)
    *   The thread focuses on a discussion about the a disclaimer included in a scientific article to recognize transgender men and non-binary people might have female reproductive organs.
14. [Time to stop fearing latents. Lets pull them out that black box](https://www.reddit.com/r/IntelligenceEngine/comments/1nnifea/time_to_stop_fearing_latents_lets_pull_them_out/) (Score: 9)
    *   The discussion revolves around exploring and understanding latent spaces in AI models, with emphasis on methods to manipulate latent data and build more tractable latent spaces.
15. [The Nature Of Hallucinations](https://blog.qaware.de/posts/nature-of-hallucinations/) (Score: 4)
    *   The thread acknowledges the challenges of working with imperfect information.
16. [How far from recursive self-improvement (RSI) ai?](https://www.reddit.com/r/singularity/comments/1norhyx/how_far_from_recursive_selfimprovement_rsi_ai/) (Score: 4)
    *   This thread discusses the timeline for achieving recursive self-improvement in AI, with varying predictions ranging from a few years to a decade or more.
17. [Why intrinsic model security is a Very Bad Idea (but extrinsic is necessary)](https://www.reddit.com/r/singularity/comments/1nohtnt/why_intrinsic_model_security_is_a_very_bad_idea/) (Score: 3)
    *   The discussion centers on the best approach to AI model security, contrasting intrinsic (built-in) security measures with extrinsic (external) oversight, with some arguing that only the model's functionality matters, regardless of the security approach.
18. [A thought experiment: If past-time travel is possible, why don’t we see evidence from future ASI?](https://www.reddit.com/r/singularity/comments/1nonwhm/a_thought_experiment_if_pasttime_travel_is/) (Score: 1)
    *   This thread explores the absence of observable evidence of time travelers from future Artificial Superintelligence (ASI).

# Detailed Analysis by Thread
**[[D] "Immortality sucks" ? Skill issue (Score: 814)](https://i.redd.it/1kbd290s0wqf1.jpeg)**
*  **Summary:** The thread explores the perspective that dissatisfaction with immortality is a personal failing, contrasting it with concerns about boredom and losing loved ones.
*  **Emotion:** The overall emotional tone is neutral, with a mix of opinions being expressed. However, some comments express negative sentiment related to getting old.
*  **Top 3 Points of View:**
    *   Immortality is a skill issue; people should be able to find ways to enjoy it.
    *   The argument about friends dying is weak, as they could also become immortal.
    *   People who say they don't want to live forever sound suicidal.

**[Incredible Wan 2.2 Animate model allows you to act as another person. For movies this is a game changer. (Score: 134)](https://v.redd.it/en7lluczzsqf1)**
*  **Summary:** The discussion revolves around the potential impact of the Wan 2.2 Animate model on movies, with some highlighting its game-changing possibilities, while others express concerns about its potential misuse for scams and question its novelty.
*  **Emotion:** The emotional tone is mixed, ranging from positive excitement to negative apprehension about the potential for misuse.
*  **Top 3 Points of View:**
    *   The model is a game-changer for the movie industry.
    *   It could be used for scams.
    *   The technology is not new, and similar quality was available years ago.

**[Suno v5 is here and it sounds amazing! (Score: 85)](https://v.redd.it/vbjopjq11yqf1)**
*  **Summary:** This thread discusses the new Suno v5 AI music model, with opinions ranging from excitement about its improvements to reservations about its overall quality compared to professional music production.
*  **Emotion:** The thread shows a generally positive emotion, with many commenters expressing excitement about the improvement in the model.
*  **Top 3 Points of View:**
    *   Suno v5 is a significant improvement and could replace generic commercial music.
    *   While improved, it still doesn't match the quality of professional music production.
    *   It could lead to a surge of AI-generated American anime music.

**[Abundant Intelligence - Sam Altman blog post on automating building AI infrastructure (Score: 78)](https://blog.samaltman.com/abundant-intelligence)**
*  **Summary:** The conversation centers on Sam Altman's blog post about automating the building of AI infrastructure, with discussions about the scale of investment, potential benefits, and comparisons to Elon Musk's infrastructure projects.
*  **Emotion:** The emotional tone is largely neutral, with some positive sentiment toward Sam Altman's ambition.
*  **Top 3 Points of View:**
    *   The plan to create a factory producing a gigawatt of AI infrastructure weekly is impressive.
    *   Sam Altman is consistently trying to accelerate the development of AI.
    *   The method of financing the project is of interest.

**[Amazing Qwen !! 6 releases tonight (Score: 72)](https://i.redd.it/w3jo2x7a2wqf1.png)**
*  **Summary:** This thread is about the release of Qwen, with people speculating what the 6 releases might be.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Speculation about future models.
    *   Qwen 6 confirmed.
    *   There is excitement about the Qwen model.

**[GPT-5 Codex is now available in API with same pricing as GPT-5 (Score: 56)](https://i.redd.it/k0lxkgdbgyqf1.png)**
*  **Summary:** Users are discussing the availability and performance of GPT-5 Codex, with some finding it underwhelming compared to other coding agents and others suggesting junior devs getting nuked
*  **Emotion:** The overall emotional tone is positive, but there's some dissapointment expressed by the performance of the API.
*  **Top 3 Points of View:**
    *   Junior devs getting nuked by it
    *   GPT-5-Codex is not as good as Cline or RooCode
    *   Happy that the API is allowed.

**[Waymo says “thank you” after humans clear obstruction from road (Score: 36)](https://v.redd.it/0kwda4lbrvqf1)**
*  **Summary:** The thread discusses a video of a Waymo self-driving car thanking humans for clearing an obstruction, with speculation on whether a remote operator was involved.
*  **Emotion:** The emotional tone is neutral.
*  **Top 2 Points of View:**
    *   The Waymo car likely has a remote operator connecting to it when problems arise.
    *   Speculation of "Teleoperator?".

**[The Next Level of AI Video Games Is Here. Put in your image, any image, and a playable game results. (Score: 22)](https://youtu.be/6Adcl7nXWuU?si=Ap84D-k89cJRX2eG)**
*  **Summary:** Users are discussing the potential of AI to generate playable video games from images.
*  **Emotion:** The emotional tone is neutral.
*  **Top 1 Points of View:**
    *   The user wondered what level 7 of the Mona Lisa is.

**[What kind of compute would it take to render all of human history into a playable simulation? So that you might choose when/where to visit/live. (Score: 19)](https://www.reddit.com/r/singularity/comments/1nojgqd/what_kind_of_compute_would_it_take_to_render_all/)**
*  **Summary:** The discussion revolves around the computational requirements for simulating all of human history, with considerations for accuracy, data storage, and potential approaches like using DNA as a template.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   One brain is enough to generate any point in time/space in human history.
    *   Deep historical data is needed to make the simulation accurate.
    *   The project is an impressive project.

**[Introducing our latest Gemini Live model (Score: 18)](https://x.com/OfficialLoganK/status/1970546338858246255)**
*  **Summary:** The thread is a quick discussion on the latest Gemini Live model.
*  **Emotion:** The overall emotional tone is negative.
*  **Top 2 Points of View:**
    *   It's useless as openAI's advanced voice mode.
    *   Hmmm.

**[Joe Rogan talks about Ai deniers (Score: 14)](https://v.redd.it/jsnypc8qqyqf1)**
*  **Summary:** This thread discusses Joe Rogan's opinions on AI deniers.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Rogan is not a credible source on AI.
    *   Rogan's statements about AI are accurate and people should accept them regardless of their opinion of him.
    *   AI will replace Joe Rogan.

**[We might come to AI kids (like iPad kids) (Score: 14)](https://www.reddit.com/r/singularity/comments/1nodmbo/we_might_come_to_ai_kids_like_ipad_kids/)**
*  **Summary:** The discussion centers on the potential impact of AI on children, drawing parallels to "iPad kids" and considering whether AI could be a beneficial or detrimental influence on development.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   AI will be used as a supplement rather than a replacement for parental guidance.
    *   AI kids will be better than iPad kids, as they will be asking questions and making commands.
    *   AI will be the better parent for some kids.

**["The mini placentas and ovaries revealing the basics of women’s health" (Score: 13)](https://www.reddit.com/r/singularity/comments/1nogs8r/the_mini_placentas_and_ovaries_revealing_the/)**
*  **Summary:** The thread focuses on a discussion about a disclaimer included in a scientific article to recognize transgender men and non-binary people might have female reproductive organs.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 1 Points of View:**
    *   The user is wondering why is there is a disclaimer on the scientific article.

**[Time to stop fearing latents. Lets pull them out that black box (Score: 9)](https://www.reddit.com/r/IntelligenceEngine/comments/1nnifea/time_to_stop_fearing_latents_lets_pull_them_out/)**
*  **Summary:** The discussion revolves around exploring and understanding latent spaces in AI models, with emphasis on methods to manipulate latent data and build more tractable latent spaces.
*  **Emotion:** The emotional tone is neutral.
*  **Top 1 Points of View:**
    *   Latent data can be nudged in meaningful ways.

**[The Nature Of Hallucinations (Score: 4)](https://blog.qaware.de/posts/nature-of-hallucinations/)**
*  **Summary:** The thread acknowledges the challenges of working with imperfect information.
*  **Emotion:** The emotional tone is neutral.
*  **Top 1 Points of View:**
    *   The challenges of working with imperfect information are huge.

**[How far from recursive self-improvement (RSI) ai? (Score: 4)](https://www.reddit.com/r/singularity/comments/1norhyx/how_far_from_recursive_selfimprovement_rsi_ai/)**
*  **Summary:** This thread discusses the timeline for achieving recursive self-improvement in AI, with varying predictions ranging from a few years to a decade or more.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   RSI is likely 2-3 years away.
    *   RSI could happen any day.
    *   RSI and AGI are likely end of 2026 and 2027-2028 respectively.

**[Why intrinsic model security is a Very Bad Idea (but extrinsic is necessary) (Score: 3)](https://www.reddit.com/r/singularity/comments/1nohtnt/why_intrinsic_model_security_is_a_very_bad_idea/)**
*  **Summary:** The discussion centers on the best approach to AI model security, contrasting intrinsic (built-in) security measures with extrinsic (external) oversight, with some arguing that only the model's functionality matters, regardless of the security approach.
*  **Emotion:** The emotional tone is mixed with disagreement, expressing a different sentiment.
*  **Top 2 Points of View:**
    *   Oversight is good.
    *   The only thing that matters is how the model functions.

**[A thought experiment: If past-time travel is possible, why don’t we see evidence from future ASI? (Score: 1)](https://www.reddit.com/r/singularity/comments/1nonwhm/a_thought_experiment_if_pasttime_travel_is/)**
*  **Summary:** This thread explores the absence of observable evidence of time travelers from future Artificial Superintelligence (ASI).
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Time travelers would go to Woodstock instead of Steven Hawkings party.
    *   Past-time travel is impossible because the past no longer exists.
    *   If you travel back in time you would be floating in space and die.
