---
title: "Machine Learning Subreddit"
date: "2025-09-12"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "MLPerf"]
---

# Overall Ranking and Top Discussions
1.  [[D]NVIDIA Blackwell Ultra crushes MLPerf](https://www.reddit.com/r/MachineLearning/comments/1ndo5md/dnvidia_blackwell_ultra_crushes_mlperf/) (Score: 53)
    *   Discusses the performance of NVIDIA's new Blackwell Ultra GPU on MLPerf benchmarks, with considerations on cost-effectiveness, relevance to RL applications, and marketing tactics.
2.  [D] Larry Ellison: “Inference is where the money is going to be made.”](https://www.reddit.com/r/MachineLearning/comments/1nfav96/d_larry_ellison_inference_is_where_the_money_is/) (Score: 31)
    *   A discussion around Larry Ellison's statement on the importance of inference in ML, with views on Oracle's position in the market compared to competitors like Google, AWS, and Azure.
3.  [[D] Math foundations to understand Convergence proofs?](https://www.reddit.com/r/MachineLearning/comments/1nehy84/d_math_foundations_to_understand_convergence/) (Score: 23)
    *   Users discuss the mathematical foundations required to understand convergence proofs in machine learning, recommending resources like numerical analysis books and convex optimization materials.
4.  [[P] Semlib: LLM-powered Data Processing](https://www.reddit.com/r/MachineLearning/comments/1neccr0/p_semlib_llmpowered_data_processing/) (Score: 18)
    *   A thread discussing Semlib, a library for LLM-powered data processing.
5.  [[D] SOTA modern alternative to BertScore?](https://www.reddit.com/r/MachineLearning/comments/1ndaesz/d_sota_modern_alternative_to_bertscore/) (Score: 15)
    *   Discussion about finding a modern alternative to BertScore for evaluating text generation, suggesting the use of modern embeddings or LLMs as judges.
6.  [[D] Will NAACL 2026 Happen?](https://www.reddit.com/r/MachineLearning/comments/1nez5p7/d_will_naacl_2026_happen/) (Score: 8)
    *   Speculation and discussion on whether the NAACL (North American Association for Computational Linguistics) conference will be held in 2026, considering the location of ACL and the typical conference schedule.
7.  [[D] Do you ever miss PyTorch-style workflows?](https://www.reddit.com/r/MachineLearning/comments/1nf9noo/d_do_you_ever_miss_pytorchstyle_workflows/) (Score: 8)
    *   A discussion about whether people miss PyTorch-style workflows given the shift towards using LLMs and existing models, with some expressing sadness about the change in required skills.
8.  [[D] Questions on Fairness and Expectations in Top-Tier Conference Submissions](https://www.reddit.com/r/MachineLearning/comments/1ndajmq/d_questions_on_fairness_and_expectations_in/) (Score: 7)
    *   This thread explores the expectations for submissions to top-tier machine learning conferences, focusing on achieving SOTA performance and demonstrating impact.
9.  [[D] Creating test cases for retrieval evaluation](https://www.reddit.com/r/MachineLearning/comments/1neobe4/d_creating_test_cases_for_retrieval_evaluation/) (Score: 7)
    *   A discussion on methods for creating test cases for evaluating retrieval systems, including LLM-based generation of question-answer pairs and using ensemble methods for relevance labeling.
10. [[D] The best way to structure data for a predictive model of corporate delinquency](https://www.reddit.com/r/MachineLearning/comments/1ndulfv/d_the_best_way_to_structure_data_for_a_predictive/) (Score: 6)
    *   The best way to structure data for a predictive model of corporate delinquency.
11. [[D] What model should I use for image matching and search use case?](https://www.reddit.com/r/MachineLearning/comments/1ner3r7/d_what_model_should_i_use_for_image_matching_and/) (Score: 5)
    *   Discussion on appropriate models for image matching and search, suggesting CNN-based embeddings, metric learning, and considerations for robustness against distortions.
12. [[D] Having trouble organising massive CSV files for your machine learning models?](https://www.reddit.com/r/MachineLearning/comments/1ndtey6/d_having_trouble_organising_massive_csv_files_for/) (Score: 2)
    *   This thread discusses challenges in organizing large CSV files for machine learning, recommending the use of Parquet format and tools like Databricks and PySpark.
13. [IMU sensor based terrain classification [P]](https://www.reddit.com/r/MachineLearning/comments/1nf03e6/imu_sensor_based_terrain_classification_p/) (Score: 2)
    *   IMU sensor based terrain classification.
14. [[D] Universal Deep Research (UDR): A general wrapper for LLM-Based research](https://www.reddit.com/r/MachineLearning/comments/1nee9fl/d_universal_deep_research_udr_a_general_wrapper/) (Score: 0)
    *   A general wrapper for LLM-Based research.
15. [My current thinking on subjectivity of time. [D]](https://www.reddit.com/r/MachineLearning/comments/1nf2h1j/my_current_thinking_on_subjectivity_of_time_d/) (Score: 0)
    *   My current thinking on subjectivity of time.
16. [[D] Seeking Recommendations for AutoML Libraries Compatible with Windows (Python 3.12) in 2025](https://www.reddit.com/r/MachineLearning/comments/1nf9cwu/d_seeking_recommendations_for_automl_libraries/) (Score: 0)
    *   Seeking Recommendations for AutoML Libraries Compatible with Windows (Python 3.12) in 2025

# Detailed Analysis by Thread
**[[D]NVIDIA Blackwell Ultra crushes MLPerf (Score: 53)](https://www.reddit.com/r/MachineLearning/comments/1ndo5md/dnvidia_blackwell_ultra_crushes_mlperf/)**
*   **Summary:** The discussion centers around NVIDIA's new Blackwell Ultra GPU and its impressive performance on MLPerf benchmarks. Commenters debate the cost-effectiveness, potential applications in reinforcement learning (RL), and the potential for inflated marketing metrics.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   NVIDIA's marketing numbers might be based on unrealistic configurations.
    *   Blackwell Ultra could be particularly beneficial for RL applications due to its high utilization during inference rollouts.
    *   The cost-effectiveness depends on factors like power costs, latency requirements, and infrastructure consolidation potential.

**[[D] Larry Ellison: “Inference is where the money is going to be made.” (Score: 31)](https://www.reddit.com/r/MachineLearning/comments/1nfav96/d_larry_ellison_inference_is_where_the_money_is/)**
*   **Summary:** The thread analyzes Larry Ellison's statement on the financial importance of inference in machine learning. It also discusses Oracle's position relative to other cloud providers.
*   **Emotion:** The overall emotional tone is Neutral, although there are some comments with Positive sentiment.
*   **Top 3 Points of View:**
    *   Inference has always been the real money driver in ML, even before LLMs.
    *   Oracle may not be as well-positioned as Google, AWS, and Azure, which are developing specialized ASICs for model deployments.
    *   Edge computing may become more significant than on-premise and cloud solutions in the future.

**[[D] Math foundations to understand Convergence proofs? (Score: 23)](https://www.reddit.com/r/MachineLearning/comments/1nehy84/d_math_foundations_to_understand_convergence/)**
*   **Summary:** The thread discusses the math background needed to understand convergence proofs, with users recommending resources like numerical analysis texts and convex optimization materials.
*   **Emotion:** The overall emotional tone is Neutral, although there are some comments with Positive sentiment.
*   **Top 3 Points of View:**
    *   A numerical analysis book is a good starting point.
    *   Convex optimization is a good way to approach the math foundations.
    *   Understanding the convergence analysis for stochastic gradient descent under general assumptions is valuable.

**[[P] Semlib: LLM-powered Data Processing (Score: 18)](https://www.reddit.com/r/MachineLearning/comments/1neccr0/p_semlib_llmpowered_data_processing/)**
*   **Summary:** A discussion around Semlib, an LLM-powered Data Processing library.
*   **Emotion:** The overall emotional tone is Positive and Neutral.
*   **Top 3 Points of View:**
    *   Prompt gives you a special return type you have control over.
    *   The project looks great.
    *   The project looks like a lot of fun and potentially fascinating.

**[[D] SOTA modern alternative to BertScore? (Score: 15)](https://www.reddit.com/r/MachineLearning/comments/1ndaesz/d_sota_modern_alternative_to_bertscore/)**
*   **Summary:** The thread seeks modern alternatives to BertScore.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Modern embeddings like OpenAI GPT or DeBertav3 Embeddings could be used.
    *   ModernBERT or EuroBERT are powerful transformer encoder-only embedding models.
    *   LLM as judge is a sought after technique.

**[[D] Will NAACL 2026 Happen? (Score: 8)](https://www.reddit.com/r/MachineLearning/comments/1nez5p7/d_will_naacl_2026_happen/)**
*   **Summary:** Discussion around whether NAACL 2026 will happen.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   NAACL will likely not happen in 2026.
    *   NAACL could happen as late as June/July.
    *   Next NAACL will be in 2027, as ACL 2026 is in NA.

**[[D] Do you ever miss PyTorch-style workflows? (Score: 8)](https://www.reddit.com/r/MachineLearning/comments/1nf9noo/d_do_you_ever_miss_pytorchstyle_workflows/)**
*   **Summary:** Discussion on whether people miss PyTorch-style workflows.
*   **Emotion:** The overall emotional tone is mixed with Neutral, Negative, and Positive sentiment.
*   **Top 3 Points of View:**
    *   Some miss TensorFlow and Keras and are sad that their skills are no longer required as much.
    *   Some are thankfully able to avoid this and think NLP and projects with questionable business value are dead.
    *   Some find that companies keep asking PyTorch experience in their job ads.

**[[D] Questions on Fairness and Expectations in Top-Tier Conference Submissions (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1ndajmq/d_questions_on_fairness_and_expectations_in/)**
*   **Summary:** Explores the expectations for submissions to top-tier machine learning conferences, focusing on achieving SOTA performance and demonstrating impact.
*   **Emotion:** A mix of Neutral, Positive, and Negative sentiments.
*   **Top 3 Points of View:**
    *   The main contribution should be something people will use.
    *   SOTA-competitive performance is a key metric.
    *   The paper needs to have a huge impact to get into an A* conference.

**[[D] Creating test cases for retrieval evaluation (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1neobe4/d_creating_test_cases_for_retrieval_evaluation/)**
*   **Summary:** The thread discusses methods for creating test cases for evaluating retrieval systems, including LLM-based generation of question-answer pairs and using ensemble methods for relevance labeling.
*   **Emotion:** The overall emotional tone is Neutral and Positive.
*   **Top 3 Points of View:**
    *   LitSearch from Danqi Chen is worth checking out.
    *   LLMs can be used to generate question-answer pairs directly from source documents.
    *   The paper "Know your RAG" by IBM should be considered.

**[[D] The best way to structure data for a predictive model of corporate delinquency (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1ndulfv/d_the_best_way_to_structure_data_for_a_predictive/)**
*   **Summary:** Discusses the best way to structure data for a predictive model of corporate delinquency.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Option 1 makes the most sense without more context.
    *   You shouldn’t average the financials over multiple years, then predict for every year.
    *   The given papers give an idea of the types of features that might be important.

**[[D] What model should I use for image matching and search use case? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1ner3r7/d_what_model_should_i_use_for_image_matching_and/)**
*   **Summary:** Discussion on appropriate models for image matching and search, suggesting CNN-based embeddings, metric learning, and considerations for robustness against distortions.
*   **Emotion:** The overall emotional tone is Neutral and Positive.
*   **Top 3 Points of View:**
    *   CNN-based embedding model is a good starting point.
    *   Adding data augmentation and using spatial transformers can help to add robustness to rotation/scale/partial scans.
    *   Starting with SigLip as baseline and fine-tuning it is recommended.

**[[D] Having trouble organising massive CSV files for your machine learning models? (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1ndtey6/d_having_trouble_organising_massive_csv_files_for/)**
*   **Summary:** Challenges in organizing large CSV files for machine learning.
*   **Emotion:** The overall emotional tone is Neutral and Positive.
*   **Top 3 Points of View:**
    *   Convert the CSV into parquet and put it into icetables if you can do that.
    *   These files should be in parquet format and you should be using something like databricks+pyspark.
    *    For dealing with power signals, it's common to have them encoded and compressed as waveforms rather than text-like files as CSVs.

**[IMU sensor based terrain classification [P]](https://www.reddit.com/r/MachineLearning/comments/1nf03e6/imu_sensor_based_terrain_classification_p/)** (Score: 2)
*   **Summary:** The original poster uses CNNs.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   They use CNNs and don't want to classify based on IMU sensor.

**[[D] Universal Deep Research (UDR): A general wrapper for LLM-Based research (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1nee9fl/d_universal_deep_research_udr_a_general_wrapper/)**
*   **Summary:** General wrapper for LLM-Based research.
*   **Emotion:** The overall emotional tone is Neutral and Positive.
*   **Top 3 Points of View:**
    *   This is the right direction to take.

**[My current thinking on subjectivity of time. [D]](https://www.reddit.com/r/MachineLearning/comments/1nf2h1j/my_current_thinking_on_subjectivity_of_time_d/)** (Score: 0)
*   **Summary:** The overall emotional tone is Neutral.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   ChatGPT psychosis.

**[[D] Seeking Recommendations for AutoML Libraries Compatible with Windows (Python 3.12) in 2025](https://www.reddit.com/r/MachineLearning/comments/1nf9cwu/d_seeking_recommendations_for_automl_libraries/)** (Score: 0)
*   **Summary:** Seeking Recommendations for AutoML Libraries Compatible with Windows (Python 3.12) in 2025.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   Autogluon is compatible with Windows and 3.12.
