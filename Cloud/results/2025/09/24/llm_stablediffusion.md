---
title: "Stable Diffusion Subreddit"
date: "2025-09-24"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] OneTrainer now supports Qwen Image training and more](https://www.reddit.com/r/StableDiffusion/comments/1npi5ps/onetrainer_now_supports_qwen_image_training_and/) (Score: 44)
    *   Users discuss the new features of OneTrainer, particularly Qwen Image training and editing capabilities.
2.  [Qwen Image Edit 2509 is an absolute beast - Segment inpaint <10 seconds (4090)](https://www.reddit.com/gallery/1npj0fj) (Score: 31)
    *   Users praise the speed and functionality of Qwen Image Edit 2509, specifically its segmentation and inpainting features.
3.  [Created a guide with examples for Qwen Image Edit 2509 for 8gb vram users. Workflow included](https://youtu.be/pPNee88eS6M) (Score: 8)
    *   A user created a guide for using Qwen Image Edit 2509 with limited VRAM and shares a workflow.
4.  [CozyGen Update 2: A Mobile-Friendly ComfyUI Controller](https://www.reddit.com/r/StableDiffusion/comments/1npiwsz/cozygen_update_2_a_mobilefriendly_comfyui/) (Score: 6)
    *   Users are interested in using CozyGen to access their desktop ComfyUI from different networks.
5.  [4-steps or 8-steps v2 Qwen-Image-Lightning for best results?](https://www.reddit.com/r/StableDiffusion/comments/1npfxg7/4steps_or_8steps_v2_qwenimagelightning_for_best/) (Score: 5)
    *   Users are experimenting with the optimal number of steps for Qwen-Image-Lightning, with some preferring 4 steps.
6.  [Future (final) : Wan 2.2 IMG2VID and FFLF, Qwen image and SRPO refiner where needed. VIbeVoice for voice cloning. Topaz VIdeo for interpolation and upscaling.](https://www.youtube.com/watch?v=fYGqw98njTo) (Score: 4)
    *   The creator introduces the future version which includes Wan 2.2 IMG2VID and FFLF, Qwen image and SRPO refiner where needed. VIbeVoice for voice cloning, and Topaz Video for interpolation and upscaling.
7.  [Anyone running local models on an M4 Mac Mini Pro](https://www.reddit.com/r/StableDiffusion/comments/1npg8wx/anyone_running_local_models_on_an_m4_mac_mini_pro/) (Score: 1)
    *   Users are discussing the performance of local models on the M4 Mac Mini Pro, with recommendations for software like Drawthings.
8.  [Can i get some assistance please Gentlemen? How do i get this?](https://i.redd.it/z2opig19r5rf1.png) (Score: 0)
    *   A user is asking for help with installing missing custom nodes in ComfyUI.
9.  [Wan2.2 animate question](https://www.reddit.com/r/StableDiffusion/comments/1npez0v/wan22_animate_question/) (Score: 0)
    *   A user is asking questions related to animating Wan2.2.
10. [Qwen image edit 2509 not giving what i want](https://www.reddit.com/r/StableDiffusion/comments/1npg5sw/qwen_image_edit_2509_not_giving_what_i_want/) (Score: 0)
    *   A user is having issues with Qwen image edit 2509 and seeks assistance.
11. [In AUTOMATIC1111 how do I re-queue img2img with the same prompt? Iterate on the same image multiple times.](https://www.reddit.com/r/StableDiffusion/comments/1npgxlw/in_automatic1111_how_do_i_requeue_img2img_with/) (Score: 0)
    *   A user is looking for a way to requeue img2img with the same prompt in AUTOMATIC1111.
12. [Are complicated local upscaling workflows really better than the simplest programmed ones](https://www.reddit.com/r/StableDiffusion/comments/1npgyid/are_complicated_local_upscaling_workflows_really/) (Score: 0)
    *   Users discuss the effectiveness of different upscaling workflows, with SUPIR being recommended for high-quality results.
13. [Am I supposed to use sdxl loras with the base sdxl model?](https://www.reddit.com/r/StableDiffusion/comments/1npjnju/am_i_supposed_to_use_sdxl_loras_with_the_base/) (Score: 0)
    *   A user asks about using SDXL LoRAs with the base SDXL model.
14. [Next major generative model???](https://www.reddit.com/r/StableDiffusion/comments/1npl5st/next_major_generative_model/) (Score: 0)
    *   Users speculate about the next major generative model, mentioning Bytedance, Hidream, Flux, Stable Diffusion, Wan, Qwen, and Chroma.

# Detailed Analysis by Thread
**[[D] OneTrainer now supports Qwen Image training and more (Score: 44)](https://www.reddit.com/r/StableDiffusion/comments/1npi5ps/onetrainer_now_supports_qwen_image_training_and/)**
*  **Summary:** This thread discusses the new features of OneTrainer, specifically the support for Qwen Image training. Users express excitement about the new Qwen image edit and the ability to train with multiple inputs.
*  **Emotion:** The overall emotional tone of the thread is Positive, with users expressing excitement and anticipation for the new features.
*  **Top 3 Points of View:**
    *   Qwen image is a great addition to OneTrainer.
    *   The new Qwen image edit feature is highly anticipated.
    *   The ability to train with multiple inputs will be a significant improvement.

**[Qwen Image Edit 2509 is an absolute beast - Segment inpaint <10 seconds (4090) (Score: 31)](https://www.reddit.com/gallery/1npj0fj)**
*  **Summary:**  A user praises the Qwen Image Edit 2509, highlighting its speed and capabilities, including segmenting characters for crop and stitch and custom resizing.
*  **Emotion:** The emotional tone of the thread is Neutral, with a strong emphasis on providing technical details and functional descriptions.
*  **Top 3 Points of View:**
    *   Qwen Image Edit 2509 is very fast, specifically noting segment inpaint under 10 seconds on a 4090.
    *   It has advanced features such as character segmentation for cropping and stitching.
    *   It allows custom resizing and scaling.

**[Created a guide with examples for Qwen Image Edit 2509 for 8gb vram users. Workflow included (Score: 8)](https://youtu.be/pPNee88eS6M)**
*  **Summary:**  A user created a guide for Qwen Image Edit 2509 for users with 8GB VRAM and included a workflow. Another user noted the significant improvement of 2509 compared to previous versions.
*  **Emotion:** The emotion in the thread is Positive, as users express appreciation for the improvement in the new version of Qwen Image Edit.
*  **Top 3 Points of View:**
    *   Qwen Image Edit 2509 is a lot better than previous versions.
    *   The provided workflow is a standard ComfyUI workflow.
    *   The guide is helpful for users with limited VRAM.

**[CozyGen Update 2: A Mobile-Friendly ComfyUI Controller (Score: 6)](https://www.reddit.com/r/StableDiffusion/comments/1npiwsz/cozygen_update_2_a_mobilefriendly_comfyui/)**
*  **Summary:** The discussion revolves around CozyGen, a mobile-friendly controller for ComfyUI. A user inquires whether it's possible to access their desktop ComfyUI from a different network.
*  **Emotion:** The emotional tone is Neutral, primarily focusing on a question regarding functionality.
*  **Top 1 Points of View:**
    *   A user wants to know if CozyGen allows access to ComfyUI from outside the local network.

**[4-steps or 8-steps v2 Qwen-Image-Lightning for best results? (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1npfxg7/4steps_or_8steps_v2_qwenimagelightning_for_best/)**
*  **Summary:** Users are discussing the optimal number of steps for achieving the best results with Qwen-Image-Lightning v2.
*  **Emotion:** The emotional tone is Neutral, with users sharing their experimental results and opinions.
*  **Top 2 Points of View:**
    *   4 steps can sometimes provide more detail and prompt adherence.
    *   4 steps is better than v1.1 and v2.

**[Future (final) : Wan 2.2 IMG2VID and FFLF, Qwen image and SRPO refiner where needed. VIbeVoice for voice cloning. Topaz VIdeo for interpolation and upscaling. (Score: 4)](https://www.youtube.com/watch?v=fYGqw98njTo)**
*  **Summary:** The thread discusses future iterations of a workflow involving Wan 2.2, Qwen image, VibeVoice, and Topaz Video, where users are trying to implement these in their workflow.
*  **Emotion:** The emotional tone is Neutral, with one comment being a feature list for the future of the project and the other questioning the approach taken in creating videos.
*  **Top 2 Points of View:**
    *  One user proposed a collaboration by providing alternate narration for the video and is seeking images and workflow to test.
    *  One user argues that short shots with cuts and smart splices look better than long, continuous shots (FFLF).

**[Anyone running local models on an M4 Mac Mini Pro (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1npg8wx/anyone_running_local_models_on_an_m4_mac_mini_pro/)**
*  **Summary:** The thread is about running local models on an M4 Mac Mini Pro. Users recommend software optimized for Apple silicon and discuss the performance capabilities of the M4 Pro and M4 Max chips.
*  **Emotion:** The overall emotional tone is Neutral, with users providing informative and technical advice.
*  **Top 3 Points of View:**
    *   Drawthings is a good option for running local models on Apple hardware.
    *   The M4 Pro can run SDXL reasonably fast.
    *   For fine-tuning, an M4 Max or M3 Ultra would be preferable.

**[Can i get some assistance please Gentlemen? How do i get this? (Score: 0)](https://i.redd.it/z2opig19r5rf1.png)**
*  **Summary:** A user is seeking assistance with installing missing custom nodes in ComfyUI.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 2 Points of View:**
    *   Install the missing nodes using ComfyUI Manager.
    *   The DIT Loader might be missing, and the user is given a link to instructions.

**[Wan2.2 animate question (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1npez0v/wan22_animate_question/)**
*  **Summary:** A user is asking questions about animating with Wan2.2. The comment gives suggestions on reference videos.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 1 Points of View:**
    *  One user states that a reference video should contain background music and face tracks. Also, lowering face pose strength can improve results.

**[Qwen image edit 2509 not giving what i want (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1npg5sw/qwen_image_edit_2509_not_giving_what_i_want/)**
*  **Summary:** A user is having issues with Qwen image edit 2509. People give advice on updating ComfyUI and using specific nodes.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Share the images so other users can help.
    *   Update ComfyUI and use the `textencodeqwenimageeditplus` nodes.
    *   The user is using the old workflow instead of the newest one.

**[In AUTOMATIC1111 how do I re-queue img2img with the same prompt? Iterate on the same image multiple times. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1npgxlw/in_automatic1111_how_do_i_requeue_img2img_with/)**
*  **Summary:** A user is seeking a way to re-queue img2img with the same prompt in AUTOMATIC1111 for iterative image generation.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 1 Points of View:**
    *   Batching from output directory1 to output directory2 and repeating the process from directory2 to directory3 in multiple A1111 tabs.

**[Are complicated local upscaling workflows really better than the simplest programmed ones (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1npgyid/are_complicated_local_upscaling_workflows_really/)**
*  **Summary:** The thread is about the effectiveness of complicated local upscaling workflows compared to simpler ones.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 1 Points of View:**
    *   SUPIR is the best option if time and hardware are not an issue, also SD Ultimate Upscale is a common go-to.

**[Am I supposed to use sdxl loras with the base sdxl model? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1npjnju/am_i_supposed_to_use_sdxl_loras_with_the_base/)**
*  **Summary:** A user is asking whether to use SDXL LoRAs with the base SDXL model.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 1 Points of View:**
    *   The SDXL refiner is not used anymore; users should opt for any SDXL fine-tune, and most LoRAs are cross-compatible.

**[Next major generative model??? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1npl5st/next_major_generative_model/)**
*  **Summary:** Users are speculating about the next major generative model.
*  **Emotion:** The overall tone is Neutral, with some Positive sentiment when mentioning Chroma.
*  **Top 3 Points of View:**
    *   Various models are suggested, including Wan, Hunyuan, Qwen, and Bytedance's unnamed model.
    *   Flux and Stable Diffusion are still popular, while Wan offers high quality but is slower.
    *   Chroma is currently incredible and may be overtaken by Qwen or Wan.
