---
title: "Machine Learning Subreddit"
date: "2025-09-24"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "NLP"]
---

# Overall Ranking and Top Discussions
1.  [[D] Is senior ML engineering just API calls now?](https://www.reddit.com/r/MachineLearning/comments/1npdfh1/d_is_senior_ml_engineering_just_api_calls_now/) (Score: 74)
    *   Discusses the shift in ML engineering towards using APIs instead of building models from scratch.
2.  [[D] NeurIPS should start a journal track.](https://www.reddit.com/r/MachineLearning/comments/1np4q19/d_neurips_should_start_a_journal_track/) (Score: 68)
    *   Debates whether NeurIPS should start a journal track and the current state of conference reviews.
3.  [[D] Industry standard for time series based forecasting models](https://www.reddit.com/r/MachineLearning/comments/1np3vup/d_industry_standard_for_time_series_based/) (Score: 5)
    *   Discusses industry standards for time series forecasting models, comparing traditional methods with newer approaches like TabPFN.
4.  [[R] Area there better ways to balance loss weights?](https://www.reddit.com/r/MachineLearning/comments/1npibp8/r_area_there_better_ways_to_balance_loss_weights/) (Score: 3)
    *   Asks about better ways to balance loss weights in machine learning models.
5.  [[R] Tabular Deep Learning: Survey of Challenges, Architectures, and Open Questions](https://www.reddit.com/r/MachineLearning/comments/1nph2lo/r_tabular_deep_learning_survey_of_challenges/) (Score: 2)
    *   Discusses challenges, architectures, and open questions in tabular deep learning.
6.  [[D] Training smaller LLM for Agentic tasks.](https://www.reddit.com/r/MachineLearning/comments/1np483r/d_training_smaller_llm_for_agentic_tasks/) (Score: 1)
    *   Discusses training smaller LLMs for agentic tasks and tool use.
7.  [[P] A Skincare Recommender, but I'm Stuck on a Data Labeling Problem (2000+ Ingredients)](https://www.reddit.com/r/MachineLearning/comments/1npfy8x/p_a_skincare_recommender_but_im_stuck_on_a_data/) (Score: 0)
    *   Asks for help with data labeling for a skincare recommender system.
8.  [[D] What's the minimum level of individual intelligence needed for agents to self-organise and collectively become superintelligent?](https://www.reddit.com/r/MachineLearning/comments/1npm71i/d_whats_the_minimum_level_of_individual/) (Score: 0)
    *   Speculates on the minimum level of intelligence needed for agents to self-organize into a superintelligence.

# Detailed Analysis by Thread
**[[D] Is senior ML engineering just API calls now? (Score: 74)](https://www.reddit.com/r/MachineLearning/comments/1npdfh1/d_is_senior_ml_engineering_just_api_calls_now/)**
*  **Summary:** The thread discusses a perceived shift in machine learning engineering where the focus has moved from building models from scratch to primarily using APIs. Many feel this change has made the work less challenging and less fulfilling.
*  **Emotion:** The overall emotional tone is negative, reflecting disappointment and nostalgia for the "old days" of ML. There are also neutral sentiments, with users trying to rationalize or contextualize the shift. Some users express a positive sentiment when discussing the freedom from hardware limitations and hyperfocus on specific models.
*  **Top 3 Points of View:**
    *   ML engineering has become more about wiring together APIs than building models from scratch.
    *   Econometrics offers more interesting and challenging problems than current ML tasks.
    *   It's important to use the best tool for the job, whether it's an API call or a custom model.

**[[D] NeurIPS should start a journal track. (Score: 68)](https://www.reddit.com/r/MachineLearning/comments/1np4q19/d_neurips_should_start_a_journal_track/)**
*  **Summary:** The thread explores the idea of NeurIPS, a prominent machine learning conference, starting its own journal track. Opinions are divided, with some arguing it would give visibility to solid work and others criticizing the rigor of conference reviews and suggesting focus should be on improving existing journals.
*  **Emotion:** The overall emotional tone is negative, with feelings of frustration toward the conference review process. Some express positive sentiment regarding the potential benefits of a journal track.
*  **Top 3 Points of View:**
    *   NeurIPS reviews are not rigorous enough and a journal track would be beneficial.
    *   NeurIPS should focus on being a conference for fast results and existing journals should be improved instead.
    *   NeurIPS should be split into smaller, more focused conferences.

**[[D] Industry standard for time series based forecasting models (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1np3vup/d_industry_standard_for_time_series_based/)**
*  **Summary:** The thread discusses industry standards for time series forecasting models, with a comparison of classic time series methods and more recent machine learning approaches. One user highlights the successful use of TabPFN.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Traditional time series methods are effective for smaller datasets.
    *   Boosted tree-based models are commonly used.
    *   TabPFN can outperform traditional models in certain applications.

**[[R] Area there better ways to balance loss weights? (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1npibp8/r_area_there_better_ways_to_balance_loss_weights/)**
*  **Summary:** A question is posed about alternative methods for balancing loss weights in machine learning models.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * Gaussian negative-log-likelihood is a guarantee that each loss will contribute to the gradient equally.

**[[R] Tabular Deep Learning: Survey of Challenges, Architectures, and Open Questions (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1nph2lo/r_tabular_deep_learning_survey_of_challenges/)**
*  **Summary:** The thread mentions a survey on tabular deep learning and one user expresses dislike for the word "homogeneous" in the abstract, suggesting "perception data" as a more appropriate term.
*  **Emotion:** The overall emotional tone is negative.
*  **Top 3 Points of View:**
    *   The term "homogeneous" is not suitable for perception data.

**[[D] Training smaller LLM for Agentic tasks. (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1np483r/d_training_smaller_llm_for_agentic_tasks/)**
*  **Summary:** The discussion centers around methods for training smaller language models for agentic tasks, particularly tool use. SFT and RL are mentioned as standard recipes, and a reference to Ellora is provided.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   A combination of SFT and RL is a standard approach.
    *   Implementation details like infra and data quality are important.
    *   Ellora provides a recipe for training tool-calling models.

**[[P] A Skincare Recommender, but I'm Stuck on a Data Labeling Problem (2000+ Ingredients) (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1npfy8x/p_a_skincare_recommender_but_im_stuck_on_a_data/)**
*  **Summary:** The poster is facing challenges with data labeling for a skincare recommender system involving a large number of ingredients.
*  **Emotion:** The overall emotional tone is negative.
*  **Top 3 Points of View:**
    *   Data labeling problems are common in machine learning and need an intermediate step as a shortcut, like a mapping matrix.

**[[D] What's the minimum level of individual intelligence needed for agents to self-organise and collectively become superintelligent? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1npm71i/d_whats_the_minimum_level_of_individual/)**
*  **Summary:** The thread explores the hypothetical question of the minimum intelligence level required for agents to self-organize and achieve superintelligence.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   You overestimate LLMs.

