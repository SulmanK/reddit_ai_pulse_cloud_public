---
title: "LocalLLaMA Subreddit"
date: "2025-09-29"
description: "Analysis of top discussions and trends in the localllama subreddit"
tags: ["LLM", "AI", "Models"]
---

# Overall Ranking and Top Discussions
1.  [[D] Fiction.liveBench tested DeepSeek 3.2, Qwen-max, grok-4-fast, Nemotron-nano-9b](https://i.redd.it/2krrie9kq4sf1.png) (Score: 60)
    *   Users are discussing and comparing the performance of various language models, including DeepSeek 3.2, Qwen-max, grok-4-fast, and Nemotron-nano-9b, based on tests conducted on Fiction.liveBench.
2.  [Sammyuri built a redstone system to run a small language model (~5M params) in Minecraft!](https://www.youtube.com/watch?v=VaeI9YgE1o8) (Score: 55)
    *   The post highlights Sammyuri's achievement of building a redstone system in Minecraft to run a small language model.
3.  [granite 4 GGUFs are still hidden](https://www.reddit.com/gallery/1ntmt7d) (Score: 37)
    *   Users are eagerly awaiting the release of Granite 4 GGUFs and expressing excitement about the unique small MoE model.
4.  [inclusionAI/Ring-1T-preview](https://i.redd.it/7vb7yumam5sf1.png) (Score: 24)
    *   The discussion revolves around inclusionAI's Ring-1T model, a large open-weight reasoning model, with users estimating its training requirements and capabilities.
5.  [I think gpt-oss:20b misunderstood its own thought process.](https://www.reddit.com/gallery/1ntml0a) (Score: 17)
    *   The post discusses the issue of the gpt-oss:20b model misunderstanding its own thought process, with users sharing their experiences and potential causes.
6.  [FULL Sonnet 4.5 System Prompt and Internal Tools](https://www.reddit.com/r/LocalLLaMA/comments/1ntofd1/full_sonnet_45_system_prompt_and_internal_tools/) (Score: 7)
    *   Users are sharing and discussing the full system prompt and internal tools of Sonnet 4.5.
7.  [Inside NVIDIA GPUs: Anatomy of high performance matmul kernels](https://www.aleksagordic.com/blog/matmul) (Score: 6)
    *   The post links to an article discussing the anatomy of high-performance matmul kernels inside NVIDIA GPUs, with users praising the detailed work.
8.  [Ai based on textbooks](https://www.reddit.com/r/LocalLLaMA/comments/1ntma74/ai_based_on_textbooks/) (Score: 2)
    *   The post discusses the use of AI based on textbooks, with users suggesting the use of a RAG setup.
9.  [Easy unit of measurement for pricing a model in terms of hardware](https://www.reddit.com/r/LocalLLaMA/comments/1ntmcpt/easy_unit_of_measurement_for_pricing_a_model_in/) (Score: 2)
    *   The discussion revolves around finding an easy unit of measurement for pricing a model in terms of hardware, with users pointing out the complexity of the task.
10. [AI Workstation (on a budget)](https://www.reddit.com/r/LocalLLaMA/comments/1ntom5r/ai_workstation_on_a_budget/) (Score: 2)
    *   The post discusses building an AI workstation on a budget, with users sharing their hardware setups and recommendations.
11. [What tools do you recommend for coding?](https://www.reddit.com/r/LocalLLaMA/comments/1ntrzml/what_tools_do_you_recommend_for_coding/) (Score: 1)
    *   Users are recommending different coding tools and language models for coding.
12. [[iOS] Pocket LLM – On-Device AI Chat, 100% Private & Offline | [$3.99 -> Free]](https://apps.apple.com/us/app/local-ai-chat-pocket-llm/id6752952699) (Score: 0)
    *   The post announces the availability of Pocket LLM, an on-device AI chat application for iOS, with users discussing its features and limitations.
13. [Two medium sized LLMs dropped the same day. DeepSeek V3.2 - Claude Sonnet 4.5. USA is winning the AI race.](https://i.redd.it/istjgh50s5sf1.jpeg) (Score: 0)
    *   The post compares the release of two medium-sized LLMs, DeepSeek V3.2 and Claude Sonnet 4.5, with users discussing their different purposes and capabilities.
14. [Apple’s Foundation Models framework unlocks new app experiences powered by Apple Intelligence](https://www.apple.com/newsroom/2025/09/apples-foundation-models-framework-unlocks-new-intelligent-app-experiences/) (Score: 0)
    *   The post shares an article about Apple's Foundation Models framework, with users commenting on the prevalence of Apple-related content in the subreddit.
15. [This Simple Trick Makes AI Far More Reliable (By Making It Argue With Itself)](https://www.reddit.com/r/LocalLLaMA/comments/1ntmbl8/this_simple_trick_makes_ai_far_more_reliable_by/) (Score: 0)
    *   The post discusses a technique to improve AI reliability by making it argue with itself, with users sharing alternative methods and research papers.
16. [so ollama just released a new optimization](https://www.reddit.com/r/LocalLLaMA/comments/1ntmqz6/so_ollama_just_released_a_new_optimization/) (Score: 0)
    *   The post announces a new optimization released by Ollama, with users discussing its potential impact on performance and memory usage.
17. [Why ollama and lm studio use CPU instead of gpu](https://www.reddit.com/r/LocalLLaMA/comments/1ntq1es/why_ollama_and_lm_studio_use_cpu_instead_of_gpu/) (Score: 0)
    *   The post asks why Ollama and LM Studio use CPU instead of GPU, with users providing suggestions on how to offload layers to the GPU.
18. [Chinese models](https://www.reddit.com/r/LocalLLaMA/comments/1ntqzar/chinese_models/) (Score: 0)
    *   The post is about Chinese language models, with users giving suggestions to try them out.

# Detailed Analysis by Thread
**[[D] Fiction.liveBench tested DeepSeek 3.2, Qwen-max, grok-4-fast, Nemotron-nano-9b (Score: 60)](https://i.redd.it/2krrie9kq4sf1.png)**
*  **Summary:** Users discuss the performance of various language models on Fiction.liveBench, focusing on context handling, reasoning abilities, and potential improvements with experimental versions. There's also criticism about the methodology of model comparisons and requests for including older models in the tests.
*  **Emotion:** The overall emotional tone is mixed. While there's excitement (Positive sentiment) about improvements in some models, there are also Negative sentiments expressed regarding model performance and Neutral sentiments regarding comparisons between models.
*  **Top 3 Points of View:**
    *   Some models, like the experimental DeepSeek, show improved long context performance.
    *   There's a critique about the methodology of removing older models from the benchmark and focusing only on the newest ones.
    *   There are varied opinions on specific models like qwq32 and gpt-oss-120b, with some praising their comprehension and others questioning their performance.

**[Sammyuri built a redstone system to run a small language model (~5M params) in Minecraft! (Score: 55)](https://www.youtube.com/watch?v=VaeI9YgE1o8)**
*  **Summary:** The post discusses Sammyuri's creation of a redstone system in Minecraft to run a small language model. Users express amazement and excitement about this achievement.
*  **Emotion:** The emotional tone is largely Positive, with users expressing awe and excitement. However, there is also a touch of Negative sentiment with a user mentioning an existential crisis. The overall sentiment is that of surprise and approval.
*  **Top 3 Points of View:**
    *   Sammyuri's creation is considered impressive and innovative.
    *   There is surprise that a language model can be run within Minecraft's mechanics.
    *   The achievement raises existential questions for some users.

**[granite 4 GGUFs are still hidden (Score: 37)](https://www.reddit.com/gallery/1ntmt7d)**
*  **Summary:** The discussion centers around the anticipation for the release of Granite 4 GGUFs. Users express excitement and anticipation for these models, hoping they haven't been overshadowed by newer models.
*  **Emotion:** The overall emotional tone is Positive, with users expressing excitement and eagerness for the release of the Granite models. Neutral sentiments are also present.
*  **Top 3 Points of View:**
    *   Users are highly anticipating the release of the Granite 4 GGUFs.
    *   There's hope that the Granite models are not eclipsed by newer releases like Qwen3-Next.
    *   The Granite 4 is expected to be a unique small MoE (Mixture of Experts) model.

**[inclusionAI/Ring-1T-preview (Score: 24)](https://i.redd.it/7vb7yumam5sf1.png)**
*  **Summary:** The discussion is about the Ring-1T model by inclusionAI. Users are discussing its size, training requirements, and capabilities.
*  **Emotion:** The emotional tone is mostly Neutral, with some undertones of excitement.
*  **Top 3 Points of View:**
    *   The Ring-1T model is considered a very large model, potentially requiring significant resources to run.
    *   It's speculated that the model's size was deliberately chosen to "flex" computational power.
    *   A chat interface for the model is anticipated.

**[I think gpt-oss:20b misunderstood its own thought process. (Score: 17)](https://www.reddit.com/gallery/1ntml0a)**
*  **Summary:** The discussion revolves around the GPT-OSS:20b model and its apparent tendency to misunderstand its own reasoning process. Users share their experiences and discuss potential reasons for this behavior.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The 20b model has inherent issues with its thought process.
    *   The "reasoning" function on local models wastes tokens and produces unrelated responses.
    *   Parameter choices might be affecting the results.

**[FULL Sonnet 4.5 System Prompt and Internal Tools (Score: 7)](https://www.reddit.com/r/LocalLLaMA/comments/1ntofd1/full_sonnet_45_system_prompt_and_internal_tools/)**
*  **Summary:** The post involves sharing and discussing the system prompt and internal tools of Sonnet 4.5. Users are providing the official source and discussing the possibility of LLMs hallucinating prompts.
*  **Emotion:** The emotional tone is predominantly Neutral.
*  **Top 3 Points of View:**
    *   Sharing the official source of the system prompts.
    *   Cautioning that LLMs may hallucinate when asked to print prompts.
    *   Search results aren't from the human - do not thank user.

**[Inside NVIDIA GPUs: Anatomy of high performance matmul kernels (Score: 6)](https://www.aleksagordic.com/blog/matmul)**
*  **Summary:** The post is a link to a blog discussing the anatomy of high performance matmul kernels.
*  **Emotion:** The overall emotional tone is Positive, with users praising the amount of work in the post.
*  **Top 1 Points of View:**
    *  The post is a lot of work and appreciated.

**[Ai based on textbooks (Score: 2)](https://www.reddit.com/r/LocalLLaMA/comments/1ntma74/ai_based_on_textbooks/)**
*  **Summary:** The post is on how to use AI based on textbooks.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 1 Points of View:**
    * A RAG setup using the textbooks as sources.

**[Easy unit of measurement for pricing a model in terms of hardware (Score: 2)](https://www.reddit.com/r/LocalLLaMA/comments/1ntmcpt/easy_unit_of_measurement_for_pricing_a_model_in/)**
*  **Summary:** The post discusses the difficulties in getting a easy measurement for pricing a model in terms of hardware.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 1 Points of View:**
    * This will not work because It is far easier to get 100t/s at prompt length 0 that at prompt length 150k.

**[AI Workstation (on a budget) (Score: 2)](https://www.reddit.com/r/LocalLLaMA/comments/1ntom5r/ai_workstation_on_a_budget/)**
*  **Summary:** The post discusses building an AI workstation on a budget.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Imo fp8 and fp4 (in hopper and blackwell) are to be considered.
    *   Ampere nvlink bridges cost more than 3090. It's nearly impossible to find them.
    *   2x3090 remains a strong option when VRAM bound.

**[What tools do you recommend for coding? (Score: 1)](https://www.reddit.com/r/LocalLLaMA/comments/1ntrzml/what_tools_do_you_recommend_for_coding/)**
*  **Summary:** The post asks for what tools do you recommend for coding?
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Roo code, GLM-4.5
    *   continue.dev extension + llama with any model you can run with your hw
    *   Qwen Code + Qwen Coder

**[[iOS] Pocket LLM – On-Device AI Chat, 100% Private & Offline | [$3.99 -> Free] (Score: 0)](https://apps.apple.com/us/app/local-ai-chat-pocket-llm/id6752952699)**
*  **Summary:** The post announces the availability of Pocket LLM, an on-device AI chat application for iOS, with users discussing its features and limitations.
*  **Emotion:** The emotional tone is mixed, with Negative sentiments regarding model performance. Neutral sentiments are also present.
*  **Top 3 Points of View:**
    *   reasoning tags and end of turns just don’t parse correctly
    *   self-promotion
    *   that's I why buy iPad m5 with 16-24gb ram ... I hate to wait

**[Two medium sized LLMs dropped the same day. DeepSeek V3.2 - Claude Sonnet 4.5. USA is winning the AI race. (Score: 0)](https://i.redd.it/istjgh50s5sf1.jpeg)**
*  **Summary:** The post compares the release of two medium-sized LLMs, DeepSeek V3.2 and Claude Sonnet 4.5, with users discussing their different purposes and capabilities.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *  Deepseek V3.2 is experimental, open and cheap. Sonnet 4.5 is the product of billions of dollars of training.
    *  Bruh deepseek literally states in their description, that this is a research model to test their new sparse attention.
    *  one is an experimental research model trying to improve context scaling they put out to the public, the other is a large corpo release.

**[Apple’s Foundation Models framework unlocks new app experiences powered by Apple Intelligence (Score: 0)](https://www.apple.com/newsroom/2025/09/apples-foundation-models-framework-unlocks-new-intelligent-app-experiences/)**
*  **Summary:** The post shares an article about Apple's Foundation Models framework, with users commenting on the prevalence of Apple-related content in the subreddit.
*  **Emotion:** The emotional tone is Negative, with users being annoyed with Apple sponsored posts.
*  **Top 1 Points of View:**
    *  A day without Apple's sponsored post on this sub is a day wasted.

**[This Simple Trick Makes AI Far More Reliable (By Making It Argue With Itself) (Score: 0)](https://www.reddit.com/r/LocalLLaMA/comments/1ntmbl8/this_simple_trick_makes_ai_far_more_reliable_by/)**
*  **Summary:** The post discusses a technique to improve AI reliability by making it argue with itself, with users sharing alternative methods and research papers.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *  do this with different models, not the same one
    *  Ask the AI to ask you questions that it might have about what you're asking until it thinks it can summarize the task - then proceed with the task.
    *  What's the difference between this and the same model with four different seeds?

**[so ollama just released a new optimization (Score: 0)](https://www.reddit.com/r/LocalLLaMA/comments/1ntmqz6/so_ollama_just_released_a_new_optimization/)**
*  **Summary:** The post announces a new optimization released by Ollama, with users discussing its potential impact on performance and memory usage.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *  Ollama's new engine may have fixed performance problems on some Macbook Pro models.
    *  Ollama's new engine allows more accurate memory estimation.
    *  wow they compare 49/49 offloaded layers with 48/49 layers then they say it's now faster because more tokens per second, maybe they should also compare with 47/49 layers for even more speedup, then 46/49 layers and so on

**[Why ollama and lm studio use CPU instead of gpu (Score: 0)](https://www.reddit.com/r/LocalLLaMA/comments/1ntq1es/why_ollama_and_lm_studio_use_cpu_instead_of_gpu/)**
*  **Summary:** The post asks why Ollama and LM Studio use CPU instead of GPU, with users providing suggestions on how to offload layers to the GPU.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 1 Points of View:**
    *  Offload all the layers to the GPU.

**[Chinese models (Score: 0)](https://www.reddit.com/r/LocalLLaMA/comments/1ntqzar/chinese_models/)**
*  **Summary:** The post is about Chinese language models, with users giving suggestions to try them out.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *  Why don‘t you just try them out?
    *  Try them.
    *  You can try them for free in their sites.
