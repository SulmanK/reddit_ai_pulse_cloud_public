---
title: "Machine Learning Subreddit"
date: "2025-12-05"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "research"]
---

# Overall Ranking and Top Discussions
1.  [[D][R] Paper Completely Ripped Off](https://www.reddit.com/r/MachineLearning/comments/1pehf5w/dr_paper_completely_ripped_off/) (Score: 200)
    *   A user claims their paper was ripped off by famous researchers, sparking discussion about plagiarism and academic integrity in the ML community.
2.  [D] IJCAI-ECAI 2026 piloting "Primary Paper" and Submission Fee initiatives](https://www.reddit.com/r/MachineLearning/comments/1pe8rix/d_ijcaiecai_2026_piloting_primary_paper_and/) (Score: 46)
    *   IJCAI-ECAI 2026 is piloting "Primary Paper" and Submission Fee initiatives. People are discussing the bad equality between countries.
3.  [[D] We stress-tested the idea of “LLMs with thousands of tools.” The results challenge some assumptions.](https://www.reddit.com/r/MachineLearning/comments/1pei5vc/d_we_stresstested_the_idea_of_llms_with_thousands/) (Score: 44)
    *   A blog post about LLMs with thousands of tools is being discussed, challenging assumptions about their effectiveness.
4.  [[D] Are there any emerging LLM related directions that do not require too expensive computing?](https://www.reddit.com/r/MachineLearning/comments/1perrq2/d_are_there_any_emerging_llm_related_directions/) (Score: 9)
    *   People are discussing about what emerging LLM related directions do not require too expensive computing.
5.  [[P] Visualizing emergent structure in the Dragon Hatchling (BDH): a brain-inspired alternative to transformers](https://www.reddit.com/r/MachineLearning/comments/1perpzl/p_visualizing_emergent_structure_in_the_dragon/) (Score: 7)
    *   A paper visualizing emergent structure in the Dragon Hatchling is being discussed.
6.  [[P] Zero Catastrophic Forgetting in MoE Continual Learning: 100% Retention Across 12 Multimodal Tasks (Results + Reproducibility Repo)](https://www.reddit.com/r/MachineLearning/comments/1pe9u25/p_zero_catastrophic_forgetting_in_moe_continual/) (Score: 7)
    *   A paper claiming zero catastrophic forgetting in MoE continual learning is being discussed.
7.  [[D] Tiny Recursive Models (TRMs), Hierarchical Reasoning Models (HRMs) too](https://www.reddit.com/r/MachineLearning/comments/1pewrwt/d_tiny_recursive_models_trms_hierarchical/) (Score: 4)
    *   People are waiting to talk about Tiny Recursive Models (TRMs) and Hierarchical Reasoning Models (HRMs).
8.  [[D] Common reasons ACL submissions are rejected](https://www.reddit.com/r/MachineLearning/comments/1peml7p/d_common_reasons_acl_submissions_are_rejected/) (Score: 4)
    *   The ARR reviewer guideline lists common problems with NLP papers and those are being discussed.
9.  [[D] From ICLR Workshop to full paper? Is this allowed?](https://www.reddit.com/r/MachineLearning/comments/1pevvrb/d_from_iclr_workshop_to_full_paper_is_this_allowed/) (Score: 4)
    *   Whether it is okay to write a full paper after presenting at an ICLR workshop.
10. [[R] Machine Learning Model Algorithm for Sign language](https://www.reddit.com/r/MachineLearning/comments/1pepjtf/r_machine_learning_model_algorithm_for_sign/) (Score: 1)
    *   Machine Learning Model Algorithm for Sign language is being researched.
11. [[D] Embedding Drift hurt our Agentic AI more than model choice](https://www.reddit.com/r/MachineLearning/comments/1peftml/d_embedding_drift_hurt_our_agentic_ai_more_than/) (Score: 0)
    *   Embedding Drift hurt the Agentic AI more than model choice.
12. [[D] Questions about advances in AI](https://www.reddit.com/r/MachineLearning/comments/1peg4gh/d_questions_about_advances_in_ai/) (Score: 0)
    *   People are discussing questions about advances in AI.
13. [Project] I built a Distributed Orchestrator Architecture using LLM to replace Search Indexing](https://www.reddit.com/r/MachineLearning/comments/1peuw7g/project_i_built_a_distributed_orchestrator/) (Score: 0)
    *   A distributed Orchestrator Architecture using LLM to replace Search Indexing is showcased.

# Detailed Analysis by Thread
**[[D][R] Paper Completely Ripped Off (Score: 200)](https://www.reddit.com/r/MachineLearning/comments/1pehf5w/dr_paper_completely_ripped_off/)**
*  **Summary:**  A researcher claims their paper was plagiarized by famous researchers from well-known universities, leading to a discussion about ethics and the review process in the machine learning community. The original poster (OP) submitted to ICLR.
*  **Emotion:** The overall emotional tone is mostly neutral.
*  **Top 3 Points of View:**
    *   The OP should take this up with their institution and raise concerns with the universities involved, suggesting potential collusion.
    *   Concurrent work is common and the OP shouldn't stress too much, focusing on publishing their good paper.
    *   Unless there is clear evidence of plagiarism, treat it as concurrent work and move on.

**[[D] IJCAI-ECAI 2026 piloting "Primary Paper" and Submission Fee initiatives (Score: 46)](https://www.reddit.com/r/MachineLearning/comments/1pe8rix/d_ijcaiecai_2026_piloting_primary_paper_and/)**
*  **Summary:**  The IJCAI-ECAI 2026 conference is piloting a "Primary Paper" initiative and submission fees.  The discussion revolves around the fairness of submission fees, especially for researchers from less wealthy countries, and the impact on smaller labs.
*  **Emotion:** The emotion is mostly neutral, but with a hint of negative sentiment because of the equality between countries and a bad idea for equality between countries.
*  **Top 3 Points of View:**
    *   Submission fees create inequality between researchers from different countries.
    *   The fees are a good idea to discourage low-quality submissions from large labs.
    *   The submission fees are not an important problem, because people spend $200+/month on chatgpt subscriptions.

**[[D] We stress-tested the idea of “LLMs with thousands of tools.” The results challenge some assumptions. (Score: 44)](https://www.reddit.com/r/MachineLearning/comments/1pei5vc/d_we_stresstested_the_idea_of_llms_with_thousands/)**
*  **Summary:**  A discussion about a blog post that stress-tested LLMs with a large number of tools.  The results challenge the assumption that simply providing more tools leads to better performance.
*  **Emotion:** The emotion is mostly neutral, but with some negative sentiment regarding the practicality and effectiveness of using LLMs with thousands of tools.
*  **Top 3 Points of View:**
    *   Intertwining task decomposition and tool searching is key to making LLMs with tools work effectively.
    *   Using LLMs with thousands of tools is fundamentally a bad idea due to security, cost, and reliability concerns.
    *   RAG may be a better way to pick tools.

**[[D] Are there any emerging LLM related directions that do not require too expensive computing? (Score: 9)](https://www.reddit.com/r/MachineLearning/comments/1perrq2/d_are_there_any_emerging_llm_related_directions/)**
*  **Summary:** The discussion is about emerging research directions in LLMs that can be pursued without requiring significant computational resources.
*  **Emotion:** The emotion is mostly neutral with a slight positivity regarding the possibilities in the field.
*  **Top 3 Points of View:**
    *   Many research areas like evaluation, user studies, and interpretability do not require extensive computing power.
    *   GPT-1 was trained with fewer resources than are typically available today, suggesting that smaller models can still be valuable for research.
    *   Small-scale research is possible on really small, low parameter models.

**[[P] Visualizing emergent structure in the Dragon Hatchling (BDH): a brain-inspired alternative to transformers (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1perpzl/p_visualizing_emergent_structure_in_the_dragon/)**
*  **Summary:**  A paper presenting the Dragon Hatchling (BDH) architecture as a brain-inspired alternative to transformers is being discussed, with some questioning its novelty and the justification for its name.
*  **Emotion:** The emotion is mostly neutral, but with a slight positivity regarding the visualisation.
*  **Top 3 Points of View:**
    *   The architecture is just linear attention with Q=K, V=hidden_states, and some extra ReLUs thrown in.
    *   The neuroscience terminology used is excessive and potentially misleading.
    *   The approach does not benefit from distribution normalization/optimal transport (softmax).

**[[P] Zero Catastrophic Forgetting in MoE Continual Learning: 100% Retention Across 12 Multimodal Tasks (Results + Reproducibility Repo) (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1pe9u25/p_zero_catastrophic_forgetting_in_moe_continual/)**
*  **Summary:**  A paper claiming zero catastrophic forgetting in a Mixture of Experts (MoE) continual learning setup is met with skepticism.  The discussion focuses on the validity of the claims, the experimental setup, and the potential for transfer learning.
*  **Emotion:** The emotion is mostly neutral.
*  **Top 3 Points of View:**
    *   The claims are too big and require careful validation, with some doubting the reproducibility of the results.
    *   The experimental setup may not demonstrate true continual learning, as the model might simply be learning isolated tasks.
    *   Geometric MoE architecture based on prototypes and EMA has the capabilities to be modular, but it's too early to tell if it will actually work.

**[[D] Tiny Recursive Models (TRMs), Hierarchical Reasoning Models (HRMs) too (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1pewrwt/d_tiny_recursive_models_trms_hierarchical/)**
*  **Summary:**  This thread consists of only a reminder comment, indicating a potential future discussion about Tiny Recursive Models (TRMs) and Hierarchical Reasoning Models (HRMs).
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    *   There is no points of view to extract from the text.

**[[D] Common reasons ACL submissions are rejected (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1peml7p/d_common_reasons_acl_submissions_are_rejected/)**
*  **Summary:**  Discussion about the common pitfalls that lead to rejection of submissions to the Association for Computational Linguistics (ACL) conferences, based on the ARR reviewer guidelines.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    *   The ARR reviewer guideline lists common problems with NLP papers.
    *   Strong baselines and clear motivation are more important than most people realize; poor framing destroys even good ideas.
    *   ACL is oriented those good storytellers.

**[[D] From ICLR Workshop to full paper? Is this allowed? (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1pevvrb/d_from_iclr_workshop_to_full_paper_is_this_allowed/)**
*  **Summary:**  A user is asking whether it is acceptable to expand a workshop paper presented at the International Conference on Learning Representations (ICLR) into a full research paper.
*  **Emotion:** The emotion is mostly neutral with a slight positivity.
*  **Top 3 Points of View:**
    *   It is acceptable to expand a workshop paper into a full research paper if the workshop is non-archival.
    *   People are more worried about all the workshops being inundated with llm adjacent topics.
    *   Non-archival workshops are unrelated to published papers.

**[[R] Machine Learning Model Algorithm for Sign language (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1pepjtf/r_machine_learning_model_algorithm_for_sign/)**
*  **Summary:**  A user is asking about machine learning algorithms for sign language recognition.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    *   The best models for sign language recognition are transformer based.

**[[D] Embedding Drift hurt our Agentic AI more than model choice (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1peftml/d_embedding_drift_hurt_our_agentic_ai_more_than/)**
*  **Summary:**  A user is discussing how embedding drift negatively impacted their agentic AI system more significantly than the choice of model.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    *   Implement a benchmark suite of query-document pairs to measure retrieval stability.
    *   Standardize the compute environment for embedding generation.
    *   Fine tune tune your embeddings model..

**[[D] Questions about advances in AI (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1peg4gh/d_questions_about_advances_in_ai/)**
*  **Summary:**  A user is asking general questions about advances in AI, particularly regarding the ability of LLMs to generalize and generate novel hypotheses.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    *   The distinction between "generalizing beyond their training data" and "only remixing the existing data" is not well defined technically.
    *   LLMs are capable of generalising beyond their training data.
    *   People confuse two distinct notions of what it means to generalize.

**[Project] I built a Distributed Orchestrator Architecture using LLM to replace Search Indexing (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1peuw7g/project_i_built_a_distributed_orchestrator/)**
*  **Summary:** A user is presenting a project with link to article and github.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    *   There is no points of view to extract from the text.
