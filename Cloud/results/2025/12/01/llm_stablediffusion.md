---
title: "Stable Diffusion Subreddit"
date: "2025-12-01"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] Z image might be the legitimate XL successor ðŸ¥¹](https://www.reddit.com/gallery/1pbk9yc) (Score: 88)
    *  Users discuss the potential of Z image as a successor to Stable Diffusion XL, with comparisons to Flux and experiences with LoRA training.
2.  [Z-Image-Turbo Prompt Enhancer V3 [FINAL]: Before & After Comparison](https://www.reddit.com/gallery/1pbidzf) (Score: 11)
    *  Users are discussing Z-Image-Turbo Prompt Enhancer V3. Some find that the workflow is no longer available and others are wondering if they can run a smaller llm locally within comfy.
3.  [Do We Know Roughly How Much VRAM Will Be Required for Z Image Base?](https://www.reddit.com/r/StableDiffusion/comments/1pbjofv/do_we_know_roughly_how_much_vram_will_be_required/) (Score: 5)
    *  Users speculate on the VRAM requirements for the Z Image Base model, with estimates ranging from 6B to 12B.
4.  [Help with Forge Ui/Neo install and setup on linux with a 5060ti](https://www.reddit.com/r/StableDiffusion/comments/1pbisy2/help_with_forge_uineo_install_and_setup_on_linux/) (Score: 3)
    *  A user is asking for help installing and setting up Forge Ui/Neo on Linux.
5.  [Latent Streaming Synthesis AKA long video generation](https://www.reddit.com/r/StableDiffusion/comments/1pbitwz/latent_streaming_synthesis_aka_long_video/) (Score: 3)
    *  Users discuss the landscape of open-source and closed-source AI models, with a focus on video generation and hardware requirements.
6.  [Best way to upscale (or img2img) while preserving a person's face?](https://www.reddit.com/r/StableDiffusion/comments/1pbkxzq/best_way_to_upscale_or_img2img_while_preserving_a/) (Score: 3)
    *  Users discuss the best way to upscale (or img2img) while preserving a person's face.
7.  [Is there a workflow for Wan 2.2 animate with Sam 3 ?](https://www.reddit.com/r/StableDiffusion/comments/1pbkq8k/is_there_a_workflow_for_wan_22_animate_with_sam_3/) (Score: 2)
    *  A user is looking for a workflow for Wan 2.2 animate with Sam 3.
8.  [How to create high quality dataset of character for lora training ?](https://www.reddit.com/r/StableDiffusion/comments/1pblua9/how_to_create_high_quality_dataset_of_character/) (Score: 2)
    *  Users discuss methods and tools for creating high-quality datasets for LoRA training, comparing SDXL training with Kohya to other methods.
9.  [Just got access to free H100, What models should I try?](https://www.reddit.com/r/StableDiffusion/comments/1pbl8h3/just_got_access_to_free_h100_what_models_should_i/) (Score: 2)
    *  Users offer suggestions for AI models to try on a free H100, including Flux Loras, Qwen, WAN2.2, and Hunyuan Image 3.0.
10. [The Abyssal Superorganism: Awakening of the Autonomous Sentinels](https://www.youtube.com/shorts/f__dRrjP6bQ) (Score: 1)
    *  A user posted a gif
11. [Jenna Ortega, Z-image lora test.](https://www.reddit.com/gallery/1pbmqtq) (Score: 1)
    *  Users react to a LoRA test featuring Jenna Ortega, with some cautioning about Reddit's policies on celebrity images.
12. [Where to check for Loras (Z Image edition)](https://www.reddit.com/r/StableDiffusion/comments/1pblmku/where_to_check_for_loras_z_image_edition/) (Score: 1)
    *  Users are looking for the best places to find Loras for Z Image.
13. [How to upscale an image from 256 to 1024?](https://www.reddit.com/r/StableDiffusion/comments/1pbmsfj/how_to_upscale_an_image_from_256_to_1024/) (Score: 1)
    *  Users are providing recommendations for upscaling images from 256 to 1024, including SeedVR2, SUPIR, and Flux upscaler.
14. [Anyone guide me please](https://www.reddit.com/r/StableDiffusion/comments/1pbjx2d/anyone_guide_me_please/) (Score: 0)
    *  Users respond to a vague request for guidance by asking for more specific questions and suggesting resources.
15. [Tried a portrait in SD and the result was off](https://www.reddit.com/r/StableDiffusion/comments/1pbieew/tried_a_portrait_in_sd_and_the_result_was_off/) (Score: 0)
    *  A user is asking for advice on how to improve portraits in Stable Diffusion.

# Detailed Analysis by Thread
**[[D] Z image might be the legitimate XL successor ðŸ¥¹ (Score: 88)](https://www.reddit.com/gallery/1pbk9yc)**
*   **Summary:** Users discuss the potential of Z image as a successor to Stable Diffusion XL, with comparisons to Flux and experiences with LoRA training.
*   **Emotion:** The emotional tone is mixed, with a combination of positive and negative sentiments. There's excitement about Z image but also some concerns about its limitations.
*   **Top 3 Points of View:**
    *   Z image shows promise as a successor to SDXL.
    *   Z image may not be good with LoRA stacking.
    *   Some argue that Flux was the successor to SDXL, and ZIT will succeed Flux.

**[Z-Image-Turbo Prompt Enhancer V3 [FINAL]: Before & After Comparison (Score: 11)](https://www.reddit.com/gallery/1pbidzf)**
*   **Summary:** Users are discussing Z-Image-Turbo Prompt Enhancer V3. Some find that the workflow is no longer available and others are wondering if they can run a smaller llm locally within comfy.
*   **Emotion:** The emotional tone is negative.
*   **Top 3 Points of View:**
    *   The workflow is no longer available.
    *   Wanting to know if there is a way to run a smaller llm locally within comfy.

**[Do We Know Roughly How Much VRAM Will Be Required for Z Image Base? (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1pbjofv/do_we_know_roughly_how_much_vram_will_be_required/)**
*   **Summary:** Users speculate on the VRAM requirements for the Z Image Base model, with estimates ranging from 6B to 12B.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   The VRAM requirement is unknown, and anyone claiming to know is guessing.
    *   It will probably be the same size. Turbo is 6B so base may also be 6B. Worse case scenario...8~12b.
    *   A 3090 should be enough.

**[Help with Forge Ui/Neo install and setup on linux with a 5060ti (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1pbisy2/help_with_forge_uineo_install_and_setup_on_linux/)**
*   **Summary:** A user is asking for help installing and setting up Forge Ui/Neo on Linux.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Use the tool [https://github.com/LykosAI/StabilityMatrix](https://github.com/LykosAI/StabilityMatrix) to install forge then change release to neo.

**[Latent Streaming Synthesis AKA long video generation (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1pbitwz/latent_streaming_synthesis_aka_long_video/)**
*   **Summary:** Users discuss the landscape of open-source and closed-source AI models, with a focus on video generation and hardware requirements.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   The next big thing will probably be US-dominated. Most of the "next big thing" models are closed-source and need enterprise-class hardware to run. The open-source models Alibaba are doing are smaller and easier to run on consumer hardware and last-gen tech

**[Best way to upscale (or img2img) while preserving a person's face? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1pbkxzq/best_way_to_upscale_or_img2img_while_preserving_a/)**
*   **Summary:** Users discuss the best way to upscale (or img2img) while preserving a person's face.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   In my opinion there are 2 kinds of upscaling tasks and the best solution depends on which one you're trying to do. Are you trying to turn a *** image into a good image, or trying to turn a good image into a great image?

**[Is there a workflow for Wan 2.2 animate with Sam 3 ? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1pbkq8k/is_there_a_workflow_for_wan_22_animate_with_sam_3/)**
*   **Summary:** A user is looking for a workflow for Wan 2.2 animate with Sam 3.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   just watched a new youtube video from Benji that comes with workflow - [https://youtu.be/jR-fMaPMYfE?si=BzgcawSrxv-DHY-M](https://youtu.be/jR-fMaPMYfE?si=BzgcawSrxv-DHY-M)

**[How to create high quality dataset of character for lora training ? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1pblua9/how_to_create_high_quality_dataset_of_character/)**
*   **Summary:** Users discuss methods and tools for creating high-quality datasets for LoRA training, comparing SDXL training with Kohya to other methods.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   SDXL training with Kohya is the best AI tool for me. For the dataset, I use 40-50 images. I usually create a second style-LoRA - photorealistic images of random people to go with the character LoRA.
    *   Once you have consistent images, you could try running it through Qwen Edit and generating the various images you require with that. There is an easy-to-use workflow for it.

**[Just got access to free H100, What models should I try? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1pbl8h3/just_got_access_to_free_h100_what_models_should_i/)**
*   **Summary:** Users offer suggestions for AI models to try on a free H100, including Flux Loras, Qwen, WAN2.2, and Hunyuan Image 3.0.
*   **Emotion:** The emotional tone is generally neutral.
*   **Top 3 Points of View:**
    *   Try regular Flux Loras with Flux 2
    *   Try qwen and wan at full xD
    *   Depends on what your goals are. If you want to explore SOTA models that no consumer GPU can run, let us know what is like to run [https://github.com/Tencent-Hunyuan/HunyuanImage-3.0](https://github.com/Tencent-Hunyuan/HunyuanImage-3.0)

**[The Abyssal Superorganism: Awakening of the Autonomous Sentinels (Score: 1)](https://www.youtube.com/shorts/f__dRrjP6bQ)**
*   **Summary:** A user posted a gif
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   ![gif](giphy|10MhRblMbDOt2g)

**[Jenna Ortega, Z-image lora test. (Score: 1)](https://www.reddit.com/gallery/1pbmqtq)**
*   **Summary:** Users react to a LoRA test featuring Jenna Ortega, with some cautioning about Reddit's policies on celebrity images.
*   **Emotion:** The overall emotional tone is positive.
*   **Top 3 Points of View:**
    *   Good job. It looks like a very good LoRA. Now, consider deleting this post. The Reddit admin bots are kinda touchy about celeb gens.
    *   Let's do a lora exchange. I did one with another celebrity. Send me a private message. Before they delete the post!
    *   First image is the only good one. Image #5 looks like Peter Dinklage

**[Where to check for Loras (Z Image edition) (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1pblmku/where_to_check_for_loras_z_image_edition/)**
*   **Summary:** Users are looking for the best places to find Loras for Z Image.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   [https://civitai.com/models](https://civitai.com/models) and then just set z-image as filter.
    *   Can try huggingface, layout is terrible though. Civitai is the only true model site that gets the new stuff though as everyone uses it as the rest pretty much *** or have very limited librarys.

**[How to upscale an image from 256 to 1024? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1pbmsfj/how_to_upscale_an_image_from_256_to_1024/)**
*   **Summary:** Users are providing recommendations for upscaling images from 256 to 1024, including SeedVR2, SUPIR, and Flux upscaler.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Something like [SeedVR2](https://github.com/numz/ComfyUI-SeedVR2_VideoUpscaler) ([demo](https://huggingface.co/spaces/ByteDance-Seed/SeedVR2-3B)), [SUPIR](https://github.com/kijai/ComfyUI-SUPIR), or this [Flux upscaler](https://huggingface.co/jasperai/Flux.1-dev-Controlnet-Upscaler) ([demo](https://huggingface.co/spaces/jasperai/Flux.1-dev-Controlnet-Upscaler)) would work better. They all more specialize at restoration, even though people use them as upscalers.

**[Anyone guide me please (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1pbjx2d/anyone_guide_me_please/)**
*   **Summary:** Users respond to a vague request for guidance by asking for more specific questions and suggesting resources.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Ask specific questions, then you will get more helpful answers.
    *   Another vague post with no context. You've tried nothing, and already gave up
    *   Check out Pixaroma's Youtube playlist: [https://www.youtube.com/playlist?list=PL-pohOSaL8P9kLZP8tQ1K1QWdZEgwiBM0](https://www.youtube.com/playlist?list=PL-pohOSaL8P9kLZP8tQ1K1QWdZEgwiBM0)

**[Tried a portrait in SD and the result was off (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1pbieew/tried_a_portrait_in_sd_and_the_result_was_off/)**
*   **Summary:** A user is asking for advice on how to improve portraits in Stable Diffusion.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   SD models are outdated and do not accept references. You need to upscale and use detailers to have detailed images with SD models. At best you could use models like Qwen Image Edit, Flux Kontext and Flux 2 Dev.
