---
title: "Machine Learning Subreddit"
date: "2025-12-07"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "research"]
---

# Overall Ranking and Top Discussions
1.  [[D] Top ICLR 2026 Papers Found with fake Citations — Even Reviewers Missed Them](https://www.reddit.com/r/MachineLearning/comments/1pg1og8/d_top_iclr_2026_papers_found_with_fake_citations/) (Score: 272)
    *   Discussion about the discovery of fake citations in top ICLR 2026 papers and the failure of reviewers to catch them.
2.  [[D] Has anyone here transitioned from Data Science to Research Engineering role?](https://www.reddit.com/r/MachineLearning/comments/1pg9zj7/d_has_anyone_here_transitioned_from_data_science/) (Score: 26)
    *   Discussion about transitioning from a Data Science role to a Research Engineering role.
3.  [[D] How did Gemini 3 Pro manage to get 38.3% on Humanity's Last Exam?](https://www.reddit.com/r/MachineLearning/comments/1pgqbjd/d_how_did_gemini_3_pro_manage_to_get_383_on/) (Score: 23)
    *   Discussion about how Gemini 3 Pro achieved a 38.3% score on Humanity's Last Exam.
4.  [[D] Thoughts on ML for drug discovery?](https://www.reddit.com/r/MachineLearning/comments/1pgeu8n/d_thoughts_on_ml_for_drug_discovery/) (Score: 13)
    *   Discussion about the applications and challenges of machine learning in drug discovery.

# Detailed Analysis by Thread
**[[D] Top ICLR 2026 Papers Found with fake Citations — Even Reviewers Missed Them](https://www.reddit.com/r/MachineLearning/comments/1pg1og8/d_top_iclr_2026_papers_found_with_fake_citations/) (Score: 272)**
*  **Summary:** This thread discusses the concerning discovery of fake citations in papers submitted to ICLR 2026, and the fact that reviewers missed these fabrications.  Users are discussing the reasons for this, and potential solutions.
*  **Emotion:** The overall emotional tone is neutral. Although concern and some negativity are expressed, the general tone of the discussion remains neutral.
*  **Top 3 Points of View:**
    *   The problem isn't just about citations, but the overall coherence and structural correctness of the papers, which allowed the fake citations to go unnoticed. Review systems should focus on semantic support, not just formatting.
    *   Someone should create a citation checker to verify the existence of cited papers.
    *   The increasing reliance on convenient AI tools may be contributing to the collapse of the ML research community, as these tools can produce convincing but ultimately flawed content.

**[[D] Has anyone here transitioned from Data Science to Research Engineering role?](https://www.reddit.com/r/MachineLearning/comments/1pg9zj7/d_has_anyone_here_transitioned_from_data_science/) (Score: 26)**
*  **Summary:** This thread centers around individuals sharing their experiences and advice on transitioning from data science roles to research engineering positions. They discuss the skills, experience, and knowledge gaps they encountered during their transition.
*  **Emotion:** The overall emotional tone is mostly positive, as users share their success stories and offer encouraging advice. Some neutral sentiments are also expressed, focusing on defining the different roles in the field.
*  **Top 3 Points of View:**
    *   Publishing papers and collaborating with researchers can help bridge the gap between data science and research engineering. PhD-level research skills are valued more than software engineering experience.
    *   The transition is achievable by getting a foot in the door and demonstrating a willingness to learn. Prior experience with ML engineering and AI agent deployment is highly valuable.
    *   The biggest knowledge gap is in theory, but the specific title is often misleading, with the day-to-day tasks varying greatly between academia and industry.

**[[D] How did Gemini 3 Pro manage to get 38.3% on Humanity's Last Exam?](https://www.reddit.com/r/MachineLearning/comments/1pgqbjd/d_how_did_gemini_3_pro_manage_to_get_383_on/) (Score: 23)**
*  **Summary:** This thread delves into potential reasons behind Gemini 3 Pro's performance on the Humanity's Last Exam (HLE). The discussion covers topics ranging from data leakage and compute power to innovative model architectures and Google's vast resources.
*  **Emotion:** The thread maintains a neutral emotional tone, with users mostly speculating and sharing insights without strong positive or negative sentiments.
*  **Top 3 Points of View:**
    *   Google's success is likely due to a combination of factors, including brainpower, hardware, architecture tweaks, data scale, and highly curated data pipelines.
    *   Some believe that training data leakage might have occurred, or that extensive test-time computation was used.
    *   Tech companies may be paying PhDs to generate HLE-level problems and solution sets.

**[[D] Thoughts on ML for drug discovery?](https://www.reddit.com/r/MachineLearning/comments/1pgeu8n/d_thoughts_on_ml_for_drug_discovery/) (Score: 13)**
*  **Summary:** This thread explores the use of machine learning in drug discovery. It touches on the field's saturation, the importance of wet lab validation, and the need for domain expertise beyond just neural networks.
*  **Emotion:** The thread's emotional tone is somewhat negative. Concerns are raised about the reliability of in-silico metrics and the lack of real-world validation.
*  **Top 3 Points of View:**
    *   The field is saturated and lacks experimental wet lab validation. In-silico metrics are unreliable, so collaboration with chemists/biologists is crucial.
    *   Machine learning has been used in drug discovery for a long time. However, the concept of a foundation model for drug discovery is absurd.
    *   Beyond neural networks, a strong understanding of classical scientific computing methods, quantum chemistry, and drug development is required.
