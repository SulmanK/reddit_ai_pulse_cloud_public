---
title: "Stable Diffusion Subreddit"
date: "2025-04-04"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stable diffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Wan 2.1 I2V (All generated with H100)](https://v.redd.it/u1mfhhli9use1) (Score: 17)
    *   Discussion about generating image to video models with H100, with a focus on resolution and potential issues with teacache.
2.  [Old techniques are still fun - OsciDiff [4]](https://v.redd.it/s8gnieuqause1) (Score: 9)
    *   Sharing experiments and project files related to OsciDiff, an old technique.
3.  [The Daily Spy - A daily hidden object game made with Stable Diffusion (Workflow included)](https://thedailyspy.com/) (Score: 8)
    *   Introducing a daily hidden object game created with Stable Diffusion and seeking feedback on improving the image generation workflow.
4.  [Demos of VACE for Wan2.1 + Tutorial/Workflow](https://youtu.be/7kSHZ5CMQXg) (Score: 8)
    *   A user shares their workflow and tutorial for VACE for Wan2.1.
5.  [I created  a SDXL  lora which works fine with base model but I am struggling to make it work with JuggernautXL. It is 90% there but even after trying various ksampler setting it just does not generate clear images](https://www.reddit.com/r/StableDiffusion/comments/1jri1uf/i_created_a_sdxl_lora_which_works_fine_with_base/) (Score: 2)
    *   A user seeks help troubleshooting an SDXL lora they created that works with the base model but not with JuggernautXL.
6.  [How do detailers work, and how would you create one?](https://www.reddit.com/r/StableDiffusion/comments/1jrdky0/how_do_detailers_work_and_how_would_you_create_one/) (Score: 1)
    *   A discussion on how detailers work, specifically ADetailer, and how to create one, including the use of YOLO models and inpainting.
7.  [Anyone else tend to get lapel mics attached to their subjects randomly in Hunyuan Video?](https://www.reddit.com/r/StableDiffusion/comments/1jrih80/anyone_else_tend_to_get_lapel_mics_attached_to/) (Score: 1)
    *   A user asks if others are experiencing lapel mics randomly appearing on subjects in Hunyuan Video.
8.  [Closed or open sourced?](https://www.reddit.com/gallery/1jrefub) (Score: 0)
    *   Asking if the images are closed or open sourced.
9.  [Apps or online services for custom character pose copying?](https://www.reddit.com/r/StableDiffusion/comments/1jre1yg/apps_or_online_services_for_custom_character_pose/) (Score: 0)
    *   A user is looking for apps or online services for custom character pose copying.
10. [Looking for a Image to Video AI](https://www.reddit.com/r/StableDiffusion/comments/1jrg2hi/looking_for_a_image_to_video_ai/) (Score: 0)
    *   A user is looking for an image to video AI.
11. [How long it takes to train Lora locally for 8 images?](https://www.reddit.com/r/StableDiffusion/comments/1jrgypz/how_long_it_takes_to_train_lora_locally_for_8/) (Score: 0)
    *   A user is asking how long it takes to train a Lora locally for 8 images.
12. [Ran out of memory when regular VAE encoding, retrying with tiled VAE encoding](https://www.reddit.com/r/StableDiffusion/comments/1jrh4wi/ran_out_of_memory_when_regular_vae_encoding/) (Score: 0)
    *   A user encountered a memory error during VAE encoding and is trying tiled VAE encoding.
13. [I created this in stable diffusion](https://www.reddit.com/r/StableDiffusion/comments/1jrhxom/i_created_this_in_stable_diffusion/) (Score: 0)
    *   A user showcases an image they created in Stable Diffusion.
14. [Forge generating much slower than Comfy, how to troubleshoot?](https://www.reddit.com/r/StableDiffusion/comments/1jrimsv/forge_generating_much_slower_than_comfy_how_to/) (Score: 0)
    *   A user is experiencing slower generation speeds in Forge compared to ComfyUI and is seeking troubleshooting advice.

# Detailed Analysis by Thread
**[Wan 2.1 I2V (All generated with H100) (Score: 17)](https://v.redd.it/u1mfhhli9use1)**
*   **Summary:** Discussion about generating image to video models with H100. Focus on resolution of the video models and possible Teacache interference.
*   **Emotion:** Mixed. Overall, the emotional tone is neutral, but some show positive sentiment related to image generation.
*   **Top 3 Points of View:**
    *   The user is generating video with an H100.
    *   Another user suspects the use of teacache.
    *   Inquiry about the resolution of the video and best practices for the 720p model.

**[Old techniques are still fun - OsciDiff [4] (Score: 9)](https://v.redd.it/s8gnieuqause1)**
*   **Summary:** User shares their experiments and project files related to OsciDiff, an older stable diffusion technique.
*   **Emotion:** Predominantly Positive. People are finding the results fun.
*   **Top 3 Points of View:**
    *   The user is sharing their project with the community.
    *   Another user expressed great enthusiasm towards the content, calling it the "best anime fight scene".
    *   Link to external resources.

**[The Daily Spy - A daily hidden object game made with Stable Diffusion (Workflow included) (Score: 8)](https://thedailyspy.com/)**
*   **Summary:** A developer introduces their daily hidden object game, "The Daily Spy," created using Stable Diffusion and seeks feedback and suggestions on improving the image generation workflow and also details the workflow.
*   **Emotion:** The emotional tone is primarily neutral, expressing informative intent.
*   **Top 3 Points of View:**
    *   The developer is looking for feedback on their Stable Diffusion workflow.
    *   The developer is sharing their workflow using ComfyUI and specific checkpoints (Serenity, DreamShaper8, Photon).
    *   The developer discusses using Krita's AI Image Generation plugin for non-AI generated images.

**[Demos of VACE for Wan2.1 + Tutorial/Workflow (Score: 8)](https://youtu.be/7kSHZ5CMQXg)**
*   **Summary:** User shares their workflow and tutorial for VACE for Wan2.1.
*   **Emotion:** Mostly positive and neutral
*   **Top 3 Points of View:**
    *   One user commented negatively on the video, calling the output "straight trash".

**[I created  a SDXL  lora which works fine with base model but I am struggling to make it work with JuggernautXL. It is 90% there but even after trying various ksampler setting it just does not generate clear images (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jri1uf/i_created_a_sdxl_lora_which_works_fine_with_base/)**
*   **Summary:** A user is seeking help with an SDXL lora they created. It works well with the base model but is struggling with JuggernautXL.
*   **Emotion:** The emotional tone is mostly neutral and positive, reflecting a problem-solving atmosphere.
*   **Top 3 Points of View:**
    *   The user is asking if they missed any training steps or information in the documentation.
    *   It was suggested that loras may morph on other models, and training on jugger may be necessary.
    *   The user was recommended to try their lora in splashed-mix-dmd, as they had amazing results with other loras.

**[How do detailers work, and how would you create one? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jrdky0/how_do_detailers_work_and_how_would_you_create_one/)**
*   **Summary:** A discussion about how detailers work, particularly ADetailer. It explains the use of YOLO models and inpainting for image enhancement.
*   **Emotion:** The overall emotional tone is neutral. The tone is largely informative.
*   **Top 3 Points of View:**
    *   ADetailer uses YOLO models and inpainting techniques.
    *   Detailers upscale faces before inpainting for better results.
    *   The importance of nailing specific settings for detailers and inpainting in ComfyUI.

**[Anyone else tend to get lapel mics attached to their subjects randomly in Hunyuan Video? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jrih80/anyone_else_tend_to_get_lapel_mics_attached_to/)**
*   **Summary:** A user asks if others are experiencing lapel mics randomly appearing on subjects in Hunyuan Video.
*   **Emotion:** The emotional tone is neutral with a hint of humor, given the slightly absurd situation.
*   **Top 3 Points of View:**
    *   The user is experiencing lapel mics appearing randomly.
    *   A user humorously replies stating that the model is bugged.

**[Closed or open sourced? (Score: 0)](https://www.reddit.com/gallery/1jrefub)**
*   **Summary:** Asking if the images are closed or open sourced.
*   **Emotion:** The emotional tone is neutral and positive, simply inquiring and making observations without strong emotions.
*   **Top 3 Points of View:**
    *   The post questions the source of the images.
    *   Response suggests images are photoshopped.

**[Apps or online services for custom character pose copying? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jre1yg/apps_or_online_services_for_custom_character_pose/)**
*   **Summary:** A user is looking for apps or online services for custom character pose copying.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    *   The user is looking for recommendations for pose copying tools.
    *   A user suggests using SDLX with Comfyui and Openpose locally.

**[Looking for a Image to Video AI (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jrg2hi/looking_for_a_image_to_video_ai/)**
*   **Summary:** A user is looking for an image to video AI.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    *   The user is asking for recommendations.
    *   Suggestions for Qwen 2.5, [Imagetovideoai.io](http://Imagetovideoai.io), Vidu, Pixverse.
    *   A user offers to create an image to video AI for the user in PM.

**[How long it takes to train Lora locally for 8 images? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jrgypz/how_long_it_takes_to_train_lora_locally_for_8/)**
*   **Summary:** A user is asking how long it takes to train a Lora locally for 8 images.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    *   It takes less than an hour on a 4060 ti, based on the training specs.
    *   May take longer than an hour and a half on the system.
    *   A user offers a fast cloud solution.

**[Ran out of memory when regular VAE encoding, retrying with tiled VAE encoding (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jrh4wi/ran_out_of_memory_when_regular_vae_encoding/)**
*   **Summary:** A user encountered a memory error during VAE encoding and is trying tiled VAE encoding.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    *   The user is experiencing memory issues with VAE encoding.
    *   Suggestions of certain models that work with 4gig.
    *   Suggestions to use VAE Decode/Encode (Tiled).

**[I created this in stable diffusion (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jrhxom/i_created_this_in_stable_diffusion/)**
*   **Summary:** A user showcases an image they created in Stable Diffusion.
*   **Emotion:** The emotional tone is positive overall, as the commenter finds the image "decent."
*   **Top 3 Points of View:**
    *   The user presents an image created in stable diffusion.
    *   Commenter states that it looks rough around the edges.

**[Forge generating much slower than Comfy, how to troubleshoot? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jrimsv/forge_generating_much_slower_than_comfy_how_to/)**
*   **Summary:** A user is experiencing slower generation speeds in Forge compared to ComfyUI and is seeking troubleshooting advice.
*   **Emotion:** The emotional tone is neutral and informative, seeking to understand the cause of the performance difference and provide helpful suggestions.
*   **Top 3 Points of View:**
    *   The user is seeking ways to improve Forge's performance.
    *   Forge speeds differ between cards and console suggestions should be implemented.
    *   Comfy has been faster than Forge in the past.
