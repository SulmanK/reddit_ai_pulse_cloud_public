---
title: "Data Engineering Subreddit"
date: "2025-04-15"
description: "Analysis of top discussions and trends in the dataengineering subreddit"
tags: ["dataengineering", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions
1. [[D] US job search 2025 results](https://www.reddit.com/r/dataengineering/comments/1jztqf6/us_job_search_2025_results/) (Score: 41)
    * A user shared the results of their US job search experience in 2025, including interview processes, offers, and rejections.
2. [Faster Data Pipelines with MCP, Cursor and DuckDB](https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai/) (Score: 18)
    *  Discussion about using MCP, Cursor, and DuckDB to create faster data pipelines.
3. [Greenfield: Do you go DWH or DL/DLH?](https://www.reddit.com/r/dataengineering/comments/1jzx8lx/greenfield_do_you_go_dwh_or_dldlh/) (Score: 10)
    *  Debate on whether to implement a Data Warehouse (DWH) or a Data Lake/Data Lakehouse (DL/DLH) in a greenfield project.
4. [Need advice - Informatica production support](https://www.reddit.com/r/dataengineering/comments/1jzt2ho/need_advice_informatica_production_support/) (Score: 2)
    *  Seeking advice about a career path in Informatica production support.
5. [Hi guys just want to ask some advice](https://www.reddit.com/r/dataengineering/comments/1jzx6ea/hi_guys_just_want_to_ask_some_advice/) (Score: 2)
    *  Request for advice on starting a career in data engineering.
6. [How would you handle the ingestion of thousands of files ?](https://www.reddit.com/r/dataengineering/comments/1jzyxdw/how_would_you_handle_the_ingestion_of_thousands/) (Score: 2)
    *  Discussing strategies for ingesting thousands of files, particularly with constraints on unzipping them permanently.
7. [Please guide me on this....](https://www.reddit.com/r/dataengineering/comments/1k004mu/please_guide_me_on_this/) (Score: 2)
    *  Seeking guidance on choosing between a career in data or software engineering.
8. [API Help](https://www.reddit.com/r/dataengineering/comments/1jztbwd/api_help/) (Score: 1)
    *  Asking for help with API queries and handling duplicates.
9. [Is it possible to generate an open-table/metadata store that combines multiple data sources?](https://www.reddit.com/r/dataengineering/comments/1jztjln/is_it_possible_to_generate_an_opentablemetadata/) (Score: 1)
    *  Question about generating an open-table/metadata store that combines multiple data sources.
10. [Looking for advice or resources on folder structure for a Data Engineering project](https://www.reddit.com/r/dataengineering/comments/1jzvxei/looking_for_advice_or_resources_on_folder/) (Score: 1)
    *  Seeking advice and resources on folder structure for data engineering projects.
11. [My Experience in preparing Azure Data Engineer Associate DP-203.](https://www.reddit.com/r/dataengineering/comments/1jzzf00/my_experience_in_preparing_azure_data_engineer/) (Score: 1)
    *  Sharing experience in preparing for the Azure Data Engineer Associate DP-203 certification.
12. [Advise needed](https://www.reddit.com/r/dataengineering/comments/1jzzgi5/advise_needed/) (Score: 1)
    *  Generic request for advice, likely about transitioning into data engineering.
13. [Airflow or Prefect](https://www.reddit.com/r/dataengineering/comments/1jzznos/airflow_or_prefect/) (Score: 1)
    *  Debate on whether to use Airflow or Prefect for workflow orchestration.
14. [[Discussion] Event sourcing isn’t about storing history. it’s about replaying it.](https://www.reddit.com/r/dataengineering/comments/1jzvfys/event_sourcing_isnt_about_storing_history_its/) (Score: 0)
    *  Discussion about the purpose and use of event sourcing.

# Detailed Analysis by Thread
**[[D] US job search 2025 results (Score: 41)](https://www.reddit.com/r/dataengineering/comments/1jztqf6/us_job_search_2025_results/)**
*  **Summary:**  A user shared the results of their US job search experience in 2025, including interview processes, offers, and rejections. Commenters are asking for more detail on resume content, interview prep, and tech screenings (specifically LeetCode).
*  **Emotion:** The overall emotional tone is Positive, with elements of Neutral curiosity. Many commenters are appreciative and show positive sentiment in thanking the OP for sharing their journey.
*  **Top 3 Points of View:**
    *   Appreciation for sharing detailed job search experience.
    *   Inquiries about the content of the resume (anonymized).
    *   Questions about LeetCode style tech screening and preparation strategies.

**[Faster Data Pipelines with MCP, Cursor and DuckDB (Score: 18)](https://motherduck.com/blog/faster-data-pipelines-with-mcp-duckdb-ai/)**
*  **Summary:**  Discussion about using MCP, Cursor, and DuckDB to create faster data pipelines. A commenter expresses skepticism about articles claiming data pipelines are inherently slow without providing evidence, questioning the need for AI to fix it.
*  **Emotion:** Positive, expressing skepticism with a call for more evidence.
*  **Top 3 Points of View:**
    *   Skepticism towards claims of slow data pipelines without evidence.
    *   Questioning the necessity of AI as a solution without defining the problem.
    *   The need for articles to provide more compelling reasons to show interest.

**[Greenfield: Do you go DWH or DL/DLH? (Score: 10)](https://www.reddit.com/r/dataengineering/comments/1jzx8lx/greenfield_do_you_go_dwh_or_dldlh/)**
*  **Summary:**  Debate on whether to implement a Data Warehouse (DWH) or a Data Lake/Data Lakehouse (DL/DLH) in a greenfield project. Factors include the goals of the data platform, skills of the team, data size, cost, and future-proofing.  The discussion leans towards Lakehouse architecture as a default choice.
*  **Emotion:** The emotional tone is Neutral. The discussion focuses on weighing the pros and cons of different architectural approaches.
*  **Top 3 Points of View:**
    *   DL/DLH offers more flexibility, range of technologies, and is more forgiving in architecture choices, especially for transformation and scalability.
    *   DWH may be suitable if users are comfortable with TSQL and resistant to learning new technologies.
    *   Lakehouse is becoming the default choice, offering the best of both worlds with separate storage and compute, open formats, and support for various data types and use cases.

**[Need advice - Informatica production support (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1jzt2ho/need_advice_informatica_production_support/)**
*  **Summary:**  Seeking advice about a career path in Informatica production support. Commenters advise against focusing on Informatica PowerCenter or IICS, suggesting learning more modern and in-demand cloud ETL tools.
*  **Emotion:** Negative. The overall tone is discouraging towards the original poster pursuing Informatica roles.
*  **Top 3 Points of View:**
    *   Informatica PowerCenter is considered a dying technology.
    *   IICS is not recommended due to lack of intuitiveness and potential boredom.
    *   Advice to switch to better and more in-demand technologies.

**[Hi guys just want to ask some advice (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1jzx6ea/hi_guys_just_want_to_ask_some_advice/)**
*  **Summary:**  Request for advice on starting a career in data engineering. The recommendations include starting as a junior data analyst or data engineer, building small projects, and learning cloud platforms.
*  **Emotion:** The emotional tone is Neutral/Positive, providing helpful advice.
*  **Top 3 Points of View:**
    *   Start with a junior data analyst or data engineer role.
    *   Build small projects to gain practical experience.
    *   Learn cloud platforms basics.

**[How would you handle the ingestion of thousands of files ? (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1jzyxdw/how_would_you_handle_the_ingestion_of_thousands/)**
*  **Summary:**  Discussing strategies for ingesting thousands of files, particularly with constraints on unzipping them permanently. The discussion involves rethinking the setup, using Autoloader, and possibly altering the contract with the data provider.
*  **Emotion:** The emotional tone is Neutral, problem-solving oriented.
*  **Top 3 Points of View:**
    *   Rethink the setup: Unzip files to a bucket temporarily and use gzipped JSONs for storage efficiency.
    *   Explore Autoloader: Use Autoloader's binary file format and potentially a decryption UDF.
    *   Alter data provider contract: Request the data provider to provide raw files in a bucket instead of zipped files.

**[Please guide me on this.... (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1k004mu/please_guide_me_on_this/)**
*  **Summary:**  Seeking guidance on choosing between a career in data or software engineering. The advice is to start with data-related tools, learn SQL and data warehousing concepts, and explore cloud warehouses.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Data-based domains are good, start with any ETL tool and learn SQL and data warehousing concepts.
    *   Software engineering requires basic HTML, CSS, JS, and frameworks like Next.js or React.
    *   Explore both data and software engineering in small proportions to find what suits you best.

**[API Help (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1jztbwd/api_help/)**
*  **Summary:**  Asking for help with API queries and handling duplicates. The solution involves using more specific query filters and creating unique constraints in the database.
*  **Emotion:** The emotional tone is Neutral, providing technical advice.
*  **Top 3 Points of View:**
    *   Use more specific query filters to improve API requests.
    *   Create a unique constraint in the database to handle duplicates.
    *   The API results can be weird with broad queries

**[Is it possible to generate an open-table/metadata store that combines multiple data sources? (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1jztjln/is_it_possible_to_generate_an_opentablemetadata/)**
*  **Summary:**  Question about generating an open-table/metadata store that combines multiple data sources.
*  **Emotion:** Positive/Neutral.
*  **Top 3 Points of View:**
    *   Yes, reading data from multiple sources like S3 and HDFS is possible.

**[Looking for advice or resources on folder structure for a Data Engineering project (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1jzvxei/looking_for_advice_or_resources_on_folder/)**
*  **Summary:**  Seeking advice and resources on folder structure for data engineering projects.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Pointer to an open-source project showcase
    *   General Learning Resources

**[My Experience in preparing Azure Data Engineer Associate DP-203. (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1jzzf00/my_experience_in_preparing_azure_data_engineer/)**
*  **Summary:**  Sharing experience in preparing for the Azure Data Engineer Associate DP-203 certification.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Pointer to general learning resources

**[Advise needed (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1jzzgi5/advise_needed/)**
*  **Summary:**  Generic request for advice, likely about transitioning into data engineering.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Link to a data engineering transition guide.

**[Airflow or Prefect (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1jzznos/airflow_or_prefect/)**
*  **Summary:**  Debate on whether to use Airflow or Prefect for workflow orchestration.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Prefect requires minimal code change from native Python.
    *   Run dbt in a container, avoiding both.

**[[Discussion] Event sourcing isn’t about storing history. it’s about replaying it. (Score: 0)](https://www.reddit.com/r/dataengineering/comments/1jzvfys/event_sourcing_isnt_about_storing_history_its/)**
*  **Summary:**  Discussion about the purpose and use of event sourcing.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Event sourcing and read models bridge OLTP and OLAP.
