---
title: "Machine Learning Subreddit"
date: "2025-04-13"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "NLP"]
---

# Overall Ranking and Top Discussions
1.  [[R] LLMs are bad at writing performant code](https://i.redd.it/uh7wh468fmue1.jpeg) (Score: 66)
    *   This thread discusses the capabilities of Large Language Models (LLMs) in writing efficient code.
2.  [[D] I don't understand, why don't the big models just eat the rest of the smaller models? [Rant]](https://www.reddit.com/r/MachineLearning/comments/1jyes3u/d_i_dont_understand_why_dont_the_big_models_just/) (Score: 28)
    *   This thread seems to be a rant about the perceived dominance of large models over smaller ones, possibly in a humorous or satirical way.
3.  [[D] The ML Paradox: When Better Metrics Lead to Worse Outcomes – Have You Faced This?](https://www.reddit.com/r/MachineLearning/comments/1jy4odf/d_the_ml_paradox_when_better_metrics_lead_to/) (Score: 21)
    *   This thread discusses situations where improving model metrics actually leads to worse real-world performance, a phenomenon known as the ML Paradox.
4.  [[P] TikTok BrainRot Generator Update](https://www.reddit.com/r/MachineLearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/) (Score: 18)
    *   This thread is an update on a project called "TikTok BrainRot Generator," which likely generates content similar to what is found on TikTok.
5.  [[D] ICML 2025: A Shift Toward Correctness Over SOTA?](https://i.redd.it/w6z8y6q87nue1.jpeg) (Score: 15)
    *   The discussion revolves around the ICML 2025 conference potentially prioritizing the correctness of research over achieving state-of-the-art (SOTA) results.
6.  [[P] Harmonic Activations: Periodic and Monotonic Function Extensions for Neural Networks (preprint)](https://www.reddit.com/r/MachineLearning/comments/1jxqtoo/p_harmonic_activations_periodic_and_monotonic/) (Score: 6)
    *   This thread discusses a preprint introducing "Harmonic Activations," which are periodic and monotonic function extensions for neural networks.
7.  [[D] How do you manage experiments with ML models at work?](https://www.reddit.com/r/MachineLearning/comments/1jy5ue4/d_how_do_you_manage_experiments_with_ml_models_at/) (Score: 5)
    *   This thread explores how people manage machine learning experiments in their professional environments.
8.  [[D]Kaggle competition is it worthwhile for PhD student ?](https://www.reddit.com/r/MachineLearning/comments/1jy9hp7/dkaggle_competition_is_it_worthwhile_for_phd/) (Score: 3)
    *   This thread discusses the value of participating in Kaggle competitions for PhD students.
9.  [[D] Will traditional machine learning algorithms (such as neural nets, logistic regressions, trees) be replaced by LLM? So data scientists will lose our jobs?](https://www.reddit.com/r/MachineLearning/comments/1jxwklu/d_will_traditional_machine_learning_algorithms/) (Score: 0)
    *   This thread discusses whether traditional machine learning algorithms will be replaced by Large Language Models (LLMs) and the potential impact on data science jobs.
10.  [[D] Did I get flagged for “cheating” on my CoderByte AI/ML assessment?](https://www.reddit.com/r/MachineLearning/comments/1jye7zk/d_did_i_get_flagged_for_cheating_on_my_coderbyte/) (Score: 0)
    *   This thread is about someone who is worried they may have gotten flagged for cheating on an AI/ML assessment.

# Detailed Analysis by Thread
**[[R] LLMs are bad at writing performant code (Score: 66)](https://i.redd.it/uh7wh468fmue1.jpeg)**
*  **Summary:**  This thread discusses the capabilities of Large Language Models (LLMs) in writing efficient code. Some users believe LLMs are not good at writing performant or maintainable code in the long term, while others argue that with the right specifications, testing frameworks, and advancements in LLM technology, they can produce optimized code.
*  **Emotion:** The overall emotional tone is neutral, with some comments expressing positive experiences with LLMs for code optimization, and others expressing negative experiences regarding code quality and maintainability.
*  **Top 3 Points of View:**
    *   LLMs are generally bad at writing good, maintainable code for long-term projects.
    *   With detailed specifications, planning, and the right frameworks, LLMs can write performant code and even optimize existing code.
    *   LLMs can write code much faster than humans and speed test different approaches.

**[[D] I don't understand, why don't the big models just eat the rest of the smaller models? [Rant] (Score: 28)](https://www.reddit.com/r/MachineLearning/comments/1jyes3u/d_i_dont_understand_why_dont_the_big_models_just/)**
*  **Summary:**  This thread appears to be a humorous or satirical rant about the perceived dominance of large models over smaller models. Commenters offer tongue-in-cheek responses, such as replacing words in reports with "THE SINGULARITY APPROACHES" or asserting that LLMs will replace programmers and increase time spent on Jira.
*  **Emotion:** The overall emotional tone is neutral, with touches of humor and sarcasm.
*  **Top 3 Points of View:**
    *   Satirical view on the rapid adoption and hype surrounding large AI models.
    *   Humorous perspective on the potential impact of AI on programming jobs and productivity.
    *   The idea that one should find a problem to fit the GenAI solution instead of vice versa.

**[[D] The ML Paradox: When Better Metrics Lead to Worse Outcomes – Have You Faced This? (Score: 21)](https://www.reddit.com/r/MachineLearning/comments/1jy4odf/d_the_ml_paradox_when_better_metrics_lead_to/)**
*  **Summary:**  This thread discusses instances where improving model metrics actually results in poorer real-world performance. The discussion covers topics such as overfitting, flawed data assumptions, misaligned metrics, and the importance of validating models and choosing appropriate metrics for the task.
*  **Emotion:** The emotional tone is largely neutral, with comments sharing experiences and offering explanations for the ML paradox.
*  **Top 3 Points of View:**
    *   The ML Paradox often arises from overfitting the model to the training data, leading to poor generalization.
    *   The paradox can happen when data makes assumptions that don't hold true in the real world.
    *   The paradox occurs due to the use of misaligned metrics that do not reflect the desired real-world outcomes.

**[[P] TikTok BrainRot Generator Update (Score: 18)](https://www.reddit.com/r/MachineLearning/comments/1jy5w5l/p_tiktok_brainrot_generator_update/)**
*  **Summary:**  This thread is an update on a project called "TikTok BrainRot Generator."
*  **Emotion:** The emotional tone is neutral
*  **Top 3 Points of View:**
    *   N/A - There aren't enough viewpoints to summarize 3.

**[[D] ICML 2025: A Shift Toward Correctness Over SOTA? (Score: 15)](https://i.redd.it/w6z8y6q87nue1.jpeg)**
*  **Summary:**  The discussion revolves around the ICML 2025 conference potentially prioritizing the correctness of research over achieving state-of-the-art (SOTA) results.
*  **Emotion:** The overall emotional tone is mixed. There's positive sentiment expressing hope that the conference will prioritize correctness, but also negative sentiment stemming from experiences where papers were rejected for not achieving SOTA results despite being correct and thoroughly evaluated.
*  **Top 3 Points of View:**
    *   There is hope that ICML 2025 will focus more on correctness and thorough evaluation rather than just SOTA results.
    *   There is skepticism about whether the shift toward correctness will actually happen, as reviewers may still prioritize SOTA results.
    *   Some people believe that chasing SOTA numbers alone is not real research.

**[[P] Harmonic Activations: Periodic and Monotonic Function Extensions for Neural Networks (preprint) (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1jxqtoo/p_harmonic_activations_periodic_and_monotonic/)**
*  **Summary:**  This thread discusses a preprint introducing "Harmonic Activations," which are periodic and monotonic function extensions for neural networks. Critics suggest the theoretical motivation is unconvincing.
*  **Emotion:** The emotional tone is negative.
*  **Top 3 Points of View:**
    *   The theoretical motivation behind Harmonic Activations is not convincing.
    *   Harmonic Activations function similarly to the Snake activation function.
    *   Experimental results are weak and unconvincing.

**[[D] How do you manage experiments with ML models at work? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1jy5ue4/d_how_do_you_manage_experiments_with_ml_models_at/)**
*  **Summary:**  This thread explores how people manage machine learning experiments in their professional environments.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Tools like hydra, mlflow, uv, and AzureML are used to manage ML experiments.
    *   Docker, Git, tensorboard are utilized for experiment tracking and version control.
    *   Training data versions are a challenge to manage.

**[[D]Kaggle competition is it worthwhile for PhD student ? (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1jy9hp7/dkaggle_competition_is_it_worthwhile_for_phd/)**
*  **Summary:**  This thread discusses the value of participating in Kaggle competitions for PhD students.
*  **Emotion:** The emotional tone is mixed, with positive and negative sentiments expressed.
*  **Top 3 Points of View:**
    *   Kaggle can be worthwhile for PhD students if they have the time and are interested in learning practical modeling skills.
    *   For PhD graduates, publications and leetcode are more important than Kaggle.
    *   People who are good at kaggle generally knows how to model better.

**[[D] Will traditional machine learning algorithms (such as neural nets, logistic regressions, trees) be replaced by LLM? So data scientists will lose our jobs? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1jxwklu/d_will_traditional_machine_learning_algorithms/)**
*  **Summary:**  This thread discusses whether traditional machine learning algorithms will be replaced by Large Language Models (LLMs) and the potential impact on data science jobs.
*  **Emotion:** The emotional tone is mostly neutral
*  **Top 3 Points of View:**
    *   LLMs are not currently capable of replacing traditional ML algorithms in all tasks.
    *   LLMs are neural networks, so asking if LLMs will replace neural networks is not right.
    *   Eventually, AI agents will do any computer stuff very well.

**[[D] Did I get flagged for “cheating” on my CoderByte AI/ML assessment? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1jye7zk/d_did_i_get_flagged_for_cheating_on_my_coderbyte/)**
*  **Summary:**  This thread is about someone who is worried they may have gotten flagged for cheating on an AI/ML assessment.
*  **Emotion:** The emotional tone is negative.
*  **Top 3 Points of View:**
    *   You're overthinking it
