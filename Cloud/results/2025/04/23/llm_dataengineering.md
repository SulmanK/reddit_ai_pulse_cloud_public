---
title: "Data Engineering Subreddit"
date: "2025-04-23"
description: "Analysis of top discussions and trends in the dataengineering subreddit"
tags: ["dataengineering", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions
1.  [[D] Is the title “Data Engineer” losing its value?](https://www.reddit.com/r/dataengineering/comments/1k5z8oa/is_the_title_data_engineer_losing_its_value/) (Score: 40)
    *   This thread discusses whether the title "Data Engineer" is losing its value due to the perception that the role is becoming easier and more tool-oriented, with less emphasis on fundamental computer science principles.

2.  [Graph Data Structures for Data Engineers Who Never Took CS101](https://www.datagibberish.com/p/graph-theory-101-for-data-engineers) (Score: 20)
    *   This thread discusses the importance of understanding graph data structures for data engineers, particularly for those without a strong computer science background.

3.  [Interviewed for Data Engineer, offer says Software Engineer — is this normal?](https://www.reddit.com/r/dataengineering/comments/1k6749b/interviewed_for_data_engineer_offer_says_software/) (Score: 17)
    *   This thread discusses the commonality of receiving a Software Engineer offer after interviewing for a Data Engineer position, and how to ensure the role aligns with one's career goals.

4.  [Game data moves fast, but our pipelines can’t keep up. Anyone tried simplifying the big data stack?](https://www.reddit.com/r/dataengineering/comments/1k60f5e/game_data_moves_fast_but_our_pipelines_cant_keep/) (Score: 10)
    *   This thread explores the challenges of managing fast-moving game data and simplifying the big data stack, with suggestions for leaner solutions and more effective data delivery.

5.  [Are Delta tables a good option for high volume, real-time data?](https://www.reddit.com/r/dataengineering/comments/1k66f2e/are_delta_tables_a_good_option_for_high_volume/) (Score: 10)
    *   This thread discusses the suitability of Delta tables for high-volume, real-time data, with alternative suggestions for data storage and processing.

6.  [Excel-based listings file into an ETL pipeline](https://www.reddit.com/r/dataengineering/comments/1k5xk1r/excelbased_listings_file_into_an_etl_pipeline/) (Score: 4)
    *   This thread provides links to community-submitted learning resources and open-source projects related to ETL pipelines and data engineering.

7.  [DAG DBT structure Intermediate vs Marts](https://www.reddit.com/r/dataengineering/comments/1k5w1hx/dag_dbt_structure_intermediate_vs_marts/) (Score: 3)
    *   This thread discusses the structure of Directed Acyclic Graphs (DAGs) in Data Build Tool (DBT), specifically focusing on the roles of intermediate and mart layers in data transformation and modeling.

8.  [What do you use for real-time time-based aggregations](https://www.reddit.com/r/dataengineering/comments/1k63yyz/what_do_you_use_for_realtime_timebased/) (Score: 3)
    *   This thread is about selecting appropriate tools for real-time, time-based data aggregations, with suggestions including Druid and Prometheus for anomaly detection.

9.  [Working on data mapping tool](https://www.reddit.com/r/dataengineering/comments/1k5xaxn/working_on_data_mapping_tool/) (Score: 2)
    *   This thread discusses the challenges of working on data mapping tools, particularly with unknown and unpredictable input data, and suggests creating a schema mapping wizard with AI assistance.

10. [Surrogate Key Implementation In Glue and Redshift](https://www.reddit.com/r/dataengineering/comments/1k61n2x/surrogate_key_implementation_in_glue_and_redshift/) (Score: 2)
    *   This thread discusses the importance of being aware that Data Warehouses (DWH) or Lakehouses don't enforce uniqueness, which can lead to issues such as duplicate keys during data ingestion.

11. [Data Retention - J-SOX / SOX in your Organisation](https://www.reddit.com/r/dataengineering/comments/1k5s8wj/data_retention_jsox_sox_in_your_organisation/) (Score: 1)
    *   This thread discusses data retention strategies for compliance with regulations like J-SOX and SOX, suggesting the use of Iceberg tables for version tracking and change data capture (CDC) at the source.

12. [How to handle coupon/promotion discounts in sale order lines when building a data warehouse?](https://www.reddit.com/r/dataengineering/comments/1k5sxqg/how_to_handle_couponpromotion_discounts_in_sale/) (Score: 1)
    *   This thread discusses how to handle coupon/promotion discounts in sale order lines when building a data warehouse and the best method to present that data.

13. [Go/NoGo to AWS for ETL ?](https://www.reddit.com/r/dataengineering/comments/1k5zt31/gonogo_to_aws_for_etl/) (Score: 1)
    *   This thread is about determining whether to move ETL processes to AWS, questioning the motivation behind the move and the daily data processing volume.

14. [Thoughts on NetCDF4 for scientific data currently?](https://www.reddit.com/r/dataengineering/comments/1k61ws0/thoughts_on_netcdf4_for_scientific_data_currently/) (Score: 1)
    *   This thread discusses the use of NetCDF4 for storing scientific data, comparing it with alternative formats like HDF5 and Zarr, and sharing experiences from an agtech company that opted for Parquet format instead.

15. [Should I Focus on Syntax or just Big Picture Concepts?](https://www.reddit.com/r/dataengineering/comments/1k5riax/should_i_focus_on_syntax_or_just_big_picture/) (Score: 0)
    *   This thread emphasizes the importance of understanding both syntax and big picture concepts in data engineering, rather than relying solely on Large Language Models (LLMs).

16. [Synthetic data was useless for domain tasks until we let models read real docs](https://www.reddit.com/r/dataengineering/comments/1k5y9sf/synthetic_data_was_useless_for_domain_tasks_until/) (Score: 0)
    *   This thread considers a post about synthetic data as being a pointless bot post and suggests that the bots need actual user docs, support guides, policies, and internal wikis.

17. [Can I Really Be Considered a Junior Data Analyst If I’m Automating Everything with ChatGPT?](https://www.reddit.com/r/dataengineering/comments/1k67at9/can_i_really_be_considered_a_junior_data_analyst/) (Score: 0)
    *   This thread discusses the role of automation with tools like ChatGPT in data analysis, with varying opinions on whether one can be considered a Junior Data Analyst when heavily relying on such automation.

# Detailed Analysis by Thread
**[ [D] Is the title “Data Engineer” losing its value? (Score: 40)](https://www.reddit.com/r/dataengineering/comments/1k5z8oa/is_the_title_data_engineer_losing_its_value/)**
*   **Summary:** The thread discusses whether the title "Data Engineer" is losing its value due to the perception that the role is becoming easier and more tool-oriented, with less emphasis on fundamental computer science principles.
*   **Emotion:** The overall emotional tone is neutral, with a mix of perspectives and rational arguments. Some comments express frustration, while others offer more positive or balanced viewpoints.
*   **Top 3 Points of View:**
    *   The role is shifting and broadening in scope, not losing value. The skillset is becoming more nuanced with both tool-oriented tasks and deeper systems thinking coexisting.
    *   The job is often reduced to moving data from point A to point B, orchestrating some tools, and calling it a day, with pipelines lacking test coverage, versioning discipline, clear modularity, or even basic error handling.
    *   Titles change, tech changes, the skills needed changes. The real data engineers are forged from the fires of burning production systems, not just boot camps and college courses.

**[Graph Data Structures for Data Engineers Who Never Took CS101 (Score: 20)](https://www.datagibberish.com/p/graph-theory-101-for-data-engineers)**
*   **Summary:** The thread discusses the importance of understanding graph data structures for data engineers, particularly for those without a strong computer science background.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   One commenter thinks one needs a cs degree to know graphs.
    *   One commenter states if you don't know this, don't come near an IDE.
    *   No other distinct viewpoints were found.

**[Interviewed for Data Engineer, offer says Software Engineer — is this normal? (Score: 17)](https://www.reddit.com/r/dataengineering/comments/1k6749b/interviewed_for_data_engineer_offer_says_software/)**
*   **Summary:** The thread discusses the commonality of receiving a Software Engineer offer after interviewing for a Data Engineer position, and how to ensure the role aligns with one's career goals.
*   **Emotion:** The overall emotional tone is positive, with many users sharing their experiences and offering helpful advice.
*   **Top 3 Points of View:**
    *   It's normal for Data Engineer roles to be classified as Software Engineer positions.
    *   It's important to clarify day-to-day responsibilities with the hiring manager to ensure the work aligns with career goals.
    *   DE is sometimes a subset of SWE.

**[Game data moves fast, but our pipelines can’t keep up. Anyone tried simplifying the big data stack? (Score: 10)](https://www.reddit.com/r/dataengineering/comments/1k60f5e/game_data_moves_fast_but_our_pipelines_cant_keep/)**
*   **Summary:** The thread explores the challenges of managing fast-moving game data and simplifying the big data stack, with suggestions for leaner solutions and more effective data delivery.
*   **Emotion:** The overall emotional tone is neutral with a hint of frustration. People are offering solutions and asking clarifying questions.
*   **Top 3 Points of View:**
    *   The problems are organizational/process based, and tech stack problems are a symptom of that.
    *   There are too many layers in the stack, when Snowflake/PostgreSQL can do things natively.
    *   Figure out what’s useful and repeatable, then build from there.

**[Are Delta tables a good option for high volume, real-time data? (Score: 10)](https://www.reddit.com/r/dataengineering/comments/1k66f2e/are_delta_tables_a_good_option_for_high_volume/)**
*   **Summary:** The thread discusses the suitability of Delta tables for high-volume, real-time data, with alternative suggestions for data storage and processing.
*   **Emotion:** The overall emotional tone is neutral, with varying opinions and technical explanations. Some express skepticism about Delta tables for real-time use cases, while others share their positive experiences.
*   **Top 3 Points of View:**
    *   Delta tables are not ideal for real-time transaction tables due to the way they handle row changes and transaction logs.
    *   A pipeline split into stages (Bronze, Silver, OPTIMIZE) may provide a better solution.
    *    Databricks can work well for streaming data received from Kafka.

**[Excel-based listings file into an ETL pipeline (Score: 4)](https://www.reddit.com/r/dataengineering/comments/1k5xk1r/excelbased_listings_file_into_an_etl_pipeline/)**
*   **Summary:** This thread provides links to community-submitted learning resources and open-source projects related to ETL pipelines and data engineering.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   No distinct viewpoints were found.

**[DAG DBT structure Intermediate vs Marts (Score: 3)](https://www.reddit.com/r/dataengineering/comments/1k5w1hx/dag_dbt_structure_intermediate_vs_marts/)**
*   **Summary:** The thread discusses the structure of Directed Acyclic Graphs (DAGs) in Data Build Tool (DBT), specifically focusing on the roles of intermediate and mart layers in data transformation and modeling.
*   **Emotion:** The overall emotional tone is positive and neutral.
*   **Top 3 Points of View:**
    *   Marts are used for complex models chunked up for readability or performance reasons.
    *   End state models are not intermediate inputs.
    *   Sometimes the mart tables I create get transformed downstream in Excel.

**[What do you use for real-time time-based aggregations (Score: 3)](https://www.reddit.com/r/dataengineering/comments/1k63yyz/what_do_you_use_for_realtime_timebased/)**
*   **Summary:** This thread is about selecting appropriate tools for real-time, time-based data aggregations, with suggestions including Druid and Prometheus for anomaly detection.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   It's possible that the stack should be able to delivery subsecond aggeegarion.
    *   Suggest rolling up your data and then store it if the velocity is too high.
    *   Use Prometheus for anomaly detection.

**[Working on data mapping tool (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1k5xaxn/working_on_data_mapping_tool/)**
*   **Summary:** This thread discusses the challenges of working on data mapping tools, particularly with unknown and unpredictable input data, and suggests creating a schema mapping wizard with AI assistance.
*   **Emotion:** The overall emotional tone is positive and neutral.
*   **Top 3 Points of View:**
    *   Create a schema mapping "wizard" that loops thebuser in, but provides suggestions, maybe using AI?
    *   It's not possible to automate this unless you can define the business rules for how to map the columns.
    *   No other distinct viewpoints were found.

**[Surrogate Key Implementation In Glue and Redshift (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1k61n2x/surrogate_key_implementation_in_glue_and_redshift/)**
*   **Summary:** This thread discusses the importance of being aware that Data Warehouses (DWH) or Lakehouses don't enforce uniqueness, which can lead to issues such as duplicate keys during data ingestion.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   DWH or Lakehouse doesn’t enforce uniqueness, you can design such that duplicate key is unlikely to occur but assuming it won’t occur at all (could be human error during data ingestion) is also problematic
    *   No other distinct viewpoints were found.
    *   No other distinct viewpoints were found.

**[Data Retention - J-SOX / SOX in your Organisation (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k5s8wj/data_retention_jsox_sox_in_your_organisation/)**
*   **Summary:** This thread discusses data retention strategies for compliance with regulations like J-SOX and SOX, suggesting the use of Iceberg tables for version tracking and change data capture (CDC) at the source.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Iceberg tables work great for version tracking, but consider implementing change data capture (CDC) at the source.
    *   What you really need is a solid versioning system with proper audit trails - we use DBmaestro.
    *   No other distinct viewpoints were found.

**[How to handle coupon/promotion discounts in sale order lines when building a data warehouse? (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k5sxqg/how_to_handle_couponpromotion_discounts_in_sale/)**
*   **Summary:** This thread discusses how to handle coupon/promotion discounts in sale order lines when building a data warehouse and the best method to present that data.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   The discount line should have the total that it discounted.
    *   Put all invoice level totals on the fact invoice - subtotal, taxes, discount, total. I also have a fact pricing table.
    *   No other distinct viewpoints were found.

**[Go/NoGo to AWS for ETL ? (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k5zt31/gonogo_to_aws_for_etl/)**
*   **Summary:** This thread is about determining whether to move ETL processes to AWS, questioning the motivation behind the move and the daily data processing volume.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   What is the motivation to move to AWS? Is the goal to offload on prem server to the cloud to reduce maintenance?
    *   What is the amount of data you are processing daily?
    *   No other distinct viewpoints were found.

**[Thoughts on NetCDF4 for scientific data currently? (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k61ws0/thoughts_on_netcdf4_for_scientific_data_currently/)**
*   **Summary:** This thread discusses the use of NetCDF4 for storing scientific data, comparing it with alternative formats like HDF5 and Zarr, and sharing experiences from an agtech company that opted for Parquet format instead.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   NetCDF and HDF5 are similar data formats. The newer version of NetCDF has an option to use HDF 5 as a backend. Zarr is an easy and lightweight approach.
    *   At Agtech company, we decided against using NetCDF4 to store the climate data from the monitored farms. Instead, we stored the data in Parquet format.
    *   No other distinct viewpoints were found.

**[Should I Focus on Syntax or just Big Picture Concepts? (Score: 0)](https://www.reddit.com/r/dataengineering/comments/1k5riax/should_i_focus_on_syntax_or_just_big_picture/)**
*   **Summary:** This thread emphasizes the importance of understanding both syntax and big picture concepts in data engineering, rather than relying solely on Large Language Models (LLMs).
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Both. You will be helpless when relying on LLM's only.
    *   No other distinct viewpoints were found.
    *   No other distinct viewpoints were found.

**[Synthetic data was useless for domain tasks until we let models read real docs (Score: 0)](https://www.reddit.com/r/dataengineering/comments/1k5y9sf/synthetic_data_was_useless_for_domain_tasks_until/)**
*   **Summary:** This thread considers a post about synthetic data as being a pointless bot post and suggests that the bots need actual user docs, support guides, policies, and internal wikis.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Pointless bot post. Perhaps your bots need actual user docs, support guides, policies, and internal wikis.
    *   No other distinct viewpoints were found.
    *   No other distinct viewpoints were found.

**[Can I Really Be Considered a Junior Data Analyst If I’m Automating Everything with ChatGPT? (Score: 0)](https://www.reddit.com/r/dataengineering/comments/1k67at9/can_i_really_be_considered_a_junior_data_analyst/)**
*   **Summary:** This thread discusses the role of automation with tools like ChatGPT in data analysis, with varying opinions on whether one can be considered a Junior Data Analyst when heavily relying on such automation.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   If you're asking, probably not.
    *   Meh, I don’t particularly care about the process, but rather the output.
    *   You are an LLM user. That's about it.
