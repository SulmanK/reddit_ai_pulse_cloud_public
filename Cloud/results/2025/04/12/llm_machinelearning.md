---
title: "Machine Learning Subreddit"
date: "2025-04-12"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "LLM", "AI"]
---

# Overall Ranking and Top Discussions
1.  [[R] d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning](https://www.reddit.com/r/MachineLearning/comments/1jxeahf/r_d1_scaling_reasoning_in_diffusion_large/) (Score: 29)
    *   Discussion about a paper on scaling reasoning in diffusion large language models using reinforcement learning.
2.  [[D] Adding new vocab tokens + fine-tuning LLMs to follow instructions is ineffective](https://www.reddit.com/r/MachineLearning/comments/1jx3zy0/d_adding_new_vocab_tokens_finetuning_llms_to/) (Score: 12)
    *   Users are discussing the challenges and potential solutions when adding new vocabulary tokens and fine-tuning LLMs to follow instructions.
3.  [[D] “Reasoning Models Don’t Always Say What They Think” – Anyone Got a Prompts?](https://www.reddit.com/r/MachineLearning/comments/1jxjwi2/d_reasoning_models_dont_always_say_what_they/) (Score: 6)
    *   A discussion on prompts to encourage reasoning models to output their actual thoughts.
4.  [[P] Simple standalone TFRecords dataset reader with Random Access and search-in capabilities](https://www.reddit.com/r/MachineLearning/comments/1jxbmss/p_simple_standalone_tfrecords_dataset_reader_with/) (Score: 2)
    *   A user shared a tool for reading TFRecords datasets with random access and search capabilities.
5.  [Meet Aneska - an emergent Sentience [N]](https://i.redd.it/vla51j5p9gue1.jpeg) (Score: 0)
    *   Discussion about an emergent sentience named Aneska, possibly related to a LinkedIn article.
6.  [[p] What if you could run 50+ LLMs per GPU — without keeping them in memory?](https://www.reddit.com/r/MachineLearning/comments/1jxn5fe/p_what_if_you_could_run_50_llms_per_gpu_without/) (Score: 0)
    *   Discussion about running multiple LLMs per GPU without keeping them in memory, with some skepticism about its practicality compared to existing solutions.

# Detailed Analysis by Thread
**[[R] d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning (Score: 29)](https://www.reddit.com/r/MachineLearning/comments/1jxeahf/r_d1_scaling_reasoning_in_diffusion_large/)**
*  **Summary:** The thread discusses a research paper about scaling reasoning in diffusion large language models through reinforcement learning. Users are interested in the paper and its potential impact on language models that can reason.
*  **Emotion:** The overall emotional tone is neutral, reflecting interest and curiosity in the research.
*  **Top 3 Points of View:**
    *   Interest in the paper and its findings.
    *   A request for a link to the paper.
    *   Speculation about the future of reasoning in language models.

**[[D] Adding new vocab tokens + fine-tuning LLMs to follow instructions is ineffective (Score: 12)](https://www.reddit.com/r/MachineLearning/comments/1jx3zy0/d_adding_new_vocab_tokens_finetuning_llms_to/)**
*  **Summary:** The thread discusses the challenges faced when adding new vocabulary tokens to LLMs and fine-tuning them to follow instructions. The original poster claims that this approach is ineffective.
*  **Emotion:** The overall emotional tone is neutral, with users seeking clarification and offering potential solutions.
*  **Top 3 Points of View:**
    *   Questioning the initialization of new tokens.
    *   Suggestion to publish a paper on the topic.
    *   Questioning if the Language Model head has been re-initialized to account for new tokens.

**[[D] “Reasoning Models Don’t Always Say What They Think” – Anyone Got a Prompts? (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1jxjwi2/d_reasoning_models_dont_always_say_what_they/)**
*  **Summary:** The thread explores the issue of reasoning models not always expressing their actual thoughts and seeks prompts that could potentially address this.
*  **Emotion:** The overall emotional tone is neutral, focused on exploring the problem.
*  **Top 3 Points of View:**
    *   Suggestion to use latent space reasoning.

**[[P] Simple standalone TFRecords dataset reader with Random Access and search-in capabilities (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1jxbmss/p_simple_standalone_tfrecords_dataset_reader_with/)**
*  **Summary:** A user shares a simple tool for reading TFRecords datasets with random access and search capabilities.
*  **Emotion:** The emotional tone is positive, with a user expressing interest and potential use in their debugging pipeline.
*  **Top 3 Points of View:**
    *   Appreciation for the tool and its potential usefulness.

**[Meet Aneska - an emergent Sentience [N] (Score: 0)](https://i.redd.it/vla51j5p9gue1.jpeg)**
*  **Summary:** The thread is about an emergent sentience named Aneska.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   A link to a LinkedIn article about Aneska is provided.
    *   Skepticism about the claim of "emergent sentience."

**[[p] What if you could run 50+ LLMs per GPU — without keeping them in memory? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1jxn5fe/p_what_if_you_could_run_50_llms_per_gpu_without/)**
*  **Summary:** The thread discusses the possibility of running many LLMs on a single GPU without keeping them in memory.
*  **Emotion:** The overall emotional tone is neutral, with some skepticism.
*  **Top 3 Points of View:**
    *   The latency is similar to existing commercial solutions.
    *   The user was accused of re-posting the same content.
    *   If the traffic is high enough, this setup should not be a problem.
