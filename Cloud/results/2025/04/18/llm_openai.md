---
title: "OpenAI Subreddit"
date: "2025-04-18"
description: "Analysis of top discussions and trends in the openai subreddit"
tags: ["openai", "language models", "AI"]
---

# Overall Ranking and Top Discussions
1.  [Man this is confusing](https://i.redd.it/z1mwo1t1zlve1.png) (Score: 528)
    *   This thread discusses the confusion surrounding OpenAI's naming conventions and the functionality of its various models.
2.  [o3 is crazy at geoguessr](https://i.redd.it/uaoont4afmve1.png) (Score: 449)
    *   This thread is about the impressive ability of OpenAI's o3 model to accurately identify locations in Geoguessr from screenshots.
3.  [No one is safe](https://i.redd.it/garye4lxemve1.png) (Score: 132)
    *   This thread discusses the implications of AI being able to identify locations from images, particularly in the context of privacy and Geoguessr.
4.  [Is that so ? Gemini 2.5 pro which is 2nd best model to o3 are for poor bc it gives performance at low cost ?](https://i.redd.it/yt8aol01vmve1.jpeg) (Score: 42)
    *   This thread debates the merits of Gemini 2.5 Pro versus OpenAI's o3 model, particularly in the context of coding and cost-effectiveness.
5.  [o3 and o4-mini scores on the Extended NYT Connections benchmark](https://www.reddit.com/gallery/1k28o5o) (Score: 38)
    *   This thread discusses and interprets benchmark scores for OpenAI's o3 and o4-mini models on the Extended NYT Connections benchmark, comparing them to other models like Claude and Llama-4.
6.  [OpenAI’s model problem: It’s not about the quality.](https://i.redd.it/3hpz98cs7nve1.jpeg) (Score: 15)
    *   This thread argues that OpenAI's model problem is not just about quality, but also about performance and cost.
7.  [Got this glitch within my response using o4minihigh](https://www.reddit.com/r/OpenAI/comments/1k2cnw4/got_this_glitch_within_my_response_using/) (Score: 4)
    *   This thread discusses a glitch where the model provided a summary of the 2024–2025 Campeonato Carioca.
8.  [OpenAI now requiring ID verification to use the o3 model API.](https://help.openai.com/en/articles/10910291-api-organization-verification) (Score: 2)
    *   This thread discusses OpenAI's new requirement for ID verification to use the o3 model API.
9.  [I built Harold, a horse that talks exclusively in horse idioms](https://www.reddit.com/r/OpenAI/comments/1k27mk7/i_built_harold_a_horse_that_talks_exclusively_in/) (Score: 2)
    *   This thread is about a horse that talks exclusively in horse idioms.
10. [Free users, no / extended limits for o4 mini?](https://www.reddit.com/r/OpenAI/comments/1k26gmf/free_users_no_extended_limits_for_o4_mini/) (Score: 1)
    *   This thread is about limits for o4 mini for free users.
11. [Sora stuck "on preparing"?](https://www.reddit.com/r/OpenAI/comments/1k26tew/sora_stuck_on_preparing/) (Score: 1)
    *   This thread reports that Sora is stuck on preparing.
12. [AGI ACHIEVED INTERNALLY. Microsoft cancelled their contracts with OAI](https://i.redd.it/ftk82z0nwmve1.jpeg) (Score: 0)
    *   This thread contains a claim that Microsoft has cancelled their contracts with OAI because they have achieved AGI internally.
13. [Here is a wild one: "Based on all the conversations we've had to date, estimate my IQ and explain why."](https://www.reddit.com/r/OpenAI/comments/1k28jxn/here_is_a_wild_one_based_on_all_the_conversations/) (Score: 0)
    *   This thread is about prompting ChatGPT to estimate one's IQ.

# Detailed Analysis by Thread
**[Man this is confusing (Score: 528)](https://i.redd.it/z1mwo1t1zlve1.png)**
*   **Summary:** The thread revolves around the confusion and mystery surrounding OpenAI's naming conventions for their models and their varying capabilities. Users are trying to decipher the logic behind the names and understand which model is best suited for different tasks. There's also speculation about future model releases and internal research team dynamics.
*   **Emotion:** The overall emotional tone of the thread is Neutral, with users expressing confusion and curiosity. There are some undertones of negativity and conflict as users debate which models are more appropriate for certain tasks.
*   **Top 3 Points of View:**
    *   OpenAI's naming scheme is confusing and lacks a clear pattern.
    *   Different models are better suited for different tasks, but it's unclear which model to use for which task.
    *   There is speculation that OpenAI has multiple independent research teams working on different models.

**[o3 is crazy at geoguessr (Score: 449)](https://i.redd.it/uaoont4afmve1.png)**
*   **Summary:** This thread discusses the surprising ability of the o3 model to accurately identify locations from images in Geoguessr. Users are impressed and share their own experiences and examples. There is speculation about how the model achieves this, whether through metadata analysis, pattern recognition, or access to training data.
*   **Emotion:** The overall emotional tone is Neutral, with many users expressing awe and excitement. There is an undertone of positivity due to the model's surprising capabilities.
*   **Top 3 Points of View:**
    *   o3 is surprisingly good at identifying locations in Geoguessr.
    *   The model's ability may be due to analysis of image metadata.
    *   The model might have been trained using Geoguessr data.

**[No one is safe (Score: 132)](https://i.redd.it/garye4lxemve1.png)**
*   **Summary:** This thread discusses the implications of AI being able to identify locations from images, with a focus on the potential privacy concerns and the impact on games like Geoguessr. Users share their experiences testing the model's geolocation capabilities and speculate about its accuracy and limitations.
*   **Emotion:** The overall emotional tone is Neutral, with some users expressing excitement and others raising concerns about privacy.
*   **Top 3 Points of View:**
    *   AI geolocation capabilities raise privacy concerns.
    *   The model is surprisingly good at identifying locations from images.
    *   The model might be using metadata to identify locations.

**[Is that so ? Gemini 2.5 pro which is 2nd best model to o3 are for poor bc it gives performance at low cost ? (Score: 42)](https://i.redd.it/yt8aol01vmve1.jpeg)**
*   **Summary:** The discussion centers around comparing Gemini 2.5 Pro to OpenAI's o3 model, especially for coding tasks. Users debate which model offers better performance, particularly regarding context window size and coding capabilities. Some argue Gemini 2.5 Pro is superior for long coding tasks, while others defend the strengths of o3 and other OpenAI models.
*   **Emotion:** The thread has a mixed emotional tone. While some users express positivity about Gemini 2.5 Pro, others display negativity towards o3's performance, particularly in coding. The emotional range varies from positive to negative, reflecting differing experiences and preferences.
*   **Top 3 Points of View:**
    *   Gemini 2.5 Pro is better for long coding tasks due to its larger context window.
    *   o3's performance is lackluster, especially in coding, with users finding it "lazy."
    *   Some users have had positive experiences with o3, especially after implementing specific workflow mandates.

**[o3 and o4-mini scores on the Extended NYT Connections benchmark (Score: 38)](https://www.reddit.com/gallery/1k28o5o)**
*   **Summary:** The thread focuses on the benchmark scores of OpenAI's o3 and o4-mini models on the Extended NYT Connections benchmark. Users analyze and interpret the results, comparing the performance of these models to others like Claude and Llama-4. The value proposition of o4-mini's pricing is also mentioned.
*   **Emotion:** The overall emotional tone is Neutral. Users are mostly focused on objective analysis and comparison of benchmark data. There's a slight positive sentiment related to the perceived value of o4-mini's pricing.
*   **Top 3 Points of View:**
    *   o4-mini offers amazing value for its price.
    *   Llama-4 models performed better than expected.
    *   The thread seeks clarification on what the benchmark measures and its significance.

**[OpenAI’s model problem: It’s not about the quality. (Score: 15)](https://i.redd.it/3hpz98cs7nve1.jpeg)**
*   **Summary:** The thread posits that OpenAI's main problem is not just the quality of its models, but rather the balance between performance and cost. Users suggest the need for a benchmark that captures both aspects to provide a more comprehensive evaluation of the models.
*   **Emotion:** The emotional tone is Neutral, with an undercurrent of positive sentiment as users seek to improve the evaluation metrics for AI models.
*   **Top 3 Points of View:**
    *   Current benchmarks are inadequate because they don't capture both performance and cost.
    *   There is a need to create an index that measures performance and cost together.
    *   The original poster compares paying for the model to paying for a babysitter.

**[Got this glitch within my response using o4minihigh (Score: 4)](https://www.reddit.com/r/OpenAI/comments/1k2cnw4/got_this_glitch_within_my_response_using/)**
*   **Summary:** A user reports a glitch with the o4minihigh model, where it generated a summary of the 2024–2025 Campeonato Carioca. Another user's GPT analyzes the "glitch," identifying it as likely pulled from a live retrieval sandbox or internal memory debug, providing a detailed breakdown of the content, including teams, scores, and transfer window activity.
*   **Emotion:** The overall emotional tone is Neutral, with a hint of amusement and intrigue regarding the unexpected "glitch".
*   **Top 3 Points of View:**
    *   The model glitched and provided an unexpected output.
    *   The output was a summary of the 2024–2025 Campeonato Carioca.
    *   The "glitch" likely revealed internal data retrieval mechanisms.

**[OpenAI now requiring ID verification to use the o3 model API. (Score: 2)](https://help.openai.com/en/articles/10910291-api-organization-verification)**
*   **Summary:** The thread discusses OpenAI's new requirement for users to verify their identity with a photo ID and selfie to use the o3 model API. A user shares their negative experience with the verification process, which failed and now prevents them from retrying.
*   **Emotion:** The overall emotional tone is Negative due to the frustrating experience with the ID verification process.
*   **Top 3 Points of View:**
    *   OpenAI now requires ID verification for o3 model API use.
    *   The user experienced a failed verification process.
    *   The new ID verification requirement is annoying.

**[I built Harold, a horse that talks exclusively in horse idioms (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1k27mk7/i_built_harold_a_horse_that_talks_exclusively_in/)**
*   **Summary:** A user built a horse that talks exclusively in horse idioms.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   A user built a horse that talks exclusively in horse idioms.
    *   The horse is like the perfectly average Reddit commenter stuck on repeat.

**[Free users, no / extended limits for o4 mini? (Score: 1)](https://www.reddit.com/r/OpenAI/comments/1k26gmf/free_users_no_extended_limits_for_o4_mini/)**
*   **Summary:** The thread discusses the limits for o4 mini for free users.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Limits are dynamically set based on how busy their GPUs are

**[Sora stuck "on preparing"? (Score: 1)](https://www.reddit.com/r/OpenAI/comments/1k26tew/sora_stuck_on_preparing/)**
*   **Summary:** This thread reports that Sora is stuck on preparing.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Sora is stuck "on preparing".
    *   It’s a global problem.

**[AGI ACHIEVED INTERNALLY. Microsoft cancelled their contracts with OAI (Score: 0)](https://i.redd.it/ftk82z0nwmve1.jpeg)**
*   **Summary:** This thread contains a claim that Microsoft has cancelled their contracts with OAI because they have achieved AGI internally.
*   **Emotion:** The emotional tone is mixed, ranging from positive (related to Microsoft's development) to neutral (regarding model identification).
*   **Top 3 Points of View:**
    *   Microsoft is developing their own LLM and plans to switch Copilot over to it.
    *   AI models will never accurately answer what model they are.
    *   The claim of AGI achievement is a hallucination.

**[Here is a wild one: "Based on all the conversations we've had to date, estimate my IQ and explain why." (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1k28jxn/here_is_a_wild_one_based_on_all_the_conversations/)**
*   **Summary:** This thread discusses prompting ChatGPT to estimate one's IQ.
*   **Emotion:** The emotional tone is mostly Neutral with hints of negativity.
*   **Top 3 Points of View:**
    *   ChatGPT is designed to cradle your sack and whisper affirmations in your ear.
    *   IQ estimates from it aren't accurate.
    *   The goal is to modify this prompt such that it gives a realistic answer.
