---
title: "Stable Diffusion Subreddit"
date: "2025-04-10"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [HiDream - My jaw dropped along with this model!](https://www.reddit.com/r/StableDiffusion/comments/1jw3rw0/hidream_my_jaw_dropped_along_with_this_model/) (Score: 60)
    *   This thread discusses the HiDream model, with users sharing their experiences, asking about inference times, compatibility with different tools (like a1111/forge), and its potential compared to other models like Flux.

2.  [Some HiDream.Dev (NF4 Comfy) vs. Flux.Dev comparisons - Same prompt](https://www.reddit.com/gallery/1jw6z42) (Score: 15)
    *   This thread compares HiDream.Dev and Flux.Dev models using the same prompt, with users discussing prompt following and VRAM requirements.

3.  [HiDream models comparable to Flux ?](https://www.reddit.com/r/StableDiffusion/comments/1jw4ec2/hidream_models_comparable_to_flux/) (Score: 10)
    *   This thread explores whether HiDream models are comparable to Flux, with discussions around prompt adherence, training, ComfyUI support, and overall quality.

4.  [I want to produce visuals using this art style. Which checkpoint, Lora and prompts can I use?](https://i.redd.it/kwvz6ffq22ue1.png) (Score: 2)
    *   Users discuss how to reproduce a particular art style, suggesting the use of IPadapters, and providing prompts generated by Gemini 2.5.

5.  [Can you apply image on image in inpainting?](https://www.reddit.com/r/StableDiffusion/comments/1jw2ken/can_you_apply_image_on_image_in_inpainting/) (Score: 2)
    *   The discussion revolves around applying an image on image in inpainting. Suggestions include using ControlNet, generating images of the phone in hand from different angles, and pasting the reference photo next to the in-painting area.

6.  [Help connecting these nodes](https://www.reddit.com/r/StableDiffusion/comments/1jw3xeb/help_connecting_these_nodes/) (Score: 1)
    *   The discussion is around connecting DualCLIPLoader node to the Anything Everywhere node.

7.  [Beginner here – trying to inpaint anime characters into real photos using Stable Diffusion](https://www.reddit.com/r/StableDiffusion/comments/1jw5y05/beginner_here_trying_to_inpaint_anime_characters/) (Score: 1)
    *   Users discuss inpainting anime characters into real photos using Stable Diffusion and suggest tools like Invoke and LoRAs.

8.  [Are the arguments correct in this version? When I start generating an image, my PC freezes. This issue did not occur with previous versions. i have a gtx 1650](https://i.redd.it/tv0bn4ki12ue1.png) (Score: 1)
    *   Users discuss running AI with low VRAM.

9. [Hulk and Wolverine - Insane Combination](https://v.redd.it/5b7o5yxn81ue1) (Score: 0)
    * The user thinks a hulk doesn’t need any claws.

10. [how to generate prefect feet for anime characters with sdxl/illustrious model？](https://www.reddit.com/gallery/1jw1qjp) (Score: 0)
    * The discussion revolves around the best methods to generate perfect feet for anime characters, including refiners, inpainting, and other tools.

11. [Artist claim NightShade could collapse current model, did anybody test?](https://www.reddit.com/r/StableDiffusion/comments/1jw1be7/artist_claim_nightshade_could_collapse_current/) (Score: 0)
    *   The discussion revolves around artist claims that Nightshade could collapse current models.

12. [Best Img-Vid AI Paid site](https://www.reddit.com/r/StableDiffusion/comments/1jw42cu/best_imgvid_ai_paid_site/) (Score: 0)
    *   The discussion is around which paid site is best for Img-Vid AI.

# Detailed Analysis by Thread
**[HiDream - My jaw dropped along with this model! (Score: 60)](https://www.reddit.com/r/StableDiffusion/comments/1jw3rw0/hidream_my_jaw_dropped_along_with_this_model/)**
*   **Summary:** The thread discusses the HiDream model, with users sharing experiences, asking about inference times and compatibility with tools like a1111/forge, and comparing it to other models.
*   **Emotion:** The overall emotional tone is positive, with excitement about the potential of the HiDream model, though some users also express frustration related to setup issues and limitations. Dominant emotions are Neutral and Positive.
*   **Top 3 Points of View:**
    *   HiDream shows real promise and might be comparable to or better than Flux, especially for full fine-tuning.
    *   Users are encountering difficulties getting HiDream to work with existing tools or specific setups (e.g., a1111/forge, Python versions).
    *   Users are interested in the VRAM usage of the model and how it compares to others.

**[Some HiDream.Dev (NF4 Comfy) vs. Flux.Dev comparisons - Same prompt (Score: 15)](https://www.reddit.com/gallery/1jw6z42)**
*   **Summary:** This thread shows comparisons between HiDream.Dev and Flux.Dev models, prompting discussions on prompt following and VRAM requirements.
*   **Emotion:** The emotional tone is mostly neutral, with users seeking information and comparing the models objectively.
*   **Top 3 Points of View:**
    *   Inquiring which model has better prompt following capabilities.
    *   Sharing information about the VRAM requirements of HiDream.Dev (NF4).

**[HiDream models comparable to Flux ? (Score: 10)](https://www.reddit.com/r/StableDiffusion/comments/1jw4ec2/hidream_models_comparable_to_flux/)**
*   **Summary:** The thread explores if HiDream models are comparable to Flux, discussing prompt adherence, training limitations, ComfyUI support, and overall quality.
*   **Emotion:** The overall emotional tone is neutral to slightly positive, with curiosity and anticipation about the new HiDream model but also recognition of its current limitations.
*   **Top 3 Points of View:**
    *   HiDream appears to be better at prompt adherence and has fewer issues with specific artifacts compared to Flux.
    *   It's too early to give a fully founded answer because it's work in progress.
    *   Some users are waiting for native ComfyUI support before trying it out.

**[I want to produce visuals using this art style. Which checkpoint, Lora and prompts can I use? (Score: 2)](https://i.redd.it/kwvz6ffq22ue1.png)**
*   **Summary:** Users discuss how to reproduce a particular art style, suggesting the use of IPadapters and providing prompts generated by Gemini 2.5.
*   **Emotion:** The emotional tone is mostly neutral, focusing on providing helpful suggestions.
*   **Top 3 Points of View:**
    *   Learning to use IPadapters may be more effective than relying on a specific model or LoRA.
    *   The original image looks like it was created with MidJourney v6.
    *   Providing a long list of prompts that could generate the image.

**[Can you apply image on image in inpainting? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jw2ken/can_you_apply_image_on_image_in_inpainting/)**
*   **Summary:** The discussion revolves around applying an image on image in inpainting. Suggestions include using ControlNet, generating images of the phone in hand from different angles, and pasting the reference photo next to the in-painting area.
*   **Emotion:** The emotional tone is generally helpful and informative.
*   **Top 3 Points of View:**
    *   ControlNet with IP Adapter is a good tool, but it's hard to get the model to understand what you want to do.
    *   Suggesting [Ace++] as it's been successful at inpainting specific subjects.
    *   Generating several images of the phone in hand from different angles.

**[Help connecting these nodes (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jw3xeb/help_connecting_these_nodes/)**
*   **Summary:** The discussion is around connecting DualCLIPLoader node to the Anything Everywhere node.
*   **Emotion:** The emotional tone is positive and helpful.
*   **Top 3 Points of View:**
    *   The user forgot to connect the DualCLIPLoader node to the Anything Everywhere node.
    *   Make sure the paths to the models and the file names themselves are valid.
    *   Why use dual loader for using the same clip twice?

**[Beginner here – trying to inpaint anime characters into real photos using Stable Diffusion (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jw5y05/beginner_here_trying_to_inpaint_anime_characters/)**
*   **Summary:** Users discuss inpainting anime characters into real photos using Stable Diffusion and suggest tools like Invoke and LoRAs.
*   **Emotion:** The overall tone is helpful and supportive.
*   **Top 3 Points of View:**
    *   Recommending Invoke over A1111/Forge.
    *   Suggesting different LoRAs (make sure the base matches the model you're using).
    *   Suggesting to use video that talks about matching lighting and perspective.

**[Are the arguments correct in this version? When I start generating an image, my PC freezes. This issue did not occur with previous versions. i have a gtx 1650 (Score: 1)](https://i.redd.it/tv0bn4ki12ue1.png)**
*   **Summary:** Users discuss running AI with low VRAM.
*   **Emotion:** The emotional tone is negative.
*   **Top 3 Points of View:**
    *   Running AI with terribly low VRAM is a curse.

**[Hulk and Wolverine - Insane Combination (Score: 0)](https://v.redd.it/5b7o5yxn81ue1)**
*   **Summary:** One user says A hulk doesn’t need any claws.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    *   A hulk doesn’t need any claws.

**[how to generate prefect feet for anime characters with sdxl/illustrious model？ (Score: 0)](https://www.reddit.com/gallery/1jw1qjp)**
*   **Summary:** The discussion revolves around the best methods to generate perfect feet for anime characters, including refiners, inpainting, and other tools.
*   **Emotion:** The overall emotional tone is neutral, with a mix of humor.
*   **Top 3 Points of View:**
    *   Illustrious models generally get feet right.
    *   The user should mark it as NSFW.
    *   Use a better checkpoint.

**[Artist claim NightShade could collapse current model, did anybody test? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jw1be7/artist_claim_nightshade_could_collapse_current/)**
*   **Summary:** The discussion revolves around artist claims that Nightshade could collapse current models.
*   **Emotion:** The overall emotional tone is neutral and informative.
*   **Top 3 Points of View:**
    *   Nightshade exploit the weakness in the diffusion models.

**[Best Img-Vid AI Paid site (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jw42cu/best_imgvid_ai_paid_site/)**
*   **Summary:** The discussion is around which paid site is best for Img-Vid AI.
*   **Emotion:** The overall emotional tone is positive and helpful.
*   **Top 3 Points of View:**
    *   KlingAI gives the best overall and consistent results.
    *   Runway Gen4 is actually pretty good.
    *   Freepik has Veo 2 which is the very best but it's expensive.
