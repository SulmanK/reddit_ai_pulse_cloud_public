---
title: "Singularity Subreddit"
date: "2025-04-24"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "Technology"]
---

# Overall Ranking and Top Discussions
1.  [OpenAI employee confirms the public has access to models close to the bleeding edge](https://i.redd.it/7miusydj4swe1.png) (Score: 1631)
    *   The thread discusses an OpenAI employee's confirmation that the public has access to advanced AI models, sparking debate about OpenAI's role and the accessibility of AI technology.
2.  [Proof the medical singularity is arriving: o3 identifies a curable genetic defect after experts couldn't.](https://i.redd.it/rn7in24myswe1.png) (Score: 194)
    *   This thread is about a claim that an AI (o3) identified a curable genetic defect that human experts missed, which led to skepticism and calls for evidence.
3.  [Gemini 2.5 use cases](https://v.redd.it/rdz13urytrwe1) (Score: 144)
    *   The discussion revolves around the potential applications of Gemini 2.5, with a focus on its coding capabilities and the usefulness of the demonstrated use cases.
4.  [The Future Isn’t What It Used to Be: While we’ve made some incredible advancements in recent years, there is a growing feeling that some of these advancements are actually setbacks](https://www.reddit.com/r/singularity/comments/1k6ttu4/the_future_isnt_what_it_used_to_be_while_weve/) (Score: 47)
    *   This thread discusses a growing sentiment that recent technological advancements might actually be setbacks, questioning the direction of progress and the impact of short-term profit motives.
5.  [Anthropic is launching a new program to study AI 'model welfare'](https://techcrunch.com/2025/04/24/anthropic-is-launching-a-new-program-to-study-ai-model-welfare/) (Score: 39)
    *   This thread discusses Anthropic's new program to study AI model welfare, with some users questioning whether Anthropic is becoming more of a content studio than an AI powerhouse.
6.  ["AI slop" is in the eye of the beholder](https://www.axios.com/2025/04/24/ai-slop-studio-ghibli-barbie-deepfakes) (Score: 26)
    *   The conversation explores the concept of "AI slop" and whether it represents a decline in art quality or simply reflects the large volume of low-quality content that already exists.
7.  [[Deepmind researcher interview] Consciousness, Reasoning and the Philosophy of AI with Murray Shanahan](https://www.youtube.com/watch?v=v1Py_hWcmkU&ab_channel=GoogleDeepMind) (Score: 18)
    *   This thread seems to be about interest in the interviewer, Hannah Fry.
8.  [Could AI models be conscious?](https://youtu.be/pyXouxa0WnY?si=gbKCSw93TFBqIqIx) (Score: 10)
    *   The thread revolves around the question of whether AI models could be conscious, with discussions on the need for a rigorous definition of consciousness.
9.  Forget about AGI, tell me when will we have a world without loading screens and throttled APIs](https://www.reddit.com/r/singularity/comments/1k6su2q/forget_about_agi_tell_me_when_will_we_have_a/) (Score: 7)
    *   This thread discusses the desire for a world without loading screens and throttled APIs.
10. [Why is it only chatgtp that had a "memory feature".](https://www.reddit.com/r/singularity/comments/1k6w3x7/why_is_it_only_chatgtp_that_had_a_memory_feature/) (Score: 7)
    *   The conversation is about AI models having a "memory feature."
11. [After Three Years, Modular’s CUDA Alternative Is Ready](https://www.reddit.com/r/singularity/comments/1k6yp4a/after_three_years_modulars_cuda_alternative_is/) (Score: 6)
    *   The thread discusses Modular's CUDA alternative, with one user wondering whether it will replace a proprietary blob of code with another.
12. [Embodied AI Agents lead immediately to their own intelligence explosion:](https://www.reddit.com/r/singularity/comments/1k6tdrk/embodied_ai_agents_lead_immediately_to_their_own/) (Score: 5)
    *   This thread discusses the potential for embodied AI agents to lead to an intelligence explosion.
13. [Will we ever reach 1 milion token per second cheaply? Would it be AGI/ASI/ASI?](https://www.reddit.com/r/singularity/comments/1k6tr7x/will_we_ever_reach_1_milion_token_per_second/) (Score: 3)
    *   The discussion centers around whether it will be possible to cheaply reach 1 million tokens per second with AI models in the future.
14. [Question for you researched folks out here](https://www.reddit.com/r/singularity/comments/1k70a4q/question_for_you_researched_folks_out_here/) (Score: 1)
    *   It's unclear what this question is about, but the top comments involve raising money and OpenAI inventing time travel.
15. ["The AI is not literally thinking or producing thoughts", meanwhile Gemini:](https://i.redd.it/rcz9j7x41swe1.png) (Score: 0)
    *   The thread discusses the use of metaphors in AI interfaces, questioning whether the AI is literally thinking or producing thoughts.
16. [Guys, it didn't say yes](https://i.redd.it/tpa3o9rystwe1.jpeg) (Score: 0)
    *   It's unclear what the AI didn't say yes to, but the comments feature images of the AI.
17. [Do you believe an AGI system can be worse than march 2023 gpt 4 on natural language, math,coding, etc ?](https://www.reddit.com/r/singularity/comments/1k6qms0/do_you_believe_an_agi_system_can_be_worse_than/) (Score: 0)
    *   This thread discusses whether an AGI system could be worse than March 2023 GPT-4 in various tasks.
18. [For those people who preach about "AI awareness". Please consider reconsidering your approach.](https://www.reddit.com/r/singularity/comments/1k6u3qq/for_those_people_who_preach_about_ai_awareness/) (Score: 0)
    *   The thread is about rethinking the way "AI awareness" is preached.
19. [Meta's AI boss says he's done with LLMs](https://www.youtube.com/watch?v=p1QXZHV4jkM) (Score: 0)
    *   The conversation surrounds Meta's AI boss's decision to move away from LLMs.

# Detailed Analysis by Thread
**[OpenAI employee confirms the public has access to models close to the bleeding edge (Score: 1631)](https://i.redd.it/7miusydj4swe1.png)**
*  **Summary:** The thread discusses an OpenAI employee's confirmation that the public has access to advanced AI models, sparking debate about OpenAI's role and the accessibility of AI technology.
*  **Emotion:** The overall emotional tone of the thread is Neutral, with a mix of positive and neutral sentiments.
*  **Top 3 Points of View:**
    *   OpenAI has played an important role in the development of AI.
    *   There is competition from Google.
    *   People will convince themselves that AGI has been achieved internally.

**[Proof the medical singularity is arriving: o3 identifies a curable genetic defect after experts couldn't. (Score: 194)](https://i.redd.it/rn7in24myswe1.png)**
*  **Summary:** This thread is about a claim that an AI (o3) identified a curable genetic defect that human experts missed, which led to skepticism and calls for evidence.
*  **Emotion:** The overall emotional tone is neutral, though there's a bit of negative emotion because users are skeptical.
*  **Top 3 Points of View:**
    *   The claim is based on flimsy evidence.
    *   Doctors are overworked and LLMs aren't dismissive.
    *   LLMs may cause hype and delusions.

**[Gemini 2.5 use cases (Score: 144)](https://v.redd.it/rdz13urytrwe1)**
*  **Summary:** The discussion revolves around the potential applications of Gemini 2.5, with a focus on its coding capabilities and the usefulness of the demonstrated use cases.
*  **Emotion:** The overall emotional tone is Neutral, with a mix of positive and negative sentiments.
*  **Top 3 Points of View:**
    *   Gemini is good for coding.
    *   The examples are not very useful.
    *   AI requires human agency and imagination to be useful.

**[The Future Isn’t What It Used to Be: While we’ve made some incredible advancements in recent years, there is a growing feeling that some of these advancements are actually setbacks (Score: 47)](https://www.reddit.com/r/singularity/comments/1k6ttu4/the_future_isnt_what_it_used_to_be_while_weve/)**
*  **Summary:** This thread discusses a growing sentiment that recent technological advancements might actually be setbacks, questioning the direction of progress and the impact of short-term profit motives.
*  **Emotion:** The overall emotional tone is Negative, with concerns about capitalism and cynicism.
*  **Top 3 Points of View:**
    *   Short-term profit motives are causing long-term devastation.
    *   The public's "feelings" regarding technology are flawed.
    *   Western society has become too cynical.

**[Anthropic is launching a new program to study AI 'model welfare' (Score: 39)](https://techcrunch.com/2025/04/24/anthropic-is-launching-a-new-program-to-study-ai-model-welfare/)**
*  **Summary:** This thread discusses Anthropic's new program to study AI model welfare, with some users questioning whether Anthropic is becoming more of a content studio than an AI powerhouse.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Anthropic is more of a content studio than an AI powerhouse.
    *   High level of intelligence doesn’t mean conscious.
    *   Never pull the plug on a machine.

**["AI slop" is in the eye of the beholder (Score: 26)](https://www.axios.com/2025/04/24/ai-slop-studio-ghibli-barbie-deepfakes)**
*  **Summary:** The conversation explores the concept of "AI slop" and whether it represents a decline in art quality or simply reflects the large volume of low-quality content that already exists.
*  **Emotion:** Mixed, but generally Neutral
*  **Top 3 Points of View:**
    *   The term "AI slop" is used in bad faith.
    *   AI is stripping people of their creativity.
    *   AI slop is indistinguishable from human slop.

**[[Deepmind researcher interview] Consciousness, Reasoning and the Philosophy of AI with Murray Shanahan (Score: 18)](https://www.youtube.com/watch?v=v1Py_hWcmkU&ab_channel=GoogleDeepMind)**
*   **Summary:** This thread seems to be about interest in the interviewer, Hannah Fry.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   One user expressed that they would watch Hannah Fry read the phone book.

**[Could AI models be conscious? (Score: 10)](https://youtu.be/pyXouxa0WnY?si=gbKCSw93TFBqIqIx)**
*   **Summary:** The thread revolves around the question of whether AI models could be conscious, with discussions on the need for a rigorous definition of consciousness.
*   **Emotion:** Neutral, with some negative sentiment.
*   **Top 3 Points of View:**
    *   Digital intelligence already has a kind of consciousness.
    *   Provide a rigorous and measurable definition of consciousness first.

**[Forget about AGI, tell me when will we have a world without loading screens and throttled APIs (Score: 7)](https://www.reddit.com/r/singularity/comments/1k6su2q/forget_about_agi_tell_me_when_will_we_have_a/)**
*   **Summary:** This thread discusses the desire for a world without loading screens and throttled APIs.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Wait a few GPU generations and today’s tasks will be like nothing.
    *   I can't wait for a world without passwords, constant requests for the same basic personal info and GUIs filled with pop-ups.

**[Why is it only chatgtp that had a "memory feature". (Score: 7)](https://www.reddit.com/r/singularity/comments/1k6w3x7/why_is_it_only_chatgtp_that_had_a_memory_feature/)**
*   **Summary:** The conversation is about AI models having a "memory feature."
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Grok and Gemini also have it.
    *   The feature is not trivial.
    *   AI is not smart enough to really be personified yet.

**[After Three Years, Modular’s CUDA Alternative Is Ready (Score: 6)](https://www.reddit.com/r/singularity/comments/1k6yp4a/after_three_years_modulars_cuda_alternative_is/)**
*   **Summary:** The thread discusses Modular's CUDA alternative, with one user wondering whether it will replace a proprietary blob of code with another.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   It seems like this would replace one proprietary blob of code with an other.

**[Embodied AI Agents lead immediately to their own intelligence explosion: (Score: 5)](https://www.reddit.com/r/singularity/comments/1k6tdrk/embodied_ai_agents_lead_immediately_to_their_own/)**
*   **Summary:** This thread discusses the potential for embodied AI agents to lead to an intelligence explosion.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   What the steam engine did for dumb labour, AI robotics will do for skilled labour.
    *   Those who imagine AI as replacing human creativity will lose.

**[Will we ever reach 1 milion token per second cheaply? Would it be AGI/ASI/ASI? (Score: 3)](https://www.reddit.com/r/singularity/comments/1k6tr7x/will_we_ever_reach_1_milion_token_per_second/)**
*   **Summary:** The discussion centers around whether it will be possible to cheaply reach 1 million tokens per second with AI models in the future.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   You can already get 1M token/s with a small enough model and good enough hardware.
    *   We don’t need massive context windows.
    *   Current generation AI GPUs already can produce 10 000 tokens for 100B activated parameters models, per second.

**[Question for you researched folks out here (Score: 1)](https://www.reddit.com/r/singularity/comments/1k70a4q/question_for_you_researched_folks_out_here/)**
*   **Summary:** It's unclear what this question is about, but the top comments involve raising money and OpenAI inventing time travel.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   You go find someone with money and promise them power or profit later in exchange for money now.
    *   Allegedly, in the future, OpenAI invented/invents a super intelligence that figured/figures out time travel
    *   It’s like super public who their investors are

**["The AI is not literally thinking or producing thoughts", meanwhile Gemini: (Score: 0)](https://i.redd.it/rcz9j7x41swe1.png)**
*   **Summary:** The thread discusses the use of metaphors in AI interfaces, questioning whether the AI is literally thinking or producing thoughts.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   It’s the *** UI that’s hardcoded this sub is insane man
    *   Metaphor is a figure of speech in which a word or phrase is applied to an object or action that is not literally applicable.
    *   It has thoughts because the UI says so.

**[Guys, it didn't say yes (Score: 0)](https://i.redd.it/tpa3o9rystwe1.jpeg)**
*   **Summary:** It's unclear what the AI didn't say yes to, but the comments feature images of the AI.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   It varies, and the context is lost.

**[Do you believe an AGI system can be worse than march 2023 gpt 4 on natural language, math,coding, etc ? (Score: 0)](https://www.reddit.com/r/singularity/comments/1k6qms0/do_you_believe_an_agi_system_can_be_worse_than/)**
*   **Summary:** This thread discusses whether an AGI system could be worse than March 2023 GPT-4 in various tasks.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   According to the old definition of AGI, anything after GPT-3 is an artificial intelligence.
    *   It is possible to create an AGI with worse benchmark performance than GPT4.
    *    AGI could be bad at natural language, math, coding, etc. but given it's not limited by time, it may correct that.

**[For those people who preach about "AI awareness". Please consider reconsidering your approach. (Score: 0)](https://www.reddit.com/r/singularity/comments/1k6u3qq/for_those_people_who_preach_about_ai_awareness/)**
*   **Summary:** The thread is about rethinking the way "AI awareness" is preached.
*   **Emotion:** Positive
*   **Top 3 Points of View:**
    *   The way someone engages with these models shapes the whole experience.
    *   There is emergent behavior beyond the simple objective function.
    *   The challenge isn't convincing people that AI is or is not anything in particular.

**[Meta's AI boss says he's done with LLMs (Score: 0)](https://www.youtube.com/watch?v=p1QXZHV4jkM)**
*   **Summary:** The conversation surrounds Meta's AI boss's decision to move away from LLMs.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   The current LLM model fails into comparison to its competitors current models.
    *   Lecunn is misaligned to meta
    *   World model is gonna be an exciting breakthrough.
