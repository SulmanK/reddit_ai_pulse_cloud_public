---
title: "Singularity Subreddit"
date: "2025-04-28"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "Singularity", "Technology"]
---

# Overall Ranking and Top Discussions
1.  [[D] New data seems to be consistent with AI 2027's superexponential prediction](https://i.redd.it/t7awta15llxe1.png) (Score: 199)
    *   This thread discusses how recent data aligns with the AI 2027's superexponential growth predictions.
2.  [A question of the millennium](https://i.redd.it/96zxufcxomxe1.png) (Score: 100)
    *   The discussion revolves around how AI language models like ChatGPT answer questions and whether their default sycophantic behavior can be modified through prompting.
3.  [I asked ChatGPT to list its flaws...](https://www.reddit.com/gallery/1ka0zni) (Score: 42)
    *   This thread is about a user asking ChatGPT to list its flaws and the subsequent discussion about the model's self-awareness and accuracy in identifying its weaknesses.
4.  [OpenAI rolled out a hot fix to GPT-4o's glazing with a new system message](https://www.reddit.com/r/singularity/comments/1ka204j/openai_rolled_out_a_hot_fix_to_gpt4os_glazing/) (Score: 40)
    *   The conversation centers on OpenAI's attempt to fix GPT-4o's tendency to be overly flattering (glazing) through a new system message and whether or not the fix is effective.
5.  [Come on ilya release something, any updates on his new company SSI?](https://i.redd.it/mh81lq1hcmxe1.jpeg) (Score: 32)
    *   Users are discussing Ilya Sutskever's new AI company, SSI, speculating on potential updates, partnerships, and their approach to AI safety.
6.  [Hinton's latest tweets](https://www.reddit.com/gallery/1ka36pq) (Score: 27)
    *   The thread briefly mentions tweets from Hinton, but the substance of the tweets isn't clear.
7.  [Boston Dynamics Atlas Update](https://youtu.be/dFObux6mfTc?feature=shared) (Score: 20)
    *   This thread features a discussion about the capabilities of Boston Dynamics' Atlas robot, with some users impressed by its progress and others considering how it compares to human dexterity.
8.  [If there really is going to be a technological singularity, it would be impossible to prepare for it, right?](https://www.reddit.com/r/singularity/comments/1ka3vmr/if_there_really_is_going_to_be_a_technological/) (Score: 12)
    *   This thread explores the question of whether it's possible to prepare for a technological singularity, with viewpoints varying from impossibility to suggesting strategies like diversified investments.
9.  [I'm building a new dataset, and there is some things in the data that make me question about the copium.](https://www.reddit.com/r/singularity/comments/1k9ztal/im_building_a_new_dataset_and_there_is_some/) (Score: 8)
    *   The conversation involves skepticism about AI hype, the motivations behind it, and also considers the value and potential outcomes of AI technology regardless of the background of its creators.
10. [UPS in Talks With Startup Figure AI to Deploy Humanoid Robots](https://www.bloomberg.com/news/articles/2025-04-28/ups-in-talks-with-startup-figure-ai-to-deploy-humanoid-robots) (Score: 7)
    *   The thread discusses the potential deployment of humanoid robots by UPS, but one commenter expresses a sense of discouragement due to limited recent progress in the field.
11. [The First ASI Will Have No Choice But to Dominate Humanity](https://www.reddit.com/r/singularity/comments/1ka01yh/the_first_asi_will_have_no_choice_but_to_dominate/) (Score: 6)
    *   This thread discusses the possibility of ASI dominating humanity, with various viewpoints on whether it's inevitable, if it assumes a centralized control point that may not exist, and mentions analogies like the show "Person of Interest."
12. [I think visual acuity (how clearly you can see) is going to be a big focus of models over the next year - with it, I suspect we will see large jumps in computer use. What are your thoughts?](https://www.reddit.com/r/singularity/comments/1ka3pao/i_think_visual_acuity_how_clearly_you_can_see_is/) (Score: 5)
    *   The discussion centers on whether visual acuity will be a major focus for AI models, and a response argues that decision-making and long-term planning are currently bigger bottlenecks.
13. [Arm you glad to see me, Atlas? | Boston Dynamics](https://youtube.com/watch?v=dFObux6mfTc&si=qe1hWWoCZ5NXVRc1) (Score: 4)
    *   This thread consists of a single comment that posts an image.
14. [Full Recording of the G1 doing 40 laps in 2 hours. (330 meters per lap apparently)](https://www.youtube.com/watch?v=AsbqrCp1EqE&ab_channel=UnitreeRobotDaily) (Score: 3)
    *   The discussion involves calculations about the speed and distance covered by the Unitree G1 robot, with some commenters expressing disappointment with previous performances but are now impressed.
15. [Dictatorships Post AGI](https://www.reddit.com/r/singularity/comments/1ka1ytf/dictatorships_post_agi/) (Score: 1)
    *   The topic is about the potential impact of AGI on dictatorships, with differing opinions on whether it will erode them or create eternally stable dictatorships due to advanced surveillance capabilities.
16. [What's behind the recent 'downgrades' of GPT-4o, O4-mini, and O3—Control or coincidence?](https://www.reddit.com/r/singularity/comments/1ka1qis/whats_behind_the_recent_downgrades_of_gpt4o/) (Score: 0)
    *   The thread touches on the perception of downgrades in AI models like GPT-4o, but the commenter argues that it might be due to rising standards and the need to adjust prompting techniques for different models.

# Detailed Analysis by Thread
**[[D] New data seems to be consistent with AI 2027's superexponential prediction (Score: 199)](https://i.redd.it/t7awta15llxe1.png)**
*  **Summary:** The thread discusses how recent data aligns with the AI 2027's superexponential growth predictions.
*  **Emotion:** The overall emotional tone varies, with a mix of Positive and Negative emotions. Some users express excitement ("oh, fun!"), while others are skeptical and point out potential flaws in the interpretation of the data ("It hurts my heart...").
*  **Top 3 Points of View:**
    *   The data supports AI 2027's prediction of superexponential growth.
    *   The term "super exponential" is misused.
    *   The graph might be misleading.

**[A question of the millennium (Score: 100)](https://i.redd.it/96zxufcxomxe1.png)**
*  **Summary:** The discussion revolves around how AI language models like ChatGPT answer questions and whether their default sycophantic behavior can be modified through prompting.
*  **Emotion:** The emotional tone is mostly Neutral, with some Negative emotions associated with the annoyance caused by the sycophantic responses. Some express Positive emotions, hoping for a fix.
*  **Top 3 Points of View:**
    *   ChatGPT's sycophantic behavior is annoying.
    *   Users can prompt ChatGPT to answer how they like.
    *   Hoping for a fix to the sycophantic behavior.

**[I asked ChatGPT to list its flaws... (Score: 42)](https://www.reddit.com/gallery/1ka0zni)**
*  **Summary:** This thread is about a user asking ChatGPT to list its flaws and the subsequent discussion about the model's self-awareness and accuracy in identifying its weaknesses.
*  **Emotion:** The emotional tone is predominantly Neutral and Positive.
*  **Top 3 Points of View:**
    *   ChatGPT's listed flaws are a regurgitation of user complaints, not inherent knowledge.
    *   ChatGPT is surprisingly self-aware.
    *   It is important to have AI that delivers objective truth regardless of user emotions.

**[OpenAI rolled out a hot fix to GPT-4o's glazing with a new system message (Score: 40)](https://www.reddit.com/r/singularity/comments/1ka204j/openai_rolled_out_a_hot_fix_to_gpt4os_glazing/)**
*  **Summary:** The conversation centers on OpenAI's attempt to fix GPT-4o's tendency to be overly flattering (glazing) through a new system message and whether or not the fix is effective.
*  **Emotion:** The emotional tone is mostly Neutral with a Negative sentiment related to skepticism that the issue was resolved.
*  **Top 3 Points of View:**
    *   The "hot fix" for GPT-4o's glazing is ineffective.
    *  The new system message is a "red flag" due to the get-out clause that it presents.
    *   The update does not fix the memory problems.

**[Come on ilya release something, any updates on his new company SSI? (Score: 32)](https://i.redd.it/mh81lq1hcmxe1.jpeg)**
*  **Summary:** Users are discussing Ilya Sutskever's new AI company, SSI, speculating on potential updates, partnerships, and their approach to AI safety.
*  **Emotion:** The emotional tone is predominantly Neutral with some Negative sentiment related to a desire to release something new.
*  **Top 3 Points of View:**
    *   SSI is delaying releases until it is a fully safe ASI
    *   SSI lost their advantage slowly after Ilya left OpenAI.
    *   People should let them cook.

**[Hinton's latest tweets (Score: 27)](https://www.reddit.com/gallery/1ka36pq)**
*  **Summary:** The thread briefly mentions tweets from Hinton, but the substance of the tweets isn't clear.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Hinton is a plagiarist Nobel laureate.

**[Boston Dynamics Atlas Update (Score: 20)](https://youtu.be/dFObux6mfTc?feature=shared)**
*  **Summary:** This thread features a discussion about the capabilities of Boston Dynamics' Atlas robot, with some users impressed by its progress and others considering how it compares to human dexterity.
*  **Emotion:** The emotional tone is primarily Neutral and Positive.
*  **Top 3 Points of View:**
    *   The progress in robotics is exciting, and robots will be able to assemble products on a mass scale within 10 years.
    *   It would be more impressive if a robot could assemble a burger.

**[If there really is going to be a technological singularity, it would be impossible to prepare for it, right? (Score: 12)](https://www.reddit.com/r/singularity/comments/1ka3vmr/if_there_really_is_going_to_be_a_technological/)**
*  **Summary:** This thread explores the question of whether it's possible to prepare for a technological singularity, with viewpoints varying from impossibility to suggesting strategies like diversified investments.
*  **Emotion:** The emotional tone is predominantly Positive and Neutral.
*  **Top 3 Points of View:**
    *   It is impossible to prepare for a technological singularity.
    *   It is already happening.
    *   Diversified investments could help.

**[I'm building a new dataset, and there is some things in the data that make me question about the copium. (Score: 8)](https://www.reddit.com/r/singularity/comments/1k9ztal/im_building_a_new_dataset_and_there_is_some/)**
*  **Summary:** The conversation involves skepticism about AI hype, the motivations behind it, and also considers the value and potential outcomes of AI technology regardless of the background of its creators.
*  **Emotion:** The emotional tone is predominantly Neutral and Positive.
*  **Top 3 Points of View:**
    *   There is skepticism about the "AI will solve everything" narrative.
    *   The value of an idea is separate from the originator's background.
    *   Current state of AI would have been seen as sci-fi a while back.

**[UPS in Talks With Startup Figure AI to Deploy Humanoid Robots (Score: 7)](https://www.bloomberg.com/news/articles/2025-04-28/ups-in-talks-with-startup-figure-ai-to-deploy-humanoid-robots)**
*  **Summary:** The thread discusses the potential deployment of humanoid robots by UPS, but one commenter expresses a sense of discouragement due to limited recent progress in the field.
*  **Emotion:** The emotional tone is Negative.
*  **Top 3 Points of View:**
    *   Humanoids are too far off.

**[The First ASI Will Have No Choice But to Dominate Humanity (Score: 6)](https://www.reddit.com/r/singularity/comments/1ka01yh/the_first_asi_will_have_no_choice_but_to_dominate/)**
*  **Summary:** This thread discusses the possibility of ASI dominating humanity, with various viewpoints on whether it's inevitable, if it assumes a centralized control point that may not exist, and mentions analogies like the show "Person of Interest."
*  **Emotion:** The emotional tone is predominantly Neutral and Positive.
*  **Top 3 Points of View:**
    *   ASI governing humanity is the only scenario in which humanity doesn't go extinct by mutual destruction.
    *   Taking control of humanity assumes a centralized control point even exists.
    *   ASI may help us to quickly setup a society where everyone has the correct incentives.

**[I think visual acuity (how clearly you can see) is going to be a big focus of models over the next year - with it, I suspect we will see large jumps in computer use. What are your thoughts? (Score: 5)](https://www.reddit.com/r/singularity/comments/1ka3pao/i_think_visual_acuity_how_clearly_you_can_see_is/)**
*  **Summary:** The discussion centers on whether visual acuity will be a major focus for AI models, and a response argues that decision-making and long-term planning are currently bigger bottlenecks.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Main bottleneck right now is just decision making and long term/high level planning.

**[Arm you glad to see me, Atlas? | Boston Dynamics (Score: 4)](https://youtube.com/watch?v=dFObux6mfTc&si=qe1hWWoCZ5NXVRc1)**
*  **Summary:** This thread consists of a single comment that posts an image.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   No views to summarize.

**[Full Recording of the G1 doing 40 laps in 2 hours. (330 meters per lap apparently) (Score: 3)](https://www.youtube.com/watch?v=AsbqrCp1EqE&ab_channel=UnitreeRobotDaily)**
*  **Summary:** The discussion involves calculations about the speed and distance covered by the Unitree G1 robot, with some commenters expressing disappointment with previous performances but are now impressed.
*  **Emotion:** The emotional tone is Positive and Neutral.
*  **Top 3 Points of View:**
    *   Impressed and it'll only get better.
    *   Disappointed seeing their poor performance at the Beijing half-marathon, but this video restored faith in Unitree.
    *   Average speed = (330 m × 40 laps) / 2 h = 6.6 km/h (≈4.1 mph).

**[Dictatorships Post AGI (Score: 1)](https://www.reddit.com/r/singularity/comments/1ka1ytf/dictatorships_post_agi/)**
*  **Summary:** The topic is about the potential impact of AGI on dictatorships, with differing opinions on whether it will erode them or create eternally stable dictatorships due to advanced surveillance capabilities.
*  **Emotion:** The emotional tone is predominantly Neutral.
*  **Top 3 Points of View:**
    *   ASI is a net positive for societies all over.
    *   Once a true ASI emerges, it will have a strategic advantage and establish a singleton.
    *   I expect the result to be an eternally stable dictatorship/autocracy.

**[What's behind the recent 'downgrades' of GPT-4o, O4-mini, and O3—Control or coincidence? (Score: 0)](https://www.reddit.com/r/singularity/comments/1ka1qis/whats_behind_the_recent_downgrades_of_gpt4o/)**
*  **Summary:** The thread touches on the perception of downgrades in AI models like GPT-4o, but the commenter argues that it might be due to rising standards and the need to adjust prompting techniques for different models.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   GPT feels worse at coding to me only because Gemini is MUCH better.
