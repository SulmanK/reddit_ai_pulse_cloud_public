---
title: "Data Engineering Subreddit"
date: "2025-04-26"
description: "Analysis of top discussions and trends in the dataengineering subreddit"
tags: ["data engineering", "airflow", "dbt"]
---

# Overall Ranking and Top Discussions
1.  [ðƒð¨ð¨ð«ðƒðšð¬ð¡ ðƒðšð­ðš ð“ðžðœð¡ ð’ð­ðšðœð¤](https://i.redd.it/lj3dfdf3j7xe1.jpeg) (Score: 71)
    *   Discusses the data technology stack used at DoorDash.
2.  [How to use Airflow and dbt together? (in a medallion architecture or otherwise)](https://www.reddit.com/r/dataengineering/comments/1k83uee/how_to_use_airflow_and_dbt_together_in_a/) (Score: 23)
    *   Explores the best practices for integrating Airflow and dbt for data orchestration and transformation, particularly within a medallion architecture.
3.  [Mongodb vs Postgres](https://www.reddit.com/r/dataengineering/comments/1k86ldy/mongodb_vs_postgres/) (Score: 21)
    *   Compares the pros and cons of using MongoDB versus Postgres for data storage, with consideration for schema flexibility, data quality, and the CAP theorem.
4.  [This environment would be a real nightmare for me.](https://www.reddit.com/r/dataengineering/comments/1k8k8s8/this_environment_would_be_a_real_nightmare_for_me/) (Score: 18)
    *   Discusses the challenges and potential benefits of working in a large-scale data environment.
5.  [Have you ever used record linkage / entity resolution at your job?](https://www.reddit.com/r/dataengineering/comments/1k8dmdp/have_you_ever_used_record_linkage_entity/) (Score: 17)
    *   Explores techniques and tools for record linkage and entity resolution, including fuzzy matching, phonetic representation, and address validation.
6.  [DevOps and Data Engineering â€” Which Offers More Career Flexibility?](https://www.reddit.com/r/dataengineering/comments/1k8eqvm/devops_and_data_engineering_which_offers_more/) (Score: 17)
    *   Compares career flexibility and responsibilities in DevOps and Data Engineering roles, noting areas of overlap and recommending preparation for both.
7.  [How would you manage multiple projects using Airflow + SQLMesh? Small team of 4 (3 DEs, 1 DA)](https://www.reddit.com/r/dataengineering/comments/1k8au6k/how_would_you_manage_multiple_projects_using/) (Score: 13)
    *   Discusses strategies for managing multiple data projects using Airflow and SQLMesh, focusing on repository structure, environment management, and deployment strategies.
8.  [Coalesce.io vs dbt](https://www.reddit.com/r/dataengineering/comments/1k7yq0d/coalesceio_vs_dbt/) (Score: 9)
    *   Compares Coalesce.io and dbt for data transformation, considering factors such as version control, ease of use for non-technical users, and community support.
9.  [Career path into DE](https://www.reddit.com/r/dataengineering/comments/1k7yi4k/career_path_into_de/) (Score: 8)
    *   Offers advice on career paths into Data Engineering, including relevant coursework, skill development, and the value of practical experience.
10. [Are we missing the point of data catalogs? Why don't they control data access too?](https://www.reddit.com/r/dataengineering/comments/1k8jmbo/are_we_missing_the_point_of_data_catalogs_why/) (Score: 7)
    *   Questions whether data catalogs should also handle data access control.
11. [Clustering with an incremental merge strategy](https://www.reddit.com/r/dataengineering/comments/1k82dcn/clustering_with_an_incremental_merge_strategy/) (Score: 4)
    *   Discusses whether clustering helps with the merge strategy for an incremental model in BigQuery.
12. [Customer Database Mapping and Migration â€“ Best Practices?](https://www.reddit.com/r/dataengineering/comments/1k8cv48/customer_database_mapping_and_migration_best/) (Score: 2)
    *   Seeks best practices for customer database mapping and migration.
13. [Data modeling question to split or not to split](https://www.reddit.com/r/dataengineering/comments/1k893vx/data_modeling_question_to_split_or_not_to_split/) (Score: 1)
    *   Discusses the question of whether to split data models.
14. [Should we use SCD Type 1 instead of Type 2 for our DWH when analytics only needs current data?](https://www.reddit.com/r/dataengineering/comments/1k8jz47/should_we_use_scd_type_1_instead_of_type_2_for/) (Score: 1)
    *   Asks whether to use SCD Type 1 instead of Type 2 when analytics only needs current data.
15. [Apache Kafka Resources for Beginner](https://www.reddit.com/r/dataengineering/comments/1k8k0jz/apache_kafka_resources_for_beginner/) (Score: 1)
    *   Asks for Apache Kafka resources for beginners.
16. [any database experts?](https://www.reddit.com/r/dataengineering/comments/1k8kqht/any_database_experts/) (Score: 1)
    *   Asks for database experts.
17. [Need opinion ( iam newbie to BI but they sent me this task)](https://www.reddit.com/gallery/1k8jnxf) (Score: 0)
    *   Seeks opinions on a BI task.
18. [Would you use this tool? AI that writes SQL queries from natural language.](https://www.reddit.com/r/dataengineering/comments/1k862la/would_you_use_this_tool_ai_that_writes_sql/) (Score: 0)
    *   Discusses the utility of AI tools that write SQL queries from natural language.

# Detailed Analysis by Thread
**[ ðƒð¨ð¨ð«ðƒðšð¬ð¡ ðƒðšð­ðš ð“ðžðœð¡ ð’ð­ðšðœð¤ (Score: 71)](https://i.redd.it/lj3dfdf3j7xe1.jpeg)**
*  **Summary:** The thread showcases the data technology stack used at DoorDash, prompting questions about covering other companies' stacks and discussions about specific technologies like Delta and Iceberg. It also raises concerns about potential spam due to the presentation style and use of UTM codes.
*  **Emotion:** The emotional tone is generally positive, with neutral sentiments regarding the specific technologies and slight positivity regarding the overall information.
*  **Top 3 Points of View:**
    *   The stack overview is informative and useful.
    *   There's interest in seeing similar overviews for other companies like Reddit, Shopify, and TikTok.
    *   The presentation style (bolding, UTM codes) may be perceived as spammy.

**[ How to use Airflow and dbt together? (in a medallion architecture or otherwise) (Score: 23)](https://www.reddit.com/r/dataengineering/comments/1k83uee/how_to_use_airflow_and_dbt_together_in_a/)**
*  **Summary:** This thread discusses how to effectively use Airflow and dbt together, particularly within a medallion architecture. Airflow is primarily an orchestration tool that can trigger ingestion services and dbt scripts for data transformation. Managed Airflow solutions are recommended to avoid common pitfalls.
*  **Emotion:** The overall emotional tone is neutral, reflecting informative and technical discussions. There's also some positivity about the user thinking ahead about the tools they are using.
*  **Top 3 Points of View:**
    *   Airflow orchestrates data workflows, triggering ingestion tools and dbt scripts.
    *   Managed Airflow solutions (Astronomer, MWAA, etc.) are preferable.
    *   Backfills in Airflow can be managed using dbt micro-batches (1.9+).

**[ Mongodb vs Postgres (Score: 21)](https://www.reddit.com/r/dataengineering/comments/1k86ldy/mongodb_vs_postgres/)**
*  **Summary:**  This thread compares MongoDB and Postgres, with most participants favoring Postgres due to concerns about data quality and the long-term implications of using a document store. Some suggest starting with a flexible database like MongoDB for early-stage companies but transitioning to a relational schema as business requirements solidify. The CAP theorem is also mentioned in the discussion.
*  **Emotion:** The emotional tone is predominantly neutral, reflecting a balanced discussion of the pros and cons of each database. There is some positivity regarding Postgres as a reliable choice.
*  **Top 3 Points of View:**
    *   Postgres is generally preferred for its data quality and structured approach.
    *   MongoDB can be suitable for early-stage companies needing flexibility but leads to tech debt.
    *   Frequent schema changes in Postgres are manageable with modern tooling.

**[ This environment would be a real nightmare for me. (Score: 18)](https://www.reddit.com/r/dataengineering/comments/1k8k8s8/this_environment_would_be_a_real_nightmare_for_me/)**
*  **Summary:**  This thread is about the pros and cons of working in a massive scale data environment, focusing on good automation and domain best practices.
*  **Emotion:** The emotional tone is generally neutral, with the recognition of the challenges of the subject.
*  **Top 3 Points of View:**
    *   Finding queries that can be optimized at a massive scale can save the company millions of dollars.
    *   Good automations and domain best practices must come with it as you grow in business.
    *   Tables are partitioned and where clauses required and other restrictions set in place.

**[ Have you ever used record linkage / entity resolution at your job? (Score: 17)](https://www.reddit.com/r/dataengineering/comments/1k8dmdp/have_you_ever_used_record_linkage_entity/)**
*  **Summary:** The thread discusses techniques and tools for record linkage/entity resolution. Suggestions include fuzzy matching, edit distance algorithms, address APIs, and tools like Quantexa and Splink. The importance of match accuracy, speed, and the need for manual overrides are emphasized.
*  **Emotion:** The overall emotion is positive due to the multiple solutions people are offering.
*  **Top 3 Points of View:**
    *   Fuzzy matching and edit distance algorithms are common techniques.
    *   Tools like Splink are recommended for probabilistic linkage.
    *   Accuracy and speed are key considerations, often requiring a trade-off.

**[ DevOps and Data Engineering â€” Which Offers More Career Flexibility? (Score: 17)](https://www.reddit.com/r/dataengineering/comments/1k8eqvm/devops_and_data_engineering_which_offers_more/)**
*  **Summary:** The thread explores the career flexibility offered by DevOps and Data Engineering, noting that the fields are different, with DevOps focusing on operations and Data Engineering on development. The discussion highlights the overlap between the two and recommends preparing for both.
*  **Emotion:** The emotional tone is mostly neutral, providing a balanced comparison of the two fields. There's also a bit of positivity from people who recommend learning as much as you can from both disciplines.
*  **Top 3 Points of View:**
    *   DevOps focuses on operations, while Data Engineering focuses on development.
    *   There's increasing overlap between the two roles, requiring developers to handle more DevOps tasks.
    *   Learning both DevOps and Data Engineering skills is beneficial for career prospects.

**[ How would you manage multiple projects using Airflow + SQLMesh? Small team of 4 (3 DEs, 1 DA) (Score: 13)](https://www.reddit.com/r/dataengineering/comments/1k8au6k/how_would_you_manage_multiple_projects_using/)**
*  **Summary:** The discussion centers on managing multiple projects using Airflow and SQLMesh within a small team. The consensus leans towards using a monorepo with a clear folder structure for each project, Dockerizing each project, and implementing CI/CD.
*  **Emotion:** The emotional tone is largely neutral, focusing on practical advice and best practices.
*  **Top 3 Points of View:**
    *   A monorepo with a clear folder structure is a good starting point.
    *   Dockerizing each project allows for isolated environments.
    *   Airflow's Kubernetes executor can handle different environments.

**[ Coalesce.io vs dbt (Score: 9)](https://www.reddit.com/r/dataengineering/comments/1k7yq0d/coalesceio_vs_dbt/)**
*  **Summary:** This thread compares Coalesce.io and dbt for data transformation. Dbt is mentioned as an industry standard, but Coalesce.io is praised for its low-code interface, version control, and ease of use for both technical and non-technical users. Concerns are raised about lock-in and costs associated with Coalesce.
*  **Emotion:** The emotional tone is mixed, with neutral assessments of both tools and some positive sentiment towards Coalesce.io from its users.
*  **Top 3 Points of View:**
    *   dbt is an industry standard with broad community support.
    *   Coalesce.io is user-friendly, especially for non-technical users.
    *   Concerns exist about potential lock-in and costs with Coalesce.io.

**[ Career path into DE (Score: 8)](https://www.reddit.com/r/dataengineering/comments/1k7yi4k/career_path_into_de/)**
*  **Summary:** The thread gives advice on how to get into a Data Engineering role. It mentions relevant course work, skills to have, and the benefits of having practical experience.
*  **Emotion:** The emotional tone is generally positive.
*  **Top 3 Points of View:**
    *   You should take a course on Databases offered in the CS, IT/IS or Business department.
    *   You should focus on programming skills (Python, SQL) and getting comfortable with cloud platforms (AWS/Azure/GCP).
    *   A part-time data science position is great experience.

**[ Are we missing the point of data catalogs? Why don't they control data access too? (Score: 7)](https://www.reddit.com/r/dataengineering/comments/1k8jmbo/are_we_missing_the_point_of_data_catalogs_why/)**
*  **Summary:** The thread questions whether data catalogs should handle data access control.
*  **Emotion:** The overall emotion is neutral.
*  **Top 3 Points of View:**
    *   None available. The only comment is the question "Isnâ€™t this Unity catalog?"

**[ Clustering with an incremental merge strategy (Score: 4)](https://www.reddit.com/r/dataengineering/comments/1k82dcn/clustering_with_an_incremental_merge_strategy/)**
*  **Summary:** The thread discusses whether clustering benefits the merge strategy for an incremental model in BigQuery. Some argue that clustering improves lookup speed and filtering, while others state that it is only beneficial after the table has been created.
*  **Emotion:** The emotional tone is neutral, as people are providing data information.
*  **Top 3 Points of View:**
    *   Clustering improves lookup speed by making it more efficient to find the right file.
    *   Clustering is only beneficial after the table has been created and improves query performance.
    *   Clustering optimizes read performance, not write operations like merge.

**[ Customer Database Mapping and Migration â€“ Best Practices? (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1k8cv48/customer_database_mapping_and_migration_best/)**
*  **Summary:** The thread is looking for best practices regarding Customer Database Mapping and Migration.
*  **Emotion:** The emotional tone is positive due to the helpful suggestions.
*  **Top 3 Points of View:**
    *   Use Excel.
    *   Pop open duckdb and do a left join and coalesces and then clean up the results afterward in excel if you still want.
    *   Have the system use strict legal trading names.

**[ Data modeling question to split or not to split (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k893vx/data_modeling_question_to_split_or_not_to_split/)**
*  **Summary:** Discusses the question of whether to split data models.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   For SCD2 tables, create a view in the consumption layer that filters for active rows to give analysts easy access to only the currently active records.
    *   If analyst teams are competent in writing SQL, they can create their own queries or be provided a workspace where they can build and manage their own datasets as needed.
    *   Avoid creating multiple views on the same base table with varying filter rules, as this can negatively impact performance and increase maintenance overhead.

**[ Should we use SCD Type 1 instead of Type 2 for our DWH when analytics only needs current data? (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k8jz47/should_we_use_scd_type_1_instead_of_type_2_for/)**
*  **Summary:** Asks whether to use SCD Type 1 instead of Type 2 when analytics only needs current data.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    *   Because you're retaining history at the raw/source layer, you can easily create scd-2 type tables with valid to/from fields later as needed.
    *   For your current use case, sure.
    *   What your stakeholders consider to be current data and what you consider to be current data may not be the same thing.

**[ Apache Kafka Resources for Beginner (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k8k0jz/apache_kafka_resources_for_beginner/)**
*  **Summary:** Asks for Apache Kafka resources for beginners.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   None, only bot comment that shares link to learning resources.

**[ any database experts? (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1k8kqht/any_database_experts/)**
*  **Summary:** Asks for database experts.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Writes directly into a db from a pandas dataframe are always going to be extremely slow. The correct workflow is Pandas -> CSV in bulk storage -> DB
    *   Consider using duckdb instead of pandas?

**[ Need opinion ( iam newbie to BI but they sent me this task) (Score: 0)](https://www.reddit.com/gallery/1k8jnxf)**
*  **Summary:** Seeks opinions on a BI task.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    *   Panels being aligned or sized according to a pattern would help make it look more polished.
    *   Several of your visualizations contain absolutely no information or value to the end user.
    *   Look into some basic UI and graphic design and then ask yourself if the visualization you chose is beneficial to the end user.

**[ Would you use this tool? AI that writes SQL queries from natural language. (Score: 0)](https://www.reddit.com/r/dataengineering/comments/1k862la/would_you_use_this_tool_ai_that_writes_sql/)**
*  **Summary:** Discusses the utility of AI tools that write SQL queries from natural language.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    *   Analysts who have used SQL a lot, it's easier for them to write the SQL than type it out in natural language/english
    *   Many companies are trying to build this exact thing into their semantic layer products as we speak, and itâ€™s extremely useful, but also extremely hard to get correct.
    *   Extremely useful and only a matter of time until this becomes the norm.

