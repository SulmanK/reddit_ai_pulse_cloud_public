---
title: "Stable Diffusion Subreddit"
date: "2025-04-03"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stable diffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Could Stable Diffusion Models Have a "Thinking Phase" Like Some Text Generation AIs?](https://www.reddit.com/gallery/1jqrr9g) (Score: 16)
    *   The discussion revolves around whether Stable Diffusion models can have a "thinking phase" similar to text generation AIs like GPT-4o, with users discussing the fundamental differences between diffusion models and LLMs.
2.  [I animated a page of a comic I drew when I was a kid (SDXL + WAN 2.1). Original page and the generated panels are included in comments.](https://v.redd.it/5u8hon1l9nse1) (Score: 11)
    *   A user animated a comic page using SDXL and WAN 2.1 and shared the original page and generated panels, receiving positive feedback.
3.  [I TRAIN FLUX CHARACTER LORA FOR FREE](https://www.reddit.com/gallery/1jqnq23) (Score: 11)
    *   A user offers to train Flux character LoRA for free, leading to discussions about the potential risks of sharing image datasets and alternative training platforms.
4.  [Wan 2.1 Fun InP start end frames. Why last frame darkening?](https://v.redd.it/l67vxjabnnse1) (Score: 7)
    *   A user is experiencing darkening in the last frame and asks for help troubleshooting, receiving suggestions related to VAE settings and configurations.
5.  [InstantCharacter](https://www.reddit.com/r/StableDiffusion/comments/1jqnfqb/instantcharacter/) (Score: 4)
    *   Discussion of the InstantCharacter tool, with users noting the subpar results of face transfer/FaceID codes, and debate around the quality of the results and how they are obtained.
6.  [Just getting started with Stable diffusion - any tips or resources to learn from?](https://www.reddit.com/r/StableDiffusion/comments/1jqnt2m/just_getting_started_with_stable_diffusion_any/) (Score: 3)
    *   A new user seeks tips and resources for learning Stable Diffusion, with suggestions including exploring open-source user apps and experimenting independently.
7.  [Best scheduler and sampler for Wan 2.1?](https://www.reddit.com/r/StableDiffusion/comments/1jqn3vc/best_scheduler_and_sampler_for_wan_21/) (Score: 2)
    *   Users discuss and recommend their preferred scheduler and sampler for Wan 2.1, with dpmpp_2m and sgm_uniform suggested.
8.  ["Vikings in battle, fierce, berserk". POST YOURS. Any models. *Non-realism, Hollywood stereotypes, Plastics, Horned helmets and Supermodels straight from the hairdresser will be frowned upon. Workflow is welcomed](https://www.reddit.com/gallery/1jqsne5) (Score: 1)
    *   A user shares their workflow for generating realistic Viking battle scenes and invites others to share theirs.
9.  [Crop Around Text](https://www.reddit.com/r/StableDiffusion/comments/1jqmobr/crop_around_text/) (Score: 1)
    *   Users discuss methods for cropping images around text, suggesting the use of bounding box models and Python scripts.
10. [Searching for a couple of prompting suggestions](https://www.reddit.com/r/StableDiffusion/comments/1jqpbas/searching_for_a_couple_of_prompting_suggestions/) (Score: 1)
    *   A user is looking for prompting suggestions.
11. [Images look really nice as they're generating, then the finished product looks terrible.](https://www.reddit.com/r/StableDiffusion/comments/1jqr601/images_look_really_nice_as_theyre_generating_then/) (Score: 1)
    *   A user is experiencing a degradation in image quality after generation and is advised to check their VAE settings.
12. [All of the good AI models are exactly as this. If you think otherwise you are mistaken](https://v.redd.it/jfxztkjxvnse1) (Score: 0)
    *   A user's post is flagged as not belonging in the local generations subreddit.
13. [A Comparison between Wan 2.1 1.3B from Huge.com vs Qwen 2.5 in a closeup fighting video of a female spy vs bad man spy guy on top of a skyscraper with a helicopter in the background. I used the same prompt for both. Realistic stunt fight physics. Panavision camera. Quality is there for fighting vids](https://v.redd.it/pj75xhhi8nse1) (Score: 0)
    *   A user compares video results from different models, prompting questions about the choice of models.
14. [Ghibli style hype](https://www.reddit.com/r/StableDiffusion/comments/1jqmdfl/ghibli_style_hype/) (Score: 0)
    *   Discussion about generating Ghibli-style images, comparing diffusion models with GPT-4o and suggesting techniques using ComfyUI, LoRAs, and controlnets.
15. [How Are AI Influencers Creating Such Realistic Videos?](https://www.reddit.com/r/StableDiffusion/comments/1jqpu6v/how_are_ai_influencers_creating_such_realistic/) (Score: 0)
    *   Users discuss how realistic AI influencer videos are created, mentioning Flux model finetuning and KlingAI.
16. [Any way to restore eyes later?](https://www.reddit.com/r/StableDiffusion/comments/1jqs6z0/any_way_to_restore_eyes_later/) (Score: 0)
    *   A user asks about restoring eyes in images, and is directed to look into inpainting techniques.

# Detailed Analysis by Thread
**[Could Stable Diffusion Models Have a "Thinking Phase" Like Some Text Generation AIs? (Score: 16)](https://www.reddit.com/gallery/1jqrr9g)**
*  **Summary:**  The thread discusses the possibility of Stable Diffusion models having a "thinking phase" akin to text generation AIs. It explores the differences between diffusion models and LLMs, highlighting the ability of models like GPT-4o to reason and plan scenes before generating images, whereas diffusion models primarily learn visual patterns.
*  **Emotion:** The overall emotional tone of the thread is Neutral, with some negative comments regarding the current state of image generation accuracies and processes.
*  **Top 3 Points of View:**
    * Diffusion models are fundamentally different from LLMs like GPT-4o; they lack explicit understanding and reasoning capabilities.
    * Prompt enhancers, such as plugging chain of thoughts GPT into ComfyUI, can introduce a "thinking phase" by refining prompts.
    * Modifying text prompts to include image construction workflows can help leverage reasoning models for image generation.

**[I animated a page of a comic I drew when I was a kid (SDXL + WAN 2.1). Original page and the generated panels are included in comments. (Score: 11)](https://v.redd.it/5u8hon1l9nse1)**
*  **Summary:** A user shares an animation of a comic page created using SDXL and WAN 2.1, posting the original page and generated panels. The work is well-received, with comments praising the retro vibe.
*  **Emotion:** Predominantly Positive due to the praise of the user's creation.
*  **Top 2 Points of View:**
    * The animation is of high quality and effectively brings the comic page to life.
    * The retro vibe of the animation is appealing and adds to its charm.

**[I TRAIN FLUX CHARACTER LORA FOR FREE (Score: 11)](https://www.reddit.com/gallery/1jqnq23)**
*  **Summary:** A user offers to train Flux character LoRA for free, leading to discussion about the risks involved with sharing personal image datasets and recommending paid alternatives.
*  **Emotion:** The overall tone is a mix of Neutral and Negative, with some positive sentiment expressed towards the quality of generated images, but also concern raised about the safety of sharing datasets.
*  **Top 3 Points of View:**
    * The generated images are of very high quality and realistic.
    * Sharing image datasets with strangers for LoRA training poses security and misuse risks.
    * Training LoRAs is inexpensive and can be done safely through official partner platforms like Replicate.

**[Wan 2.1 Fun InP start end frames. Why last frame darkening? (Score: 7)](https://v.redd.it/l67vxjabnnse1)**
*  **Summary:** The user presents a problem with their Wan 2.1 generation, where the last frame is darkening, and is asking the community for potential solutions.
*  **Emotion:** Neutral as users are troubleshooting the issue of the last frame darkening. Some negative emotions due to the creepiness/horror vibe.
*  **Top 3 Points of View:**
    * The darkening issue may be related to incorrect VAE settings or VRAM usage.
    * The issue may be related to a native version of the workflow and its artifacts.
    * Some users were not experiencing the issue, suggesting a configuration-specific problem.

**[InstantCharacter (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1jqnfqb/instantcharacter/)**
*  **Summary:** The discussion centers on the InstantCharacter tool, with users expressing skepticism about the quality of results, comparing them to subpar face transfer/FaceID codes.
*  **Emotion:** The sentiment is largely Positive, with some negative undertones regarding the perceived quality of results compared to advertised demos.
*  **Top 2 Points of View:**
    * The demos for face transfer technologies are often cherry-picked to show optimal results, which may not reflect real-world performance.
    * The technology effectively resolves the issue of adhering to prompts during image sampling after applying the Redux model.

**[Just getting started with Stable diffusion - any tips or resources to learn from? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1jqnt2m/just_getting_started_with_stable_diffusion_any/)**
*  **Summary:** A newcomer requests advice on starting with Stable Diffusion and suggestions include exploring open-source apps, consulting the wiki, and experimenting independently.
*  **Emotion:** Primarily Neutral, with some Positive sentiment in offering encouraging advice to the beginner.
*  **Top 2 Points of View:**
    * Beginners should explore various open-source applications and their associated documentation.
    * New users should focus on independent experimentation and creative exploration.

**[Best scheduler and sampler for Wan 2.1? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jqn3vc/best_scheduler_and_sampler_for_wan_21/)**
*  **Summary:** Users are discussing their preferred scheduler and sampler for the Wan 2.1 model.
*  **Emotion:** Mostly Neutral with a hint of positive sentiment.
*  **Top 2 Points of View:**
    * One user recommends "dpmpp_2m + sgm_uniform".
    * Another finds "Uni PC" to be satisfactory.

**["Vikings in battle, fierce, berserk". POST YOURS. Any models. *Non-realism, Hollywood stereotypes, Plastics, Horned helmets and Supermodels straight from the hairdresser will be frowned upon. Workflow is welcomed (Score: 1)](https://www.reddit.com/gallery/1jqsne5)**
*  **Summary:** The user shares a prompt and settings used to generate an image of Vikings in battle.
*  **Emotion:** Neutral.
*  **Top 1 Point of View:**
    * The poster shares their workflow.

**[Crop Around Text (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jqmobr/crop_around_text/)**
*  **Summary:** A user is looking for a way to crop around text in an image.
*  **Emotion:** Neutral.
*  **Top 2 Points of View:**
    * One suggestion is to use Florence to output bounding boxes and feed those boxes to a python script.
    * Another suggestion is to use ComfyUI with a model that identifies Japanese text.

**[Searching for a couple of prompting suggestions (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jqpbas/searching_for_a_couple_of_prompting_suggestions/)**
*  **Summary:** User is asking for prompting suggestions.
*  **Emotion:** Neutral
*  **Top 1 Point of View:**
    * One user simply suggests "Squish?"

**[Images look really nice as they're generating, then the finished product looks terrible. (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jqr601/images_look_really_nice_as_theyre_generating_then/)**
*  **Summary:** A user is experiencing image degradation after the image generation process is complete.
*  **Emotion:** Neutral
*  **Top 1 Point of View:**
    * One user suggested to check the VAE.

**[All of the good AI models are exactly as this. If you think otherwise you are mistaken (Score: 0)](https://v.redd.it/jfxztkjxvnse1)**
*  **Summary:** User made a post not meant for local generations.
*  **Emotion:** Neutral
*  **Top 1 Point of View:**
    * Users are told to post the content elsewhere since it's not for local generations.

**[A Comparison between Wan 2.1 1.3B from Huge.com vs Qwen 2.5 in a closeup fighting video of a female spy vs bad man spy guy on top of a skyscraper with a helicopter in the background. I used the same prompt for both. Realistic stunt fight physics. Panavision camera. Quality is there for fighting vids (Score: 0)](https://v.redd.it/pj75xhhi8nse1)**
*  **Summary:** User shows a comparison between two AI models.
*  **Emotion:** Neutral
*  **Top 2 Points of View:**
    * The post shows the user's Riffusion Music video compilation.
    * Questioning the comparison of a 1.3B model.

**[Ghibli style hype (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jqmdfl/ghibli_style_hype/)**
*  **Summary:** Discussion surrounding the trend of generating Ghibli-style images.
*  **Emotion:** A bit of Negative tone from the user talking about the hype running out.
*  **Top 3 Points of View:**
    * GPT-4o results are likely to be better.
    * Suggestion on using ComfyUI to get Ghibli-style results.
    * Image workflow using an image inversion approach.

**[How Are AI Influencers Creating Such Realistic Videos? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jqpu6v/how_are_ai_influencers_creating_such_realistic/)**
*  **Summary:** Users discuss how realistic AI videos are being created.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Flux model finetune + Kling
    * A lot of testing, trying, reading, learning, looking, searching...
    * KlingAI

**[Any way to restore eyes later? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jqs6z0/any_way_to_restore_eyes_later/)**
*  **Summary:** User asks how to restore eyes in images.
*  **Emotion:** Neutral
*  **Top 1 Point of View:**
    * Suggestion to look up inpainting.
