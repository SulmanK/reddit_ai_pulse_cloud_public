---
title: "Stable Diffusion Subreddit"
date: "2025-04-01"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] VACE Code and Models Now on GitHub (Partial Release)](https://www.reddit.com/r/StableDiffusion/comments/1jp1ioe/vace_code_and_models_now_on_github_partial_release/) (Score: 37)
    *   Users are discussing the release of VACE code and models on GitHub, with some wondering about its capabilities and compatibility with existing tools.
2.  [Wan 2.1 I2V](https://v.redd.it/ullrnm31f9se1) (Score: 13)
    *   The thread discusses Wan 2.1 I2V.
3.  [[Dev] Portraits made with FLUX 1](https://www.reddit.com/gallery/1jozsiy) (Score: 9)
    *   Users are sharing and admiring portraits created with FLUX 1, inquiring about the Loras and guidance used.
4.  [WAN 2.1 RTX 5090](https://www.reddit.com/r/StableDiffusion/comments/1jp1z3k/wan_21_rtx_5090/) (Score: 3)
    *   Discussion about using WAN 2.1 with an RTX 5090, with one user humorously noting the guide focuses on affording the card.
5.  [I've reverse-engineered OpenAI's ChatGPT 4o image generation algorithm. Get the source code here!](https://github.com/envy-ai/4o_image_gen/tree/master) (Score: 2)
    *   A user humorously claims to have reverse-engineered OpenAI's ChatGPT 4o image generation algorithm and shares a GitHub link, with others recognizing it as an April Fool's joke.
6.  [Is it possible to adapt an existing t2i model to generate structures in Minecraft?](https://www.reddit.com/r/StableDiffusion/comments/1jp0sq6/is_it_possible_to_adapt_an_existing_t2i_model_to/) (Score: 2)
    *   The thread explores the possibility of adapting an existing text-to-image model for generating structures in Minecraft, with explanations about the limitations of diffusion models for this purpose.
7.  [Has anyone tried changing the Hunyuan LLM prompt?](https://www.reddit.com/r/StableDiffusion/comments/1jp2qty/has_anyone_tried_changing_the_hunyuan_llm_prompt/) (Score: 1)
    *   Users discuss and share experiences with modifying the Hunyuan LLM prompt to improve image generation results.
8.  [MVadapter and Micmumpitz workflow](https://www.reddit.com/r/StableDiffusion/comments/1jp2t38/mvadapter_and_micmumpitz_workflow/) (Score: 1)
    *   A user shares an obligatory workflow involving MVadapter and Micmumpitz.
9.  [Best deepfake video models](https://www.reddit.com/r/StableDiffusion/comments/1jozplx/best_deepfake_video_models/) (Score: 0)
    *   Users are seeking recommendations for the best deepfake video models, with others providing links to tools and discussing workflows.
10. [5080 or 5070](https://www.reddit.com/r/StableDiffusion/comments/1jozwep/5080_or_5070/) (Score: 0)
    *   The thread discusses whether to buy a 5080 or 5070 GPU for Stable Diffusion.
11. [Comfy UI on Linux. Any Drawbacks?](https://www.reddit.com/r/StableDiffusion/comments/1jp27nb/comfy_ui_on_linux_any_drawbacks/) (Score: 0)
    *   Users are discussing the pros and cons of using ComfyUI on Linux compared to Windows, focusing on dependency management, memory usage, and convenience.

# Detailed Analysis by Thread
**[[D] VACE Code and Models Now on GitHub (Partial Release) (Score: 37)](https://www.reddit.com/r/StableDiffusion/comments/1jp1ioe/vace_code_and_models_now_on_github_partial_release/)**
*  **Summary:** The thread is about the release of VACE (presumably a video or animation related tool) code and models on GitHub. Users are expressing interest, asking about its capabilities, and comparing it to other closed-source alternatives.
*  **Emotion:** Predominantly positive, with users expressing excitement and gratitude for the open-source release. Neutral sentiments are also present as users ask clarifying questions.
*  **Top 3 Points of View:**
    *   Excitement about the potential of open-source video generation leveling up.
    *   Inquiry regarding compatibility with WAN Loras.
    *   Gratitude for the open-source release in comparison to recent closed-source alternatives.

**[Wan 2.1 I2V (Score: 13)](https://v.redd.it/ullrnm31f9se1)**
*  **Summary:** This thread appears to be about a video or animation created with Wan 2.1 I2V. A comment suggests the content features a "hot genAI lady".
*  **Emotion:** The thread has a neutral emotional tone.
*  **Top 3 Points of View:**
    *   The user commented on the nature of the content, referencing a "hot genAI lady" and cake.

**[[Dev] Portraits made with FLUX 1 (Score: 9)](https://www.reddit.com/gallery/1jozsiy)**
*  **Summary:** Users share and discuss portraits created with FLUX 1.
*  **Emotion:** Predominantly positive. Users praise the beauty of the portraits.
*  **Top 3 Points of View:**
    *   Admiration for the quality and aesthetics of the generated portraits.
    *   Inquiry about the specific Loras used to generate the images.
    *   Request for details on the guidance settings employed.

**[WAN 2.1 RTX 5090 (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1jp1z3k/wan_21_rtx_5090/)**
*  **Summary:** Discussion around using WAN 2.1 with the unreleased RTX 5090.
*  **Emotion:** Mostly neutral with a hint of humor.
*  **Top 3 Points of View:**
    *   The primary point is around using WAN 2.1.
    *   One user jokes that the guide is more about affording a 5090.
    *   Another user confirms that a certain repository works well with the guide.

**[I've reverse-engineered OpenAI's ChatGPT 4o image generation algorithm. Get the source code here! (Score: 2)](https://github.com/envy-ai/4o_image_gen/tree/master)**
*  **Summary:** A user claims to have reverse-engineered OpenAI's ChatGPT 4o image generation algorithm and shares a GitHub link. The comments indicate that this is an April Fool's Day joke.
*  **Emotion:** Neutral, with a sense of humor.
*  **Top 3 Points of View:**
    *   The poster is presenting their action as a serious reverse-engineering effort (satirical).
    *   Commenters recognize it as an April Fool's joke.
    *   Appreciation for the satirical nature of the "reverse-engineered" code, particularly the SYSTEM_PROMPT.

**[Is it possible to adapt an existing t2i model to generate structures in Minecraft? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jp0sq6/is_it_possible_to_adapt_an_existing_t2i_model_to/)**
*  **Summary:** This thread explores the feasibility of using existing text-to-image (t2i) models for generating Minecraft structures.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Diffusion models operate on the latent, image patch level, not the bitmap level required for Minecraft structures.
    *   Diffusion models do not predict discrete values needed for game maps.
    *   Most diffusion models struggle to break away from 2D structures.

**[Has anyone tried changing the Hunyuan LLM prompt? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jp2qty/has_anyone_tried_changing_the_hunyuan_llm_prompt/)**
*  **Summary:** Users are sharing their experiences with modifying the Hunyuan LLM prompt, reporting improvements in image generation.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Changing the LLM prompt can lead to improved image generation results.
    *   A user shares their modified LLM prompt for generating video descriptions.
    *   Mention of the Banodoco discord hub as a place for discussing alternative prompts.

**[MVadapter and Micmumpitz workflow (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jp2t38/mvadapter_and_micmumpitz_workflow/)**
*  **Summary:** A user shares their MVadapter and Micmumpitz workflow.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Sharing of a workflow image.

**[Best deepfake video models (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jozplx/best_deepfake_video_models/)**
*  **Summary:** Users are looking for the best deepfake video models.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Roop unleashed has a lot of good functions.
    *   Creating an SDXL lora and using Wan I2V is a consistent approach.
    *   Stable animator, FaceFusion and ControlNext are other options.

**[5080 or 5070 (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jozwep/5080_or_5070/)**
*  **Summary:** This thread revolves around the choice between a 5080 and a 5070 GPU for stable diffusion tasks.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   A 3090 might be sufficient, with VRAM being more important than the GPU core.
    *   A 5070 Ti could be a good middle ground if the price is reasonable.
    *   A user reports good performance with a 5070 and Wan I2V for SDXL.

**[Comfy UI on Linux. Any Drawbacks? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jp27nb/comfy_ui_on_linux_any_drawbacks/)**
*  **Summary:** Users discuss the advantages and disadvantages of using ComfyUI on Linux compared to Windows.
*  **Emotion:** Neutral, leaning slightly positive towards Linux.
*  **Top 3 Points of View:**
    *   Linux package managers handle dependencies more conveniently.
    *   Windows' memory fallback feature can be useful for ltxv.
    *   Some users strongly prefer Linux over Windows for ComfyUI.
