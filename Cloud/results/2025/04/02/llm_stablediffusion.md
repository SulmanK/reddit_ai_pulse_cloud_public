---
title: "Stable Diffusion Subreddit"
date: "2025-04-02"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [STYLE & MOTION TRANSFER USING WAN 2.1 FUN AND FLUX MODEL](https://v.redd.it/bv3vs18x3fse1) (Score: 21)
    *   Discussion around using WAN 2.1 FUN and Flux models for style and motion transfer, particularly for creating Ghibli-style animations from images and videos.
2.  [flux pro vs google imagen3, did google secretly changed its text encoder?](https://www.reddit.com/gallery/1jpthv7) (Score: 14)
    *   Debate about whether Google's Imagen3 secretly changed its text encoder, potentially enhancing prompts automatically. Speculation on whether it utilizes T5 or autoregressive technology like HART.
3.  [Uncensored models, 2025](https://www.reddit.com/r/StableDiffusion/comments/1jprzdd/uncensored_models_2025/) (Score: 12)
    *   Discussion about available uncensored models for image generation, focusing on alternatives to Dall-E 3, such as Civitai, Flux, and Pony, and the hardware requirements for running them.
4.  [Wan2.1 - I2v - 3d rotation](https://v.redd.it/yg3bad60zgse1) (Score: 7)
    *   A user shares a video related to Wan2.1 and I2V with 3D rotation, but a commenter finds it boring.
5.  [Please halp me with this](https://i.redd.it/6z08hssbkgse1.png) (Score: 4)
    *   A user needs help with a launch problem in Stable Diffusion, possibly related to a missing Python installation.
6.  [Trying to figure out which illustrious is being used](https://i.redd.it/li9jc72xacse1.jpeg) (Score: 3)
    *   The user is seeking help identifying the specific "illustrious" model used in an image.
7.  [As of 2025 April, what are the most flexible cloud service providers for SD worth using?](https://www.reddit.com/r/StableDiffusion/comments/1jpt3z4/as_of_2025_april_what_are_the_most_flexible_cloud/) (Score: 3)
    *   Discussion on the most flexible cloud service providers for Stable Diffusion, with Runpod being recommended.
8.  [Apple M1 ultra issues](https://www.reddit.com/r/StableDiffusion/comments/1jps0dq/apple_m1_ultra_issues/) (Score: 2)
    *   Users are discussing the performance of Stable Diffusion on Apple M1 Ultra machines, mentioning the limited CUDA support and suggesting alternative tools like InvokeAI or DrawThings.
9.  [Open Source is more enjoyable for lobbyists of generative art than OpenAi/Google Products](https://www.reddit.com/r/StableDiffusion/comments/1jpxu27/open_source_is_more_enjoyable_for_lobbyists_of/) (Score: 2)
    *   A user expresses preference for open-source generative art tools like ComfyUI, while acknowledging the accuracy and speed of ChatGPT.
10. [3D motion designer looking to include GenAi in my workflow.](https://www.reddit.com/r/StableDiffusion/comments/1jpn2sv/3d_motion_designer_looking_to_include_genai_in_my/) (Score: 1)
    *   A 3D motion designer seeks advice on incorporating GenAI into their workflow, with suggestions including ComfyUI and glyf.space.
11. [Have been trying to visualize a specific scene from a book and nothing generates anything useful](https://www.reddit.com/r/StableDiffusion/comments/1jprbm4/have_been_trying_to_visualize_a_specific_scene/) (Score: 1)
    *   A user is having trouble generating a specific scene from a book, and receives suggestions to simplify the prompt, use image-to-image techniques, or even draw it manually.
12. [Wan2.1 Fun ControlNet Workflow & Tutorial - *** free (workflow in comments)](https://www.youtube.com/watch?v=krN1dIwJ4kc&ab_channel=HearmemanAI) (Score: 1)
    *   The post provides a free workflow for Wan2.1 Fun ControlNet, addressing concerns about the original Patreon link.
13. [quick question](https://www.reddit.com/r/StableDiffusion/comments/1jpph2w/quick_question/) (Score: 0)
    *   A user asks a question and receives suggestions to use GPT-4o or ComfyUI-ReActor.
14. [Please someone help](https://www.reddit.com/r/StableDiffusion/comments/1jpqq21/please_someone_help/) (Score: 0)
    *   A user seeks help and is advised to try free websites like Tensorart AI or Seart AI, or download Foocus.
15. [My friend created an AI video platform like tiktok and all generations are free (Wan 2.1 1.3b and more)](https://www.reddit.com/r/StableDiffusion/comments/1jptdcz/my_friend_created_an_ai_video_platform_like/) (Score: 0)
    *   A user shares a link to an AI video platform created by a friend, and users provide feedback on the UI and potential.
16. [can comfyUI do what chatgpt does and better?](https://www.reddit.com/r/StableDiffusion/comments/1jpx7ef/can_comfyui_do_what_chatgpt_does_and_better/) (Score: 0)
    *   Discussion comparing the capabilities of ComfyUI and ChatGPT for image generation, focusing on prompt adherence, censorship, and technical differences.

# Detailed Analysis by Thread
**[STYLE & MOTION TRANSFER USING WAN 2.1 FUN AND FLUX MODEL (Score: 21)](https://v.redd.it/bv3vs18x3fse1)**
*   **Summary:** The thread discusses the use of the WAN 2.1 FUN and Flux models for style and motion transfer, specifically to transform images into Ghibli-style animations. The creator provides a workflow link, and users share their experiences and feedback.
*   **Emotion:** The overall emotional tone is mixed. There's excitement and positivity from users who appreciate the workflow and its potential (Positive), but also negativity from those who criticize the quality of the Ghibli transformation and find the results unconvincing (Negative). There's also some Neutral sentiment from users offering neutral feedback.
*   **Top 3 Points of View:**
    *   The workflow is well-organized and offers nice stylization.
    *   The Ghibli transformation is not convincing and the results are poor.
    *   The Wan Vace model is an improvement over Wan Fun for controlnet uses.

**[flux pro vs google imagen3, did google secretly changed its text encoder? (Score: 14)](https://www.reddit.com/gallery/1jpthv7)**
*   **Summary:** This thread discusses whether Google's Imagen3 has secretly changed its text encoder. Participants speculate on the technology behind Imagen3, including the possibility of using T5 or autoregressive methods, and whether Google is enhancing prompts behind the scenes.
*   **Emotion:** The overall emotional tone of the thread is Neutral. Users are mostly providing information and asking questions related to the technology behind Imagen3.
*   **Top 3 Points of View:**
    *   Imagen3 technology is not disclosed, and it's uncertain if it uses T5.
    *   Google might be enhancing prompts with Gemini for better results.
    *   Imagen3 could be autoregressive like HART.

**[Uncensored models, 2025 (Score: 12)](https://www.reddit.com/r/StableDiffusion/comments/1jprzdd/uncensored_models_2025/)**
*   **Summary:** The discussion revolves around the availability and quality of uncensored AI models for image generation in 2025. Users mention alternatives to Dall-E 3, such as Civitai, Flux, and Pony, and discuss the hardware requirements for running these models. Some users offer recommendations for user-friendly interfaces, cautioning against ComfyUI for beginners.
*   **Emotion:** The overall emotional tone is mostly Neutral, with users providing factual information and suggestions. However, there are some Negative comments expressing concerns about the potential misuse of uncensored models and the legal ramifications.
*   **Top 3 Points of View:**
    *   There are many uncensored models available, such as Civitai, Flux, and Pony.
    *   Advanced techniques can allow SDXL to match GPT-4o image generation.
    *   ComfyUI is not beginner-friendly. Forge has a better UI.

**[Wan2.1 - I2v - 3d rotation (Score: 7)](https://v.redd.it/yg3bad60zgse1)**
*   **Summary:** This thread features a video showcasing Wan2.1 and I2V with 3D rotation. A commenter expresses that the video is boring.
*   **Emotion:** The overall emotion of the thread is neutral. The original content poster had no explicit emotion attached, while the commenter had a slightly negative one, deeming the posted material "insanely boring".
*   **Top 3 Points of View:**
    *   Wan2.1 content can be perceived as unexciting.

**[Please halp me with this (Score: 4)](https://i.redd.it/6z08hssbkgse1.png)**
*   **Summary:** A user is seeking help with a launch problem in Stable Diffusion, showing an error message indicating a missing Python installation. Other users offer advice, suggesting checking Python installation, using tools like DeepSeek or ChatGPT for troubleshooting, or switching to webforgeUI.
*   **Emotion:** The emotional tone is mixed. There's positive sentiment from users trying to help and offering solutions, but also some neutral sentiments from users explaining the problem.
*   **Top 3 Points of View:**
    *   The error indicates a missing or incorrectly installed Python.
    *   Using an LLM to analyze the command prompt return can help with troubleshooting.
    *   Switching to webforgeUI may simplify installation and configuration.

**[Trying to figure out which illustrious is being used (Score: 3)](https://i.redd.it/li9jc72xacse1.jpeg)**
*   **Summary:** The user is trying to identify which "illustrious" model is being used. Other users offer suggestions, pointing to specific models on Civitai.
*   **Emotion:** The emotional tone is primarily Neutral, with users offering suggestions and information without strong emotional expression.
*   **Top 3 Points of View:**
    *   The model might be Wai Toon.
    *   The model may be Hassaku XL (Illustrious) or WAI-NSFW-illustrious-SDXL.

**[As of 2025 April, what are the most flexible cloud service providers for SD worth using? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1jpt3z4/as_of_2025_april_what_are_the_most_flexible_cloud/)**
*   **Summary:** Users discuss the most flexible cloud service providers for Stable Diffusion in April 2025. The main recommendation is Runpod, praised for its ease of use and various presets.
*   **Emotion:** The emotional tone is mainly Neutral, with users offering practical recommendations and information.
*   **Top 3 Points of View:**
    *   Runpod is the most popular and easiest cloud service to use.
    *   Users need to bring their own models, LoRAs, and workflows to the cloud.
    *   Cloud providers generally don't restrict specific functionalities like flux or I2V.

**[Apple M1 ultra issues (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jps0dq/apple_m1_ultra_issues/)**
*   **Summary:** The thread discusses issues with running Stable Diffusion on Apple M1 Ultra machines. Users point out the limited CUDA support for Apple's Metal and suggest alternatives like InvokeAI or DrawThings. They also note potential problems with bfloat16 emulation on M1 and recommend specific Torch versions.
*   **Emotion:** The overall emotional tone is Neutral, with users providing technical information and advice.
*   **Top 3 Points of View:**
    *   Stable Diffusion is slow on Macs due to limited CUDA support.
    *   InvokeAI or DrawThings are better alternatives for Mac users.
    *   The M1's bfloat16 emulation can cause issues.

**[Open Source is more enjoyable for lobbyists of generative art than OpenAi/Google Products (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1jpxu27/open_source_is_more_enjoyable_for_lobbyists_of/)**
*   **Summary:** A user expresses their preference for open-source generative art tools like ComfyUI but acknowledges the speed and accuracy of ChatGPT. The user also corrects a typo, clarifying that they meant "hobbyist" instead of "lobbyist."
*   **Emotion:** The emotional tone is Positive, expressing love for ComfyUI, but also contains Neutral sentiment as the user clarifies an error made in the post.
*   **Top 3 Points of View:**
    *   ComfyUI is preferable to walled-garden systems.
    *   ChatGPT is useful for quick and accurate results.

**[3D motion designer looking to include GenAi in my workflow. (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jpn2sv/3d_motion_designer_looking_to_include_genai_in_my/)**
*   **Summary:** A 3D motion designer seeks advice on integrating GenAI into their workflow. Recommendations include getting familiar with ComfyUI for image and video generation, and using glyf.space for pre-visualization work.
*   **Emotion:** The overall emotional tone is Neutral, with users offering helpful advice and resources.
*   **Top 3 Points of View:**
    *   ComfyUI is a good tool to learn for GenAI integration.
    *   glyf.space is useful for pre-viz work using 3D animation and style references.
    *   Hardware with a decent GPU is required.

**[Have been trying to visualize a specific scene from a book and nothing generates anything useful (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jprbm4/have_been_trying_to_visualize_a_specific_scene/)**
*   **Summary:** A user is struggling to visualize a scene from a book using AI image generation. Suggestions include simplifying the prompt, using image-to-image techniques with a doodle, and sharing the prompts used for troubleshooting.
*   **Emotion:** The overall emotional tone is Neutral, with users offering advice and constructive criticism. Some positive elements, as users attempt to assist the original poster.
*   **Top 3 Points of View:**
    *   The description might be too complex for AI to interpret effectively.
    *   Simplifying the prompt or using image-to-image with a doodle can help.
    *   Sharing the prompts used is crucial for troubleshooting.

**[Wan2.1 Fun ControlNet Workflow & Tutorial - *** free (workflow in comments) (Score: 1)](https://www.youtube.com/watch?v=krN1dIwJ4kc&ab_channel=HearmemanAI)**
*   **Summary:** The post provides a free workflow for Wan2.1 Fun ControlNet, addressing concerns about the original link pointing to a Patreon page. A Google Drive link to the workflow is provided.
*   **Emotion:** The emotional tone is positive, as the author attempts to meet the needs of the community by providing the requested link.
*   **Top 3 Points of View:**
    *   The author is providing a free workflow to the community.

**[quick question (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jpph2w/quick_question/)**
*   **Summary:** A user asks a quick question and receives two very brief recommendations in response.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Using GPT-4o with an initial image is an option.
    *   ComfyUI-ReActor can be used.

**[Please someone help (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jpqq21/please_someone_help/)**
*   **Summary:** A user asks for help, and suggestions involve using free websites like tensorart ai or seart ai, or downloading Foocus.
*   **Emotion:** The emotional tone is Neutral
*   **Top 3 Points of View:**
    *   Try free websites like tensorart ai or seart ai first.
    *   Download Foocus from GitHub.

**[My friend created an AI video platform like tiktok and all generations are free (Wan 2.1 1.3b and more) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jptdcz/my_friend_created_an_ai_video_platform_like/)**
*   **Summary:** A user shares a link to an AI video platform created by their friend, and users provide feedback on the UI and potential.
*   **Emotion:** The overall emotional tone is mixed, with generally Positive remarks.
*   **Top 3 Points of View:**
    *   The UI needs improvement and should look more modern.
    *   The platform has enormous potential.
    *   Keeping a free version will attract more users.

**[can comfyUI do what chatgpt does and better? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jpx7ef/can_comfyui_do_what_chatgpt_does_and_better/)**
*   **Summary:** This thread explores whether ComfyUI can match or surpass ChatGPT's capabilities in image generation. The consensus is that while ComfyUI offers extensive tools and flexibility, ChatGPT excels in prompt adherence, though is censored.
*   **Emotion:** The overall emotional tone is mixed, consisting of Neutral, Positive, and Negative sentiment.
*   **Top 3 Points of View:**
    *   ChatGPT is better at prompt adherence, but ComfyUI has a larger ecosystem of tools.
    *   ChatGPT is censored.
    *   ChatGPT is using a multimodal LLM.
