---
title: "Stable Diffusion Subreddit"
date: "2025-04-14"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[HiDream-I1] The Llama encoder is doing all the lifting for HiDream-I1](https://www.reddit.com/r/StableDiffusion/comments/1jz6s6c/hidreami1_the_llama_encoder_is_doing_all_the/) (Score: 21)
    *   Discussion about the HiDream-I1 model, specifically the role of the Llama encoder compared to Clip and T5.
2.  [Wan 2.1 1.3b text to video](https://v.redd.it/41f54pdoguue1) (Score: 18)
    *   People were discussing the Wan 2.1 1.3b text-to-video model and requesting prompts and styles used with it.
3.  [EasyControl training code released](https://www.reddit.com/r/StableDiffusion/comments/1jz4g5m/easycontrol_training_code_released/) (Score: 15)
    *   Discussion about the release of EasyControl training code, its hardware requirements, and the lack of ComfyUI implementation.
4.  [What am i doing wrong? (ComfyUi Flux)](https://i.redd.it/ssilrlcynuue1.png) (Score: 4)
    *   Users are giving advice on using ComfyUI Flux.
5.  ["Outrun" A retro anime short film](https://youtu.be/iAxhkJ24krI) (Score: 4)
    *   Discussion about a retro anime short film generated using AI, with mixed reactions.
6.  [In your own experience when training LORAs, what is a good percentage of close up/portrait photos versus full body photos that gives you the best quality? 80%/20%? 60%/40%? 90%/10%?](https://www.reddit.com/r/StableDiffusion/comments/1jz29dk/in_your_own_experience_when_training_loras_what/) (Score: 1)
    *   Users discuss ideal ratios of close-up/portrait photos versus full body photos when training LORAs.
7.  [Just cannot get my lora's to integrate into prompts](https://www.reddit.com/r/StableDiffusion/comments/1jz40n2/just_cannot_get_my_loras_to_integrate_into_prompts/) (Score: 1)
    *   Users are offering advice and troubleshooting Lora integration issues, focusing on training data, tagging, and Lora strength.
8.  [Video Length vs VRAM question…](https://www.reddit.com/r/StableDiffusion/comments/1jz2qbp/video_length_vs_vram_question/) (Score: 0)
    *   The discussion revolves around the relationship between video length and VRAM usage in AI video generation, addressing misconceptions and current limitations.
9.  [Provide a feedback on my AI Generated Short Film](https://www.reddit.com/r/StableDiffusion/comments/1jz30kh/provide_a_feedback_on_my_ai_generated_short_film/) (Score: 0)
    *   Users are discussing the quality of an AI generated film
10. [Want to create consistent and proper 2D game asset via SD based on reference images](https://www.reddit.com/r/StableDiffusion/comments/1jz5cgb/want_to_create_consistent_and_proper_2d_game/) (Score: 0)
    *   A user asks for guidance on creating 2D game assets with Stable Diffusion, and is pointed to ComfyUI examples.
11. [Looking for photos of simple gestures and modeling figures to use for generating images.](https://www.reddit.com/r/StableDiffusion/comments/1jz5fmf/looking_for_photos_of_simple_gestures_and/) (Score: 0)
    *   Users are giving advice on where to find artist reference photos and suggesting taking the photos.
12. [How do I create these kind of thumbnail image?](https://www.reddit.com/r/StableDiffusion/comments/1jz6i2m/how_do_i_create_these_kind_of_thumbnail_image/) (Score: 0)
    *   Discussion on creating thumbnail images, with suggestions on using Flux dev and different software platforms.

# Detailed Analysis by Thread
**[[HiDream-I1] The Llama encoder is doing all the lifting for HiDream-I1 (Score: 21)](https://www.reddit.com/r/StableDiffusion/comments/1jz6s6c/hidreami1_the_llama_encoder_is_doing_all_the/)**
*  **Summary:** The thread discusses the HiDream-I1 model, with the consensus that the Llama encoder is the primary driver, while Clip and T5 contribute minimally, possibly even hindering performance.
*  **Emotion:** The emotional tone is mostly neutral with a hint of positive sentiment, likely due to the excitement surrounding the model's performance.
*  **Top 3 Points of View:**
    *   The Llama encoder is the most important part of the HiDream-I1 model.
    *   Clip-L is useless, and should be turned off.
    *   T5 and OpenClip contribute primarily to style.

**[Wan 2.1 1.3b text to video (Score: 18)](https://v.redd.it/41f54pdoguue1)**
*  **Summary:** This thread is centered around a user showcasing the Wan 2.1 1.3b text-to-video model. Other users are requesting prompts and styles used with the model.
*  **Emotion:** The overall emotional tone is positive, with users expressing excitement and appreciation.
*  **Top 3 Points of View:**
    *   The model is impressive and generates nice results.
    *   Interest in replicating the results.
    *   Noteworthy model.

**[EasyControl training code released (Score: 15)](https://www.reddit.com/r/StableDiffusion/comments/1jz4g5m/easycontrol_training_code_released/)**
*  **Summary:** This thread discusses the release of the EasyControl training code. Users express interest but also note the high hardware requirements and the lack of a ComfyUI implementation.
*  **Emotion:** The emotional tone is mixed, with neutral and slightly negative sentiments due to the hardware requirements and lack of implementation.
*  **Top 3 Points of View:**
    *   The hardware requirements (expensive GPUs) make it inaccessible to many users.
    *   The lack of a ComfyUI implementation is a drawback.
    *   Users are curious about what EasyControl is.

**[What am i doing wrong? (ComfyUi Flux) (Score: 4)](https://i.redd.it/ssilrlcynuue1.png)**
*  **Summary:** A user is seeking help with ComfyUI Flux. Other users are offering advice on sampler settings, prompt engineering, and Lora usage.
*  **Emotion:** The emotional tone is neutral, with users trying to assist with technical issues.
*  **Top 3 Points of View:**
    *   Use 4 steps for Schnell.
    *   Write natural language prompts.
    *   Don't use Dev lora with Schnell.

**["Outrun" A retro anime short film (Score: 4)](https://youtu.be/iAxhkJ24krI)**
*  **Summary:** This thread features feedback on an AI-generated retro anime short film. The responses are mixed, with some finding it both great and hilariously bad.
*  **Emotion:** The overall emotional tone is mixed, with elements of both positive (amusement, appreciation) and negative (criticism) sentiments.
*  **Top 3 Points of View:**
    *   The short film is both great and hilariously bad.
    *   The short film is a waste of resources.

**[In your own experience when training LORAs, what is a good percentage of close up/portrait photos versus full body photos that gives you the best quality? 80%/20%? 60%/40%? 90%/10%? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jz29dk/in_your_own_experience_when_training_loras_what/)**
*  **Summary:** The thread discusses the optimal ratio of close-up/portrait photos versus full-body photos for training LORAs to achieve the best quality.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The ideal ratio depends on the detail in the character design and style.
    *   70% close up and 30% full body works well.

**[Just cannot get my lora's to integrate into prompts (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1jz40n2/just_cannot_get_my_loras_to_integrate_into_prompts/)**
*  **Summary:** A user is having trouble integrating LORAs into prompts. Other users are providing possible solutions, such as adjusting Lora strength, refining tagging practices, and ensuring consistent models.
*  **Emotion:** The emotional tone is neutral, with users seeking and offering technical assistance.
*  **Top 3 Points of View:**
    *   Reduce Lora strength.
    *   Use your name instead of 'a man'.
    *   Make sure you are using the same model as base for lora as you are for generating images.

**[Video Length vs VRAM question… (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jz2qbp/video_length_vs_vram_question/)**
*  **Summary:** This thread addresses the relationship between video length and VRAM in AI video generation, correcting common misconceptions.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   AI video generates all frames at the same time, not sequentially.
    *   Context consistency requires generating all frames together.
    *   Newer technologies such as VACE can write a video that inherits the dynamic trend from a previous video.

**[Provide a feedback on my AI Generated Short Film (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jz30kh/provide_a_feedback_on_my_ai_generated_short_film/)**
*  **Summary:** A user asks for feedback on their AI generated short film.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The user found the video to be a ***.

**[Want to create consistent and proper 2D game asset via SD based on reference images (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jz5cgb/want_to_create_consistent_and_proper_2d_game/)**
*  **Summary:** The user is looking for a tutorial on how to create 2D game assets based on reference images. Other users point them to ComfyUI resources.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   User needs a tutorial on generating 2D game assets.
    *   The user was pointed to ComfyUI examples.

**[Looking for photos of simple gestures and modeling figures to use for generating images. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jz5fmf/looking_for_photos_of_simple_gestures_and/)**
*  **Summary:** A user is looking for photos of simple gestures and modeling figures for image generation. Other users provide suggestions, including artist reference websites and taking the pictures themselves.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Look for artist reference websites.
    *   Use Google to search.
    *   Just take the pictures.

**[How do I create these kind of thumbnail image? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1jz6i2m/how_do_i_create_these_kind_of_thumbnail_image/)**
*  **Summary:** A user asks how to create thumbnail images. Other users offer suggestions such as using Flux dev with enough VRAM or GGUF variants and recommend various software platforms.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Flux dev requires a lot of VRAM.
    *   Use Flux dev on Civitai.
    *   ComfyUI and ForgeUI are good platforms for image generation.
