---
title: "Stable Diffusion Subreddit"
date: "2025-10-29"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Music Video using Qwen and Kontext for consistency](https://v.redd.it/jx6as3k5w1yf1) (Score: 98)
    *  The thread discusses a music video created using Qwen and Kontext for consistency in AI-generated content.
2.  [Has anyone tested Lightvae yet?](https://i.redd.it/cryrdio8k3yf1.png) (Score: 10)
    *  This thread asks for community experiences with Lightvae, a new VAE (Variational Autoencoder) model, focusing on speed and quality trade-offs.
3.  [How do people use WAN for image generation?](https://www.reddit.com/r/StableDiffusion/comments/1oj8ubq/how_do_people_use_wan_for_image_generation/) (Score: 8)
    *  Users are exchanging tips and resources for using WAN (Weight Agnostic Neural Networks) in image generation workflows, including model recommendations and links to helpful guides.
4.  [Your Hunyuan 3D 2.1 preferred workflow, settings, techniques?](https://www.reddit.com/r/StableDiffusion/comments/1ojcfti/your_hunyuan_3d_21_preferred_workflow_settings/) (Score: 5)
    *  The thread asks for preferred workflows, settings, and techniques for Hunyuan 3D 2.1.
5.  [Labubu Generator: Open the Door to Mischief, Monsters, and Your Imagination (Qwen Image LoRA, Civitai Release, Training Details Included)](https://www.reddit.com/gallery/1oj3lgt) (Score: 5)
    *  This thread discusses the Labubu Generator, a Qwen Image LoRA (Low-Rank Adaptation) that is used to create mischief, monsters, and your imagination.
6.  [Which WAN 2.2 I2V variant/checkpoint is the fastest on a 3090 while still looking decent](https://www.reddit.com/r/StableDiffusion/comments/1oj5lxg/which_wan_22_i2v_variantcheckpoint_is_the_fastest/) (Score: 4)
    *  The thread asks which WAN 2.2 I2V variant or checkpoint is the fastest on a 3090 while still looking decent.
7.  [NVIDIA DGX Spark - any thoughts?](https://www.reddit.com/r/StableDiffusion/comments/1ojcga4/nvidia_dgx_spark_any_thoughts/) (Score: 3)
    *  The thread is about NVIDIA DGX Spark and its performance in stable diffusion.
8.  [Wan2.2 low quality when not using Lightning LoRAs](https://www.reddit.com/r/StableDiffusion/comments/1oj1q9b/wan22_low_quality_when_not_using_lightning_loras/) (Score: 3)
    *  This thread discusses the low quality of Wan2.2 when not using Lightning LoRAs.
9.  [Would there be interest in another ComfyUI Wrapper Webui?](https://www.reddit.com/gallery/1ojdkey) (Score: 3)
    *  The thread is about whether there would be any interest in another ComfyUI Wrapper Webui.
10. [How to prevent original clothes on anime characters?](https://www.reddit.com/r/StableDiffusion/comments/1oj4zp9/how_to_prevent_original_clothes_on_anime/) (Score: 2)
    *  The thread seeks advice on preventing original clothes on anime characters in Stable Diffusion.
11. [Can someone explain 'inpainting models' to me?](https://www.reddit.com/r/StableDiffusion/comments/1oj28gj/can_someone_explain_inpainting_models_to_me/) (Score: 2)
    *  The thread asks for explanation about "inpainting models".
12. [anyone. please help me. please my lord im using realcartoon pny and keep noisy.](https://i.redd.it/jog9gj4hi3yf1.png) (Score: 1)
    *  The thread asks for help on fixing the noisy image when using realcartoon pny model.
13. [Perplexity is Giving Students ChatGPT o1 Pro, Claude Sonnet 4.5, & All Premium AI Models FREE up to one year](https://www.reddit.com/r/StableDiffusion/comments/1oj4qei/perplexity_is_giving_students_chatgpt_o1_pro/) (Score: 0)
    *  The thread shares that Perplexity is giving students free access to ChatGPT o1 Pro, Claude Sonnet 4.5, and other premium AI models for up to one year.
14. [hi just here to ask how do stable diffusion models work compared to chatgpt and Gemini?](https://www.reddit.com/r/StableDiffusion/comments/1oj3e70/hi_just_here_to_ask_how_do_stable_diffusion/) (Score: 0)
    *  This thread is a question on how stable diffusion models work compared to ChatGPT and Gemini.
15. [Using AI for quick headshots instead of full SD workflows?](https://www.reddit.com/r/StableDiffusion/comments/1oj65cw/using_ai_for_quick_headshots_instead_of_full_sd/) (Score: 0)
    *  The thread explores the use of AI for generating quick headshots as an alternative to full Stable Diffusion workflows.
16. [Looking for a model/service to create an image with multiple references.](https://www.reddit.com/r/StableDiffusion/comments/1oj8xwb/looking_for_a_modelservice_to_create_an_image/) (Score: 0)
    *  The thread asks for recommendations for a model or service to create an image with multiple references.
17. [Wan causing loud GPU fan revving](https://www.reddit.com/r/StableDiffusion/comments/1oj9ena/wan_causing_loud_gpu_fan_revving/) (Score: 0)
    *  The thread discusses the issue of WAN causing loud GPU fan revving.
18. [How to actually use WAN locally?](https://www.reddit.com/r/StableDiffusion/comments/1ojbz1g/how_to_actually_use_wan_locally/) (Score: 0)
    *  The thread asks how to actually use WAN locally.

# Detailed Analysis by Thread
**[Music Video using Qwen and Kontext for consistency (Score: 98)](https://v.redd.it/jx6as3k5w1yf1)**
*  **Summary:** The thread discusses a music video created using Qwen and Kontext for consistency. Users share their opinions on the quality, consistency, and potential future of AI-generated content.
*  **Emotion:** Predominantly Positive. The overall emotional tone is enthusiastic and appreciative, with several comments expressing amazement and praise for the work. Some comments are neutral, focusing on technical aspects or offering constructive criticism.
*  **Top 3 Points of View:**
    *   The video is impressive and shows the potential of AI in creative fields.
    *   Current AI still struggles with realistic skin texture, resulting in a "plastic" look.
    *   AI is nearing the point where it will be impossible to distinguish from real scenes.

**[Has anyone tested Lightvae yet? (Score: 10)](https://i.redd.it/cryrdio8k3yf1.png)**
*  **Summary:** This thread asks for community experiences with Lightvae, a new VAE (Variational Autoencoder) model, focusing on speed and quality trade-offs. Users discuss its implementation in ComfyUI and compare it with other VAEs for SDXL models.
*  **Emotion:** Predominantly Neutral. The overall emotional tone is inquisitive and technical, focusing on the practical aspects and potential benefits of Lightvae. Some comments express interest and anticipation.
*  **Top 3 Points of View:**
    *   Lightvae offers faster performance but at the cost of some quality.
    *   Lightvae can be easily implemented in ComfyUI using the provided Huggingface implementation.
    *   Users are looking for recommendations for other VAEs to use with SDXL models.

**[How do people use WAN for image generation? (Score: 8)](https://www.reddit.com/r/StableDiffusion/comments/1oj8ubq/how_do_people_use_wan_for_image_generation/)**
*  **Summary:** Users are exchanging tips and resources for using WAN (Weight Agnostic Neural Networks) in image generation workflows, including model recommendations and links to helpful guides.
*  **Emotion:** Positive overall, with a mix of helpfulness and shared enthusiasm for the technology.
*  **Top 3 Points of View:**
    *   WAN 2.2 low noise is a great refiner model when used with Flux or SDXL.
    *   Using frames set to 1 is important.
    *   Several guides and resources (YouTube videos, Reddit posts) are available for those seeking help with WAN.

**[Your Hunyuan 3D 2.1 preferred workflow, settings, techniques? (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1ojcfti/your_hunyuan_3d_21_preferred_workflow_settings/)**
*  **Summary:** The thread asks for preferred workflows, settings, and techniques for Hunyuan 3D 2.1.
*  **Emotion:** Neutral. The emotional tone is factual.
*  **Top 3 Points of View:**
    *   Local 3D generation is not as good as cloud-based services for video game artists.
    *   Hitem 3D is a paid option for 3D generation.
    *   Hunyuan offers a cloud-based option for 3D generation.

**[Labubu Generator: Open the Door to Mischief, Monsters, and Your Imagination (Qwen Image LoRA, Civitai Release, Training Details Included) (Score: 5)](https://www.reddit.com/gallery/1oj3lgt)**
*  **Summary:** This thread discusses the Labubu Generator, a Qwen Image LoRA (Low-Rank Adaptation) that is used to create mischief, monsters, and your imagination.
*  **Emotion:** Mostly Positive. The comments are enthusiastic, with users expressing satisfaction with the LoRA's performance.
*  **Top 3 Points of View:**
    *   LoRA model is working well.
    *   LoRA model can do 1labubu instead of 1girl.

**[Which WAN 2.2 I2V variant/checkpoint is the fastest on a 3090 while still looking decent (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1oj5lxg/which_wan_22_i2v_variantcheckpoint_is_the_fastest/)**
*  **Summary:** The thread asks which WAN 2.2 I2V variant or checkpoint is the fastest on a 3090 while still looking decent.
*  **Emotion:** Neutral overall, with users sharing technical information and recommendations.
*  **Top 3 Points of View:**
    *   fp8 scaled versions with lightning LoRAs can be used for better results.
    *   There is no consensus on which approach is the best regarding the lightning loras.
    *   SageAttention is recommended for extra speed.

**[NVIDIA DGX Spark - any thoughts? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1ojcga4/nvidia_dgx_spark_any_thoughts/)**
*  **Summary:** The thread is about NVIDIA DGX Spark and its performance in stable diffusion.
*  **Emotion:** Neutral overall, with a focus on technical specifications and performance comparisons.
*  **Top 3 Points of View:**
    *   DGX Spark has roughly the compute performance of a 5070 but is more expensive than a 5090.
    *   RTX 5090 is around 3 times faster than DGX Spark for image and video generation.
    *   DGX Spark has similar speeds as RTX 3090 for image and video generation.

**[Wan2.2 low quality when not using Lightning LoRAs (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1oj1q9b/wan22_low_quality_when_not_using_lightning_loras/)**
*  **Summary:** This thread discusses the low quality of Wan2.2 when not using Lightning LoRAs.
*  **Emotion:** Mostly Neutral, with some negative sentiment about the difficulty in achieving high quality without specific configurations.
*  **Top 3 Points of View:**
    *   FP16 or Q8 models are better than the fp8-scaled model type.
    *   Turning up the CFG can help when disconnecting the speed loras.
    *   Speed loras can speed things up.

**[Would there be interest in another ComfyUI Wrapper Webui? (Score: 3)](https://www.reddit.com/gallery/1ojdkey)**
*  **Summary:** The thread is about whether there would be any interest in another ComfyUI Wrapper Webui.
*  **Emotion:** The sentiment is generally positive and constructive, with a focus on collaboration and community benefit.
*  **Top 3 Points of View:**
    *   A new ComfyUI wrapper webui should only be created if it is unique.
    *   Better to contribute to existing UIs such as Swarm.
    *   Opening a GitHub repo and sharing the existing work is a good idea to gauge interest.

**[How to prevent original clothes on anime characters? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1oj4zp9/how_to_prevent_original_clothes_on_anime/)**
*  **Summary:** The thread seeks advice on preventing original clothes on anime characters in Stable Diffusion.
*  **Emotion:** The sentiment is generally neutral.
*  **Top 3 Points of View:**
    *   Inpainting is an easier method.
    *   Use *** or completely *** as tags, then add the actual clothes.
    *   Find a lora with separate tags for character and clothes.

**[Can someone explain 'inpainting models' to me? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1oj28gj/can_someone_explain_inpainting_models_to_me/)**
*  **Summary:** The thread asks for explanation about "inpainting models".
*  **Emotion:** The overall emotional tone is neutral, focusing on providing explanations and technical details.
*  **Top 3 Points of View:**
    *   Inpainting with an inpaintable model is similar to painting with a normal model.
    *   Special models or optional Controlnets let inpainting operations to be more focused.
    *   You can try combining img2img with 2008-era inpainting (like Gimp Resynthesizer).

**[anyone. please help me. please my lord im using realcartoon pny and keep noisy. (Score: 1)](https://i.redd.it/jog9gj4hi3yf1.png)**
*   **Summary:** The thread asks for help on fixing the noisy image when using realcartoon pny model.
*   **Emotion:** Mostly Neutral, with a sense of urgency and desperation in the original post, contrasted with helpful and technical advice from other users.
*   **Top 3 Points of View:**
    *   The issue might be due to LCM LoRA weights.
    *   The issue might be because the width and height needs to be multiples of 256.
    *   The issue might be due to VAE or sampling method with low steps (10ish or so) and very low CFG (1-2).

**[Perplexity is Giving Students ChatGPT o1 Pro, Claude Sonnet 4.5, & All Premium AI Models FREE up to one year (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oj4qei/perplexity_is_giving_students_chatgpt_o1_pro/)**
*   **Summary:** The thread shares that Perplexity is giving students free access to ChatGPT o1 Pro, Claude Sonnet 4.5, and other premium AI models for up to one year.
*   **Emotion:** The overall emotional tone is largely negative, driven by reports that the offer doesn't work, and suggestions it might be spam or a tactic to hook users.
*   **Top 3 Points of View:**
    *   The offer doesn't work.
    *   The post is spam.
    *   Perplexity is doing this to get you hooked so that you will spend money on them next year.

**[hi just here to ask how do stable diffusion models work compared to chatgpt and Gemini? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oj3e70/hi_just_here_to_ask_how_do_stable_diffusion/)**
*   **Summary:** This thread is a question on how stable diffusion models work compared to ChatGPT and Gemini.
*   **Emotion:** Neutral, leaning towards informative.
*   **Top 3 Points of View:**
    *   ChatGPT and Gemini are LLMs connected to their proprietary Diffusion Models.
    *   Chatgpt /gemini is typically for people with absolutely no skills in ai. Stable diffusion gives you control over everything.
    *   There are too many things to compare.

**[Using AI for quick headshots instead of full SD workflows? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oj65cw/using_ai_for_quick_headshots_instead_of_full_sd/)**
*   **Summary:** The thread explores the use of AI for generating quick headshots as an alternative to full Stable Diffusion workflows.
*   **Emotion:** Mostly neutral, with some positive sentiment towards the convenience of quick AI tools and the creative freedom of ComfyUI.
*   **Top 3 Points of View:**
    *   ComfyUI is for power users who like to tinker and fine tune.
    *   Quick tools are for those who don't have the time and just want something quick without the headache like Chat GPT.
    *   The pricing for quick headshot services can be considered expensive.

**[Looking for a model/service to create an image with multiple references. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oj8xwb/looking_for_a_modelservice_to_create_an_image/)**
*   **Summary:** The thread asks for recommendations for a model or service to create an image with multiple references.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Google Gemini, ChatGPT or Copilot can be used.
    *   Civitai can be used by paying for the models.

**[Wan causing loud GPU fan revving (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oj9ena/wan_causing_loud_gpu_fan_revving/)**
*   **Summary:** The thread discusses the issue of WAN causing loud GPU fan revving.
*   **Emotion:** The emotional tone is generally negative.
*   **Top 3 Points of View:**
    *   All the heat comes from the gpu and its vram, so undervolt + underclock + underclock vram.
    *   WAN runs the chip significantly hotter than most benchmarking software.
    *   ASUS can't control the load you put on the thing.

**[How to actually use WAN locally? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ojbz1g/how_to_actually_use_wan_locally/)**
*   **Summary:** The thread asks how to actually use WAN locally.
*   **Emotion:** The emotional tone varies from neutral and helpful to slightly frustrated, reflecting the complexities of using WAN locally.
*   **Top 3 Points of View:**
    *   ComfyUI comes with built in workflows for all ages and generations.
    *   Bruh, use your scrollwheel to zoom in and then give it your image and write the prompt (you will figure out where, it's easy).
    *   A workflow is a way to connect different nodes, and these nodes can contain AI models.

