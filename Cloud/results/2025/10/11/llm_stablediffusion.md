---
title: "Stable Diffusion Subreddit"
date: "2025-10-11"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Tested the new OVI model](https://v.redd.it/04kvqv7hlhuf1) (Score: 52)
    *   Users are testing and discussing the new OVI model, sharing experiences, and comparing it to existing tools like Wan S2V.
2.  [Qwen Edit Skintone Recovery for Photography](https://v.redd.it/875ye8xymhuf1) (Score: 10)
    *   A user shared an image and others requested the prompt used to generate it.
3.  [Wan2.2 I2V - 2 vs 3 Ksamplers - questions on steps & samplers](https://www.reddit.com/r/StableDiffusion/comments/1o3w5r0/wan22_i2v_2_vs_3_ksamplers_questions_on_steps/) (Score: 10)
    *   Users are discussing the optimal settings and techniques for using Wan2.2 I2V, specifically comparing the performance of 2 vs 3 Ksamplers and the impact of different step counts and samplers.
4.  [Average Comfyui workflow](https://i.redd.it/h15zrpvkmhuf1.png) (Score: 7)
    *   Users express a desire for a more user-friendly all-in-one UI, similar to A1111, that simplifies the node-based workflow of ComfyUI.
5.  [I have updated the ComfyUI with Flux1.dev oneclick template on Runpod (CUDA 12.8, Wan2.2, InfiniteTalk, Qwen-image-edit-2509 and VibeVoice). Also the new AI Toolkit UI is now started automatically!](https://v.redd.it/wo0vkqsdthuf1) (Score: 5)
    *   A user shared an update on their ComfyUI setup, and another user questioned the compatibility of InfiniteTalk with Wan2.2.
6.  [Did someone notice Wan2.2 txt2img performance drop with RES4LYF samplers after recent Nvidia driver update 581.42](https://www.reddit.com/r/StableDiffusion/comments/1o41de3/did_someone_notice_wan22_txt2img_performance_drop/) (Score: 5)
    *   Users are discussing a potential performance drop in Wan2.2 txt2img after updating Nvidia drivers, troubleshooting the issue and comparing driver versions.
7.  [Most flexible FLUX checkpoint right now?](https://www.reddit.com/r/StableDiffusion/comments/1o3wn2x/most_flexible_flux_checkpoint_right_now/) (Score: 4)
    *   Users are seeking recommendations for the most flexible FLUX checkpoint, with discussions around different checkpoints and their strengths, such as NSFW content generation or LoRA compatibility.
8.  [Is there any “Pause” switch nodes?](https://www.reddit.com/r/StableDiffusion/comments/1o42et6/is_there_any_pause_switch_nodes/) (Score: 3)
    *   Users are looking for "pause" or switch nodes in ComfyUI to control workflow execution, with suggestions for different custom nodes and tools.
9.  [The datasets of the most established open source models](https://www.reddit.com/r/StableDiffusion/comments/1o44sl3/the_datasets_of_the_most_established_open_source/) (Score: 3)
    *   Users are discussing datasets of open source models like FLUX, Qwen, and Chroma, focusing on the depth and quality of training data.
10. [Turned my dog in a pumpkin costume](https://i.redd.it/fj1le9nudiuf1.jpeg) (Score: 2)
    *   A user shared an image of their dog in a pumpkin costume, leading to positive reactions and requests for the prompt used.
11. [What should I do with 20 unused GPUs (RTX 3060 Ti + one 3090 Ti)?](https://i.redd.it/i7efkcp6gjuf1.jpeg) (Score: 2)
    *   A user is seeking advice on what to do with a large number of unused GPUs, with suggestions ranging from selling/renting them out to using them for personal projects like GPU clusters or 3D modeling.
12. [Correct method for object inpainting in Vace 2.2?](https://www.reddit.com/r/StableDiffusion/comments/1o3v3yz/correct_method_for_object_inpainting_in_vace_22/) (Score: 2)
    *   A user is asking about the correct method for object inpainting in Vace 2.2, and another user provides a link to a potentially helpful workflow.
13. [Help MAC user question- cant seem to upgrade Comfyui above 0.3.27 mgr 3.37 front end 1.29](https://www.reddit.com/r/StableDiffusion/comments/1o3ytkd/help_mac_user_question_cant_seem_to_upgrade/) (Score: 2)
    *   A user is asking for help upgrading ComfyUI on a Mac, and another user suggests checking for an update folder and using the update script.
14. [which edit model can do this successfully](https://www.reddit.com/r/StableDiffusion/comments/1o40j3q/which_edit_model_can_do_this_successfully/) (Score: 2)
    *   A user is asking about which edit model can perform a specific task, and another user suggests trying to rotate the image first.
15. [What’s the best up-to-date method for outfit swapping](https://www.reddit.com/r/StableDiffusion/comments/1o3vjqi/whats_the_best_uptodate_method_for_outfit_swapping/) (Score: 1)
    *   A user is asking for the best up-to-date method for outfit swapping, and another user suggests trying qwen image edit.
16. [What is the best model to generate similar image to this?(Free or paid)](https://i.redd.it/sbq4ssabgiuf1.jpeg) (Score: 0)
    *   A user is asking for the best model to generate a similar image to a reference image, and other users suggest different models, LoRAs, and techniques.
17. [Created with Stable diffuion](https://www.reddit.com/gallery/1o3xrhp) (Score: 0)
    *   A user shared images created with Stable Diffusion, and others reacted with simple comments, metadata extraction from a bot, and congratulations.
18. [Could I run a image or video gen LLM on my PC locally with the following specifications ?](https://www.reddit.com/r/StableDiffusion/comments/1o3zq8q/could_i_run_a_image_or_video_gen_llm_on_my_pc/) (Score: 0)
    *   A user is asking if they can run an image or video generation LLM on their PC with specific hardware, and other users discuss the feasibility, performance limitations, and alternative solutions like cloud-based GPU rentals.

# Detailed Analysis by Thread
**[[Tested the new OVI model](https://v.redd.it/04kvqv7hlhuf1)](URL) (Score: 52)**
*   **Summary:**  Users are testing and discussing the new OVI model, sharing experiences, and comparing it to existing tools like Wan S2V. They are commenting on aspects like speed, VRAM usage, video quality, and potential applications.
*   **Emotion:** The overall emotional tone is Neutral, with users sharing technical observations and opinions. There are both positive and negative sentiments, with some praising the model's potential while others express disappointment with the results.
*   **Top 3 Points of View:**
    *   OVI model is a good start but not yet a replacement for using txt2audio combined with Wan S2V.
    *   The fp8 model peaks at about 16.4gb with sage attention 2. The length of the speech has an effect on the quality of the video.
    *   The video model of Ovi needs to behave more like a standard WAN 2.2 model to accept accelerators and LoRAs.

**[Qwen Edit Skintone Recovery for Photography](https://v.redd.it/875ye8xymhuf1) (Score: 10)**
*   **Summary:** A user shared an image and others requested the prompt used to generate it.
*   **Emotion:** The overall emotional tone is Neutral, focusing on a technical request for information.
*   **Top 3 Points of View:**
    *   User requesting the prompt for the image.

**[Wan2.2 I2V - 2 vs 3 Ksamplers - questions on steps & samplers](https://www.reddit.com/r/StableDiffusion/comments/1o3w5r0/wan22_i2v_2_vs_3_ksamplers_questions_on_steps/) (Score: 10)**
*   **Summary:** Users are discussing the optimal settings and techniques for using Wan2.2 I2V, specifically comparing the performance of 2 vs 3 Ksamplers and the impact of different step counts and samplers.
*   **Emotion:** The overall emotional tone is Neutral, with users sharing technical advice and workflows.
*   **Top 3 Points of View:**
    *   The 3 Ksamplers approach is still the best deal for maximizing speed while preserving motion quality.
    *   MoE Ksampler and the TripleKSampler won't solve your problem.
    *   If you can't run the FP16 model, then go for the highest quantized version possible

**[Average Comfyui workflow](https://i.redd.it/h15zrpvkmhuf1.png) (Score: 7)**
*   **Summary:** Users express a desire for a more user-friendly all-in-one UI, similar to A1111, that simplifies the node-based workflow of ComfyUI.
*   **Emotion:** The overall emotional tone is Neutral, with a slight undertone of frustration regarding the complexity of ComfyUI.
*   **Top 3 Points of View:**
    *   Users want an all in one a1111 style or even better ui that can do everything

**[I have updated the ComfyUI with Flux1.dev oneclick template on Runpod (CUDA 12.8, Wan2.2, InfiniteTalk, Qwen-image-edit-2509 and VibeVoice). Also the new AI Toolkit UI is now started automatically!](https://v.redd.it/wo0vkqsdthuf1) (Score: 5)**
*   **Summary:** A user shared an update on their ComfyUI setup, and another user questioned the compatibility of InfiniteTalk with Wan2.2.
*   **Emotion:** The overall emotional tone is Neutral, with a focus on technical compatibility and setup.
*   **Top 3 Points of View:**
    *   Concern about InfiniteTalk corrupting the benefit of 2.2

**[Did someone notice Wan2.2 txt2img performance drop with RES4LYF samplers after recent Nvidia driver update 581.42](https://www.reddit.com/r/StableDiffusion/comments/1o41de3/did_someone_notice_wan22_txt2img_performance_drop/) (Score: 5)**
*   **Summary:** Users are discussing a potential performance drop in Wan2.2 txt2img after updating Nvidia drivers, troubleshooting the issue and comparing driver versions.
*   **Emotion:** The overall emotional tone is Neutral, with a slight negative undertone due to the performance issue.
*   **Top 3 Points of View:**
    *   Possible performance drop after updating Nvidia drivers.
    *   The VAE at the end takes a lot of time, but the sampling is still very fast with triton.
    *   Check if the memory fallback option is reenabled.

**[Most flexible FLUX checkpoint right now?](https://www.reddit.com/r/StableDiffusion/comments/1o3wn2x/most_flexible_flux_checkpoint_right_now/) (Score: 4)**
*   **Summary:** Users are seeking recommendations for the most flexible FLUX checkpoint, with discussions around different checkpoints and their strengths, such as NSFW content generation or LoRA compatibility.
*   **Emotion:** The overall emotional tone is Neutral, with users offering suggestions and comparing different options.
*   **Top 3 Points of View:**
    *   Chroma is good for NSFW or celebrities.
    *   Krea or SRPO are good for SFW photo style images of people without any extra LoRAs.
    *   Flux-Dev is still the best because most LoRA are trained using it as

**[Is there any “Pause” switch nodes?](https://www.reddit.com/r/StableDiffusion/comments/1o42et6/is_there_any_pause_switch_nodes/) (Score: 3)**
*   **Summary:** Users are looking for "pause" or switch nodes in ComfyUI to control workflow execution, with suggestions for different custom nodes and tools.
*   **Emotion:** The overall emotional tone is Positive and Neutral, with users offering helpful solutions.
*   **Top 3 Points of View:**
    *   Use https://github.com/lquesada/ComfyUI-Interactive - Selector and switch ComfyUI nodes "to make the ComfyUI UI interactive".
    *   Use https://github.com/wywywywy/ComfyUI-pause/ - Custom node to pause a workflow.
    *   Use Prompt Stash to save lists of prompts and access them quickly from any workflow.

**[The datasets of the most established open source models](https://www.reddit.com/r/StableDiffusion/comments/1o44sl3/the_datasets_of_the_most_established_open_source/) (Score: 3)**
*   **Summary:** Users are discussing datasets of open source models like FLUX, Qwen, and Chroma, focusing on the depth and quality of training data.
*   **Emotion:** The overall emotional tone is Neutral, with a focus on technical aspects of datasets and model training.
*   **Top 3 Points of View:**
    *   Neither FLUX nor QWEN have any particular 'depth' in training apart from cookie cutter basic stuff.
    *   Chroma has greater depth of training data than base FLUX and QWen.

**[Turned my dog in a pumpkin costume](https://i.redd.it/fj1le9nudiuf1.jpeg) (Score: 2)**
*   **Summary:** A user shared an image of their dog in a pumpkin costume, leading to positive reactions and requests for the prompt used.
*   **Emotion:** The overall emotional tone is Positive, with users expressing enjoyment and appreciation for the image.
*   **Top 3 Points of View:**
    *   Admiration for the image
    *   Request for the prompt used to generate the image

**[What should I do with 20 unused GPUs (RTX 3060 Ti + one 3090 Ti)?](https://i.redd.it/i7efkcp6gjuf1.jpeg) (Score: 2)**
*   **Summary:** A user is seeking advice on what to do with a large number of unused GPUs, with suggestions ranging from selling/renting them out to using them for personal projects like GPU clusters or 3D modeling.
*   **Emotion:** The overall emotional tone is Neutral and Positive, with users offering creative and practical suggestions.
*   **Top 3 Points of View:**
    *   Sell em for cheap or give them away
    *   Set up a site and rent them out to creators
    *   Use them as a GPU cluster for SD, or learn blender and get really into 3D modelling.

**[Correct method for object inpainting in Vace 2.2?](https://www.reddit.com/r/StableDiffusion/comments/1o3v3yz/correct_method_for_object_inpainting_in_vace_22/) (Score: 2)**
*   **Summary:** A user is asking about the correct method for object inpainting in Vace 2.2, and another user provides a link to a potentially helpful workflow.
*   **Emotion:** The overall emotional tone is Neutral, focusing on a technical question and a helpful suggestion.
*   **Top 3 Points of View:**
    *   Recommendation of workflow on civitai.com

**[Help MAC user question- cant seem to upgrade Comfyui above 0.3.27 mgr 3.37 front end 1.29](https://www.reddit.com/r/StableDiffusion/comments/1o3ytkd/help_mac_user_question_cant_seem_to_upgrade/) (Score: 2)**
*   **Summary:** A user is asking for help upgrading ComfyUI on a Mac, and another user suggests checking for an update folder and using the update script.
*   **Emotion:** The overall emotional tone is Neutral, with a focus on troubleshooting a technical issue.
*   **Top 3 Points of View:**
    *   Check for an update folder and use the update_comfyui script that updates the front end shenanigans

**[which edit model can do this successfully](https://www.reddit.com/r/StableDiffusion/comments/1o40j3q/which_edit_model_can_do_this_successfully/) (Score: 2)**
*   **Summary:** A user is asking about which edit model can perform a specific task, and another user suggests trying to rotate the image first.
*   **Emotion:** The overall emotional tone is Neutral, with a focus on finding a solution to a specific problem.
*   **Top 3 Points of View:**
    *   Suggestion to rotate the image

**[What’s the best up-to-date method for outfit swapping](https://www.reddit.com/r/StableDiffusion/comments/1o3vjqi/whats_the_best_uptodate_method_for_outfit_swapping/) (Score: 1)**
*   **Summary:** A user is asking for the best up-to-date method for outfit swapping, and another user suggests trying qwen image edit.
*   **Emotion:** The overall emotional tone is Neutral, with a focus on seeking and providing technical advice.
*   **Top 3 Points of View:**
    * Suggest trying qwen image edit

**[What is the best model to generate similar image to this?(Free or paid)](https://i.redd.it/sbq4ssabgiuf1.jpeg) (Score: 0)**
*   **Summary:** A user is asking for the best model to generate a similar image to a reference image, and other users suggest different models, LoRAs, and techniques.
*   **Emotion:** The overall emotional tone is Neutral, with users offering a range of suggestions.
*   **Top 3 Points of View:**
    *   Use Seedream 4.0 for style transfer.
    *   Use LoRAs for Family Guy or American Dad style.

**[Created with Stable diffuion](https://www.reddit.com/gallery/1o3xrhp) (Score: 0)**
*   **Summary:** A user shared images created with Stable Diffusion, and others reacted with simple comments, metadata extraction from a bot, and congratulations.
*   **Emotion:** The overall emotional tone is Neutral, with some comments being positive (congrats) and others being neutral observations.
*   **Top 3 Points of View:**
    *   Simple acknowledgement of the post
    *   Automated metadata extraction
    *   Positive feedback (congratulations)

**[Could I run a image or video gen LLM on my PC locally with the following specifications ?](https://www.reddit.com/r/StableDiffusion/comments/1o3zq8q/could_i_run_a_image_or_video_gen_llm_on_my_pc/) (Score: 0)**
*   **Summary:** A user is asking if they can run an image or video generation LLM on their PC with specific hardware, and other users discuss the feasibility, performance limitations, and alternative solutions like cloud-based GPU rentals.
*   **Emotion:** The overall emotional tone is Neutral, with some users offering realistic assessments and others suggesting upgrades or alternatives.
*   **Top 3 Points of View:**
    *   It will take a couple of hours to generate each picture.
    *   You can only run it on CPU locally, which is slower than GPU.
    *   Rent a 3090rtx gpu from runpod or such websites for a buck an hour.
