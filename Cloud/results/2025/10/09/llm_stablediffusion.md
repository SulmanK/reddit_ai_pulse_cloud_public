---
title: "Stable Diffusion Subreddit"
date: "2025-10-09"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] Text encoders in Noobai are... PART 2](https://www.reddit.com/r/StableDiffusion/comments/1o25x9t/text_encoders_in_noobai_are_part_2/) (Score: 65)
    * Discusses the tuning of text encoders in NoobAI, particularly for anime finetunes, and the potential for improvement with newly trained versions of clip-l and clip-g.
2.  [Iphone V1.1 - Qwen-Image LoRA](https://www.reddit.com/gallery/1o2fdbm) (Score: 30)
    * Users are asking for training data and config settings.
3.  [AMD ROCm7 + Pytorch 2.10 Huge Performance Gains - ComfyUI | Flux | SD3 | Qwen 2509 | OpenSUSE Linux](https://youtube.com/watch?v=kpO_6K0yiTs&si=tqF40xZ0X5SLUbes) (Score: 15)
    * A user is asking about more info about the article and how to use WAN.
4.  [WAN Animate Tutorial/ Workflow Walkthrough](https://youtu.be/gHqxQcPT8k0) (Score: 12)
    * A user thanks the author for the tutorial and workflow.
5.  [Is there a way to convert a vector map into an antique map?](https://i.redd.it/g6r9zjrb54uf1.png) (Score: 9)
    * Users discuss methods for converting vector maps into antique-style maps, including using specific AI tools and ControlNet.
6.  [How can I achieve this in my local, like can you please suggest open source model](https://i.redd.it/3sn8yv0r64uf1.jpeg) (Score: 8)
    * A user is asking for suggestions for an open source model.
7.  [Compositing in Comfyui - Maintaining High Quality Multi-Character Consistency](https://www.youtube.com/watch?v=hsEI2gEuwvI) (Score: 5)
    * A user asks if the method also fixes hand issues in distance shots.
8.  [What’s the best approach or workflow to get a truly seamless looping animation with WAN 2.2?](https://www.reddit.com/r/StableDiffusion/comments/1o23hf2/whats_the_best_approach_or_workflow_to_get_a/) (Score: 4)
    * Users discuss using VACE, generating and merging videos, and adapting prompts to I2V checkpoints.
9. [Questions about potential new build for SD - Looking at options with Nvidia over my current AMD GPU](https://www.reddit.com/r/StableDiffusion/comments/1o23ddw/questions_about_potential_new_build_for_sd/) (Score: 2)
    * A user shares a link to a Reddit post about ROCm.
10. [Is there a way to set "OR" statement in SDXL or Flux?](https://www.reddit.com/r/StableDiffusion/comments/1o25037/is_there_a_way_to_set_or_statement_in_sdxl_or_flux/) (Score: 2)
    * A user suggests a way to set an "OR" statement in SDXL or Flux.
11. [Hey! I'm running the "issue" of having very often the same or similar face of a character.](https://www.reddit.com/r/StableDiffusion/comments/1o2ek72/hey_im_running_the_issue_of_having_very_often_the/) (Score: 2)
    * Users suggest using famous names in the prompt or using the NoobAI model.
12. [Need to generate GTA-like footage](https://www.reddit.com/r/StableDiffusion/comments/1o2fkh6/need_to_generate_gtalike_footage/) (Score: 2)
    * Users suggest training a LoRA on clips and pictures that have the style.
13. [Should l charge for these kind of videos?](https://v.redd.it/edi4i5hdf4uf1) (Score: 0)
    * Users are divided on whether to charge for the videos, with some questioning the originality and others suggesting charging for custom work.
14. [Share your AI journey: what you’re building, how you got started, any tips for newcomers?](https://www.reddit.com/r/StableDiffusion/comments/1o23wec/share_your_ai_journey_what_youre_building_how_you/) (Score: 0)
    * Users share their experiences with Stable Diffusion, including their starting points, projects, and tips for newcomers.
15. [Metadata](https://www.reddit.com/r/StableDiffusion/comments/1o24jwk/metadata/) (Score: 0)
    * Users discuss how to view and edit metadata in AI-generated images, including using image editing software and ComfyUI.
16. [Mon influenceuse OF](https://www.reddit.com/r/StableDiffusion/comments/1o28b8m/mon_influenceuse_of/) (Score: 0)
    * Users suggest training a Lora or using face swapping.

# Detailed Analysis by Thread
**[[D] Text encoders in Noobai are... PART 2 (Score: 65)](https://www.reddit.com/r/StableDiffusion/comments/1o25x9t/text_encoders_in_noobai_are_part_2/)**
*  **Summary:** This thread discusses the performance of text encoders in NoobAI models for stable diffusion, particularly in the context of anime finetunes. The original poster (OP) has trained new versions of clip-l and clip-g, claiming they outperform the existing NoobAI versions. The discussion revolves around the implications of these findings and how to utilize the new CLIP models.
*  **Emotion:** The overall emotional tone is positive and interested. Users are fascinated by the findings and express excitement about potential improvements to their workflows. There's also a hint of frustration that the issues weren't addressed earlier.
*  **Top 3 Points of View:**
    * The OP's trained CLIP models significantly outperform existing NoobAI versions, especially in anime finetunes.
    * Replacing the clip-l model is relatively straightforward and improves the model, but replacing clip-g requires a large training budget due to its significant contribution.
    * Users are eager to understand how to practically use these improved CLIP models in tools like ComfyUI and Forge.

**[Iphone V1.1 - Qwen-Image LoRA (Score: 30)](https://www.reddit.com/gallery/1o2fdbm)**
*  **Summary:** This thread features a user showcasing their "Iphone V1.1" Qwen-Image LoRA (Low-Rank Adaptation) model, presumably used for generating images resembling iPhone photography. Other users express admiration and inquire about the training data and configuration used to create the LoRA.
*  **Emotion:** Positive, with users expressing admiration for the results. There is also a sense of curiosity as users ask for the settings used to achieve the results.
*  **Top 3 Points of View:**
    * The generated images look amazing.
    * Users are seeking details on the training data and configuration.
    * A user commented "pondering orbs".

**[AMD ROCm7 + Pytorch 2.10 Huge Performance Gains - ComfyUI | Flux | SD3 | Qwen 2509 | OpenSUSE Linux (Score: 15)](https://youtube.com/watch?v=kpO_6K0yiTs&si=tqF40xZ0X5SLUbes)**
*  **Summary:** This thread shares a video showcasing performance improvements in Stable Diffusion using AMD ROCm7 and Pytorch 2.10, specifically within ComfyUI, Flux, SD3, and Qwen 2509 on OpenSUSE Linux.
*  **Emotion:** Positive and inquisitive. The thread is short, with one user thanking the author for the info and asking about WAN usage.
*  **Top 3 Points of View:**
    * The video provides valuable information on performance gains.
    * Users are interested in an accompanying article.
    * There is an interest in using WAN.

**[WAN Animate Tutorial/ Workflow Walkthrough (Score: 12)](https://youtu.be/gHqxQcPT8k0)**
*  **Summary:** This thread links to a tutorial and workflow walkthrough for WAN Animate.
*  **Emotion:** Positive. Users are appreciative of the content.
*  **Top 3 Points of View:**
    * The tutorial and workflow are helpful and appreciated.
    * (Only one viewpoint available)

**[Is there a way to convert a vector map into an antique map? (Score: 9)](https://i.redd.it/g6r9zjrb54uf1.png)**
*  **Summary:** The thread is a request on how to convert a vector map into an antique map.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * Several AI tools such as Kontext, Qwen-Edit, Hidream-E, ICEdit are ideal for this task.
    * ControlNet can be used to maintain the structure of an image.
    * Getting high res scans is hard to find.

**[How can I achieve this in my local, like can you please suggest open source model (Score: 8)](https://i.redd.it/3sn8yv0r64uf1.jpeg)**
*  **Summary:** A user is seeking recommendations for open-source models to achieve a specific visual style, possibly related to image manipulation or generation. The commenter recalls a model or LoRA with a distinctive visual example but provides limited specific suggestions.
*  **Emotion:** The overall emotion is neutral. The commenter seems helpful but is vague due to memory limitations.
*  **Top 3 Points of View:**
    * The user is looking for an open-source model to achieve a certain style.
    * The commenter vaguely recalls a model or LoRA but cannot provide specific details.
    * Suggested options might not fully meet the user's needs.

**[Compositing in Comfyui - Maintaining High Quality Multi-Character Consistency (Score: 5)](https://www.youtube.com/watch?v=hsEI2gEuwvI)**
*  **Summary:** This thread links to a video tutorial on compositing in ComfyUI while maintaining high-quality multi-character consistency. A user asks if this method addresses hand issues.
*  **Emotion:** The overall tone is neutral and inquisitive.
*  **Top 3 Points of View:**
    * The video focuses on multi-character consistency in ComfyUI.
    * A user is concerned about hand fidelity in distance shots.
    * (Fewer than 3 viewpoints are available)

**[What’s the best approach or workflow to get a truly seamless looping animation with WAN 2.2? (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1o23hf2/whats_the_best_approach_or_workflow_to_get_a/)**
*  **Summary:** The thread is about the best way to get seamless looping animations.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * Use VACE and don't rely on just one frame.
    * Generate 2 videos and merge them.
    * Adapt your prompts to the I2V checkpoints as well as some of your weights.

**[Questions about potential new build for SD - Looking at options with Nvidia over my current AMD GPU (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1o23ddw/questions_about_potential_new_build_for_sd/)**
*  **Summary:** A user is looking at options with Nvidia over their current AMD GPU.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * Posted 11 minutes ago https://www.reddit.com/r/ROCm/s/kYIbZX6qyM
    * (Fewer than 3 viewpoints are available)

**[Is there a way to set "OR" statement in SDXL or Flux? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1o25037/is_there_a_way_to_set_or_statement_in_sdxl_or_flux/)**
*  **Summary:** A user is asking about how to set an "OR" statement in SDXL or Flux.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * try this {red|blue|green}
    * [https://comfyui-wiki.com/en/interface/prompt](https://comfyui-wiki.com/en/interface/prompt)
    * [https://github.com/lordgasmic/comfyui\_wildcards](https://github.com/lordgasmic/comfyui_wildcards)

**[Hey! I'm running the "issue" of having very often the same or similar face of a character. (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1o2ek72/hey_im_running_the_issue_of_having_very_often_the/)**
*  **Summary:** The thread is a request on how to fix the issue of a character having the same or similar face.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * Use famous names in the prompt, e.g.
    * WAI is overfitted on producing generic AI "slop" so it's popular on civitai.
    * That  a diffusion models problem ,the lack of variation in appearance

**[Need to generate GTA-like footage (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1o2fkh6/need_to_generate_gtalike_footage/)**
*  **Summary:** The thread is a request on how to generate GTA-like footage.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * Well, you could train a LoRA on clips and pictures that have the style you’re after, then use that.
    * (Fewer than 3 viewpoints are available)

**[Should l charge for these kind of videos? (Score: 0)](https://v.redd.it/edi4i5hdf4uf1)**
*  **Summary:** The user is asking if they should charge for these kind of videos.
*  **Emotion:** The overall tone is negative.
*  **Top 3 Points of View:**
    * Can you find a sucker to pay for these? Because otherwise, no.
    * a lot of the footage I recognize from other people works, so no.
    * if someone wants you to make them for their business. *** yea.. if you are asking if people would pay money to watch these? no

**[Share your AI journey: what you’re building, how you got started, any tips for newcomers? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o23wec/share_your_ai_journey_what_youre_building_how_you/)**
*  **Summary:** People are sharing their journey through AI.
*  **Emotion:** The emotion is positive.
*  **Top 3 Points of View:**
    * Most of what he does is for fun or small, personal projects.
    * It started with a 1.5 back when it all started.
    * Was a regular at subreddit ***, the convinced my self some gallerys could be "better".

**[Metadata (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o24jwk/metadata/)**
*  **Summary:** The thread is about metadata.
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * Most image editing software can show you metadata in the image.
    * Search hugginface space for png info, you’ll find apps ppl have made to do this its free
    * I think about metadata such as prompt information, lora, checkpoint, etc., I don't know if I'm right

**[Mon influenceuse OF (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o28b8m/mon_influenceuse_of/)**
*  **Summary:** The thread is about "Mon influenceuse OF".
*  **Emotion:** The emotion is neutral.
*  **Top 3 Points of View:**
    * you should train a lora based on your character (best option) or use faceswapping methods (faster but not as good IMO).
    * You should find a model that can create good consistent realistic images and just do face swap, a trick is to censor the body of the person so you can upload it to nanobanana or similar then compose the face swap on to of the original uncensored image
    * (Fewer than 3 viewpoints are available)
