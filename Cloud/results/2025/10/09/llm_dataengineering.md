---
title: "Data Engineering Subreddit"
date: "2025-10-09"
description: "Analysis of top discussions and trends in the dataengineering subreddit"
tags: ["dataengineering", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions
1.  [I'm sick of the misconceptions that laymen have about data engineering](https://www.reddit.com/r/dataengineering/comments/1o23nxt/im_sick_of_the_misconceptions_that_laymen_have/) (Score: 260)
    *   The original poster is frustrated with the misconceptions that people outside of data engineering have about the field.

2.  [Eventually got a DE job, but what's next?](https://www.reddit.com/r/dataengineering/comments/1o1udcq/eventually_got_a_de_job_but_whats_next/) (Score: 34)
    *   A recent boot camp graduate who landed a Data Engineering job is asking for advice on how to progress their career.

3.  [Iceberg is an overkill and most people don't realise it but its metadata model will sneak up on you](https://olake.io/blog/2025/10/03/iceberg-metadata) (Score: 31)
    *   The post discusses the benefits and drawbacks of using Iceberg, a table format, for data management.

4.  [We built Arc, a high-throughput time-series warehouse on DuckDB + Parquet (1.9M rec/sec)](https://www.reddit.com/r/dataengineering/comments/1o1u64i/we_built_arc_a_highthroughput_timeseries/) (Score: 21)
    *   The post introduces Arc, a new time-series warehouse built on DuckDB and Parquet.

5.  [What's this ***, Google?](https://i.redd.it/x5bq3s6jyytf1.png) (Score: 18)
    *   The poster is confused by Google's OAuth process for a service account.

6.  [Has anyone built python models with DBT](https://www.reddit.com/r/dataengineering/comments/1o1yixn/has_anyone_built_python_models_with_dbt/) (Score: 8)
    *   The post asks whether anyone has experience building python models with DBT.

7.  [What do you think about the Open Semantic Interchange (OSI)?](https://www.reddit.com/r/dataengineering/comments/1o25ss6/what_do_you_think_about_the_open_semantic/) (Score: 6)
    *   The post is about an open semantic layer and its use case for data engineering.

8.  [SCD Type 3 vs an alternate approach?](https://www.reddit.com/r/dataengineering/comments/1o1rzve/scd_type_3_vs_an_alternate_approach/) (Score: 4)
    *   The original poster is asking for help between two SCD (Slowly Changing Dimension) approaches for data.

9.  [Snowflake (or any DWH) Data Compression on Parquet files](https://www.reddit.com/r/dataengineering/comments/1o27u1n/snowflake_or_any_dwh_data_compression_on_parquet/) (Score: 4)
    *   The post is about Snowflake and its Data Compression on Parquet files.

10. [Data pipelines(AWS)](https://www.reddit.com/r/dataengineering/comments/1o21bdo/data_pipelinesaws/) (Score: 3)
    *   The original poster asks for advice on data pipeline architecture in AWS.

11. [Poor update performance with clickhouse](https://www.reddit.com/r/dataengineering/comments/1o20ilj/poor_update_performance_with_clickhouse/) (Score: 3)
    *   The poster is experiencing poor update performance with Clickhouse.

12. [Stay at current job or take new hybrid offer in a different industry?](https://www.reddit.com/r/dataengineering/comments/1o1x0t8/stay_at_current_job_or_take_new_hybrid_offer_in_a/) (Score: 2)
    *   The original poster is asking if he should stay at the current job or take the new hybrid job offer in a different industry.

13. [Replacing Legacy Message Queueing Solutions with RabbitMQ - Upcoming Conference Talk for Data Engineers!](https://www.reddit.com/r/dataengineering/comments/1o24far/replacing_legacy_message_queueing_solutions_with/) (Score: 1)
    *   The post is about replacing legacy message queueing solutions with RabbitMQ.

14. [Open-source python data profiling tools](https://www.reddit.com/r/dataengineering/comments/1o255dh/opensource_python_data_profiling_tools/) (Score: 1)
    *   The original poster is asking about open-source python data profiling tools

15. [Data Cleanup for AI/Automation Prep?](https://www.reddit.com/r/dataengineering/comments/1o28s9e/data_cleanup_for_aiautomation_prep/) (Score: 1)
    *   The post is about data cleanup for AI/Automation Prep.

16. [Semantic Layers Are Bad for AI](https://bagofwords.com/blog/semantic-layers-are-bad-for-ai/) (Score: 0)
    *   The original poster shared a blog post explaining why semantic layers are bad for AI.

# Detailed Analysis by Thread
**[I'm sick of the misconceptions that laymen have about data engineering (Score: 260)](https://www.reddit.com/r/dataengineering/comments/1o23nxt/im_sick_of_the_misconceptions_that_laymen_have/)**
*  **Summary:** The original poster is frustrated with the misconceptions that people outside of data engineering have about the field. Many comments discuss the challenges of dealing with stakeholders who don't understand the complexities of data engineering, particularly around requirements like "real-time" data. Others talk about the importance of project managers and analysts in bridging the gap between business needs and technical execution.
*  **Emotion:** The overall emotional tone is neutral, with a hint of frustration and shared understanding among data engineers.
*  **Top 3 Points of View:**
    *   Stakeholders often ask for "everything" without understanding the underlying complexities and costs, especially with requests like "real-time" data.
    *   Project managers and analysts are crucial for translating business needs into actionable technical requirements and for managing stakeholder expectations.
    *   Data engineers should proactively address potential future requests by taking a pessimistic approach that should cover as many possible future requests as possible.

**[Eventually got a DE job, but what's next? (Score: 34)](https://www.reddit.com/r/dataengineering/comments/1o1udcq/eventually_got_a_de_job_but_whats_next/)**
*  **Summary:** A recent boot camp graduate who landed a Data Engineering job is asking for advice on how to progress their career. The comments generally advise the poster to focus on their current role, learn as much as possible, and revisit their career plans in a year or two. Some suggest using tools like ChatGPT to help with legacy code.
*  **Emotion:** The overall emotional tone is positive and encouraging, with a focus on practical advice.
*  **Top 3 Points of View:**
    *   Focus on the current job and learn the ropes before worrying about the next step.
    *   Use the opportunity to standardize the tech stack and improve existing systems.
    *   It's too early to be thinking about the next gig or promotion.

**[Iceberg is an overkill and most people don't realise it but its metadata model will sneak up on you (Score: 31)](https://olake.io/blog/2025/10/03/iceberg-metadata)**
*  **Summary:** The post discusses the benefits and drawbacks of using Iceberg, a table format, for data management. Commenters discuss when Iceberg is a good solution, with some questioning its utility when data will end up in a warehouse. DuckLake is mentioned as a possible alternative.
*  **Emotion:** The overall emotional tone is neutral, with some confusion about the original poster's stance on Iceberg.
*  **Top 3 Points of View:**
    *   Iceberg might be overkill for some use cases, particularly when the data volume is small.
    *   The benefits and disadvantages mentioned are true for the other two major table formats Delta and Hudi as well.
    *   DuckLake is a nice alternative once it's mature.

**[We built Arc, a high-throughput time-series warehouse on DuckDB + Parquet (1.9M rec/sec) (Score: 21)](https://www.reddit.com/r/dataengineering/comments/1o1u64i/we_built_arc_a_highthroughput_timeseries/)**
*  **Summary:** The post introduces Arc, a new time-series warehouse built on DuckDB and Parquet. Commenters are curious about what makes Arc unique compared to other time-series databases and why Rust wasn't used for the implementation.
*  **Emotion:** The overall emotional tone is neutral and inquisitive.
*  **Top 3 Points of View:**
    *   Arc is basically a wrapper around DuckDB.
    *   Why not use Rust?
    *   There are many products named "Arc".

**[What's this ***, Google? (Score: 18)](https://i.redd.it/x5bq3s6jyytf1.png)**
*  **Summary:** The poster is confused by Google's OAuth process for a service account. Commenters suggest that the poster is on the wrong path and should be creating a Client ID and secret instead. They also point out the distinction between internal and external users and the appropriate OAuth configurations for each.
*  **Emotion:** The overall emotional tone is neutral, with a hint of frustration from the original poster and helpful suggestions from other commenters.
*  **Top 3 Points of View:**
    *   The poster is using the wrong OAuth configuration for their use case.
    *   Google's documentation can be confusing.
    *   For internal applications, use a service account.

**[Has anyone built python models with DBT (Score: 8)](https://www.reddit.com/r/dataengineering/comments/1o1yixn/has_anyone_built_python_models_with_dbt/)**
*  **Summary:** The post asks whether anyone has experience building python models with DBT. Commenters share their experiences, noting that it requires a setup on the DWH/DBMS side, and your DBMS has to support it and has to have the libraries you need.
*  **Emotion:** The overall emotional tone is positive and informative.
*  **Top 3 Points of View:**
    *   Python models in DBT are useful for transformations that are hard to express in SQL.
    *   It simplifies workflows if you're already comfortable with Python.
    *   It requires a setup on your DWH/DBMS side first.

**[What do you think about the Open Semantic Interchange (OSI)? (Score: 6)](https://www.reddit.com/r/dataengineering/comments/1o25ss6/what_do_you_think_about_the_open_semantic/)**
*  **Summary:** The post is about an open semantic layer and its use case for data engineering. Commenters discuss a relief to have it and hope it will consider an ai friendly format.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 3 Points of View:**
    *   Semantic layers can provide interoperability pain.
    *   The name of OSI is dumb considering the OSI stack we were all taught in CS 100.
    *   Hoping it's considering a format that is more ai friendly

**[SCD Type 3 vs an alternate approach? (Score: 4)](https://www.reddit.com/r/dataengineering/comments/1o1rzve/scd_type_3_vs_an_alternate_approach/)**
*  **Summary:** The original poster is asking for help between two SCD (Slowly Changing Dimension) approaches for data. Commenters discuss whether business need to know the previous value and only the original value.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   If the field gets updated twice you will lose the previous value.
    *   No reason not to do it if it works
    *   SCD Type 3 only capture 2 states of a key: it's too limited.

**[Snowflake (or any DWH) Data Compression on Parquet files (Score: 4)](https://www.reddit.com/r/dataengineering/comments/1o27u1n/snowflake_or_any_dwh_data_compression_on_parquet/)**
*  **Summary:** The post is about Snowflake and its Data Compression on Parquet files. Commenters discuss that the data will reside in whatever storage you decide and that the compression Snowflake has won't be able to compress data much different to Parquet size.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The data will reside in whatever storage you decide.
    *   Compression Snowflake has won't be able to compress data much different to Parquet size.
    *   If tables are frequently updated, the historical data can easily be much larger than the active snapshot.

**[Data pipelines(AWS) (Score: 3)](https://www.reddit.com/r/dataengineering/comments/1o21bdo/data_pipelinesaws/)**
*  **Summary:** The original poster asks for advice on data pipeline architecture in AWS. Commenters discuss AWS S3, Snowpipe, Iceberg, and CDC.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Default to S3 as your raw landing zone and load into Snowflake with Snowpipe or Snowpipe Streaming
    *   CDC for databases to S3 Parquet
    *   Data into S3 or Iceberg as a staging layer, then load or query it from Snowflake.

**[Poor update performance with clickhouse (Score: 3)](https://www.reddit.com/r/dataengineering/comments/1o20ilj/poor_update_performance_with_clickhouse/)**
*  **Summary:** The poster is experiencing poor update performance with Clickhouse. Commenters advise that DWH is not designed around update.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Delete and updates can get dangerous in clickhouse.
    *   DWH (which are mostly columnar) is not designed around update.
    *   With Clickhouse you should be embracing eventual consistency.

**[Stay at current job or take new hybrid offer in a different industry? (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1o1x0t8/stay_at_current_job_or_take_new_hybrid_offer_in_a/)**
*  **Summary:** The original poster is asking if he should stay at the current job or take the new hybrid job offer in a different industry. Commenters suggest making a cost-benefit analysis and that they don't think you can count on internal promotion.
*  **Emotion:** The overall emotional tone is negative.
*  **Top 3 Points of View:**
    *   Relevant experience to have on your resume for data jobs.
    *   Make a cost benefit analysis
    *   The new role sounds better, and I don't think you can count on internal promotion

**[Replacing Legacy Message Queueing Solutions with RabbitMQ - Upcoming Conference Talk for Data Engineers! (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1o24far/replacing_legacy_message_queueing_solutions_with/)**
*  **Summary:** The post is about replacing legacy message queueing solutions with RabbitMQ. The general tone of comments is positive with a commenter thinking RabbitMQ is legacy :⁠-⁠) Isn't it known for losing messages on crashes?
*  **Emotion:** The overall emotional tone is positive.
*  **Top 3 Points of View:**
    *   I just use whatever message queue platform is recommended by the cloud provider. 😅
    *   RabbitMQ is legacy.
    *   Rabbitmq is solid for handling traditional middleware issues.

**[Open-source python data profiling tools (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1o255dh/opensource_python_data_profiling_tools/)**
*  **Summary:** The original poster is asking about open-source python data profiling tools. Commenters recommend Great Expectations.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 2 Points of View:**
    *   Great Expectations seems like your best bet.
    *   95% of the value add comes from implementing an org's specific business rules that dont necessarily conform to existing schemas.

**[Data Cleanup for AI/Automation Prep? (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1o28s9e/data_cleanup_for_aiautomation_prep/)**
*  **Summary:** The post is about data cleanup for AI/Automation Prep. Commenters discuss that consultants don’t have the time or interest to learn the business well enough and build something truly sustainable without them.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Consultants can be used for general project or for specific project.
    *   The same people who've always done data cleanup/standardisation.
    *   A lot of consultants don't have the time or interest to learn the business well enough and build something truly sustainable without them.

**[Semantic Layers Are Bad for AI (Score: 0)](https://bagofwords.com/blog/semantic-layers-are-bad-for-ai/)**
*  **Summary:** The original poster shared a blog post explaining why semantic layers are bad for AI. Commenters disagree on the post.
*  **Emotion:** The overall emotional tone is negative.
*  **Top 3 Points of View:**
    *   Delete it bro
    *   The whole article is so dumb
    *   I NEED a semantic layer for an LLM to help me understand why sales are down.
