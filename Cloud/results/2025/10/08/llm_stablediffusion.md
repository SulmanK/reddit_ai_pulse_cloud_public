---
title: "Stable Diffusion Subreddit"
date: "2025-10-08"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Unfinished : Wan 2.2 (1 step for high 2 for low), Wan 2.2 I2v and FFLF , lightning loras 4 low steps. Just something I was working on today so I would not get depressed.](https://www.youtube.com/watch?v=N3vVjC7BqNk) (Score: 12)
    * This thread discusses the user's work on Wan 2.2 with different settings and lightning loras, created to alleviate depression.
2.  [Is JoyCaption Still the Best Tagging Model?](https://www.reddit.com/r/StableDiffusion/comments/1o1gbye/is_joycaption_still_the_best_tagging_model/) (Score: 10)
    * Users are discussing and comparing the performance and speed of different tagging models like JoyCaption, Gemma3, and Llama 4, particularly regarding NSFW content and the description of people and outfits.
3.  [ImageCrop v1.1.0 Released! Major Cross-Platform Improvements + Easier Upgrades Coming in v1.2.0](https://www.reddit.com/r/StableDiffusion/comments/1o1gjbb/imagecrop_v110_released_major_crossplatform/) (Score: 10)
    * This thread announces the release of ImageCrop v1.1.0, highlighting cross-platform improvements. Users are asking what the app is for and sharing alternative solutions.
4.  [Peter Paul Rubens‘s style Lora for Flux](https://www.reddit.com/gallery/1o1kf5n) (Score: 8)
    * This thread showcases a Peter Paul Rubens style Lora for the Flux model. Users express their enjoyment of style loras based on masters and praise the Flux model.
5.  [[Q] How do you guys learn more about a specific model?](https://www.reddit.com/r/StableDiffusion/comments/1o1dxwe/q_how_do_you_guys_learn_more_about_a_specific/) (Score: 3)
    * This thread asks about methods for learning more about specific models in Stable Diffusion. Users suggest using ComfyUI templates, experimenting with different settings, and referring to Huggingface or Civitai pages.
6.  [Up to date recommendations?](https://www.reddit.com/r/StableDiffusion/comments/1o1ecdp/up_to_date_recommendations/) (Score: 3)
    * The thread discusses up-to-date recommendations for Stable Diffusion models. Users recommend models like Illustrious, Flux Krea, Wan 2.2, and Qwen-Image, as well as using ComfyUI for experimentation.
7.  [Which one is the base model and which is the tuned version for Illustrious 2.0?](https://www.reddit.com/r/StableDiffusion/comments/1o1gyop/which_one_is_the_base_model_and_which_is_the/) (Score: 3)
    * This thread asks about the base and tuned models for Illustrious 2.0. One user suggests one is for inference and the other for LoRA training.
8.  [A 1000 character lora, is it possible?](https://www.reddit.com/r/StableDiffusion/comments/1o1cum5/a_1000_character_lora_is_it_possible/) (Score: 2)
    * The thread questions the possibility of creating a LoRA for 1000 characters. Users suggest that LoRAs are not suitable for such a large number of characters and that fine-tuning may be a better approach.
9.  [Is there any tutorial show how to install the sage attention 3?](https://www.reddit.com/r/StableDiffusion/comments/1o1kj4x/is_there_any_tutorial_show_how_to_install_the/) (Score: 2)
    * This thread asks about tutorials for installing sage attention 3. A user suggests that it's still bleeding edge and may require waiting.
10. [What is the best way to create low poly 3d models out of me?](https://www.reddit.com/r/StableDiffusion/comments/1o1knfb/what_is_the_best_way_to_create_low_poly_3d_models/) (Score: 2)
    * This thread asks about the best tools for creating low-poly 3D models. Hunyuan 3D is recommended as a better option than Meshy and Tripo AI.
11. [Nano Banana Watermark?](https://i.redd.it/19dqz1om1ytf1.png) (Score: 1)
    * This thread discusses a potential Nano Banana watermark. Users note it's the wrong subreddit.
12. [There are no posts for this subreddit today](https://www.reddit.com/r/StableDiffusion/) (Score: 1)
    * This is a placeholder comment for a day with no posts.
13. [Is there a specific node that can display the number of frames?](https://www.reddit.com/r/StableDiffusion/comments/1o1fd1k/is_there_a_specific_node_that_can_display_the/) (Score: 1)
    * The thread asks about a node to display the number of frames in Stable Diffusion. Users suggest using "Get Image Count" from the ComfyUI-VideoHelperSuite or the preview image node.
14. [WAN 2.2 Generation Times](https://www.reddit.com/r/StableDiffusion/comments/1o1g2zp/wan_22_generation_times/) (Score: 1)
    * This thread is about WAN 2.2 generation times. Users suggest specifying the model being used.
15. [A new model is hanging around called Lumina.](https://www.reddit.com/r/StableDiffusion/comments/1o1irpf/a_new_model_is_hanging_around_called_lumina/) (Score: 1)
    * This thread introduces a new model called Lumina. One user notes that it has a lot of potential and is still in training.
16. [AMD GPU user, Windows, Amuse, and the aggressive blurring.](https://www.reddit.com/r/StableDiffusion/comments/1o1cem1/amd_gpu_user_windows_amuse_and_the_aggressive/) (Score: 0)
    * This thread discusses issues with aggressive blurring in Amuse AI on AMD GPUs. Users suggest disabling the filter or using ROCm.
17. [StableDiffusion University?](https://www.reddit.com/r/StableDiffusion/comments/1o1citq/stablediffusion_university/) (Score: 0)
    * This thread discusses how to learn about Stable Diffusion. Users recommend using AI tools like ChatGPT, watching YouTube videos, and focusing on technical content.
18. [SwarmUI error - Backends are still loading on the server](https://www.reddit.com/r/StableDiffusion/comments/1o1dpv3/swarmui_error_backends_are_still_loading_on_the/) (Score: 0)
    * This thread reports an error in SwarmUI. One user suggests checking the console/backend log for Comfy errors.
19. [what re the best settings for lora qwen image training with ai toolkit for 30,60 and 100 picture. does the setting depends from the number of pictures?](https://www.reddit.com/r/StableDiffusion/comments/1o1fhtk/what_re_the_best_settings_for_lora_qwen_image/) (Score: 0)
    * The thread asks about the best settings for Lora Qwen image training. Users share their settings and emphasize the importance of dataset quality and testing.
20. [Is Qwen-Image Edit better than Qwen-Image?](https://www.reddit.com/r/StableDiffusion/comments/1o1j8gh/is_qwenimage_edit_better_than_qwenimage/) (Score: 0)
    * This thread compares Qwen-Image Edit and Qwen-Image. Users note that they are different use cases, with Qwen-Image being better for generating images from scratch and Qwen-Image Edit being better for editing existing images.

# Detailed Analysis by Thread
**[Unfinished : Wan 2.2 (1 step for high 2 for low), Wan 2.2 I2v and FFLF , lightning loras 4 low steps. Just something I was working on today so I would not get depressed. (Score: 12)](https://www.youtube.com/watch?v=N3vVjC7BqNk)**
*  **Summary:**  The user shares their work on Wan 2.2 with different settings and lightning loras, mentioning it was a way to avoid feeling depressed.
*  **Emotion:** Predominantly positive, with users expressing encouragement and admiration for the work.
*  **Top 3 Points of View:**
    * Appreciation for the work as a source of positivity.
    * Inquiry about the role of simpler plays in the workflow.
    * Acknowledgment of the work's quality, even if not entirely cheery.

**[Is JoyCaption Still the Best Tagging Model? (Score: 10)](https://www.reddit.com/r/StableDiffusion/comments/1o1gbye/is_joycaption_still_the_best_tagging_model/)**
*  **Summary:**  Users are comparing the performance and speed of different tagging models like JoyCaption, Gemma3, and Llama 4, particularly regarding NSFW content and the description of people and outfits.
*  **Emotion:** The emotional tone is mostly neutral, with discussions revolving around technical aspects and comparisons of different models. Some positive sentiment is present, but the overall tone is informational and analytical.
*  **Top 3 Points of View:**
    * JoyCaption is a solid model, particularly for describing people and outfits.
    * Gemma3 and Llama 4 are smarter but not as fast.
    * The speed of processing images with JoyCaption varies significantly based on hardware.

**[ImageCrop v1.1.0 Released! Major Cross-Platform Improvements + Easier Upgrades Coming in v1.2.0 (Score: 10)](https://www.reddit.com/r/StableDiffusion/comments/1o1gjbb/imagecrop_v110_released_major_crossplatform/)**
*  **Summary:** This thread announces the release of ImageCrop v1.1.0, highlighting cross-platform improvements. Users are asking what the app is for and sharing alternative solutions.
*  **Emotion:** The emotional tone is mixed, with some positive sentiment towards the release and some confusion about the app's purpose.
*  **Top 3 Points of View:**
    * Positive feedback for the release and improvements.
    * Confusion and questions about the app's purpose.
    * Suggestion of alternative, simpler solutions like BIRME.

**[Peter Paul Rubens‘s style Lora for Flux (Score: 8)](https://www.reddit.com/gallery/1o1kf5n)**
*  **Summary:** This thread showcases a Peter Paul Rubens style Lora for the Flux model. Users express their enjoyment of style loras based on masters and praise the Flux model.
*  **Emotion:** The overall emotional tone is positive, with expressions of enjoyment and appreciation for the shared Lora and the Flux model.
*  **Top 3 Points of View:**
    * Appreciation for the style Lora based on Peter Paul Rubens.
    * Endorsement and continued use of the Flux image model.
    * Humorous observation with a reference to "Wee Herman."

**[[Q] How do you guys learn more about a specific model? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1o1dxwe/q_how_do_you_guys_learn_more_about_a_specific/)**
*  **Summary:** This thread asks about methods for learning more about specific models in Stable Diffusion. Users suggest using ComfyUI templates, experimenting with different settings, and referring to Huggingface or Civitai pages.
*  **Emotion:** The emotional tone is largely neutral, focused on providing informative and practical advice. Some comments express positivity through encouragement and support.
*  **Top 3 Points of View:**
    * Utilize ComfyUI templates as a starting point for learning about models.
    * Experiment with different settings like samplers and schedulers in ComfyUI.
    * Consult Huggingface or Civitai pages for model-specific information.

**[Up to date recommendations? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1o1ecdp/up_to_date_recommendations/)**
*  **Summary:** The thread discusses up-to-date recommendations for Stable Diffusion models. Users recommend models like Illustrious, Flux Krea, Wan 2.2, and Qwen-Image, as well as using ComfyUI for experimentation.
*  **Emotion:** The overall emotional tone is mixed. There's helpful and neutral advice, but also some negative sentiment expressed towards the original poster's approach.
*  **Top 3 Points of View:**
    * Some users recommend specific models like Illustrious, Flux Krea, Wan 2.2, and Qwen-Image.
    * Some users suggest a structured learning approach starting with ComfyUI templates.
    * Some users express frustration with the poster's perceived lack of effort.

**[Which one is the base model and which is the tuned version for Illustrious 2.0? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1o1gyop/which_one_is_the_base_model_and_which_is_the/)**
*  **Summary:** This thread asks about the base and tuned models for Illustrious 2.0. One user suggests one is for inference and the other for LoRA training.
*  **Emotion:** The emotional tone is neutral, with a straightforward question and a tentative answer.
*  **Top 3 Points of View:**
    * Speculation that one model is for inference and the other for LoRA training.

**[A 1000 character lora, is it possible? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1o1cum5/a_1000_character_lora_is_it_possible/)**
*  **Summary:** The thread questions the possibility of creating a LoRA for 1000 characters. Users suggest that LoRAs are not suitable for such a large number of characters and that fine-tuning may be a better approach.
*  **Emotion:** The overall emotional tone is neutral, with users primarily offering advice and expressing skepticism about the feasibility of the request.
*  **Top 3 Points of View:**
    * Creating a LoRA for 1000 characters is likely not feasible due to LoRA limitations.
    * Fine-tuning is a more appropriate method for training on a large number of characters.
    * The purpose and goal of the LoRA need to be clearly defined.

**[Is there any tutorial show how to install the sage attention 3? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1o1kj4x/is_there_any_tutorial_show_how_to_install_the/)**
*  **Summary:** This thread asks about tutorials for installing sage attention 3. A user suggests that it's still bleeding edge and may require waiting.
*  **Emotion:** The emotional tone is neutral, as the conversation is simply about the availability of a tutorial and the current state of the technology.
*  **Top 3 Points of View:**
    * Sage attention 3 is very new and may not have readily available tutorials yet.

**[What is the best way to create low poly 3d models out of me? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1o1knfb/what_is_the_best_way_to_create_low_poly_3d_models/)**
*  **Summary:** This thread asks about the best tools for creating low-poly 3D models. Hunyuan 3D is recommended as a better option than Meshy and Tripo AI.
*  **Emotion:** The overall emotional tone is neutral and informative, with a focus on recommending a specific tool.
*  **Top 3 Points of View:**
    * Hunyuan 3D is the best tool for creating low-poly 3D models.
    * Meshy and Tripo AI are not as effective.

**[Nano Banana Watermark? (Score: 1)](https://i.redd.it/19dqz1om1ytf1.png)**
*  **Summary:** This thread discusses a potential Nano Banana watermark. Users note it's the wrong subreddit.
*  **Emotion:** The emotional tone is neutral and slightly dismissive, as it's deemed off-topic.
*  **Top 3 Points of View:**
    * The post is likely about a Nano Banana watermark.
    * The post is in the wrong subreddit.

**[There are no posts for this subreddit today (Score: 1)](https://www.reddit.com/r/StableDiffusion/)**
*  **Summary:** This is a placeholder comment for a day with no posts.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    * N/A

**[Is there a specific node that can display the number of frames? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1o1fd1k/is_there_a_specific_node_that_can_display_the/)**
*  **Summary:** The thread asks about a node to display the number of frames in Stable Diffusion. Users suggest using "Get Image Count" from the ComfyUI-VideoHelperSuite or the preview image node.
*  **Emotion:** The emotional tone is neutral and helpful, with users providing solutions to the question.
*  **Top 3 Points of View:**
    * Use "Get Image Count" from the ComfyUI-VideoHelperSuite.
    * Use the preview image node, which displays the frame count in the bottom right.

**[WAN 2.2 Generation Times (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1o1g2zp/wan_22_generation_times/)**
*  **Summary:** This thread is about WAN 2.2 generation times. Users suggest specifying the model being used.
*  **Emotion:** The emotional tone is neutral, with a focus on gathering more information.
*  **Top 3 Points of View:**
    * Providing the specific model used would help in understanding generation times.

**[A new model is hanging around called Lumina. (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1o1irpf/a_new_model_is_hanging_around_called_lumina/)**
*  **Summary:** This thread introduces a new model called Lumina. One user notes that it has a lot of potential and is still in training.
*  **Emotion:** The emotional tone is mildly positive due to the mention of potential.
*  **Top 3 Points of View:**
    * Lumina is a promising new model still in training.
    * Lumina is a better architecture than Illustrious.

**[AMD GPU user, Windows, Amuse, and the aggressive blurring. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o1cem1/amd_gpu_user_windows_amuse_and_the_aggressive/)**
*  **Summary:** This thread discusses issues with aggressive blurring in Amuse AI on AMD GPUs. Users suggest disabling the filter or using ROCm.
*  **Emotion:** The emotional tone is mostly neutral, with users offering technical solutions.
*  **Top 3 Points of View:**
    * Disable the blurring filter in the app settings.
    * Use ROCm for more stable performance.
    * Try SD.next as an alternative.

**[StableDiffusion University? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o1citq/stablediffusion_university/)**
*  **Summary:** This thread discusses how to learn about Stable Diffusion. Users recommend using AI tools like ChatGPT, watching YouTube videos, and focusing on technical content.
*  **Emotion:** The overall tone is neutral, offering suggestions and advice.
*  **Top 3 Points of View:**
    * Learn the theoretical background at a university.
    * Use AI like ChatGPT to explain concepts.
    * Focus on technical videos with smaller audiences rather than hype videos.

**[SwarmUI error - Backends are still loading on the server (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o1dpv3/swarmui_error_backends_are_still_loading_on_the/)**
*  **Summary:** This thread reports an error in SwarmUI. One user suggests checking the console/backend log for Comfy errors.
*  **Emotion:** The emotional tone is neutral, with a focus on troubleshooting.
*  **Top 3 Points of View:**
    * Check the console/backend log for Comfy errors.

**[what re the best settings for lora qwen image training with ai toolkit for 30,60 and 100 picture. does the setting depends from the number of pictures? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o1fhtk/what_re_the_best_settings_for_lora_qwen_image/)**
*  **Summary:** The thread asks about the best settings for Lora Qwen image training. Users share their settings and emphasize the importance of dataset quality and testing.
*  **Emotion:** The emotional tone is neutral and informative, with users sharing their experiences and settings.
*  **Top 3 Points of View:**
    * The key is to test the epochs and quality of the dataset.
    * Each image needs at least 80 steps.
    * Users shared some useful information on steps, learning rate, image number, ect.

**[Is Qwen-Image Edit better than Qwen-Image? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1o1j8gh/is_qwenimage_edit_better_than_qwenimage/)**
*  **Summary:** This thread compares Qwen-Image Edit and Qwen-Image. Users note that they are different use cases, with Qwen-Image being better for generating images from scratch and Qwen-Image Edit being better for editing existing images.
*  **Emotion:** The emotional tone is largely neutral and informative, with users providing different perspectives based on their experiences.
*  **Top 3 Points of View:**
    * Qwen-Image is better for generating images from scratch, while Qwen-Image Edit is better for editing existing images.
    * Qwen-Image can compete with nano banana.
    * The effectiveness of each model can vary depending on the specific prompt and application.
