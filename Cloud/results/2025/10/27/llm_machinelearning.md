---
title: "Machine Learning Subreddit"
date: "2025-10-27"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "research"]
---

# Overall Ranking and Top Discussions
1.  [[D] Google PhD Fellowship recipients 2025](https://www.reddit.com/r/MachineLearning/comments/1ogy6z9/google_phd_fellowship_recipients_2025_d/) (Score: 96)
    *   Discussion about the Google PhD Fellowship recipients, the application process, and the qualifications of the recipients.
2.  [[R] PKBoost: Gradient boosting that stays accurate under data drift (2% degradation vs XGBoost's 32%)](https://www.reddit.com/r/MachineLearning/comments/1ohbdgu/r_pkboost_gradient_boosting_that_stays_accurate/) (Score: 41)
    *   A new gradient boosting method called PKBoost that maintains accuracy under data drift is introduced.
3.  [[P] Clojure Runs ONNX AI Models Now](https://dragan.rocks/articles/25/Clojure-Runs-ONNX-AI-Models-Now) (Score: 7)
    *   Discussion of running ONNX AI models in Clojure.
4.  [World Foundation Models 2025 [R]](https://www.reddit.com/r/MachineLearning/comments/1oh73b3/world_foundation_models_2025_r/) (Score: 7)
    *   Discussion about world foundation models.

# Detailed Analysis by Thread
**[[D] Google PhD Fellowship recipients 2025 (Score: 96)](https://www.reddit.com/r/MachineLearning/comments/1ogy6z9/google_phd_fellowship_recipients_2025_d/)**
*   **Summary:** This thread discusses the recipients of the Google PhD Fellowship, with commenters sharing their experiences applying for similar fellowships, observing trends in recipient profiles, and speculating on the selection criteria.
*   **Emotion:** The overall emotional tone is neutral, with some commenters expressing slight negativity related to rejection experiences.
*   **Top 3 Points of View:**
    *   The application process is helpful for refining research focus, even if unsuccessful.
    *   Recipients often have strong research directions, sometimes specializing in underserved areas, and connections with Google researchers via their supervisors.
    *   Novelty of research is important with original contributions.

**[[R] PKBoost: Gradient boosting that stays accurate under data drift (2% degradation vs XGBoost's 32%) (Score: 41)](https://www.reddit.com/r/MachineLearning/comments/1ohbdgu/r_pkboost_gradient_boosting_that_stays_accurate/)**
*   **Summary:** A new gradient boosting method called PKBoost that maintains accuracy under data drift is introduced and received positively due to its improvement on imbalanced datasets.
*   **Emotion:** The emotional tone is positive.
*   **Top 3 Points of View:**
    *   PKBoost is a welcome improvement, especially for imbalanced datasets.
    *   Creating a Python wrapper using PyO3 would expand the usage of PKBoost.

**[[P] Clojure Runs ONNX AI Models Now (Score: 7)](https://dragan.rocks/articles/25/Clojure-Runs-ONNX-AI-Models-Now)**
*   **Summary:**  Discussion of running ONNX AI models in Clojure and suggestion of using Reactant.jl in Julia as a better alternative.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Running models in Clojure isnâ€™t terribly useful.
    *   Reactant.jl in Julia compiles a subset of the language to StableHLO and leverages XLA.

**[World Foundation Models 2025 [R] (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1oh73b3/world_foundation_models_2025_r/)**
*   **Summary:** Discussion about world foundation models and understanding transformers.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Start off by understanding transformers and the current SOTA, then get into yann lecun's work of world models, JEPA/I-JEPA and stuff
    *   Building a world model is to test different approaches to solve a problem.
