---
title: "Stable Diffusion Subreddit"
date: "2025-10-27"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Tried longer videos with WAN 2.2 Animate](https://v.redd.it/xusemoun9oxf1) (Score: 236)
    * The discussion revolves around a user showcasing longer videos created with WAN 2.2 Animate, with people asking about the workflow, comparing the real and AI model, and commenting on the quality of animation and expressions.
2.  [Midjourny V7 vs HiDream l1 vs DALLE3 vs Flux Dev](https://www.reddit.com/gallery/1ohebfy) (Score: 21)
    * This thread compares image outputs from various AI models (Midjourney V7, HiDream l1, DALLE3, and Flux Dev), with users discussing the strengths and weaknesses of each for different prompts and subjects.
3.  [A request to anyone training new models: please let this composition die](https://www.reddit.com/gallery/1ohi83c) (Score: 17)
    *  The post expresses frustration with the repetitive "cyberpunk" composition commonly generated by AI models, leading to a discussion about overused aesthetics and the need for more diverse and interesting outputs.
4.  [Just a few qwen experiments.](https://www.reddit.com/gallery/1ohkd4k) (Score: 17)
    * This thread showcases experiments with the Qwen image model, with positive feedback and inquiries about whether the images were generated via prompt or image edit.
5.  ["When this was the pinnacle of AI art" (details in comments)](https://i.redd.it/dwiq8ln5bpxf1.png) (Score: 3)
    * The user reflects on the early days of Stable Diffusion, specifically version 1.3, and the effort required to achieve high-quality images at the time. They recreate an image using the old model and detail the process.
6.  [Looking for a simple WAN Upscale](https://www.reddit.com/r/StableDiffusion/comments/1ohljcg/looking_for_a_simple_wan_upscale/) (Score: 2)
    * A user is looking for a simple way to upscale using WAN. People suggest using seedvr2.
7.  [Wan 2.2 - gen mid/last frame only as preview before full gen?](https://www.reddit.com/r/StableDiffusion/comments/1ohddpx/wan_22_gen_midlast_frame_only_as_preview_before/) (Score: 1)
    * User asks if there is a way to generate the mid or last frame of a WAN 2.2 video to preview it before generating the whole video.
8.  [What to do if Flux Kontext changes the whole image when I only ask it to change part?](https://www.reddit.com/r/StableDiffusion/comments/1ohoc6w/what_to_do_if_flux_kontext_changes_the_whole/) (Score: 1)
    * A user is experiencing issues with Flux Kontext changing the entire image when they only want to change a part of it and is looking for solutions.
9.  [Example dataset for Lora](https://www.reddit.com/r/StableDiffusion/comments/1ohntv0/example_dataset_for_lora/) (Score: 1)
    *  This thread discusses what kind of caption is needed depending on the model training. The user mentions that some people have had success with character loras without even having a tag other than a single trigger word, like the name of the character.
10. [Why Forge Neo not have Deepbooru Img2img script?](https://i.redd.it/ztclha6ozoxf1.jpeg) (Score: 0)
    * User is wondering why Forge Neo does not have Deepbooru Img2img script.
11. [I trained stable diffusion to generate pixel art](https://youtu.be/OdafuDeNMyM) (Score: 0)
    * User shares that he used his own script to create a lora trainer to train an image pixel lora for SD 1.5 and SDXL.
12. [This Bruce Wayne made by me solo fiction his costume is behind him don't worry](https://i.redd.it/n8brfgf04pxf1.jpeg) (Score: 0)
    * User shared an image of Bruce Wayne.
13. [Ostris AI-Tookit running super slow on 5090 (windows)](https://www.reddit.com/r/StableDiffusion/comments/1ohdc64/ostris_aitookit_running_super_slow_on_5090_windows/) (Score: 0)
    * User has an issue where Ostris AI-Toolkit is running super slow on 5090 windows.
14. [How can I improve image resolution with Nano Banana without changing the image too much?](https://www.reddit.com/r/StableDiffusion/comments/1ohf28f/how_can_i_improve_image_resolution_with_nano/) (Score: 0)
    * A user is asking how to improve image resolution with Nano Banana without changing the image too much.
15. [Illustrious model showdown](https://www.reddit.com/r/StableDiffusion/comments/1ohhbpy/illustrious_model_showdown/) (Score: 0)
    * User is discussing different Illustrious models.
16. [merging checkpoints and lora with comfyui](https://www.reddit.com/r/StableDiffusion/comments/1ohi64o/merging_checkpoints_and_lora_with_comfyui/) (Score: 0)
    * User is discussing merging checkpoints and lora with comfyui.
17. [Do I need to reinstall AI Software like stable difusion, comfyui, WAN, if a upgrade my entire pc?](https://www.reddit.com/r/StableDiffusion/comments/1ohjgin/do_i_need_to_reinstall_ai_software_like_stable/) (Score: 0)
    * User is asking if they need to reinstall AI Software like stable difusion, comfyui, WAN, if they upgrade their entire PC.
18. ["viral" doorbell cam style videos in Wan 2.2?](https://www.reddit.com/r/StableDiffusion/comments/1ohmmtd/viral_doorbell_cam_style_videos_in_wan_22/) (Score: 0)
    * User is asking how to create "viral" doorbell cam style videos in Wan 2.2.

# Detailed Analysis by Thread
**[Tried longer videos with WAN 2.2 Animate (Score: 236)](https://v.redd.it/xusemoun9oxf1)**
*  **Summary:**  A user showcased longer videos created with WAN 2.2 Animate. Other users inquired about the workflow, compared the real and AI model, and commented on the quality of animation and expressions.
*  **Emotion:** The overall emotional tone is neutral with some positive sentiments expressed by users who thought the video was cool or thanked the poster for the shoutout. There's also some slightly negative sentiment regarding whether starting with a similar model is cheating.
*  **Top 3 Points of View:**
    * Some users are impressed by the animation and express positive feedback.
    * Others are curious about the workflow used to create the videos.
    * Some users questioned if the generated video is a form of cheating.

**[Midjourny V7 vs HiDream l1 vs DALLE3 vs Flux Dev (Score: 21)](https://www.reddit.com/gallery/1ohebfy)**
*  **Summary:**  The post compares image outputs from various AI models (Midjourney V7, HiDream l1, DALLE3, and Flux Dev). Users are discussing the strengths and weaknesses of each for different prompts and subjects.
*  **Emotion:** The emotional tone is generally positive, with people expressing interest in the comparison and offering opinions on which model performs best.
*  **Top 3 Points of View:**
    * HiDream is considered the best by some users.
    * Some users appreciate the comparison between different models.
    * One user inquired about how to post images with better quality.

**[A request to anyone training new models: please let this composition die (Score: 17)](https://www.reddit.com/gallery/1ohi83c)**
*  **Summary:**  The post expresses frustration with the repetitive "cyberpunk" composition commonly generated by AI models. This leads to a discussion about overused aesthetics and the need for more diverse and interesting outputs.
*  **Emotion:** The overall tone is neutral. There's a hint of frustration in the original post and some comments.
*  **Top 3 Points of View:**
    * The poster requests that trainers of new models avoid the overused cyberpunk aesthetic.
    * Some agree that this composition is overused and needs to be replaced.
    * Others believe the composition is a valuable style comparison point.

**[Just a few qwen experiments. (Score: 17)](https://www.reddit.com/gallery/1ohkd4k)**
*  **Summary:** This thread showcases experiments with the Qwen image model, with positive feedback and inquiries about whether the images were generated via prompt or image edit.
*  **Emotion:** The emotional tone is predominantly positive, with users expressing admiration for the results.
*  **Top 3 Points of View:**
    * Users are impressed with the images generated by Qwen.
    * Some inquire whether the images were created via prompt or image edit.
    * Others are happy to see people posting their experiments.

**["When this was the pinnacle of AI art" (details in comments) (Score: 3)](https://i.redd.it/dwiq8ln5bpxf1.png)**
*  **Summary:**  The user reflects on the early days of Stable Diffusion, specifically version 1.3, and the effort required to achieve high-quality images at the time. They recreate an image using the old model and detail the process.
*  **Emotion:** The overall tone is neutral and nostalgic.
*  **Top 3 Points of View:**
    * The main point is to highlight the progress made in AI art generation.
    * The user shares their experience and process of creating art with older models.
    * The post is intended as a blast from the past.

**[Looking for a simple WAN Upscale (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1ohljcg/looking_for_a_simple_wan_upscale/)**
*  **Summary:** A user is looking for a simple way to upscale using WAN. People suggest using seedvr2.
*  **Emotion:** The overall tone is positive.
*  **Top 3 Points of View:**
    * The user is looking for a simple way to upscale using WAN.
    * The user is impressed by the results of seedvr2.

**[Wan 2.2 - gen mid/last frame only as preview before full gen? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ohddpx/wan_22_gen_midlast_frame_only_as_preview_before/)**
*  **Summary:** User asks if there is a way to generate the mid or last frame of a WAN 2.2 video to preview it before generating the whole video.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is asking if there is a way to generate the mid or last frame of a WAN 2.2 video to preview it before generating the whole video.
    * The encoder encodes the whole 81 latents and passes one of them to a sampler to render one step of the whole frame. The sampler renders the latent frame and passes it to the next set of samplers that finish the job until denoising is.

**[What to do if Flux Kontext changes the whole image when I only ask it to change part? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ohoc6w/what_to_do_if_flux_kontext_changes_the_whole/)**
*  **Summary:** A user is experiencing issues with Flux Kontext changing the entire image when they only want to change a part of it and is looking for solutions.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * The user is experiencing issues with Flux Kontext changing the entire image when they only want to change a part of it.
    * For selection, use an object detection/segmentation model, Florence-2 or similar.
    * Use inpainting.

**[Example dataset for Lora (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1ohntv0/example_dataset_for_lora/)**
*  **Summary:**  This thread discusses what kind of caption is needed depending on the model training. The user mentions that some people have had success with character loras without even having a tag other than a single trigger word, like the name of the character.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * The type of caption you need depends on the model you're training on.
    * Some people have success with character loras without even having a tag.
    * CeFurkan has examples of a training set that are on purpose not great, so that he can show what's possible with them.

**[Why Forge Neo not have Deepbooru Img2img script? (Score: 0)](https://i.redd.it/ztclha6ozoxf1.jpeg)**
*  **Summary:** User is wondering why Forge Neo does not have Deepbooru Img2img script.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is wondering why Forge Neo does not have Deepbooru Img2img script.

**[I trained stable diffusion to generate pixel art (Score: 0)](https://youtu.be/OdafuDeNMyM)**
*  **Summary:** User shares that he used his own script to create a lora trainer to train an image pixel lora for SD 1.5 and SDXL.
*  **Emotion:** The overall tone is positive.
*  **Top 3 Points of View:**
    * User shares that he used his own script to create a lora trainer to train an image pixel lora for SD 1.5 and SDXL.

**[This Bruce Wayne made by me solo fiction his costume is behind him don't worry (Score: 0)](https://i.redd.it/n8brfgf04pxf1.jpeg)**
*  **Summary:** User shared an image of Bruce Wayne.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User shared an image of Bruce Wayne.

**[Ostris AI-Tookit running super slow on 5090 (windows) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ohdc64/ostris_aitookit_running_super_slow_on_5090_windows/)**
*  **Summary:** User has an issue where Ostris AI-Toolkit is running super slow on 5090 windows.
*  **Emotion:** The overall tone is negative.
*  **Top 3 Points of View:**
    * User has an issue where Ostris AI-Toolkit is running super slow on 5090 windows.
    * There is an issue with not calling for full GPU power on the PC.
    * It sounds like you might be filling the card's VRAM and it's offloading to CPU or regular RAM.

**[How can I improve image resolution with Nano Banana without changing the image too much? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ohf28f/how_can_i_improve_image_resolution_with_nano/)**
*  **Summary:** A user is asking how to improve image resolution with Nano Banana without changing the image too much.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is asking how to improve image resolution with Nano Banana without changing the image too much.

**[Illustrious model showdown (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ohhbpy/illustrious_model_showdown/)**
*  **Summary:** User is discussing different Illustrious models.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is discussing different Illustrious models.

**[merging checkpoints and lora with comfyui (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ohi64o/merging_checkpoints_and_lora_with_comfyui/)**
*  **Summary:** User is discussing merging checkpoints and lora with comfyui.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is discussing merging checkpoints and lora with comfyui.

**[Do I need to reinstall AI Software like stable difusion, comfyui, WAN, if a upgrade my entire pc? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ohjgin/do_i_need_to_reinstall_ai_software_like_stable/)**
*  **Summary:** User is asking if they need to reinstall AI Software like stable difusion, comfyui, WAN, if they upgrade their entire PC.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is asking if they need to reinstall AI Software like stable difusion, comfyui, WAN, if they upgrade their entire PC.

**["viral" doorbell cam style videos in Wan 2.2? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1ohmmtd/viral_doorbell_cam_style_videos_in_wan_22/)**
*  **Summary:** User is asking how to create "viral" doorbell cam style videos in Wan 2.2.
*  **Emotion:** The overall tone is neutral.
*  **Top 3 Points of View:**
    * User is asking how to create "viral" doorbell cam style videos in Wan 2.2.
