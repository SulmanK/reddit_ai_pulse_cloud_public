---
title: "Stable Diffusion Subreddit"
date: "2025-10-28"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["AI", "stablediffusion", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] Quillworks SimpleShade V4 - Free to Download](https://www.reddit.com/gallery/1oiai10) (Score: 85)
    *   A discussion about a new version of the Quillworks SimpleShade model, with users providing feedback on its quality, accessibility, and training process.
2.  [How did I know that OP doesn't know anything about AI](https://i.redd.it/q8xamyv3xuxf1.jpeg) (Score: 84)
    *   Users are debating the extent to which recent AI advancements are being accurately represented to the public, with some expressing concerns about sensationalism and a lack of understanding.
3.  [What free ai text-to-video generation tool is the closest to SORA or VEO? i wanna make shi like this](https://v.redd.it/niq5bd5czvxf1) (Score: 24)
    *   Users are discussing the current state of free AI text-to-video generation tools, comparing them to advanced models like SORA and VEO, and recommending tools like WAN2.2
4.  [Nitro-E: 300M params means 18 img/s, and fast train/finetune](https://huggingface.co/amd/Nitro-E) (Score: 11)
    *   A thread about the Nitro-E model, highlighting its speed and training efficiency.
5.  [One of each is my original and the other is generated with Qwen image and a trained lora after my style.](https://www.reddit.com/gallery/1oifnik) (Score: 5)
    *   A user is showcasing images generated with Qwen and a trained LoRA to replicate their photographic style, with other users giving feedback on the results and the capabilities of LoRA.
6.  [need help w/ makeup transfer lora – kinda confused about dataset setup](https://www.reddit.com/r/StableDiffusion/comments/1oih9go/need_help_w_makeup_transfer_lora_kinda_confused/) (Score: 1)
    *   A user seeks advice on setting up a dataset for a makeup transfer LoRA, with other users providing guidance on the required image formats and models to use.
7.  [Question: WAN 2.2 Fun Control combined with Blender output (depth and canny)](https://www.reddit.com/r/StableDiffusion/comments/1oih20a/question_wan_22_fun_control_combined_with_blender/) (Score: 1)
    *   A discussion on combining WAN 2.2 with Blender output for video generation.
8.  [Chroma v.s. Pony v7: Pony7 barely under control, not predictable at all, thousands of possibilities yet none is what I want](https://www.reddit.com/gallery/1oicvuq) (Score: 0)
    *   A comparison of the Chroma and Pony v7 models, with a user expressing frustration with the lack of control and predictability of Pony v7.
9.  [How good is the worklow with comfyui?](https://www.reddit.com/r/StableDiffusion/comments/1oiiz6y/how_good_is_the_worklow_with_comfyui/) (Score: 0)
    *   A discussion about the ComfyUI workflow, covering topics such as image-to-image transfers, model recommendations, and the use of LoRAs.
10. [Is this level of consistency achieved only with closed source models?](https://www.reddit.com/gallery/1oifedg) (Score: 0)
    *   Users are discussing methods to achieve consistent image generation, including the use of Seedream, Qwen Image, LoRAs, and specific training processes.
11. [Image with T2V](https://www.reddit.com/r/StableDiffusion/comments/1oiajsh/image_with_t2v/) (Score: 0)
    *   A user asks about using images with T2V models and adding LoRAs.
12. [Colleges teaching how to create?](https://www.reddit.com/r/StableDiffusion/comments/1oibt9c/colleges_teaching_how_to_create/) (Score: 0)
    *   A discussion about whether colleges are teaching how to create with generative AI.
13. [Best comfyui work flow for image to video action/horror movies (local)](https://www.reddit.com/r/StableDiffusion/comments/1oidxez/best_comfyui_work_flow_for_image_to_video/) (Score: 0)
    *   A user is looking for the best ComfyUI workflow for image-to-video generation for action/horror movies.
14. [Wich AI is the best to clothing shop](https://www.reddit.com/r/StableDiffusion/comments/1oietu9/wich_ai_is_the_best_to_clothing_shop/) (Score: 0)
    *   A discussion about the best AI for clothing shops, including legal implications and recommendations.
15. [Tips for generating realistic crowd or real-life scene photos with people?](https://www.reddit.com/gallery/1oic1d0) (Score: 0)
    *   A user is asking for tips on generating realistic crowds or real-life scene photos with people, and others recommend models and manual editing techniques.
16. [E-commerce Fetish Wear Store - Using AI for Product Images/Vids?](https://www.reddit.com/r/StableDiffusion/comments/1oihl07/ecommerce_fetish_wear_store_using_ai_for_product/) (Score: 0)
    *   A user asks about using AI for product images and videos for an e-commerce fetish wear store, and they are recommended uncensored models like Wan 2.2 and Flux Kontext.

# Detailed Analysis by Thread
**[ [D] Quillworks SimpleShade V4 - Free to Download (Score: 85)](https://www.reddit.com/gallery/1oiai10)**
*  **Summary:** Users are discussing the new Quillworks SimpleShade V4 model, providing feedback on its quality, accessibility, and training process, as well as expressing their experiences using the model for local training and suggesting improvements.
*  **Emotion:** The overall emotional tone is neutral, with instances of positive sentiment expressing appreciation for the model, and negative sentiment criticizing the model's documentation and face structure.
*  **Top 3 Points of View:**
    *   The new version of the model is a significant improvement.
    *   The model's documentation and promotional material contain too much fluff and should be more concise.
    *   The model's facial structure has a unique look that may not appeal to everyone.

**[How did I know that OP doesn't know anything about AI (Score: 84)](https://i.redd.it/q8xamyv3xuxf1.jpeg)**
*  **Summary:** Users are debating the extent to which recent AI advancements are being accurately represented to the public, with some expressing concerns about sensationalism, misinformation, and a lack of understanding, while others are sarcastically joking about AI.
*  **Emotion:** The overall emotional tone is negative, reflecting frustration with the misrepresentation of AI and the spread of misinformation.
*  **Top 3 Points of View:**
    *   The public is being manipulated by AI nonsense due to a lack of understanding.
    *   Sensationalist media and posts contribute to the problem.
    *   The term "AI" has become a meaningless buzzword.

**[What free ai text-to-video generation tool is the closest to SORA or VEO? i wanna make shi like this (Score: 24)](https://v.redd.it/niq5bd5czvxf1)**
*  **Summary:** Users are discussing the current state of free AI text-to-video generation tools, comparing them to advanced models like SORA and VEO, and recommending tools like WAN2.2. They also discuss the hardware requirements and workflow for creating videos with these tools.
*  **Emotion:** The overall emotional tone is neutral, with some positive sentiment expressing amusement at the sample video and excitement about the potential of WAN2.2.
*  **Top 3 Points of View:**
    *   No free tool currently matches the capabilities of SORA or VEO.
    *   WAN2.2 is the best available free option, but requires significant work and powerful hardware.
    *   The workflow for creating videos with current tools involves combining multiple techniques and tools, similar to how movies are made.

**[Nitro-E: 300M params means 18 img/s, and fast train/finetune (Score: 11)](https://huggingface.co/amd/Nitro-E)**
*  **Summary:** A thread about the Nitro-E model, highlighting its speed and training efficiency.
*  **Emotion:** The overall emotional tone is neutral, focusing on factual information about the model.
*  **Top 2 Points of View:**
    *   Nitro-E trains quickly from scratch.
    *   The model hasn't had a lot of samples generated.

**[One of each is my original and the other is generated with Qwen image and a trained lora after my style. (Score: 5)](https://www.reddit.com/gallery/1oifnik)**
*  **Summary:** A user is showcasing images generated with Qwen and a trained LoRA to replicate their photographic style, with other users giving feedback on the results and the capabilities of LoRA.
*  **Emotion:** The overall emotional tone is positive, with users praising the image quality and the effectiveness of the LoRA.
*  **Top 2 Points of View:**
    *   LoRA is capable of capturing the original style.
    *   The original images can be distinguished by footsteps in the snow.

**[need help w/ makeup transfer lora – kinda confused about dataset setup (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1oih9go/need_help_w_makeup_transfer_lora_kinda_confused/)**
*  **Summary:** A user seeks advice on setting up a dataset for a makeup transfer LoRA, with other users providing guidance on the required image formats and models to use.
*  **Emotion:** The overall emotional tone is neutral, focusing on providing technical advice and guidance.
*  **Top 2 Points of View:**
    *   Kontext remove makeup lora can be used to create a before and after dataset.
    *   The updated qwen edit model can have multiple input and output images.

**[Question: WAN 2.2 Fun Control combined with Blender output (depth and canny) (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1oih20a/question_wan_22_fun_control_combined_with_blender/)**
*  **Summary:** A discussion on combining WAN 2.2 with Blender output for video generation.
*  **Emotion:** The overall emotional tone is neutral, offering suggestions and sharing experiences with similar approaches.
*  **Top 2 Points of View:**
    *   Using the render in blender as an input video guided to video is possible.
    *   The Image Blend node in Wan 2.1 VACE works with Fun Control 2.2 Fun VACE.

**[Chroma v.s. Pony v7: Pony7 barely under control, not predictable at all, thousands of possibilities yet none is what I want (Score: 0)](https://www.reddit.com/gallery/1oicvuq)**
*  **Summary:** A comparison of the Chroma and Pony v7 models, with a user expressing frustration with the lack of control and predictability of Pony v7.
*  **Emotion:** The overall emotional tone is negative, reflecting dissatisfaction with Pony v7 and its lack of prompt adherence.
*  **Top 3 Points of View:**
    *   Pony7 needs a "subject" word to "trigger" its actor identity.
    *   Chroma is probably gonna benefit from negative prompts a lot more.
    *   Both models look bad and Chroma looks like a low resolution image upscaled.

**[How good is the worklow with comfyui? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oiiz6y/how_good_is_the_worklow_with_comfyui/)**
*  **Summary:** A discussion about the ComfyUI workflow, covering topics such as image-to-image transfers, model recommendations, and the use of LoRAs.
*  **Emotion:** The overall emotional tone is neutral, providing information and advice on using ComfyUI and related tools.
*  **Top 3 Points of View:**
    *   There are edit models (Flux Kontext/Qwen Image Edit) but they can have LoRAs for styles and accept references.
    *   ChatGPT is too slow to have a longer chat.
    *   Comfy is more complicated than GPT.

**[Is this level of consistency achieved only with closed source models? (Score: 0)](https://www.reddit.com/gallery/1oifedg)**
*  **Summary:** Users are discussing methods to achieve consistent image generation, including the use of Seedream, Qwen Image, LoRAs, and specific training processes.
*  **Emotion:** The overall emotional tone is positive, offering potential solutions and expressing confidence in achieving consistent results with open-source models.
*  **Top 3 Points of View:**
    *   Qwen can do it with some loras and tweaks.
    *   Seedream with a reference image gives amazing consistency.
    *   Qwen Image (with LoRA) and Qwen Image Edit can also achieve similarly good consistency.

**[Image with T2V (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oiajsh/image_with_t2v/)**
*  **Summary:** A user asks about using images with T2V models and adding LoRAs.
*  **Emotion:** The overall emotional tone is neutral, providing a technical explanation.
*  **Top 1 Point of View:**
    *   You can't use images with T2V models.

**[Colleges teaching how to create? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oibt9c/colleges_teaching_how_to_create/)**
*  **Summary:** A discussion about whether colleges are teaching how to create with generative AI.
*  **Emotion:** The overall emotional tone is slightly negative, with skepticism about the extent to which colleges are teaching generative AI and concerns about the rapid obsolescence of knowledge in the field.
*  **Top 3 Points of View:**
    *   There is no formal educational curriculum teaching AI specifically.
    *   Kind of pointless, when you advance to third year almost everything you learnt at the first will be obsolete.
    *   YouTube University is an alternative learning resource.

**[Best comfyui work flow for image to video action/horror movies (local) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oidxez/best_comfyui_work_flow_for_image_to_video/)**
*  **Summary:** A user is looking for the best ComfyUI workflow for image-to-video generation for action/horror movies.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 1 Point of View:**
    *   You definitely want to then use wan2.2 at full steps and skip lightning or at least go with the tripple ksampler setup.

**[Wich AI is the best to clothing shop (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oietu9/wich_ai_is_the_best_to_clothing_shop/)**
*  **Summary:** A discussion about the best AI for clothing shops, including legal implications and recommendations.
*  **Emotion:** The overall emotional tone is neutral, providing practical advice and legal information.
*  **Top 2 Points of View:**
    *   Qwen image edit on comfyui is a good tool.
    *   The New York Fashion Workers Act requires brands to get written consent from a model before creating a digital replica of them with AI.

**[Tips for generating realistic crowd or real-life scene photos with people? (Score: 0)](https://www.reddit.com/gallery/1oic1d0)**
*  **Summary:** A user is asking for tips on generating realistic crowds or real-life scene photos with people, and others recommend models and manual editing techniques.
*  **Emotion:** The overall emotional tone is neutral, providing helpful suggestions and resources.
*  **Top 2 Points of View:**
    *   Manual editing is needed for high quality crowd shots.
    *   cineReal IL Studio gives great results.

**[E-commerce Fetish Wear Store - Using AI for Product Images/Vids? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1oihl07/ecommerce_fetish_wear_store_using_ai_for_product/)**
*  **Summary:** A user asks about using AI for product images and videos for an e-commerce fetish wear store, and they are recommended uncensored models like Wan 2.2 and Flux Kontext.
*  **Emotion:** The overall emotional tone is neutral, offering a specific recommendation.
*  **Top 1 Point of View:**
    *   Wan 2.2 for images is basically uncensored and Flux Kontext for image editing is also less censored than nano banana.
