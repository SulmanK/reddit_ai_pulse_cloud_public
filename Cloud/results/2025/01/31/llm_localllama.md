---
title: "LocalLLaMA Subreddit"
date: "2025-01-31"
description: "Analysis of top discussions and trends in the localllama subreddit"
tags: ["AI", "LLM", "DeepSeek", "LocalLLaMA"]
---

# Overall Ranking and Top Discussions
1.  [[D] Deepseek R1 is now hosted by Nvidia](https://i.redd.it/1zufl131vdge1.jpeg) (Score: 120)
    * This thread is about the news that Deepseek R1 is now hosted by Nvidia, with users discussing the implications, performance, and pricing.
2.  [DeepSeek R1 takes #1 overall on a Creative Short Story Writing Benchmark](https://i.redd.it/i2p0m8em4ege1.png) (Score: 27)
    * This discussion centers around DeepSeek R1's top performance in a creative writing benchmark, with comparisons to other models and concerns about the evaluation method.
3.  [Relatively budget 671B R1 CPU inference workstation setup, 2-3T/s](https://www.reddit.com/r/LocalLLaMA/comments/1ieosbx/relatively_budget_671b_r1_cpu_inference/) (Score: 11)
    * Users are discussing hardware setups for running the R1 model, specifically the cost and performance of different CPUs.
4.  [One of the most illuminating ways to assess these models to me so far](https://www.reddit.com/r/LocalLLaMA/comments/1ien50m/one_of_the_most_illuminating_ways_to_assess_these/) (Score: 5)
    *  This thread is about assessing AI models, and the users ask for more information in the form of articles.
5.  [The O3 mini is now available in two flavors.](https://www.reddit.com/r/LocalLLaMA/comments/1ien3fv/the_o3_mini_is_now_available_in_two_flavors/) (Score: 2)
    * This thread discusses the availability of the O3 mini model, its speed, and suitability for reasoning tasks.
6.  [DeepSeek AI blocked by Italian authorities](https://www.euronews.com/next/2025/01/31/deepseek-ai-blocked-by-italian-authorities-as-others-member-states-open-probes) (Score: 2)
    *  The discussion revolves around the news that DeepSeek AI has been blocked in Italy, with some users noting the news is old.
7.  [NASA becomes latest federal agency to block China's DeepSeek on 'security and privacy concerns'](https://www.cnbc.com/2025/01/31/nasa-becomes-latest-federal-agency-to-block-chinas-deepseek.html) (Score: 1)
    * This thread discusses NASA blocking DeepSeek due to security concerns, and raises points about cloud usage in government.
8.  [Simple web app to run local instances of R1](https://www.reddit.com/r/LocalLLaMA/comments/1ienvtp/simple_web_app_to_run_local_instances_of_r1/) (Score: 1)
    * This is about the UI of a web application to run local instances of the R1 model.
9. [Cheapest way to run R1 locally?](https://www.reddit.com/r/LocalLLaMA/comments/1ieo4ik/cheapest_way_to_run_r1_locally/) (Score: 1)
    * This thread asks for advice on running the R1 model locally at a low cost.
10. [Smallest, cheapest option for running local LLMs.](https://www.reddit.com/r/LocalLLaMA/comments/1ieotry/smallest_cheapest_option_for_running_local_llms/) (Score: 1)
    * Users are asking about trade-offs between size and speed when running local LLMs.
11. [Is there any proof that deep seek was trained on Open AI’s data?](https://www.reddit.com/r/LocalLLaMA/comments/1iem9q4/is_there_any_proof_that_deep_seek_was_trained_on/) (Score: 0)
    * The discussion centers around the possibility of DeepSeek being trained on OpenAI data, and some users point out industry standards around using data from other models.
12. [OpenC/crypto-gpt-o3-mini: Worth a look for AI + Crypto?](https://www.reddit.com/r/LocalLLaMA/comments/1ien88y/openccryptogpto3mini_worth_a_look_for_ai_crypto/) (Score: 0)
    * Users express skepticism about a new AI model related to crypto, pointing to lack of details and broken links.

# Detailed Analysis by Thread
**[ [D] Deepseek R1 is now hosted by Nvidia (Score: 120)](https://i.redd.it/1zufl131vdge1.jpeg)**
*   **Summary:** This thread discusses the news of Deepseek R1 being hosted by Nvidia. Users are asking about the microservice, if it works with OpenAI clients, pricing, and performance compared to alternatives.
*   **Emotion:** The overall emotional tone is neutral, with users primarily seeking information and sharing observations.
*   **Top 3 Points of View:**
    *   Users are curious about the specific details of Nvidia's microservice for Deepseek R1.
    *   Some users are concerned with compatibility with existing OpenAI clients and APIs.
    *   Users are comparing the performance of Deepseek R1 on Nvidia's platform to other providers like Azure.

**[ DeepSeek R1 takes #1 overall on a Creative Short Story Writing Benchmark (Score: 27)](https://i.redd.it/i2p0m8em4ege1.png)**
*   **Summary:** This thread discusses DeepSeek R1's top ranking in a creative writing benchmark. Users discuss the benchmark methodology, express surprise at OpenAI's models performing poorly, and share anecdotal experiences of R1's capabilities.
*   **Emotion:** The emotional tone is mostly neutral, with some positive sentiments about DeepSeek R1's performance.
*   **Top 3 Points of View:**
    *   Some users are skeptical about the use of LLMs to grade the creative writing benchmark.
    *   Users are surprised that OpenAI's models underperformed in this particular benchmark.
    *   Some users are impressed with DeepSeek R1's performance in writing tasks.

**[ Relatively budget 671B R1 CPU inference workstation setup, 2-3T/s (Score: 11)](https://www.reddit.com/r/LocalLLaMA/comments/1ieosbx/relatively_budget_671b_r1_cpu_inference/)**
*   **Summary:** The discussion revolves around the hardware requirements and costs for running the R1 model, particularly focusing on CPU setups and price comparisons.
*   **Emotion:** The overall tone is neutral, with some frustration expressed about the pricing discrepancies of CPUs.
*   **Top 3 Points of View:**
     * Users are finding discrepancies in the prices of certain CPUs.
    *  Some users consider older hardware to be not viable for the task.
    * The focus is on getting the most performance for the budget.

**[ One of the most illuminating ways to assess these models to me so far (Score: 5)](https://www.reddit.com/r/LocalLLaMA/comments/1ien50m/one_of_the_most_illuminating_ways_to_assess_these/)**
*   **Summary:** The thread is about sharing ways to assess AI models. The only responses are asking for the related articles.
*   **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
    * The thread is asking to share resources that help with the assessment of models.

**[ The O3 mini is now available in two flavors. (Score: 2)](https://www.reddit.com/r/LocalLLaMA/comments/1ien3fv/the_o3_mini_is_now_available_in_two_flavors/)**
*   **Summary:** This thread discusses the availability of the O3 mini model, API access, speed, and perceived suitability for reasoning tasks. Some users report not seeing it in interfaces.
*   **Emotion:** The emotional tone is mixed, with some excitement about the model's potential and some confusion about its availability.
*   **Top 3 Points of View:**
    *   The O3 mini model is considered fast and suitable for reasoning tasks, with some users having API access.
    *   Users are experiencing inconsistencies with the availability of the model in different platforms.
    *   Some users see it as a good upgrade to previous models.

**[ DeepSeek AI blocked by Italian authorities (Score: 2)](https://www.euronews.com/next/2025/01/31/deepseek-ai-blocked-by-italian-authorities-as-others-member-states-open-probes)**
*   **Summary:** The thread discusses the news of DeepSeek AI being blocked by Italian authorities, some users state that the news is old.
*   **Emotion:** The tone is primarily neutral, with some users stating the information is old and that the service is still working.
*   **Top 3 Points of View:**
    * The news is considered old by some users.
    * Users note the website still works, potentially only blocking the app.
    * Some users make a comment "they know who daddy is", which is a positive view of the news.

**[ NASA becomes latest federal agency to block China's DeepSeek on 'security and privacy concerns' (Score: 1)](https://www.cnbc.com/2025/01/31/nasa-becomes-latest-federal-agency-to-block-chinas-deepseek.html)**
*   **Summary:** This thread is about NASA blocking DeepSeek for security reasons. Users debate whether the government should host their own models.
*   **Emotion:** The emotional tone is neutral, with concern over security and privacy.
*   **Top 3 Points of View:**
    *   Some users feel NASA should self-host models instead of using general-purpose models.
    *   Users note some companies have general policies against online models that might train on their data.
    *   Some see this as an issue with cloud services in government in general.

**[ Simple web app to run local instances of R1 (Score: 1)](https://www.reddit.com/r/LocalLLaMA/comments/1ienvtp/simple_web_app_to_run_local_instances_of_r1/)**
*   **Summary:** This thread is about the UI of a web application to run local instances of the R1 model.
*  **Emotion:** The emotional tone is neutral.
*   **Top 3 Points of View:**
     * The thread is mostly a demonstration of the web application.

**[ Cheapest way to run R1 locally? (Score: 1)](https://www.reddit.com/r/LocalLLaMA/comments/1ieo4ik/cheapest_way_to_run_r1_locally/)**
*   **Summary:** The discussion is about ways to run the R1 model locally at a low cost. Users share resources and potential hardware options.
*   **Emotion:** The overall emotional tone is neutral, with users exchanging information.
*   **Top 3 Points of View:**
    *  Users discuss memory usage of quantized versions of R1.
    * Users suggest hardware configurations to run the model.
    * Users mention a specific hardware configuration as the minimum.

**[ Smallest, cheapest option for running local LLMs. (Score: 1)](https://www.reddit.com/r/LocalLLaMA/comments/1ieotry/smallest_cheapest_option_for_running_local_llms/)**
*  **Summary:** This thread discusses the trade-offs between the size and speed of models that can run locally.
*  **Emotion:** The tone is neutral, with the focus on trading off performance.
*   **Top 3 Points of View:**
    * The users are concerned with both the model size and speed, trading off one for the other.

**[ Is there any proof that deep seek was trained on Open AI’s data? (Score: 0)](https://www.reddit.com/r/LocalLLaMA/comments/1iem9q4/is_there_any_proof_that_deep_seek_was_trained_on/)**
*   **Summary:** Users discuss the possibility of DeepSeek being trained on OpenAI's data, citing news articles and comparing responses from the models. Some point out industry standards of using synthetic data from other models.
*   **Emotion:** The emotional tone is neutral, with some skepticism and debate.
*   **Top 3 Points of View:**
    *   There is debate about whether DeepSeek used OpenAI's data, with some calling it "distillation".
    *   Some users consider that it is normal for companies to use data generated by GPT-4 models.
    *   Some users mention that the models are too similar to each other.

**[ OpenC/crypto-gpt-o3-mini: Worth a look for AI + Crypto? (Score: 0)](https://www.reddit.com/r/LocalLLaMA/comments/1ien88y/openccryptogpto3mini_worth_a_look_for_ai_crypto/)**
*   **Summary:** This thread discusses a new model, with users pointing out missing details, dead links and questioning its legitimacy.
*   **Emotion:** The tone is skeptical, with users noting that the information is incomplete.
*   **Top 3 Points of View:**
    *   Users are skeptical about the model due to the name and lack of details.
    *   Users note the links provided are not working.
    * Users consider it might be a fake model.
