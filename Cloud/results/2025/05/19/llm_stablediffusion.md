---
title: "Stable Diffusion Subreddit"
date: "2025-05-19"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Video Extension using VACE 14b](https://v.redd.it/o2us835zwq1f1) (Score: 82)
    *   Discussion about using VACE 14b for video extension, with some users sharing their experiences and results.
2.  [Real time generation on LTXV 13b distilled](https://v.redd.it/1wrqye0goq1f1) (Score: 43)
    *   Discussion about real-time image generation using a distilled model, with mixed feedback on its performance.
3.  [Vace 14B + CausVid (480p Video Gen in Under 1 Minute!) Demos, Workflows (Native&Wrapper), and Guide](https://youtu.be/Yd4P2K0Bgqg) (Score: 37)
    *   Discussion about using Vace 14B and CausVid for fast video generation, with users sharing workflows and experiences.
4.  [So. Who's buying the Arc Pro B60? 25GB for 500](https://www.reddit.com/r/StableDiffusion/comments/1kqhq3d/so_whos_buying_the_arc_pro_b60_25gb_for_500/) (Score: 36)
    *   Discussion about the potential of the Intel Arc Pro B60 GPU for stable diffusion, considering its price and software support.
5.  [It took 1 year for really good SDXL models to come out. Maybe SD 3.5 medium and large are trainable, but people gave up](https://www.reddit.com/r/StableDiffusion/comments/1kqcclo/it_took_1_year_for_really_good_sdxl_models_to/) (Score: 28)
    *   Discussion about the development and training of SDXL models, with some users sharing their experiences and results using sigma 3.5.
6.  [LORA training advice when dataset is less than optimal?](https://www.reddit.com/r/StableDiffusion/comments/1kqcrjh/lora_training_advice_when_dataset_is_less_than/) (Score: 8)
    *   Discussion about how to improve LORA training with the accidental trigger words, but put them in the negative prompt.
7.  [Causvid wan lora confirmed works well with CFG](https://www.reddit.com/r/StableDiffusion/comments/1kqgl4x/causvid_wan_lora_confirmed_works_well_with_cfg/) (Score: 8)
    *   Discussion about the CFG parameter to improve Lora's performance.
8.  [Just bit the bullet on a 5090...are there many AI tools/models still waiting to be updated to support 5 Series?](https://www.reddit.com/r/StableDiffusion/comments/1kqg6k3/just_bit_the_bullet_on_a_5090are_there_many_ai/) (Score: 7)
    *   Discussion about AI tools and models update to support 5 Series.
9.  [Buying new GPU, - options (Intel new 48GB B60)](https://www.reddit.com/r/StableDiffusion/comments/1kqkmcx/buying_new_gpu_options_intel_new_48gb_b60/) (Score: 2)
    *   Discussion about if the new Intel 48GB B60 GPU is a viable option.
10. [Dataset formats for Hunyuan Video LORAs](https://www.reddit.com/r/StableDiffusion/comments/1kqe91b/dataset_formats_for_hunyuan_video_loras/) (Score: 1)
    *   Discussion about the dataset formats for Hunyuan Video LORAs, such as lowering the FPS, the model will fill the gaps.
11. [upgrade to DDR5](https://www.reddit.com/r/StableDiffusion/comments/1kqerti/upgrade_to_ddr5/) (Score: 1)
    *   Discussion about upgrading to DDR5 and the effect it has on image generation.
12. [SDXL with 248 token length](https://www.reddit.com/r/StableDiffusion/comments/1kqjagy/sdxl_with_248_token_length/) (Score: 1)
    *   Discussion about the length of the token and curious if hacking on A1111 or Forge code could make this work.
13. [How do I incorporate inpainting into Workflow?](https://www.reddit.com/r/StableDiffusion/comments/1kqk7j6/how_do_i_incorporate_inpainting_into_workflow/) (Score: 1)
    *   Discussion on how to incorporate inpainting into Workflow.
14. [Charming AI Elf](https://www.reddit.com/gallery/1kqcp5f) (Score: 0)
    *   Discussion about an AI image of an elf and how long it took to work.
15. [Is the 12GB 5070 enough for just Illustrious, NoobAI, and image generation? How much vram does SDXL typically use?](https://www.reddit.com/r/StableDiffusion/comments/1kqdqqc/is_the_12gb_5070_enough_for_just_illustrious/) (Score: 0)
    *   Discussion on if 12GB of VRAM is enough for the models being asked about.

# Detailed Analysis by Thread
**[Video Extension using VACE 14b (Score: 82)](https://v.redd.it/o2us835zwq1f1)**
*  **Summary:** Discussion about using VACE 14b for video extension, with some users sharing their experiences and results.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Sharing video results of the extension.
    *   Sharing the process for video extension.
    *   Pointing out the visibility of the extension point in the video.

**[Real time generation on LTXV 13b distilled (Score: 43)](https://v.redd.it/1wrqye0goq1f1)**
*  **Summary:** Discussion about real-time image generation using a distilled model, with mixed feedback on its performance.
*  **Emotion:** The overall emotional tone is mixed, with both positive and negative sentiments expressed.
*  **Top 3 Points of View:**
    *   Expressing excitement about the speed of the generation.
    *   Reporting poor results and errors when trying the same workflow.

**[Vace 14B + CausVid (480p Video Gen in Under 1 Minute!) Demos, Workflows (Native&Wrapper), and Guide (Score: 37)](https://youtu.be/Yd4P2K0Bgqg)**
*  **Summary:** Discussion about using Vace 14B and CausVid for fast video generation, with users sharing workflows and experiences.
*  **Emotion:** The overall emotional tone is positive and neutral.
*  **Top 3 Points of View:**
    *   Questioning the memory requirements for the software.
    *   Questioning the number of reference images allowed.
    *   Praising the power and versatility of the tool.

**[So. Who's buying the Arc Pro B60? 25GB for 500 (Score: 36)](https://www.reddit.com/r/StableDiffusion/comments/1kqhq3d/so_whos_buying_the_arc_pro_b60_25gb_for_500/)**
*  **Summary:** Discussion about the potential of the Intel Arc Pro B60 GPU for stable diffusion, considering its price and software support.
*  **Emotion:** The overall emotional tone is mixed, with some optimism tempered by concerns about software support and CUDA compatibility.
*  **Top 3 Points of View:**
    *   The card's price and VRAM are attractive, making it worth considering despite potential drawbacks.
    *   The lack of CUDA support makes the card unusable for many in the Stable Diffusion community.
    *   Software support and optimization for Intel cards are uncertain but could improve.

**[It took 1 year for really good SDXL models to come out. Maybe SD 3.5 medium and large are trainable, but people gave up (Score: 28)](https://www.reddit.com/r/StableDiffusion/comments/1kqcclo/it_took_1_year_for_really_good_sdxl_models_to/)**
*  **Summary:** Discussion about the development and training of SDXL models, with some users sharing their experiences and results.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   SD 3.5 was made in bad faith and poisoned from the start
    *   SD3.5 medium has some decent models already "successful" in a way, but even the fine-tunes look exactly like SDXL.
    *   It's too expensive to train them！

**[LORA training advice when dataset is less than optimal? (Score: 8)](https://www.reddit.com/r/StableDiffusion/comments/1kqcrjh/lora_training_advice_when_dataset_is_less_than/)**
*  **Summary:** Discussion about how to improve LORA training with the accidental trigger words, but put them in the negative prompt.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Use masked training.
    *   Remove unwanted items with inpaint.
    *   In general, you need to work a bit for the solution to the problem.

**[Causvid wan lora confirmed works well with CFG (Score: 8)](https://www.reddit.com/r/StableDiffusion/comments/1kqgl4x/causvid_wan_lora_confirmed_works_well_with_cfg/)**
*  **Summary:** Discussion about the CFG parameter to improve Lora's performance.
*  **Emotion:** The overall emotional tone is positive and neutral.
*  **Top 3 Points of View:**
    *   Want another trick? Break the animation in two parts, 4 steps total.
    *   “Strength” ... are we talking “model strength” or “clip strength”. My Lora node has both.
    *   0.7 is more natural than 0.3 and 0.25 for me.

**[Just bit the bullet on a 5090...are there many AI tools/models still waiting to be updated to support 5 Series? (Score: 7)](https://www.reddit.com/r/StableDiffusion/comments/1kqg6k3/just_bit_the_bullet_on_a_5090are_there_many_ai/)**
*  **Summary:** Discussion about AI tools and models update to support 5 Series.
*  **Emotion:** The overall emotional tone is positive and neutral.
*  **Top 3 Points of View:**
    *   What do you mean by 'updated to support'?
    *   Invoke has a preview build (5.12.0rc1) that supports it now.
    *   It's a little harder and you might need to make sure you use the nightly newest versions of Pytorch ect but it seems very usable.

**[Buying new GPU, - options (Intel new 48GB B60) (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1kqkmcx/buying_new_gpu_options_intel_new_48gb_b60/)**
*  **Summary:** Discussion about if the new Intel 48GB B60 GPU is a viable option.
*  **Emotion:** The overall emotional tone is positive and neutral.
*  **Top 3 Points of View:**
    *   The new Intel GPUs are being sold as part of workstations that have an estimated price tag of 5k-10k.
    *   Honestly 5090s are dropping greatly in price, and would be better then the b60 because I think the dual GPU could give issues.
    *   As far as I know most models support only Nvidia cards.

**[Dataset formats for Hunyuan Video LORAs (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1kqe91b/dataset_formats_for_hunyuan_video_loras/)**
*  **Summary:** Discussion about the dataset formats for Hunyuan Video LORAs, such as lowering the FPS, the model will fill the gaps.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 1 Points of View:**
    *   If the motion you want to show can be shown in less than time, less frames = less training time. Resolution can be 512x512 or higher, I trained a Lora with GIFs and it worked.

**[upgrade to DDR5 (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1kqerti/upgrade_to_ddr5/)**
*  **Summary:** Discussion about upgrading to DDR5 and the effect it has on image generation.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   I have 64GB of DDR5 and it still goes to an absolute *crawl* if it spills over into it.
    *   DDR4's bandwidth is about 25GB/s, DDR5 is doubling the Bandwidth 50GB/s. which is 100% increase.
    *   If you're using System RAM to load models, you've already lost. It's swap-space at best.

**[SDXL with 248 token length (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1kqjagy/sdxl_with_248_token_length/)**
*  **Summary:** Discussion about the length of the token and curious if hacking on A1111 or Forge code could make this work.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 1 Points of View:**
    *   Thanks for sharing, i'm curious if some hacking on A1111 or Forge code could make this work.

**[How do I incorporate inpainting into Workflow? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1kqk7j6/how_do_i_incorporate_inpainting_into_workflow/)**
*  **Summary:** Discussion on how to incorporate inpainting into Workflow.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 1 Points of View:**
    *   This node will not continue workflow if mask is empty so you can manually draw mask and press run again without interrupting or letting it waste time

**[Charming AI Elf (Score: 0)](https://www.reddit.com/gallery/1kqcp5f)**
*  **Summary:** Discussion about an AI image of an elf and how long it took to work.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 2 Points of View:**
    *   She's beautiful.
    *   It took me sometime to make this work, so I went a bit crazy

**[Is the 12GB 5070 enough for just Illustrious, NoobAI, and image generation? How much vram does SDXL typically use? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1kqdqqc/is_the_12gb_5070_enough_for_just_illustrious/)**
*  **Summary:** Discussion on if 12GB of VRAM is enough for the models being asked about.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   A 16gb vram card plus 48-64gb of ram is midrange future proof.
    *   i run those on a 1070ti 8gb lol you're good
    *   This is enough, However, if you can get more vram GPU - please go for it.
