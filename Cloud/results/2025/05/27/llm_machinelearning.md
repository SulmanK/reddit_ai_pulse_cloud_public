---
title: "Machine Learning Subreddit"
date: "2025-05-27"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "NLP"]
---

# Overall Ranking and Top Discussions
1.  [[D] How long did it take to get an industry research job after PhD?](https://www.reddit.com/r/MachineLearning/comments/1kw7c3c/d_how_long_did_it_take_to_get_an_industry/) (Score: 107)
    *   Discussion about the time it takes for PhD graduates to secure industry research jobs, with varied experiences shared.
2.  [[R] AutoThink: Adaptive reasoning technique that improves local LLM performance by 43% on GPQA-Diamond](https://www.reddit.com/r/MachineLearning/comments/1kwqwpr/r_autothink_adaptive_reasoning_technique_that/) (Score: 43)
    *   Sharing of the new adaptive reasoning technique that improves local LLM performance.
3.  [[D] in GRPO is the KL divergence penalty applied at the token level or computed once for the whole sequence?](https://www.reddit.com/r/MachineLearning/comments/1kwcg96/d_in_grpo_is_the_kl_divergence_penalty_applied_at/) (Score: 37)
    *   Question regarding the application of the KL divergence penalty in GRPO, specifically whether it's applied at the token level or for the entire sequence.
4.  [[P] Zasper: an opensource High Performance IDE for Jupyter Notebooks](https://www.reddit.com/r/MachineLearning/comments/1kwic5r/p_zasper_an_opensource_high_performance_ide_for/) (Score: 35)
    *   Sharing of Zasper, an open-source IDE for Jupyter Notebooks, and discussing its features and potential replacements for existing tools.
5.  [[R] Panda: A pretrained forecast model for universal representation of chaotic dynamics](https://www.reddit.com/r/MachineLearning/comments/1kw7kip/r_panda_a_pretrained_forecast_model_for_universal/) (Score: 22)
    *   Discussion about PANDA framework and pretrained forecast model for universal representation of chaotic dynamics.
6.  [[D] Thinking about building a peer review tool for the community](https://www.reddit.com/r/MachineLearning/comments/1kwn8q3/d_thinking_about_building_a_peer_review_tool_for/) (Score: 4)
    *   Discussion about building a peer review tool for the community.
7.  [[D] How can I use embedding models to find similar items with controlled attribute variation? For example, finding a similar story where the progtagnist is female instead of male while story is as similar as possible or chicken is replaced by beef in a recipe index?](https://www.reddit.com/r/MachineLearning/comments/1kwfr7f/d_how_can_i_use_embedding_models_to_find_similar/) (Score: 2)
    *   Question about using embedding models to find similar items with controlled attribute variations.
8.  [[R] question about Neurips double-blind policy](https://www.reddit.com/r/MachineLearning/comments/1kwill3/r_question_about_neurips_doubleblind_policy/) (Score: 2)
    *   Question about NeurIPS double-blind policy.
9.  [[D] What's your embedding model update policy? Trying to settle a debate](https://www.reddit.com/r/MachineLearning/comments/1kwv5lx/d_whats_your_embedding_model_update_policy_trying/) (Score: 1)
    *   Discussion about embedding model update policies.
10. [[R] Invented a new AI reasoning framework called HDA2A and wrote a basic paper - Potential to be something massive - check it out](https://www.reddit.com/r/MachineLearning/comments/1kwlral/r_invented_a_new_ai_reasoning_framework_called/) (Score: 0)
    *   Discussion of the new AI reasoning framework.
11. [[D] The Emergence-Constraint Framework: A Model for Recursive Identity and Symbolic Behaviour in LLMs](https://www.reddit.com/r/MachineLearning/comments/1kwmtlz/d_the_emergenceconstraint_framework_a_model_for/) (Score: 0)
    *   Discussion about The Emergence-Constraint Framework.

# Detailed Analysis by Thread
**[[D] How long did it take to get an industry research job after PhD? (Score: 107)](https://www.reddit.com/r/MachineLearning/comments/1kw7c3c/d_how_long_did_it_take_to_get_an_industry/)**
*   **Summary:** The thread discusses the experiences of PhD graduates in securing industry research jobs, with varied timelines and strategies.
*   **Emotion:** The overall emotional tone is neutral, with some comments expressing gratitude and excitement, while others convey the challenges and efforts involved in the job search.
*   **Top 3 Points of View:**
    *   Some people had job offers lined up before or shortly after graduating.
    *   Others took several months of applying and interviewing.
    *   Networking and internships are valuable for securing positions.

**[[R] AutoThink: Adaptive reasoning technique that improves local LLM performance by 43% on GPQA-Diamond (Score: 43)](https://www.reddit.com/r/MachineLearning/comments/1kwqwpr/r_autothink_adaptive_reasoning_technique_that/)**
*   **Summary:** The thread shares a new adaptive reasoning technique that improves local LLM performance.
*   **Emotion:** The overall emotional tone is positive, with people expressing excitement.
*   **Top 3 Points of View:**
    *   The new reasoning technique allocates different amounts of computation based on the query.
    *   The results seem very cool.

**[[D] in GRPO is the KL divergence penalty applied at the token level or computed once for the whole sequence? (Score: 37)](https://www.reddit.com/r/MachineLearning/comments/1kwcg96/d_in_grpo_is_the_kl_divergence_penalty_applied_at/)**
*   **Summary:** The thread questions the application of the KL divergence penalty in GRPO.
*   **Emotion:** The overall emotional tone is neutral and informative, consisting of people discussing technical details of GRPO and KL divergence penalty.
*   **Top 3 Points of View:**
    *   The KL penalty is computed once for the entire output sequence.
    *   The token-wise formulation was dropped in the R1 paper.
    *   Sequence level loss is only during SFT.

**[[P] Zasper: an opensource High Performance IDE for Jupyter Notebooks (Score: 35)](https://www.reddit.com/r/MachineLearning/comments/1kwic5r/p_zasper_an_opensource_high_performance_ide_for/)**
*   **Summary:** The thread introduces Zasper, an open-source IDE for Jupyter Notebooks, and discusses its potential as a replacement for JupyterLab.
*   **Emotion:** The overall emotional tone is neutral, with curious and slightly positive sentiment.
*   **Top 3 Points of View:**
    *   The project is interesting, and people are thankful for the sharing.
    *   People are curious about what Zasper is supposed to replace and the upsides.
    *   Questioning why Zasper is a separate project instead of upstreaming improvements to Jupyter directly.

**[[R] Panda: A pretrained forecast model for universal representation of chaotic dynamics (Score: 22)](https://www.reddit.com/r/MachineLearning/comments/1kw7kip/r_panda_a_pretrained_forecast_model_for_universal/)**
*   **Summary:** The thread discusses the framework and pretrained forecast model PANDA.
*   **Emotion:** The overall emotional tone is neutral to positive.
*   **Top 3 Points of View:**
    *   There is a link between chaotic system and neural network.
    *   Warning that there is another PANDA framework for GNNs.
    *   The paper doesn't show any forecasts of chaotic regimes.

**[[D] Thinking about building a peer review tool for the community (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1kwn8q3/d_thinking_about_building_a_peer_review_tool_for/)**
*   **Summary:** The thread discusses the idea of building a peer review tool for the community.
*   **Emotion:** The overall emotional tone is neutral to negative.
*   **Top 2 Points of View:**
    *   The peer review tool could bridge the gap between students and advisors.
    *   There is not much interest in the tool.

**[[D] How can I use embedding models to find similar items with controlled attribute variation? For example, finding a similar story where the progtagnist is female instead of male while story is as similar as possible or chicken is replaced by beef in a recipe index? (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1kwfr7f/d_how_can_i_use_embedding_models_to_find_similar/)**
*   **Summary:** The thread discusses using embedding models to find similar items with controlled attribute variations.
*   **Emotion:** The overall emotional tone is neutral, with helpful suggestions provided.
*   **Top 3 Points of View:**
    *   Suggests a hybrid approach like extracting keywords/summaries.
    *   Recommends a hybrid keyword + semantic search and Reciprocal Rank Fusion.
    *   A paper proposes something very similar for text.

**[[R] question about Neurips double-blind policy (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1kwill3/r_question_about_neurips_doubleblind_policy/)**
*   **Summary:** The thread asks a question about the NeurIPS double-blind policy.
*   **Emotion:** The overall emotional tone is neutral and informative.
*   **Top 2 Points of View:**
    *   The reviewer might miss the additional results.
    *   If the model name is never released, then the reviewer wouldn’t know which organization it belongs to.

**[[D] What's your embedding model update policy? Trying to settle a debate (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1kwv5lx/d_whats_your_embedding_model_update_policy_trying/)**
*   **Summary:** The thread discusses embedding model update policies.
*   **Emotion:** The overall emotional tone is positive.
*   **Top 1 Points of View:**
    *   If it ain’t broke don’t fix it.

**[[R] Invented a new AI reasoning framework called HDA2A and wrote a basic paper - Potential to be something massive - check it out (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kwlral/r_invented_a_new_ai_reasoning_framework_called/)**
*   **Summary:** The thread discusses the new AI reasoning framework called HDA2A.
*   **Emotion:** The overall emotional tone is neutral with suggestions provided.
*   **Top 3 Points of View:**
    *   There is a lot in the paper that highlights the issues with this method in general and there is nothing quantitative about the results.
    *   The scoring system is a common design pattern once you start building a production grade solution.
    *   Have you tried coding this out or is this all theoretical?

**[[D] The Emergence-Constraint Framework: A Model for Recursive Identity and Symbolic Behaviour in LLMs (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kwmtlz/d_the_emergenceconstraint_framework_a_model_for/)**
*   **Summary:** The thread discusses The Emergence-Constraint Framework.
*   **Emotion:** The overall emotional tone is positive.
*   **Top 1 Points of View:**
    *   The framework includes a bunch of math and jargon.
