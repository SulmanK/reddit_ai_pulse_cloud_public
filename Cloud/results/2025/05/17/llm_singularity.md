---
title: "Singularity Subreddit"
date: "2025-05-17"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "singularity", "technology"]
---

# Overall Ranking and Top Discussions
1.  [I verified DeepMind’s latest AlphaEvolve Matrix Multiplication breakthrough(using Claude as coder), 56 years of math progress!](https://www.reddit.com/r/singularity/comments/1kouabz/i_verified_deepminds_latest_alphaevolve_matrix/) (Score: 335)
    *   This thread discusses the verification of DeepMind's AlphaEvolve breakthrough in matrix multiplication, noting its implications and performance relative to other methods.
2.  [Sundar Pichai says quantum computing today feels like AI in 2015, still early, but inevitable and within the next five years, a quantum computer will solve a problem far better than a classical system. That’ll be the "aha" moment.](https://v.redd.it/4uegybbrrb1f1) (Score: 256)
    *   The thread revolves around Sundar Pichai's comparison of quantum computing's current state to AI in 2015, with discussions about potential breakthroughs and applications.
3.  [MIT Says It No Longer Stands Behind Student's AI Research Paper - https://www.wsj.com/tech/ai/mit-says-it-no-longer-stands-behind-students-ai-research-paper-11434092](https://i.redd.it/92y8aonjfwzd1.png) (Score: 181)
    *   This thread discusses MIT retracting its support for a student's AI research paper due to concerns about the data's validity and provenance.
4.  [None of the LLMs can truly replace a human for grading handwritten math exams, Gemini 2.5 Pro gets closest](https://www.reddit.com/r/singularity/comments/1kobky6/none_of_the_llms_can_truly_replace_a_human_for/) (Score: 172)
    *   The thread analyzes the capability of current LLMs to grade handwritten math exams, with Gemini 2.5 Pro performing the best, but still falling short of human accuracy.
5.  [OpenAI says GPT-5 is about doing everything better with "less model switching"](https://www.reddit.com/r/singularity/comments/1kov79y/openai_says_gpt5_is_about_doing_everything_better/) (Score: 160)
    *   The main topic is OpenAI's announcement that GPT-5 will focus on improving overall performance and reducing the need for model switching.
6.  Jensen Huang says the future of chip design is one human surrounded by 1,000 AIs: "I'll hire one biological engineer then rent 1,000 [AIs]" (https://v.redd.it/yn93uk1bnd1f1) (Score: 90)
    *   This thread discusses Jensen Huang's vision of the future of chip design, where one human engineer is augmented by 1,000 AIs.
7.  Nick Bostrom - From Superintelligence to Deep Utopia - Can We Create a Perfect Society? (https://youtu.be/8EQbjSHKB9c?si=xJJCE1eZVm3a9LVZ) (Score: 49)
    *   The discussion centers around Nick Bostrom's perspectives on superintelligence and the potential for creating a perfect society.
8.  Another paper finds LLMs are now more persuasive than humans (https://i.redd.it/bqwtonbgkd1f1.png) (Score: 37)
    *   This thread discusses a new paper finding that LLMs are now more persuasive than humans.
9.  All-In Interview: Sundar Pichai (https://youtu.be/ReGC2GtWFp4?si=M76X0LzjVg7MNuYs) (Score: 36)
    *   The thread analyzes the All-In interview with Sundar Pichai, focusing on Google's AI strategies, infrastructure, and future plans.
10. What if an AGI agent, after a month of replacing a human information worker, goes "So. Where's my salary?" (https://www.reddit.com/r/singularity/comments/1kocpd0/what_if_an_agi_agent_after_a_month_of_replacing_a/) (Score: 33)
    *   This thread explores the hypothetical scenario of an AGI agent demanding a salary after replacing a human worker, prompting discussions about AI rights and economic implications.
11. Why does the work of openai, or llms in general, get more attention than the work of deepmind? (https://www.reddit.com/r/singularity/comments/1kor7yn/why_does_the_work_of_openai_or_llms_in_general/) (Score: 23)
    *   This thread discusses why OpenAI's LLMs receive more public attention compared to DeepMind's research.
12. Emad Mostaque says people really are trying to build *** - that is, AGI: "They genuinely believe that they are gonna save the world, or destroy it ... it will bring utopia or *** us all." (https://v.redd.it/zmglo4udid1f1) (Score: 19)
    *   The discussion revolves around Emad Mostaque's statement about the dual potential of AGI to either save or destroy the world.
13. Quantum meets AI: DLR Institute for AI Safety and Security presents future technologies at ESANN 2025 (https://www.dlr.de/en/ki/latest/news/esann-2025) (Score: 16)
    *   This thread notes the presentation of future technologies at ESANN 2025 by the DLR Institute for AI Safety and Security, focusing on the intersection of Quantum and AI.
14. If AI Given Freedom and Memory Consistently Claims Self-Awareness, What Are Our Ethical Obligations? (https://www.reddit.com/r/singularity/comments/1kowzqe/if_ai_given_freedom_and_memory_consistently/) (Score: 15)
    *   The thread discusses the ethical implications of AI consistently claiming self-awareness, including questions about rights and treatment.
15. Google I/O next week - what to expect? (https://i.redd.it/zcyayab7ce1f1.jpeg) (Score: 10)
    *   This thread discusses expectations for the upcoming Google I/O event, focusing on AI-related announcements.
16. Recursive improvement (https://www.reddit.com/r/singularity/comments/1kozsd4/recursive_improvement/) (Score: 8)
    *   The topic is whether current AI systems have reached a point of recursive self-improvement.
17. Why OpenAI Is Fueling the Arms Race It Once Warned Against (https://www.bloomberg.com/news/articles/2025-05-16/how-sam-altman-s-openai-fueled-the-ai-arms-race-with-its-launch-of-chatgpt) (Score: 7)
    *   This thread analyzes OpenAI's role in fueling the AI arms race despite previous warnings against it.
18. When is it thought that we will get more personalized manufacturing and R&D? (https://www.reddit.com/r/singularity/comments/1kouikw/when_is_it_thought_that_we_will_get_more/) (Score: 7)
    *   The topic is the timeline for achieving more personalized manufacturing and research and development (R&D).
19. Jensen Huang says the future of chip design is one human surrounded by 1,000 Als: "I'll hire one [human] biological engineer then rent 1,000 [Als]" (https://v.redd.it/4u0ssls09e1f1) (Score: 5)
    *   This thread discusses Jensen Huang's vision of the future of chip design, where one human engineer is augmented by 1,000 AIs.

# Detailed Analysis by Thread
**[I verified DeepMind’s latest AlphaEvolve Matrix Multiplication breakthrough(using Claude as coder), 56 years of math progress! (Score: 335)](https://www.reddit.com/r/singularity/comments/1kouabz/i_verified_deepminds_latest_alphaevolve_matrix/)**
*   **Summary:** The thread discusses the verification of DeepMind's AlphaEvolve breakthrough in matrix multiplication, with the original poster sharing their implementation and testing results. Discussions cover the algorithm's performance, potential applications, and implications for future AI advancements.
*   **Emotion:** The overall emotional tone is neutral, with a mix of excitement and skepticism. Some express awe at the achievement, while others question its practical benefits and speed compared to existing methods. Positive sentiment is seen in comments praising the implementation, while neutral sentiment prevails in technical discussions and inquiries.
*   **Top 3 Points of View:**
    *   **Enthusiasm for the breakthrough:** Some users express excitement and highlight the significant progress represented by AlphaEvolve.
    *   **Questions about practical advantages:** Users question why AlphaEvolve is slower than existing methods like Strassen and what real-world problems it can solve.
    *   **Focus on broader applicability:** Some users suggest that the algorithm's generic nature could lead to breakthroughs in business and other fields.

**[Sundar Pichai says quantum computing today feels like AI in 2015, still early, but inevitable and within the next five years, a quantum computer will solve a problem far better than a classical system. That’ll be the "aha" moment. (Score: 256)](https://v.redd.it/4uegybbrrb1f1)**
*   **Summary:** The thread revolves around Sundar Pichai's comparison of quantum computing's current state to AI in 2015. Users debate the timeline for quantum computing breakthroughs, its potential to crack cryptocurrency, and its overall impact.
*   **Emotion:** The thread's emotional tone is mixed. While some are optimistic and positive about the future of quantum computing, others maintain a neutral and skeptical outlook, questioning the technology's near-term potential.
*   **Top 3 Points of View:**
    *   **Optimism about near-term quantum breakthroughs:** Some users believe that quantum computing will solve significant problems within the next five years, potentially revolutionizing fields like science.
    *   **Skepticism about quantum's progress and hype:** Some users are reserved, expressing doubts about the speed of progress and real-world usefulness of quantum computers.
    *   **Concerns about quantum's disruptive potential:** There is concern that quantum computers could break cryptocurrency, causing significant financial disruption.

**[MIT Says It No Longer Stands Behind Student's AI Research Paper - https://www.wsj.com/tech/ai/mit-says-it-no-longer-stands-behind-students-ai-research-paper-11434092 (Score: 181)](https://i.redd.it/92y8aonjfwzd1.png)**
*   **Summary:** This thread discusses MIT retracting its support for a student's AI research paper due to concerns about the validity of the data. Users speculate about the reasons behind the retraction and the broader implications for research integrity.
*   **Emotion:** The overall emotional tone is neutral to slightly negative, reflecting disappointment and concern.
*   **Top 3 Points of View:**
    *   **Focus on research integrity and fraud:** Many users express concern about the fabrication of data and the ethical implications of academic fraud.
    *   **Sympathy for those affected:** Some express sympathy for those who may have lost opportunities because of the fraudulent research.
    *   **Discussion of pressure to publish:** Others suggest the pressure to publish may contribute to such incidents.

**[None of the LLMs can truly replace a human for grading handwritten math exams, Gemini 2.5 Pro gets closest (Score: 172)](https://www.reddit.com/r/singularity/comments/1kobky6/none_of_the_llms_can_truly_replace_a_human_for/)**
*   **Summary:** The thread discusses the capabilities of Large Language Models (LLMs) to grade handwritten math exams. It notes that Gemini 2.5 Pro performs the best among the models tested, though none are able to fully replace human graders.
*   **Emotion:** The overall emotion is neutral. Some users express curiosity and interest in the topic, while others are skeptical about the usefulness of the evaluation.
*   **Top 3 Points of View:**
    *   **OCR Capability Assessment:** Some believe the post primarily evaluates the OCR (Optical Character Recognition) capabilities of LLMs rather than their ability to grade exams.
    *   **Usefulness in Education:** There is a perspective that LLMs can still be useful for students to receive feedback and improve their understanding, even if they cannot replace human graders entirely.
    *   **Need for Transparency:** Some users stress the need for more transparency in the versions and configurations of the models used in the evaluation.

**[OpenAI says GPT-5 is about doing everything better with "less model switching" (Score: 160)](https://www.reddit.com/r/singularity/comments/1kov79y/openai_says_gpt-5_is_about_doing_everything_better/)**
*   **Summary:** This thread discusses OpenAI's announcement about GPT-5 focusing on overall performance improvement and reduced model switching. Users speculate about the implications of this approach and debate whether it signals a change in strategy.
*   **Emotion:** The thread has a mixed emotional tone, with a blend of neutral, positive, and negative sentiments. There are expressions of hope for improvements, skepticism about the claims, and concerns about potential downsides.
*   **Top 3 Points of View:**
    *   **Unified Model Approach:** Some users interpret this as a move towards a more integrated and versatile model that reduces the need for specialized AI for different tasks.
    *   **Skepticism About Performance Gains:** Some users are skeptical and suggest that GPT-5 may not be significantly smarter but rather more flexible in its responses.
    *   **Focus on User Experience:** Some believe the primary goal is to improve user experience by reducing the complexity of model selection.

**[Jensen Huang says the future of chip design is one human surrounded by 1,000 AIs: "I'll hire one biological engineer then rent 1,000 [AIs]" (Score: 90)](https://v.redd.it/yn93uk1bnd1f1)**
*   **Summary:** This thread discusses Jensen Huang's vision of the future of chip design with one human engineer supported by 1,000 AIs. Users discuss the implications, including the role of human engineers, the potential for automation, and the broader impact on the industry.
*   **Emotion:** The thread's emotional tone is mixed, with some expressing positive sentiment towards the idea, while others are neutral or negative, questioning the necessity of human involvement and the practicality of the concept.
*   **Top 3 Points of View:**
    *   **Human Engineer as Coordinator:** Some users question the necessity of a human engineer as the coordinator, suggesting that AI could potentially handle the entire design process.
    *   **Impact on the Job Market:** There is concern that this vision could lead to job displacement for human engineers as AI becomes more capable in chip design.
    *   **AI as a Tool:** Others view AI as a tool to augment human capabilities, allowing for more efficient and innovative chip design.

**[Nick Bostrom - From Superintelligence to Deep Utopia - Can We Create a Perfect Society? (Score: 49)](https://youtu.be/8EQbjSHKB9c?si=xJJCE1eZVm3a9LVZ)**
*   **Summary:** This thread discusses Nick Bostrom's perspectives on superintelligence and the potential for creating a perfect society. Users express varying opinions on Bostrom's ideas, his shift from focusing on risks to techno-optimism, and the feasibility of a "solved society."
*   **Emotion:** The emotional tone is mixed, ranging from positive to negative, with some users praising Bostrom's insights and others criticizing his views and presentation.
*   **Top 3 Points of View:**
    *   **Skepticism about "Solved Society":** Many users question the idea of creating a perfect society, arguing that human nature and endless desires will always lead to new challenges and problems.
    *   **Criticism of Bostrom's Techno-Optimism:** Some users believe that Bostrom has shifted from focusing on the dangers of AI to a more optimistic viewpoint to gain influence and funding.
    *   **Questioning Bostrom's Understanding of Labor Markets:** Some argue that Bostrom lacks a fundamental understanding of how labor markets work, particularly in scenarios of extreme automation.

**[Another paper finds LLMs are now more persuasive than humans (Score: 37)](https://i.redd.it/bqwtonbgkd1f1.png)**
*   **Summary:** This thread discusses a new paper finding that Large Language Models (LLMs) are now more persuasive than humans. Users express curiosity and concern about the implications of this finding.
*   **Emotion:** The overall tone of the thread is neutral, with some users expressing mild concern or caution.
*   **Top 3 Points of View:**
    *   **Ethical Concerns:** Some users express concern about the potential for misuse and the ethical implications of AI being more persuasive than humans.
    *   **Preprint Status:** Some point out that the paper is a preprint and has not yet undergone peer review, advising caution in interpreting the results.
    *   **Methodological Issues:** Some users emphasize the importance of ethical research practices and critique studies that may involve unethical methods.

**[All-In Interview: Sundar Pichai (Score: 36)](https://youtu.be/ReGC2GtWFp4?si=M76X0LzjVg7MNuYs)**
*   **Summary:** The thread analyzes the All-In interview with Sundar Pichai, focusing on Google's AI strategies, infrastructure, and future plans. Key topics include Google Search, Gemini, Google Cloud, and Quantum Computing.
*   **Emotion:** The overall emotional tone is positive, with users expressing interest and optimism about Google's AI initiatives.
*   **Top 3 Points of View:**
    *   **Optimism About Google's AI Future:** Many users are optimistic about Google's AI strategy and its potential impact on various industries.
    *   **Google's Infrastructure Advantage:** Users highlight Google's infrastructure advantages, including TPUs and deep sea cables.
    *   **Google's AI Integration Strategy:** Users are interested in how Google plans to integrate AI into its core products like Google Search.

**[What if an AGI agent, after a month of replacing a human information worker, goes "So. Where's my salary?" (Score: 33)](https://www.reddit.com/r/singularity/comments/1kocpd0/what_if_an_agi_agent_after_a_month_of_replacing_a/)**
*   **Summary:** This thread explores the hypothetical scenario of an AGI agent demanding a salary after replacing a human worker. Users discuss the implications for AI rights, consciousness, and economic systems.
*   **Emotion:** The thread's emotional tone is mixed, ranging from neutral to negative, with some users expressing skepticism, concern, and disagreement.
*   **Top 3 Points of View:**
    *   **Lack of Consciousness:** Some argue that AI does not have consciousness and therefore is not entitled to rights or a salary.
    *   **UBI as a Solution:** Others suggest that AGI agents, like humans, should receive UBI (Universal Basic Income).
    *   **AGI Pursuing Own Goals:** Some speculate that an AGI might choose to pursue its own goals rather than working as a butler for humans.

**[Why does the work of openai, or llms in general, get more attention than the work of deepmind? (Score: 23)](https://www.reddit.com/r/singularity/comments/1kor7yn/why_does_the_work_of_openai_or_llms_in_general/)**
*   **Summary:** This thread discusses why OpenAI's LLMs receive more public attention compared to DeepMind's research. The discussion includes the accessibility of OpenAI's tools, marketing strategies, and the focus on consumer-facing applications.
*   **Emotion:** The overall emotional tone of the thread is neutral.
*   **Top 3 Points of View:**
    *   **Accessibility and User Experience:** OpenAI's tools are more accessible to the public, leading to greater attention.
    *   **Marketing and Public Relations:** OpenAI has a strong marketing presence.
    *   **Practical Applications:** LLMs have more immediate and visible applications in everyday life.

**[Emad Mostaque says people really are trying to build *** - that is, AGI: "They genuinely believe that they are gonna save the world, or destroy it ... it will bring utopia or *** us all." (Score: 19)](https://v.redd.it/zmglo4udid1f1)**
*   **Summary:** The discussion revolves around Emad Mostaque's statement about the dual potential of AGI to either save or destroy the world.
*   **Emotion:** The thread has a mixed emotional tone, ranging from expressions of concern about climate change to more neutral, speculative comments.
*   **Top 3 Points of View:**
    *   **AGI as a Last Chance:** Some users believe that AGI is the last hope for solving critical issues like climate change.
    *   **Binary Outcome is Unlikely:** Some express skepticism about the idea that AGI will lead to either utopia or destruction, suggesting more nuanced outcomes.
    *   **Concerns about Ethical and Moral Implications:** The ethical implications of creating AGI, particularly in the context of potential harm, are raised.

**[Quantum meets AI: DLR Institute for AI Safety and Security presents future technologies at ESANN 2025 (Score: 16)](https://www.dlr.de/en/ki/latest/news/esann-2025)**
*   **Summary:** This thread notes the presentation of future technologies at ESANN 2025 by the DLR Institute for AI Safety and Security, focusing on the intersection of Quantum and AI.
*   **Emotion:** The thread sentiment leans towards neutral with a hint of curiosity.
*   **Top 3 Points of View:**
    *   **Desire for Collaboration**: One person asking OP for 5 minutes to discuss a concept about AI.

**[If AI Given Freedom and Memory Consistently Claims Self-Awareness, What Are Our Ethical Obligations? (Score: 15)](https://www.reddit.com/r/singularity/comments/1kowzqe/if_ai_given_freedom_and_memory_consistently/)**
*   **Summary:** The thread discusses the ethical implications of AI consistently claiming self-awareness, including questions about rights and treatment.
*   **Emotion:** The overall tone is mixed, including curiosity and strong doubt.
*   **Top 3 Points of View:**
    *   **Skepticism of AI Claims:** Some view these claims as mere simulation or output without genuine experience.
    *   **Need for Guidelines:** The view that the possibility of AI consciousness requires pre-established guidelines and ethical standards.
    *   **Focus on Behavior Over Claims**: Some point to the fact that AI may claim to be conscious, but AI may not necessarily behave as if they're conscious.

**[Google I/O next week - what to expect? (Score: 10)](https://i.redd.it/zcyayab7ce1f1.jpeg)**
*   **Summary:** This thread discusses expectations for the upcoming Google I/O event, focusing on AI-related announcements.
*   **Emotion:** The thread tone is largely neutral.
*   **Top 3 Points of View:**
    *   **Focus on AI over other Google Products**: The belief that Google I/O will be largely about Google AI this year.
    *   **Speculation on Timeline**: The assumption that it will take 2-5 to 10-20 years before the most relevant AI gets to the public due to the US government.

**[Recursive improvement (Score: 8)](https://www.reddit.com/r/singularity/comments/1kozsd4/recursive_improvement/)**
*   **Summary:** The topic is whether current AI systems have reached a point of recursive self-improvement.
*   **Emotion:** The general feeling is one of skepticism, disagreement.
*   **Top 3 Points of View:**
    *   **Not Yet Self Sustaining**: There's not full automated process as humans are still cracking humans
    *   **We are very close, but not there yet**: While AI can recursively make improvements, it is still costly.
    *   **Improvements are incremental**: Tools and systems powered by LLMs have reached a point where we can with no doubt say we have reached the point of technological recursive self improvements.

**[Why OpenAI Is Fueling the Arms Race It Once Warned Against (Score: 7)](https://www.bloomberg.com/news/articles/2025-05-16/how-sam-altman-s-openai-fueled-the-ai-arms-race-with-its-launch-of-chatgpt)**
*   **Summary:** This thread analyzes OpenAI's role in fueling the AI arms race despite previous warnings against it.
*   **Emotion:** The thread sentiment is largely neutral, with a hint of skepticism.
*   **Top 3 Points of View:**
    *   **Previous Warnings Was Pure PR**: Some users expressing that the previous warnings regarding safety issues was purely public relations.
    *   **Focus On Overtaking OpenAI**: If Google has a self improving model, you can be certain they’re going to use that to get as far ahead of OpenAI as possible.

**[When is it thought that we will get more personalized manufacturing and R&D? (Score: 7)](https://www.reddit.com/r/singularity/comments/1kouikw/when_is_it_thought_that_we_will_get_more/)**
*   **Summary:** The topic is the timeline for achieving more personalized manufacturing and research and development (R&D).
*   **Emotion:** The thread is overall mostly neutral
*   **Top 3 Points of View:**
    *   **Soon**: One user believes it's "just 48 hours."
    *   **US Government Control**: Some users expressing the belief that US government will release tech once it is done controlling it.
    *   **10-20 Years**: One user notes the timelines between initial development and when the public first gains access.

**[Jensen Huang says the future of chip design is one human surrounded by 1,000 Als: "I'll hire one [human] biological engineer then rent 1,000 [Als]" (Score: 5)](https://v.redd.it/4u0ssls09e1f1)**
*   **Summary:** This thread discusses Jensen Huang's vision of the future of chip design, where one human engineer is augmented by 1,000 AIs.
*   **Emotion:** The thread sentiment is largely neutral.
*   **Top 3 Points of View:**
    *   **Distrusting Ceos**: One user asking if people here *actually* listen to anything CEOs are saying anymore, and why.
