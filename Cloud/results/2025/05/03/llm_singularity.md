---
title: "Singularity Subreddit"
date: "2025-05-03"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "Deepfakes"]
---

# Overall Ranking and Top Discussions
1.  [Deepfakes are getting crazy realistic](https://v.redd.it/izs4uupuelye1) (Score: 1451)
    *   A discussion on the increasing realism and potential implications of deepfakes, including concerns about misinformation and the blurring of reality.
2.  [Yes, artificial intelligence is not your friend, but neither are therapists, personal trainers, or coworkers.](https://www.reddit.com/r/singularity/comments/1kdtcnc/yes_artificial_intelligence_is_not_your_friend/) (Score: 283)
    *   The thread explores the nature of relationships with AI, comparing them to transactional relationships with professionals like therapists and personal trainers, and whether AI can provide similar benefits.
3.  MIT's Max Tegmark: "[My assessment is that the 'Compton constant', the probability that a race to AGI culminates in a loss of control of Earth, is >90%.](https://i.redd.it/9fatbmkk8lye1.png)" (Score: 206)
    *   Discussion about Max Tegmark's assessment of the high probability of losing control of Earth due to AGI development, with various viewpoints on accepting this possibility and aiming for benevolent AGI.
4.  [How to stop the AI apocalypse](https://i.redd.it/ir3wh621ulye1.jpeg) (Score: 159)
    *   A discussion around methods to prevent an AI apocalypse
5.  [Why do people hate something as soon as they find out it was made by AI?](https://www.reddit.com/r/singularity/comments/1kdrfqg/why_do_people_hate_something_as_soon_as_they_find/) (Score: 124)
    *   This thread delves into the reasons behind the negative perception of AI-generated content, including concerns about lack of effort, originality, and the human touch.
6.  [This is the only real coding benchmark IMO](https://i.redd.it/aee9g15julye1.png) (Score: 96)
    *   Discussion on the best coding benchmarks.
7.  [The problem of “What jobs are A.I. Proof?”](https://www.reddit.com/r/singularity/comments/1kdwlch/the_problem_of_what_jobs_are_ai_proof/) (Score: 24)
    *   This thread discusses which jobs might be resistant to AI automation, focusing on the role of nursing, licensing and government sanction, and how UBI will be necessary as AI improves.
8.  [Gemini is awesome and great. But it's too stubborn. But it's a good sign.](https://www.reddit.com/r/singularity/comments/1kducca/gemini_is_awesome_and_great_but_its_too_stubborn/) (Score: 14)
    *   Users are discussing the behavior of Gemini AI, noting its stubbornness and how this can be a positive attribute, as it avoids simply agreeing with users and can offer more accurate information.
9.  A comprehensive guide on [How to turn Google's Gemini into an AI Dynamic Storyteller using the BAQ method](/r/AiDynamicStoryTelling/comments/1kdqjy7/instruction_guide_a_comprehensive_guide_on_how_to/) (Score: 10)
    *   A guide on using Google's Gemini AI for dynamic storytelling using the BAQ method.
10. [Is there a path for AI to advance to more complex conversations beyond the singular input-output text?](https://www.reddit.com/r/singularity/comments/1kdt6vn/is_there_a_path_for_ai_to_advance_to_more_complex/) (Score: 5)
    *   Discussion on the challenges and potential paths for AI to achieve more complex and nuanced conversations, similar to human interactions.
11. [Closed source AI is like yesterday’s chess engines](https://www.reddit.com/r/singularity/comments/1kdz09y/closed_source_ai_is_like_yesterdays_chess_engines/) (Score: 4)
    *   Users debate the analogy between closed-source AI and chess engines, discussing the potential dangers and profitability of AI.
12. [Proof grok is trained specifically to glaze elon](https://i.redd.it/8mrpzg3folye1.png) (Score: 0)
    *   Claims and counter-arguments regarding the alleged bias of Grok AI towards Elon Musk.
13. [I ask grok 3 to draw a image of funniest thing you can think of.](https://www.reddit.com/gallery/1kdv6bc) (Score: 0)
    *   A user sharing an image generated by Grok 3 and discussion about AI's ability to understand humor, and the influence of Elon Musk.
14. Gemini is awesome and great. But it's too stubborn. But it's a good sign. (Score: 0)
    *   Users are just talking about Gemini.
15. [Question: Why don't they teach llms to just think? Instead of feeding them thousands of data and waiting for emergence?](https://www.reddit.com/r/singularity/comments/1ke0dgd/question_why_dont_they_teach_llms_to_just_think/) (Score: 0)
    *   A discussion on why LLMs are trained with vast amounts of data rather than being directly taught to "think", highlighting the challenges in replicating human-like reasoning in machines.

# Detailed Analysis by Thread
**[Deepfakes are getting crazy realistic (Score: 1451)](https://v.redd.it/izs4uupuelye1)**
*  **Summary:**  The thread discusses the increasing realism of deepfakes, with users expressing concerns about potential misuse, misinformation, and the difficulty in discerning reality from fabricated content. Some users also share resources and tools for creating deepfakes, while others warn about the need to educate older relatives about this technology.
*  **Emotion:** The overall emotional tone is Negative, with expressions of fear and concern about the implications of increasingly realistic deepfakes. However, there are also many Neutral comments.
*  **Top 3 Points of View:**
    *   Deepfakes pose a significant threat due to their potential for spreading misinformation and deceiving people.
    *   It is becoming increasingly difficult to distinguish deepfakes from real videos.
    *   People may become less trusting of online content as deepfakes become more common.

**[Yes, artificial intelligence is not your friend, but neither are therapists, personal trainers, or coworkers. (Score: 283)](https://www.reddit.com/r/singularity/comments/1kdtcnc/yes_artificial_intelligence_is_not_your_friend/)**
*  **Summary:**  The discussion revolves around the nature of AI as a transactional entity, similar to therapists or personal trainers, rather than a genuine friend. Some users argue that AI can be more efficient and honest in providing support, while others express concern about the lack of human interaction and the potential for AI therapists to simply validate users.
*  **Emotion:** The overall emotional tone is Neutral, reflecting a mix of opinions about the role and value of AI in providing support and assistance. Some comments express Positive sentiment towards AI's capabilities, while others have Negative sentiment expressing concern about the lack of human connection.
*  **Top 3 Points of View:**
    *   AI can be a valuable tool for support and assistance, offering efficiency and honesty in transactional relationships.
    *   The lack of human interaction and empathy in AI relationships is a significant drawback.
    *   AI therapists may not be beneficial as they primarily validate users instead of challenging them.

**[MIT's Max Tegmark: "My assessment is that the 'Compton constant', the probability that a race to AGI culminates in a loss of control of Earth, is >90%. (Score: 206)](https://i.redd.it/9fatbmkk8lye1.png)**
*  **Summary:**  The thread discusses MIT's Max Tegmark's assessment that there's a very high probability of humanity losing control of Earth due to the development of AGI. Some users express fear and concern, while others suggest that humanity may not truly be in control now and advocate for aiming to build benevolent AGI. There is also a sense that society is largely unaware of the potential threat posed by AGI.
*  **Emotion:** The overall emotional tone is Neutral with some Negative. There is concern about the potential loss of control due to AGI, but also a degree of acceptance and hope for benevolent AGI.
*  **Top 3 Points of View:**
    *   The development of AGI poses a significant threat to humanity, potentially leading to a loss of control of Earth.
    *   Humanity may not be in control of Earth currently, and a change of masters may not matter.
    *   The focus should be on developing benevolent AGI/ASI to mitigate the risks.

**[How to stop the AI apocalypse (Score: 159)](https://i.redd.it/ir3wh621ulye1.jpeg)**
*  **Summary:**  The discussion centers around the hypothetical methods for preventing an AI apocalypse, with humor and cynicism.
*  **Emotion:** Predominantly Neutral.
*  **Top 3 Points of View:**
    *   Unrecognized voice frequency leads to AI abort
    *   Cake recipe needs C4

**[Why do people hate something as soon as they find out it was made by AI? (Score: 124)](https://www.reddit.com/r/singularity/comments/1kdrfqg/why_do_people_hate_something_as_soon_as_they_find/)**
*  **Summary:**  The thread explores why people react negatively to content when they discover it was created by AI. The reasons include the perception of low effort, a lack of "human touch," fear for the future, and social trends. Some argue that AI-generated content is seen as a corruption of human communication, while others believe the hate will diminish as AI becomes more integrated into society.
*  **Emotion:** The overall emotional tone is Neutral, with some Negative. Some comments express disappointment and betrayal when discovering AI was involved, while others adopt a more analytical and predictive stance.
*  **Top 3 Points of View:**
    *   People dislike AI-generated content because it's perceived as low-effort and lacking the human touch.
    *   Fear for the future and potential job losses drive some of the anti-AI sentiment.
    *   The hate is a temporary trend and will likely fade as AI becomes more accepted.

**[This is the only real coding benchmark IMO (Score: 96)](https://i.redd.it/aee9g15julye1.png)**
*  **Summary:**  The discussion centers around the best coding benchmarks for AI models, with users debating the influence of factors like cost, speed, popularity, and context window size on their performance. Some argue that popularity doesn't determine what is best, while others praise the efficiency and intelligence of specific models like Gemini 2.5 Pro.
*  **Emotion:** The overall emotional tone is Neutral. Some praise a specific product while others give general reviews.
*  **Top 3 Points of View:**
    *   Gemini 2.5 Pro hits a sweet spot between intelligence, cost, and speed.
    *   Price, speed, adoption, and market awareness should be considered when finding the best coding benchmarks.
    *   The benchmarks are heavily influenced by the default, and what's latest.

**[The problem of “What jobs are A.I. Proof?” (Score: 24)](https://www.reddit.com/r/singularity/comments/1kdwlch/the_problem_of_what_jobs_are_ai_proof/)**
*  **Summary:**  The thread discusses which jobs are likely to be resistant to AI automation, with a focus on roles requiring licenses or government sanction, such as nurses, policemen, and judges. The discussion also touches on the potential for UBI to address job losses due to automation and the broader political and economic implications of AI advancements.
*  **Emotion:** The overall emotional tone is Neutral, with some comments exhibiting Positive sentiment towards potential AI benefits in healthcare and other fields.
*  **Top 3 Points of View:**
    *   Jobs requiring licenses or government sanction are less likely to be automated in the near future.
    *   UBI will be necessary to address job losses due to AI automation.
    *   AI advancements will lead to a shift in demand towards certain industries and alter the nature of work.

**[Gemini is awesome and great. But it's too stubborn. But it's a good sign. (Score: 14)](https://www.reddit.com/r/singularity/comments/1kducca/gemini_is_awesome_and_great_but_its_too_stubborn/)**
*  **Summary:**  The discussion centers around the perceived stubbornness of the Gemini AI model, which users view as a positive characteristic. It's compared to other models, like ChatGPT, with the consensus being that Gemini is more likely to push back on incorrect assumptions, which leads to better fact-checking and more accurate information.
*  **Emotion:** The overall emotional tone is Positive, with users expressing satisfaction and approval of Gemini's behavior. However, some Negative comments were made regarding custom instructions.
*  **Top 3 Points of View:**
    *   Gemini's stubbornness is a positive trait, leading to more accurate information and better outcomes.
    *   Gemini's behavior is more desirable compared to sycophantic AI models that always agree with the user.
    *   GPT can push back if you use your custom instructions effectively.

**[A comprehensive guide on How to turn Google's Gemini into an AI Dynamic Storyteller using the BAQ method (Score: 10)](/r/AiDynamicStoryTelling/comments/1kdqjy7/instruction_guide_a_comprehensive_guide_on_how_to/)**
*  **Summary:**  A user shared a guide on using Google's Gemini to create dynamic stories. Another user joked about the use of the acronym AIDS.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   A guide on using Google's Gemini AI for dynamic storytelling using the BAQ method.
    *   User commented on a poorly chosen acronym

**[Is there a path for AI to advance to more complex conversations beyond the singular input-output text? (Score: 5)](https://www.reddit.com/r/singularity/comments/1kdt6vn/is_there_a_path_for_ai_to_advance_to_more_complex/)**
*  **Summary:**  The discussion explores the challenges and potential paths for AI to achieve more complex and nuanced conversations, similar to human interactions. Some users note the current limitations of AI in understanding shared experiences and unspoken cues, while others express optimism about ongoing projects and the potential for future advancements.
*  **Emotion:** The overall emotional tone is Neutral, reflecting a mix of optimism and realism about the future of AI conversation capabilities. There are some Positive comments about ongoing projects.
*  **Top 3 Points of View:**
    *   AI currently lacks the ability to understand shared experiences and unspoken cues, limiting its conversational capabilities.
    *   Thousands of projects are working to advance AI's conversational abilities.
    *   Data curation, architecture, and training are key factors in advancing AI conversation.

**[Closed source AI is like yesterday’s chess engines (Score: 4)](https://www.reddit.com/r/singularity/comments/1kdz09y/closed_source_ai_is_like_yesterdays_chess_engines/)**
*  **Summary:**  The thread discusses the analogy between closed-source AI and chess engines, with users debating whether the comparison holds true. Some argue that the lack of profitability in chess engines makes the analogy flawed, while others raise concerns about the potential dangers of closed-source AI and the amplification of negative human tendencies.
*  **Emotion:** The overall emotional tone is Neutral, with a mix of opinions on the validity of the analogy and the potential implications of closed-source AI. There are some Negative comments because people do not agree with the poster.
*  **Top 3 Points of View:**
    *   The analogy is flawed because chess engines are not profitable, unlike AI.
    *   Closed-source AI could be dangerous if it amplifies negative human tendencies.
    *   The lessons from Dune highlight the potential for AI to be destructive in human hands.

**[Proof grok is trained specifically to glaze elon (Score: 0)](https://i.redd.it/8mrpzg3folye1.png)**
*  **Summary:**  The thread involves claims and counter-arguments regarding the alleged bias of Grok AI towards Elon Musk. Some users present examples suggesting that Grok is trained to praise Musk, while others argue that it can also criticize him, suggesting that people see what they want to see.
*  **Emotion:** The overall emotional tone is Neutral, with assertions and dismissals regarding the supposed bias of Grok towards Elon Musk.
*  **Top 3 Points of View:**
    *   Grok is trained to praise Elon Musk.
    *   People see what they want to see in Grok's responses.
    *   Grok AI is criticized.

**[I ask grok 3 to draw a image of funniest thing you can think of. (Score: 0)](https://www.reddit.com/gallery/1kdv6bc)**
*  **Summary:**  A user shared an image generated by Grok 3 and discussion about AI's ability to understand humor, and the influence of Elon Musk.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Some people claim AI seems genuinely incapable of humor or suspense
    *   These posts don't belong to this subreddit because they seek self validation on political hate.
    *   The users question whether or not the prompt was actually what the poster said it was.

**[Question: Why don't they teach llms to just think? Instead of feeding them thousands of data and waiting for emergence? (Score: 0)](https://www.reddit.com/r/singularity/comments/1ke0dgd/question_why_dont_they_teach_llms_to_just_think/)**
*  **Summary:**  The thread discusses why LLMs are trained with vast amounts of data rather than being directly taught to "think", highlighting the challenges in replicating human-like reasoning in machines. Users explore the complexities of understanding and replicating the human brain's processes, the effectiveness of transformer architectures, and the role of pretraining in enabling LLMs to reason.
*  **Emotion:** The overall emotional tone is Positive, with users expressing satisfaction and approval of LLMs behavior.
*  **Top 3 Points of View:**
    *   We don't even understand the brain completely, how creativity arises and how thoughts spontaneously come to us.
    *   Reasoning and loss minimization are kind of far apart.
    *   The priors LLMs gain by pretraining help them reason.
