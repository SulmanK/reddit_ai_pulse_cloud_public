---
title: "Machine Learning Subreddit"
date: "2025-05-13"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "LLM"]
---

# Overall Ranking and Top Discussions
1.  [[D] Had an AI Engineer interview recently and the startup wanted to fine-tune sub-80b parameter models for their platform, why?](https://www.reddit.com/r/MachineLearning/comments/1klf53p/d_had_an_ai_engineer_interview_recently_and_the/) (Score: 110)
    *   The discussion revolves around the reasons why a startup might choose to fine-tune sub-80 billion parameter models, with considerations of cost, performance, intellectual property, and differentiation from competitors.
2.  [[D] Reviewer cited a newer arXiv paper as prior work and ours was online earlier. How to handle in rebuttal?](https://www.reddit.com/r/MachineLearning/comments/1klppvn/d_reviewer_cited_a_newer_arxiv_paper_as_prior/) (Score: 32)
    *   The discussion centers around how to handle a reviewer citing a newer arXiv paper as prior work when the author's paper was online earlier.
3.  [[D] MICCAI 2025 Review Results](https://www.reddit.com/r/MachineLearning/comments/1kl4sly/d_miccai_2025_review_results/) (Score: 30)
    *   This thread is about the MICCAI 2025 review results, with people discussing their acceptance/rejection status and the fairness/stringency of the review process.
4.  [[N] The Reinforcement Learning and Video Games Workshop @RLC 2025](https://www.reddit.com/r/MachineLearning/comments/1klgyqy/n_the_reinforcement_learning_and_video_games/) (Score: 20)
    *   This thread discusses the Reinforcement Learning and Video Games Workshop at RLC 2025.
5.  [[D] Why do people (mostly in media, not in AI/ML research) talk about Meta as if it is behind in the AI industry?](https://www.reddit.com/r/MachineLearning/comments/1klnby4/d_why_do_people_mostly_in_media_not_in_aiml/) (Score: 7)
    *   The discussion focuses on why Meta is perceived as being behind in the AI industry, particularly concerning LLMs and its corporate structure.
6.  [[D] Is topic modelling obsolete?](https://www.reddit.com/r/MachineLearning/comments/1klsnfl/d_is_topic_modelling_obsolete/) (Score: 7)
    *   This thread discusses whether topic modeling is obsolete with the rise of transformer models and explores modern topic modeling techniques.
7.  [[D] LxMLS 2025 decision](https://www.reddit.com/r/MachineLearning/comments/1klovx6/d_lxmls_2025_decision/) (Score: 1)
    *   The discussion revolves around the LxMLS 2025 decision, with people sharing their acceptance status and concerns about funding.
8.  [[R] How do I become an AI Engineer from a Computer Engineering background?](https://www.reddit.com/r/MachineLearning/comments/1klisb6/r_how_do_i_become_an_ai_engineer_from_a_computer/) (Score: 0)
    *   This thread discusses how to transition from a computer engineering background to becoming an AI engineer.
9.  [[D] Thoughts on use of the term AI & whether LLMs are actually a 'step on the way' to advancements in AI?](https://www.reddit.com/r/MachineLearning/comments/1klkqi6/d_thoughts_on_use_of_the_term_ai_whether_llms_are/) (Score: 0)
    *   The discussion is about the use of the term "AI" and whether LLMs represent a genuine advancement in the field.
10. [[D] xAI Releasing *** and Romantic Voice Chatbots](https://www.reddit.com/r/MachineLearning/comments/1klm09z/d_xai_releasing_sexual_and_romantic_voice_chatbots/) (Score: 0)
    *   The thread discusses the release of *** and romantic voice chatbots by xAI.
11. [[D] Helps in Neurips submission](https://www.reddit.com/r/MachineLearning/comments/1klqq4a/d_helps_in_neurips_submission/) (Score: 0)
    *   This thread discusses about the helps regarding the Neurips submission.
12. [[P] Al Solution for identifying suspicious Audio recordings](https://www.reddit.com/r/MachineLearning/comments/1klrn30/p_al_solution_for_identifying_suspicious_audio/) (Score: 0)
    *   The discussion revolves around an AI solution for identifying suspicious audio recordings.
13. [[D] Confused PhD ML Student: Looking for advice on tying research to industry](https://www.reddit.com/r/MachineLearning/comments/1kltq40/d_confused_phd_ml_student_looking_for_advice_on/) (Score: 0)
    *   A PhD ML student seeks advice on how to connect their research to the industry.

# Detailed Analysis by Thread
**[[D] Had an AI Engineer interview recently and the startup wanted to fine-tune sub-80b parameter models for their platform, why? (Score: 110)](https://www.reddit.com/r/MachineLearning/comments/1klf53p/d_had_an_ai_engineer_interview_recently_and_the/)**
*   **Summary:** The discussion revolves around the reasons why a startup might choose to fine-tune sub-80 billion parameter models, with considerations of cost, performance, intellectual property, and differentiation from competitors.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Fine-tuning smaller models (sub-80b) can achieve comparable or superior performance to larger models within specific domains, at a fraction of the cost. This can provide a competitive advantage and be attractive to investors.
    *   Fine-tuning is not as widely considered by AI practitioners as it once was, but it remains a valuable technique for achieving specific goals like brand-specific tone, internal ontology, and private workflows that prompt engineering cannot easily address.
    *   Fine-tuning might be chosen to impress stakeholders, as it sounds more advanced than prompt engineering. It's important to ensure it's a well-considered decision based on cost-benefit analysis, not just a default choice due to discomfort with prompt engineering.

**[[D] Reviewer cited a newer arXiv paper as prior work and ours was online earlier. How to handle in rebuttal? (Score: 32)](https://www.reddit.com/r/MachineLearning/comments/1klppvn/d_reviewer_cited_a_newer_arxiv_paper_as_prior/)**
*   **Summary:** The discussion centers around how to handle a reviewer citing a newer arXiv paper as prior work when the author's paper was online earlier.
*   **Emotion:** The overall emotional tone is positive.
*   **Top 3 Points of View:**
    *   Authors are not required to compare their work with recent arXiv reports, but they must properly cite those that inspired them.
    *   Respectfully inform the reviewer that you were unaware of the work prior to submission and offer to add it as a baseline.
    *   ACL ARR has a clear policy where authors are exempted from citing any contemporary work from less than 3 months.

**[[D] MICCAI 2025 Review Results (Score: 30)](https://www.reddit.com/r/MachineLearning/comments/1kl4sly/d_miccai_2025_review_results/)**
*   **Summary:** This thread is about the MICCAI 2025 review results, with people discussing their acceptance/rejection status and the fairness/stringency of the review process.
*   **Emotion:** The overall emotional tone is negative.
*   **Top 3 Points of View:**
    *   The MICCAI review process is deeply flawed, with reviewers often misunderstanding the work and giving low scores with unjustified high confidence.
    *   Reviewers are extremely stringent on surgical video analysis papers and very lenient on brain-related papers.
    *   Submitting multiple low to medium quality papers is the way to go, because the review process seems to be a lottery.

**[[N] The Reinforcement Learning and Video Games Workshop @RLC 2025 (Score: 20)](https://www.reddit.com/r/MachineLearning/comments/1klgyqy/n_the_reinforcement_learning_and_video_games/)**
*   **Summary:** This thread discusses the Reinforcement Learning and Video Games Workshop at RLC 2025.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   There are not enough point of views to summarize. Only a statement about the reinforcement learning workshop.

**[[D] Why do people (mostly in media, not in AI/ML research) talk about Meta as if it is behind in the AI industry? (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1klnby4/d_why_do_people_mostly_in_media_not_in_aiml/)**
*   **Summary:** The discussion focuses on why Meta is perceived as being behind in the AI industry, particularly concerning LLMs and its corporate structure.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Meta's top-of-the-line language models are worse than those of the other big labs.
    *   Media focuses on LLMs, and LLMs = models bigger than 80B, which might be why Meta seems behind.
    *   Meta is still a leading AI company and ahead of many others, but might be "behind" compared to OpenAI, Anthropic, Google, and Alibaba. Their major investment in large models without immediate ROI is concerning shareholders.

**[[D] Is topic modelling obsolete? (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1klsnfl/d_is_topic_modelling_obsolete/)**
*   **Summary:** This thread discusses whether topic modeling is obsolete with the rise of transformer models and explores modern topic modeling techniques.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Transformer models like Bertopic make topic modeling is more than summarizing.

**[[D] LxMLS 2025 decision (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1klovx6/d_lxmls_2025_decision/)**
*   **Summary:** The discussion revolves around the LxMLS 2025 decision, with people sharing their acceptance status and concerns about funding.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   People share their acceptance status and ask if it is worth attending without scholarship.

**[[R] How do I become an AI Engineer from a Computer Engineering background? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1klisb6/r_how_do_i_become_an_ai_engineer_from_a_computer/)**
*   **Summary:** This thread discusses how to transition from a computer engineering background to becoming an AI engineer.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Find a project to work on and start.
    *   Have a mathematical background and learn machine learning/deep learning optimization.
    *   The most important thing is to find a project you want to work on and just try it out. In terms of self study, he recommends the hugging face courses. When you get to more advanced topics, you can chat with Claude and ask them to explain it to you.

**[[D] Thoughts on use of the term AI & whether LLMs are actually a 'step on the way' to advancements in AI? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1klkqi6/d_thoughts_on_use_of_the_term_ai_whether_llms_are/)**
*   **Summary:** The discussion is about the use of the term "AI" and whether LLMs represent a genuine advancement in the field.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   AI is just a blanket term at this point. Most people who say AI don’t know what it means technically speaking.
    *   The term AI is misused because it's a blanket term. LLMs are useful but not truly intelligent, lacking self-directedness.
    *   LLMs are interesting. It’s the first instance where a system inhibits intelligence in a way that it’s not globally optimizing some reward function, a metric that is often flawed and hackable.

**[[D] xAI Releasing *** and Romantic Voice Chatbots (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1klm09z/d_xai_releasing_sexual_and_romantic_voice_chatbots/)**
*   **Summary:** The thread discusses the release of *** and romantic voice chatbots by xAI.
*   **Emotion:** The overall emotional tone is positive.
*   **Top 3 Points of View:**
    *   It's ok, and hopefully humanity rediscovers the value of human connection. It will a bumpy road ahead, however
    *   It could also do alot of good and avoid issues within the *** or *** industry or even help prevent crime.
    *   Talking to men and machines only 95% of the time makes people depressed.

**[[D] Helps in Neurips submission (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1klqq4a/d_helps_in_neurips_submission/)**
*   **Summary:** This thread discusses about the helps regarding the Neurips submission.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   No that ship has sailed, make the papers even better and submit both to AAAI or ICLR few month after that.
    *   No, there isn't. Nearest next big one is AAAI, if I remember correctly.

**[[P] Al Solution for identifying suspicious Audio recordings (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1klrn30/p_al_solution_for_identifying_suspicious_audio/)**
*   **Summary:** The discussion revolves around an AI solution for identifying suspicious audio recordings.
*   **Emotion:** The overall emotional tone is negative.
*   **Top 3 Points of View:**
    *   Transformer is almost certainly isn't the right approach here. A single CNN for classification will almost certainly do better and be much cleaner.

**[[D] Confused PhD ML Student: Looking for advice on tying research to industry (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kltq40/d_confused_phd_ml_student_looking_for_advice_on/)**
*   **Summary:** A PhD ML student seeks advice on how to connect their research to the industry.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Apply for internships. That's the best way to do that because then they'll put you to work on something they are working. Also, do the normal work of doing a literature review.
    *   Internships. Align protects where possible with job descriptions from companies you're interested in. Adapt something from the literature (not necessarily your own) to an interesting, real world problem.
    *   Go to the careers page of companies that you like to work. Read the job description of roles that you want to do.
