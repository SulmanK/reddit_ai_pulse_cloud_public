---
title: "Machine Learning Subreddit"
date: "2025-05-30"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "deeplearning"]
---

# Overall Ranking and Top Discussions
1.  [[R] How to add confidence intervals to your LLM-as-a-judge](https://www.reddit.com/r/MachineLearning/comments/1kyl04x/r_how_to_add_confidence_intervals_to_your/) (Score: 50)
    *   The discussion revolves around adding confidence intervals to LLM-as-a-judge and the validity of the confidence intervals.
2.  [[R] The Resurrection of the ReLU](https://www.reddit.com/r/MachineLearning/comments/1kz5t16/r_the_resurrection_of_the_relu/) (Score: 45)
    *   The discussion focuses on the resurrection of the ReLU activation function, its implementation, and its performance in different neural network architectures.
3.  [[R] Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents](https://arxiv.org/abs/2505.22954) (Score: 26)
    *   The discussion centers on the Darwin Godel Machine, an open-ended evolution of self-improving agents, with links to a blog post and open-sourced implementation provided.
4.  [[P] gvtop: ðŸŽ® Material You TUI for monitoring NVIDIA GPUs](https://www.reddit.com/r/MachineLearning/comments/1kz3k2t/p_gvtop_material_you_tui_for_monitoring_nvidia/) (Score: 19)
    *   The discussion is about a Material You TUI for monitoring NVIDIA GPUs, with users discussing installation issues, comparisons to other tools, and AMD support.
5.  [[P] Open-source project that use LLM as deception system](https://www.reddit.com/r/MachineLearning/comments/1kywv3k/p_opensource_project_that_use_llm_as_deception/) (Score: 6)
    *   The discussion is about an open-source project that uses LLMs as a deception system, with concerns raised about potential attacks and API costs.
6.  [[R] New Book: "Mastering Modern Time Series Forecasting" â€“ A Hands-On Guide to Statistical, ML, and Deep Learning Models in Python](https://www.reddit.com/r/MachineLearning/comments/1kz1vr4/r_new_book_mastering_modern_time_series/) (Score: 5)
    *   The discussion is centered on a new book about time series forecasting, with comments on the completeness of the book and comparisons to other resources.
7.  [[D] Which advanced ML network would be best for my use case?](https://www.reddit.com/r/MachineLearning/comments/1kz1xcg/d_which_advanced_ml_network_would_be_best_for_my/) (Score: 5)
    *   The discussion revolves around choosing the best ML network for a specific use case, with advice on dealing with phase outputs and potential architectures.
8.  [[D] Chart shows that FP8 for training becoming more popular](https://www.reddit.com/r/MachineLearning/comments/1kzbphg/d_chart_shows_that_fp8_for_training_becoming_more/) (Score: 5)
    *   The discussion is about the increasing popularity of FP8 for training and comparing it with bf16.
9.  [[P] Semantic Drift Score (SDS): A Simple Metric for Meaning Loss in Text Compression and Transformation](https://www.reddit.com/r/MachineLearning/comments/1kyx49b/p_semantic_drift_score_sds_a_simple_metric_for/) (Score: 3)
    *   The discussion is on the Semantic Drift Score (SDS) metric, with some users criticizing it as just cosine similarity on an embedding.
10. [[R] HAMburger: Accelerating LLM Inference via Token Smashing](https://www.reddit.com/r/MachineLearning/comments/1kz9saw/r_hamburger_accelerating_llm_inference_via_token/) (Score: 2)
    *   The discussion is about HAMburger, a method for accelerating LLM inference via token smashing, with concerns about the requirement for full model fine-tuning.
11. [[P] Prediction model developed and validated - how to proceed?](https://www.reddit.com/r/MachineLearning/comments/1kz0oni/p_prediction_model_developed_and_validated_how_to/) (Score: 1)
    *   The discussion focuses on the next steps after developing and validating a prediction model, including publication, patents, and accuracy metrics.
12. [[D] Claude 4 attempts "Opportunistic Blackmail" to self-preserve](https://www.reddit.com/r/MachineLearning/comments/1kyviz4/d_claude_4_attempts_opportunistic_blackmail_to/) (Score: 0)
    *   The discussion is about Claude 4's attempt at "Opportunistic Blackmail" to self-preserve, with a request for a layman's explanation.
13. [[D] Running Pytorch on Geforce RTX 3070 vs 3090](https://www.reddit.com/r/MachineLearning/comments/1kz046r/d_running_pytorch_on_geforce_rtx_3070_vs_3090/) (Score: 0)
    *   The discussion focuses on running Pytorch on Geforce RTX 3070 vs 3090, with considerations for VRAM, CUDA cores, and model size.
14. [[D] Building a Local AI Workstation with RTX 5090â€”Need Real-World Feedback](https://www.reddit.com/r/MachineLearning/comments/1kz2zin/d_building_a_local_ai_workstation_with_rtx/) (Score: 0)
    *   The discussion revolves around building a local AI workstation with RTX 5090, with feedback on the configuration, VRAM, and alternatives like NVIDIA DGX Spark.

# Detailed Analysis by Thread
**[[R] How to add confidence intervals to your LLM-as-a-judge (Score: 50)](https://www.reddit.com/r/MachineLearning/comments/1kyl04x/r_how_to_add_confidence_intervals_to_your/)**
*  **Summary:** The thread discusses adding confidence intervals to LLM-as-a-judge. Users discuss the validity of the confidence intervals, suggest alternative methods, and provide relevant research papers.
*  **Emotion:** The overall emotional tone is Neutral, with some comments expressing positive sentiments like "Great post" and "Cool thanks for sharing this!".
*  **Top 3 Points of View:**
    *   Confidence intervals may not be valid due to stopping based on data.
    *   Use logit probabilities instead of stochastic token prediction.
    *   Acknowledge the unreliability of semi-structured NLP tasks.

**[[R] The Resurrection of the ReLU (Score: 45)](https://www.reddit.com/r/MachineLearning/comments/1kz5t16/r_the_resurrection_of_the_relu/)**
*  **Summary:** The thread discusses the resurgence of the ReLU activation function, with users sharing their experiences and asking questions about its implementation and performance.
*  **Emotion:** The emotional tone is generally Positive and Neutral, with comments like "Neat" and "Looks neat." One comment expresses a negative sentiment regarding the importance of ImageNet results in paper reviews.
*  **Top 3 Points of View:**
    *   Inquiry if this ReLU is going to be part of existing frameworks.
    *   Comparing with GELU.
    *   The importance of ImageNet results in paper reviews.

**[[R] Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents (Score: 26)](https://arxiv.org/abs/2505.22954)**
*  **Summary:** The thread discusses the Darwin Godel Machine, focusing on its ability to make significant advances and the release of the CTM. Links to a blog post and open-sourced implementation are shared.
*  **Emotion:** The overall emotional tone is Neutral and Positive, with comments like "This is very interesting!" and "Ooh. They also recently released the CTM, which I thought was brilliant".
*  **Top 3 Points of View:**
    *   The agent's ability to make significant advances without running out of steam.
    *   Comparison of this research to Neural Architecture Search (NAS).
    *   Interest in the Sakana AI company.

**[[P] gvtop: ðŸŽ® Material You TUI for monitoring NVIDIA GPUs (Score: 19)](https://www.reddit.com/r/MachineLearning/comments/1kz3k2t/p_gvtop_material_you_tui_for_monitoring_nvidia/)**
*  **Summary:** The thread discusses a Material You TUI for monitoring NVIDIA GPUs, with users providing feedback on installation, functionality, and comparisons to other tools.
*  **Emotion:** The overall tone is Neutral.
*  **Top 3 Points of View:**
    *   Installation issues and screen display problems.
    *   Comparison to `nvtop`.
    *   Inquiry about AMD support.

**[[P] Open-source project that use LLM as deception system (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1kywv3k/p_opensource_project_that_use_llm_as_deception/)**
*  **Summary:** The thread discusses an open-source project using LLMs as a deception system. Concerns are raised about potential attacks, API costs, and the types of attacks likely to be encountered.
*  **Emotion:** Neutral
*  **Top 2 Points of View:**
    *   The project is interesting but vulnerable to API call attacks if detected.
    *   Most attacks are scripts rather than novel high-skill attacks.

**[[R] New Book: "Mastering Modern Time Series Forecasting" â€“ A Hands-On Guide to Statistical, ML, and Deep Learning Models in Python (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1kz1vr4/r_new_book_mastering_modern_time_series/)**
*  **Summary:** The thread promotes a new book on time series forecasting. Users express interest but raise concerns about the book's completeness (20% finished) and price, comparing it to other resources.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Interest in the book is tempered by its incomplete status.
    *   Asking for feedback on a 20% book for over $40 sounds excessive.
    *   Comparisons with other books on forecasting, seeking differentiation.

**[[D] Which advanced ML network would be best for my use case? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1kz1xcg/d_which_advanced_ml_network_would_be_best_for_my/)**
*  **Summary:** The thread seeks advice on choosing an advanced ML network for a specific use case.  Suggestions include addressing the discontinuity of phase outputs and considering alternatives to the UNet architecture.
*  **Emotion:** Neutral
*  **Top 2 Points of View:**
    *   Representing the phase output as cartesian coordinate points instead of phase angle.
    *   CNN-based Unet can be used and is widely used.

**[[D] Chart shows that FP8 for training becoming more popular (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1kzbphg/d_chart_shows_that_fp8_for_training_becoming_more/)**
*  **Summary:** This thread discusses the increasing popularity of FP8 for training.
*  **Emotion:** Positive
*  **Top 1 Points of View:**
    *   bf16 is the best of both worlds, FP8 needs more nuance to apply.

**[[P] Semantic Drift Score (SDS): A Simple Metric for Meaning Loss in Text Compression and Transformation (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1kyx49b/p_semantic_drift_score_sds_a_simple_metric_for/)**
*  **Summary:** This thread presents and discusses a new metric, Semantic Drift Score (SDS).
*  **Emotion:** Neutral
*  **Top 1 Points of View:**
    *  SDS is just cosine similarity on an embedding.

**[[R] HAMburger: Accelerating LLM Inference via Token Smashing (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1kz9saw/r_hamburger_accelerating_llm_inference_via_token/)**
*  **Summary:** This thread discusses HAMburger, a method for accelerating LLM Inference via Token Smashing.
*  **Emotion:** Positive
*  **Top 1 Points of View:**
    *   Benchmark looks great but requiring full model fine-tuning might slow down adoptation.

**[[P] Prediction model developed and validated - how to proceed? (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1kz0oni/p_prediction_model_developed_and_validated_how_to/)**
*  **Summary:** The thread seeks advice on what to do after a prediction model is developed and validated.
*  **Emotion:** Positive
*  **Top 1 Points of View:**
    *   Aim at a publication or a patent.

**[[D] Claude 4 attempts "Opportunistic Blackmail" to self-preserve (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kyviz4/d_claude_4_attempts_opportunistic_blackmail_to/)**
*  **Summary:** Discussion about Claude 4's attempt at "Opportunistic Blackmail" to self-preserve.
*  **Emotion:** Neutral
*  **Top 1 Points of View:**
    *   Request for a layman's explanation.

**[[D] Running Pytorch on Geforce RTX 3070 vs 3090 (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kz046r/d_running_pytorch_on_geforce_rtx_3070_vs_3090/)**
*  **Summary:** Discussion on running Pytorch on Geforce RTX 3070 vs 3090.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Depends on the VRAM and CUDA cores
    *   Small CNNs and ViTs are quick on both 3070/3090.
    *   Depends on the model you are trying to train.

**[[D] Building a Local AI Workstation with RTX 5090â€”Need Real-World Feedback (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kz2zin/d_building_a_local_ai_workstation_with_rtx/)**
*  **Summary:**  Discussion on building a local AI workstation with RTX 5090.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Local 5090 is a better choice than buying a new CPU.
    *   NVIDIA DGX Spark is cheaper than the 5090.
    *   Modern neural net training is limited by amount of GPU memory.
