---
title: "Machine Learning Subreddit"
date: "2025-05-28"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machine learning", "AI", "research"]
---

# Overall Ranking and Top Discussions
1.  [[R] New ICML25 paper: Train and fine-tune large models faster than Adam while using only a fraction of the memory, with guarantees!](https://www.reddit.com/r/MachineLearning/comments/1kx3ve1/r_new_icml25_paper_train_and_finetune_large/) (Score: 96)
    *   Discussion about a new paper on training and fine-tuning large models more efficiently than Adam, with lower memory usage.
2.  [[D] Removing my Authorship After Submission to NeurIPS](https://www.reddit.com/r/MachineLearning/comments/1kxa4wh/d_removing_my_authorship_after_submission_to/) (Score: 75)
    *   A user seeks advice on removing their name from a NeurIPS submission after realizing they didn't contribute significantly and questioning the use of LLMs in writing the paper.
3.  [[D] Which open-source models are under-served by APIs and inference providers?](https://www.reddit.com/r/MachineLearning/comments/1kxl4pp/d_which_opensource_models_are_underserved_by_apis/) (Score: 42)
    *   Users discussing open-source models that lack sufficient API support and inference providers.
4.  [[D] Do all conferences require you to pay to have your paper in their proceedings?](https://www.reddit.com/r/MachineLearning/comments/1kxni6m/d_do_all_conferences_require_you_to_pay_to_have/) (Score: 11)
    *   Discussion on conference fees for publishing papers in proceedings and alternative options for publishing without fees.
5.  [[P] Anyone playing with symbolic overlays or memory-routing scaffolds on LLMs?](https://www.reddit.com/r/MachineLearning/comments/1kxjns3/p_anyone_playing_with_symbolic_overlays_or/) (Score: 7)
    *   A user asks if anyone is experimenting with symbolic overlays or memory-routing scaffolds on LLMs, followed by a request for a simplified explanation.
6.  [VideoGameBench: Can Language Models play Video Games (arXiv)](https://arxiv.org/abs/2505.18134) (Score: 5)
    *   Sharing a paper about evaluating language models in video games, with open-source code and game trajectory clips available.
7.  [[D] Advices for Machine Learning competitions](https://www.reddit.com/r/MachineLearning/comments/1kxhckl/d_advices_for_machine_learning_competitions/) (Score: 5)
    *   Users share advice on preparing for and participating in machine learning competitions.
8.  [[P] Davia : build data apps from Python with Auto-Generated UI](https://www.reddit.com/r/MachineLearning/comments/1kxpy96/p_davia_build_data_apps_from_python_with/) (Score: 2)
    *   Introducing Davia, a tool for building data apps from Python with auto-generated UI, with a user comparing it to Reflex or Streamlit.
9.  [[D] UCL Foundational AI PhD](https://www.reddit.com/r/MachineLearning/comments/1kwz9ra/d_ucl_foundational_ai_phd/) (Score: 0)
    *   Discussion about the UCL Foundational AI PhD program, including information about internships, stipends, research proposals, and connections to DeepMind.
10. [[D] AI tools for reading and comparing dense technical papers - how RAGstyle segmentation makes a difference](https://www.reddit.com/r/MachineLearning/comments/1kx5a3l/d_ai_tools_for_reading_and_comparing_dense/) (Score: 0)
    *   Discussion about AI tools for reading and comparing dense technical papers, with a user mentioning a tool they built called searchplus.ai
11. [[P]Using Machine Learning to Compensate for Wind-Induced Noise in Load Cell Measurements in Real Time](https://www.reddit.com/r/MachineLearning/comments/1kxd83f/pusing_machine_learning_to_compensate_for/) (Score: 0)
    *   Discussion about using Machine Learning to Compensate for Wind-Induced Noise in Load Cell Measurements in Real Time.
12. [[D]Where do you save frequently used prompts and how do you use them?](https://www.reddit.com/r/MachineLearning/comments/1kxgncj/dwhere_do_you_save_frequently_used_prompts_and/) (Score: 0)
    *   Discussion about saving frequently used prompts.
13. [[D] Best Path for University Graduate Moving Forward](https://www.reddit.com/r/MachineLearning/comments/1kxjbws/d_best_path_for_university_graduate_moving_forward/) (Score: 0)
    *   Discussion about the best path for a university graduate moving forward

# Detailed Analysis by Thread
**[[R] New ICML25 paper: Train and fine-tune large models faster than Adam while using only a fraction of the memory, with guarantees! (Score: 96)](https://www.reddit.com/r/MachineLearning/comments/1kx3ve1/r_new_icml25_paper_train_and_finetune_large/)**
*   **Summary:** This thread discusses a new ICML25 paper that introduces a method for training and fine-tuning large models faster than Adam while using less memory. Users are asking about comparisons to other optimization techniques, applicability to non-LLM models, and performance with larger context sizes.
*   **Emotion:** The overall emotional tone of the thread is neutral, with some instances of positive sentiment. The comments primarily consist of technical questions and requests for clarification.
*   **Top 3 Points of View:**
    *   The paper's method is potentially a significant advancement in LLM training efficiency.
    *   Users are curious about its practical applications and limitations compared to existing techniques.
    *   There is interest in whether it can be applied to models beyond LLMs.

**[[D] Removing my Authorship After Submission to NeurIPS (Score: 75)](https://www.reddit.com/r/MachineLearning/comments/1kxa4wh/d_removing_my_authorship_after_submission_to/)**
*   **Summary:** A user is seeking advice on removing their authorship from a NeurIPS submission. They did not significantly contribute to the paper and are concerned about the use of LLMs in writing the paper.
*   **Emotion:** The emotional tone of the thread is mixed, with some comments expressing concern and support, while others are more critical.  There are elements of guilt and frustration expressed.
*   **Top 3 Points of View:**
    *   The user should contact the NeurIPS editors and request a paper withdrawal due to the unauthorized addition of their name.
    *   It is essential to review papers thoroughly and that all authors should agree with being in the author list.
    *   There is a debate about the ethical implications of using LLMs to write research papers.

**[[D] Which open-source models are under-served by APIs and inference providers? (Score: 42)](https://www.reddit.com/r/MachineLearning/comments/1kxl4pp/d_which_opensource_models_are_underserved_by_apis/)**
*   **Summary:** This thread is a simple query about open-source models lacking adequate API and inference support.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Llama 4

**[[D] Do all conferences require you to pay to have your paper in their proceedings? (Score: 11)](https://www.reddit.com/r/MachineLearning/comments/1kxni6m/d_do_all_conferences_require_you_to_pay_to_have/)**
*   **Summary:** The discussion revolves around whether conferences require payment for papers to be included in their proceedings.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Conferences generally require registration fees which cover the cost of publication.
    *   Alternative publishing options, like non-OA journals or those with university agreements, exist.
    *   Some conferences offer bursaries to help with travel and registration costs.

**[[P] Anyone playing with symbolic overlays or memory-routing scaffolds on LLMs? (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1kxjns3/p_anyone_playing_with_symbolic_overlays_or/)**
*   **Summary:** This thread consists of a question and a request for a simpler explanation of a complex concept.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   The user is curious about the use of symbolic overlays or memory-routing scaffolds on LLMs.

**[VideoGameBench: Can Language Models play Video Games (arXiv) (Score: 5)](https://arxiv.org/abs/2505.18134)**
*   **Summary:** The thread shares a link to a paper and related resources about evaluating language models in video games.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   The code is open-source

**[[D] Advices for Machine Learning competitions (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1kxhckl/d_advices_for_machine_learning_competitions/)**
*   **Summary:**  The thread gives advice about how to manage time as effectively as possible.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Outline the problem early on and prioritize the easier/higher-weighted tasks first.

**[[P] Davia : build data apps from Python with Auto-Generated UI (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1kxpy96/p_davia_build_data_apps_from_python_with/)**
*   **Summary:** The thread is an introduction to Davia.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   This sounds like a backwards, slightly more complex version of reflex or streamlit?

**[[D] UCL Foundational AI PhD (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kwz9ra/d_ucl_foundational_ai_phd/)**
*   **Summary:** The thread provides information about internships, stipends, research proposals, and connections to DeepMind.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   London is expensive
    *   UCL has connections to deepmind
    *   It's possible to do internships but not easy

**[[D] AI tools for reading and comparing dense technical papers - how RAGstyle segmentation makes a difference (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kx5a3l/d_ai_tools_for_reading_and_comparing_dense/)**
*   **Summary:** The thread discusses AI tools for reading dense technical papers.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   [searchplus.ai] has support for 5GB files and advanced semantic parsing.

**[[P]Using Machine Learning to Compensate for Wind-Induced Noise in Load Cell Measurements in Real Time (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kxd83f/pusing_machine_learning_to_compensate_for/)**
*   **Summary:** The thread discusses using ML to Compensate for Wind-Induced Noise in Load Cell Measurements in Real Time.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Before applying any ML-technique, you need to set up some research scope.

**[[D]Where do you save frequently used prompts and how do you use them? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kxgncj/dwhere_do_you_save_frequently_used_prompts_and/)**
*   **Summary:** The thread discusses saving frequently used prompts.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Use notepad, excel sheets or have your ai do the prompting for you

**[[D] Best Path for University Graduate Moving Forward (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kxjbws/d_best_path_for_university_graduate_moving_forward/)**
*   **Summary:** The thread discusses the best path for a university graduate moving forward.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Go get a job, start living life and do a part time MS.
