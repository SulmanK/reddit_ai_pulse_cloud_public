---
title: "Stable Diffusion Subreddit"
date: "2025-05-29"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image editing"]
---

# Overall Ranking and Top Discussions
1.  [New FLUX image editing models dropped](https://i.redd.it/zev1b3kk9r3f1.png) (Score: 440)
    *   Users discuss the new FLUX image editing models, expressing excitement to try them locally and hoping for compatibility with existing tools.
2.  [Testing FLUX.1 Kontext (Open-weights coming soon)](https://www.reddit.com/gallery/1kyh5d4) (Score: 118)
    *   Users are testing the FLUX.1 Kontext model, anticipating the release of open weights and discussing its integration with ComfyUI.
3.  [Black Forest Labs - Flux Kontext Model Release](https://bfl.ai/models/flux-kontext) (Score: 116)
    *   The community discusses the release of the Flux Kontext model by Black Forest Labs, focusing on its features, potential, and the eventual availability of the open-weights version.
4.  [Huge news BFL announced new amazing Flux model open weights](https://www.reddit.com/gallery/1kyhyl1) (Score: 29)
    *   Users react to the announcement of the FLUX model, focusing on open weights, the 12B Kontext-Dev model, and its potential impact on local generation.
5.  [C4D to ComfyUI - NEW AI PLUGIN](https://i.redd.it/elie1zdh5r3f1.png) (Score: 17)
    *   A new Cinema 4D plugin that integrates with ComfyUI is announced, and users express interest and inquire about Blender support.
6.  [Looks like kontext is raising the bar cant wait for dev - Spotify Light mode](https://www.reddit.com/gallery/1kyk1hc) (Score: 9)
    *   Users observe that Kontext is raising the bar on breaking Rule 1.
7.  [C4D to ComfyUI (0.1.9) - AI PLUGIN](https://v.redd.it/t26h6nyq6r3f1) (Score: 8)
    *   Users discuss the release of a C4D to ComfyUI plugin and show interest in testing it for production pipelines.
8.  [If I train a LoRA using only close-up, face-focused images, will it still work well when I use it to generate full-body images?](https://www.reddit.com/r/StableDiffusion/comments/1kyhepz/if_i_train_a_lora_using_only_closeup_facefocused/) (Score: 5)
    *   Users discuss the effectiveness of training a LoRA with only close-up images for generating full-body images, offering advice and sharing experiences.
9.  [what program to train loras that actually work with hunyuan and framepack?](https://www.reddit.com/r/StableDiffusion/comments/1kyim6y/what_program_to_train_loras_that_actually_work/) (Score: 3)
    *   Users are looking for a program to train LoRAs.
10. [How to Resolve Startup Error with Kohya - "When localhost is not accessible, a shareable link must be created"?](https://i.redd.it/7defzgx7xr3f1.jpeg) (Score: 2)
    *   Users are troubleshooting a startup error with Kohya.
11. [Conspiracy theory: closed-source video generation scams people?](https://www.reddit.com/r/StableDiffusion/comments/1kyfzyy/conspiracy_theory_closedsource_video_generation/) (Score: 2)
    *   Users discuss the possibility of closed-source video generation services scamming users by degrading quality over time.
12. [How do I use WAN 2.1 VACE?](https://www.reddit.com/r/StableDiffusion/comments/1kygawa/how_do_i_use_wan_21_vace/) (Score: 2)
    *   Users seek guidance on how to use WAN 2.1 VACE, and are directed to documentation.
13. [What is being used here to rotate 2d images ?](https://www.reddit.com/r/StableDiffusion/comments/1kyjw3v/what_is_being_used_here_to_rotate_2d_images/) (Score: 2)
    *   Users discuss how to rotate 2d images and what Lora is used.
14. [What are your methods for improving details and resolution for i2v videos? Wan 2.1](https://www.reddit.com/r/StableDiffusion/comments/1kyha8e/what_are_your_methods_for_improving_details_and/) (Score: 1)
    *   Users discuss methods for improving details and resolution for i2v videos using Wan 2.1.

# Detailed Analysis by Thread
**[New FLUX image editing models dropped (Score: 440)](https://i.redd.it/zev1b3kk9r3f1.png)**
*   **Summary:** Users discuss the new FLUX image editing models, expressing excitement to try them locally and hoping for compatibility with existing tools.
*   **Emotion:** Predominantly Positive, with users expressing excitement and anticipation. Some Neutral comments provide additional information.
*   **Top 3 Points of View:**
    *   Excitement about trying the models locally.
    *   Hope that Flux\[dev\] LoRAs will be compatible.
    *   Desire for the models to be open source.

**[Testing FLUX.1 Kontext (Open-weights coming soon) (Score: 118)](https://www.reddit.com/gallery/1kyh5d4)**
*   **Summary:** Users are testing the FLUX.1 Kontext model, anticipating the release of open weights and discussing its integration with ComfyUI.
*   **Emotion:** Predominantly Positive, expressing excitement and anticipation for the open-weights version. Neutral comments are questions seeking more info.
*   **Top 3 Points of View:**
    *   Anticipation for the open-weights version and its potential.
    *   Confirmation that it is already ComfyUI bound.
    *   Questions about VRAM requirements.

**[Black Forest Labs - Flux Kontext Model Release (Score: 116)](https://bfl.ai/models/flux-kontext)**
*   **Summary:** The community discusses the release of the Flux Kontext model by Black Forest Labs, focusing on its features, potential, and the eventual availability of the open-weights version.
*   **Emotion:** Mostly Positive, with users expressing optimism and sharing their initial positive experiences with the model. Neutral comments mostly provided factual information or asked clarifying questions.
*   **Top 3 Points of View:**
    *   Excitement about the potential of the Flux Kontext model and its capabilities.
    *   Hope for the open-weights release and its accessibility.
    *   Discussion about the model's performance and requirements (e.g., VRAM).

**[Huge news BFL announced new amazing Flux model open weights (Score: 29)](https://www.reddit.com/gallery/1kyhyl1)**
*   **Summary:** Users react to the announcement of the FLUX model, focusing on open weights, the 12B Kontext-Dev model, and its potential impact on local generation.
*   **Emotion:** Mostly Positive, with excitement about the open weights. Some Negative sentiment expresses skepticism. Neutral comments present facts and links.
*   **Top 3 Points of View:**
    *   Enthusiasm about the open weights and the 12B Kontext-Dev model.
    *   Skepticism about the 12B dev model being dumbed down.
    *   Desire for the model to maintain compatibility with existing tools like ControlNet.

**[C4D to ComfyUI - NEW AI PLUGIN (Score: 17)](https://i.redd.it/elie1zdh5r3f1.png)**
*   **Summary:** A new Cinema 4D plugin that integrates with ComfyUI is announced, and users express interest and inquire about Blender support.
*   **Emotion:** A mix of Positive and Neutral. Users are excited about the plugin, and also want support for Blender.
*   **Top 3 Points of View:**
    *   Enthusiasm for the new plugin for C4D.
    *   Request for a similar plugin for Blender.

**[Looks like kontext is raising the bar cant wait for dev - Spotify Light mode (Score: 9)](https://www.reddit.com/gallery/1kyk1hc)**
*   **Summary:** Users observe that Kontext is raising the bar on breaking Rule 1.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Kontext is raising the bar on people breaking Rule 1.

**[C4D to ComfyUI (0.1.9) - AI PLUGIN (Score: 8)](https://v.redd.it/t26h6nyq6r3f1)**
*   **Summary:** Users discuss the release of a C4D to ComfyUI plugin and show interest in testing it for production pipelines.
*   **Emotion:** Positive.
*   **Top 3 Points of View:**
    *   Interest in testing and utilizing the C4D to ComfyUI plugin in their production pipeline.

**[If I train a LoRA using only close-up, face-focused images, will it still work well when I use it to generate full-body images? (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1kyhepz/if_i_train_a_lora_using_only_closeup_facefocused/)**
*   **Summary:** Users discuss the effectiveness of training a LoRA with only close-up images for generating full-body images, offering advice and sharing experiences.
*   **Emotion:** Mostly Neutral, providing advice on LoRA training. Occasional positive sentiments based on individual experience.
*   **Top 3 Points of View:**
    *   It's possible, but not ideal; training with full-body images mixed in would improve results.
    *   It can work for face swapping with extra steps like using adetailer.
    *   It may work in some cases, depending on the desired results.

**[what program to train loras that actually work with hunyuan and framepack? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1kyim6y/what_program_to_train_loras_that_actually_work/)**
*   **Summary:** Users are looking for a program to train LoRAs.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Musubi works but the documentation is hard to follow.

**[How to Resolve Startup Error with Kohya - "When localhost is not accessible, a shareable link must be created"? (Score: 2)](https://i.redd.it/7defzgx7xr3f1.jpeg)**
*   **Summary:** Users are troubleshooting a startup error with Kohya.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Disable VPN.

**[Conspiracy theory: closed-source video generation scams people? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1kyfzyy/conspiracy_theory_closedsource_video_generation/)**
*   **Summary:** Users discuss the possibility of closed-source video generation services scamming users by degrading quality over time.
*   **Emotion:** Mixed, with Negative sentiments expressing concern about quality degradation and Neutral sentiments offering alternative explanations or solutions. Some positive sentiment about abandoning paid services.
*   **Top 3 Points of View:**
    *   Closed-source video generation services might degrade quality over time to save money or encourage users to upgrade.
    *   This might be what happens with LLMs as well.
    *   The quality drop could be due to server load.

**[How do I use WAN 2.1 VACE? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1kygawa/how_do_i_use_wan_21_vace/)**
*   **Summary:** Users seek guidance on how to use WAN 2.1 VACE, and are directed to documentation.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Provide documentation to user.

**[What is being used here to rotate 2d images ? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1kyjw3v/what_is_being_used_here_to_rotate_2d_images/)**
*   **Summary:** Users discuss how to rotate 2d images and what Lora is used.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Theres a turntable wan Lora for this.

**[What are your methods for improving details and resolution for i2v videos? Wan 2.1 (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1kyha8e/what_are_your_methods_for_improving_details_and/)**
*   **Summary:** Users discuss methods for improving details and resolution for i2v videos using Wan 2.1.
*   **Emotion:** Mixed, with Positive sentiments about the effectiveness of FramePack and Neutral sentiments providing advice on rendering settings.
*   **Top 3 Points of View:**
    *   FramePack is very good at maintaining the exact details of the original image.
    *   Use 720p rather than 480p.
