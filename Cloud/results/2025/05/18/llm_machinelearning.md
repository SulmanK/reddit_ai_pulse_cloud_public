---
title: "Machine Learning Subreddit"
date: "2025-05-18"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "research"]
---

# Overall Ranking and Top Discussions
1.  [[D] Has a research field ever been as saturated or competitive as Machine Learning in 2025?](https://www.reddit.com/r/MachineLearning/comments/1kph8k7/d_has_a_research_field_ever_been_as_saturated_or/) (Score: 117)
    *   Users discuss the saturation and competitiveness of the Machine Learning research field in 2025, with many feeling that it has become overly saturated with low-quality papers.
2.  [[P] I built a transformer that skips layers per token based on semantic importance](https://www.reddit.com/r/MachineLearning/comments/1kpalhd/p_i_built_a_transformer_that_skips_layers_per/) (Score: 103)
    *   A user presents a transformer architecture that skips layers per token based on semantic importance, leading to discussions about efficiency and comparisons to existing techniques like input pruning and mixture of depths.
3.  [[D] Can we possibly construct an AlphaEvolve@HOME?](https://www.reddit.com/r/MachineLearning/comments/1kp4nxq/d_can_we_possibly_construct_an_alphaevolvehome/) (Score: 33)
    *   Users discuss the possibility of creating a distributed computing project similar to AlphaEvolve, but for home users. Concerns are raised about network connectivity issues and the challenges of orchestrating distributed work.
4.  [[D] Inspired by Anthropic’s Biology of an LLM: Exploring Prompt Cues in Two LLMs](https://www.reddit.com/gallery/1kpfwfb) (Score: 10)
    *   A user shares work inspired by Anthropic's "Biology of an LLM," exploring prompt cues in two LLMs. The discussion involves confidence measurement and a potential plugin submission.
5.  [[R] First Paper Submission](https://www.reddit.com/r/MachineLearning/comments/1kp4fud/r_first_paper_submission/) (Score: 8)
    *   The thread discusses whether or not reviewers actually look at the code submission with a paper.
6.  [[D] Complete Analysis of System Prompt Leaks from Major LLMs](https://www.reddit.com/r/MachineLearning/comments/1kphqkb/d_complete_analysis_of_system_prompt_leaks_from/) (Score: 8)
    *   A user shares a complete analysis of system prompt leaks from major LLMs. Another user shares a fix for the English translation.
7.  [[D] Is python ever the bottle neck?](https://www.reddit.com/r/MachineLearning/comments/1kpg89p/d_is_python_ever_the_bottle_neck/) (Score: 5)
    *   Users debate whether Python can be a bottleneck in machine learning workflows, particularly in data preprocessing and custom implementations.
8.  [[D] ML for Aerospace: any course?](https://www.reddit.com/r/MachineLearning/comments/1kpj59u/d_ml_for_aerospace_any_course/) (Score: 5)
    *   A user asks about relevant courses for applying machine learning in aerospace. Others suggest focusing on research papers, networking on LinkedIn, and gaining experience with sensor data and time-series analysis.
9.  [[P] Project Feedback Request: Tackling Catastrophic Forgetting with a Modular LLM Approach (PEFT Router + CL)](https://www.reddit.com/r/MachineLearning/comments/1kpax4u/p_project_feedback_request_tackling_catastrophic/) (Score: 4)
    *   A user requests feedback on a project addressing catastrophic forgetting in LLMs using a modular approach. Similar implementations and evaluation methods are discussed.
10. [[D] Hardware Stuff : Nvidia P104-100 for Machine Learning?](https://www.reddit.com/r/MachineLearning/comments/1kpdqt7/d_hardware_stuff_nvidia_p104100_for_machine/) (Score: 3)
    *   The discussion focuses on the usability of Nvidia P104-100 GPUs for machine learning tasks. Users share their experiences, noting its suitability for inference but potential limitations for training, along with compatibility issues with newer Python libraries.
11. [[D] Best tools for academic writing](https://www.reddit.com/r/MachineLearning/comments/1kpi1w9/d_best_tools_for_academic_writing/) (Score: 2)
    *   The thread discusses best tools for academic writing.
12. [[R] What if only final output of Neural ODE is available for supervision?](https://www.reddit.com/r/MachineLearning/comments/1kpr5pa/r_what_if_only_final_output_of_neural_ode_is/) (Score: 2)
    *   A theoretical question is asked and answered regarding Neural ODE.
13. [[D] Training RT-DETR with MPS on M4 Max)](https://www.reddit.com/r/MachineLearning/comments/1kpj446/d_training_rtdetr_with_mps_on_m4_max/) (Score: 1)
    *   Users discuss the challenges and limitations of training RT-DETR with MPS on the M4 Max chip. Compatibility issues with operations, CPU fallbacks, and the advantages of using RTX cards are highlighted.
14. [[D] Gemini's Long Context MoE Architecture (Hypothesized)](https://i.redd.it/zs928kisik1f1.png) (Score: 0)
    *   A user hypothesizes about Gemini's long-context MoE architecture.
15. [[D] ACL ARR May 2025 Discussion](https://www.reddit.com/r/MachineLearning/comments/1kpeo4i/d_acl_arr_may_2025_discussion/) (Score: 0)
    *   The thread posts important dates and deadlines regarding the ACL ARR cycle.
16. [[D] What to expect next for ICCV 2025?](https://www.reddit.com/r/MachineLearning/comments/1kpmlz8/d_what_to_expect_next_for_iccv_2025/) (Score: 0)
    *   The thread discusses what to expect next regarding ICCV 2025.

# Detailed Analysis by Thread

**[[D] Has a research field ever been as saturated or competitive as Machine Learning in 2025? (Score: 117)](https://www.reddit.com/r/MachineLearning/comments/1kph8k7/d_has_a_research_field_ever_been_as_saturated_or/)**
*  **Summary:** Users discuss the increasing saturation and competitiveness of the machine learning research field in 2025. Many commenters express concerns about the proliferation of low-quality papers and the difficulty of standing out. Others note that this saturation is a natural consequence of the field's growth and importance, and that it ultimately drives innovation.
*  **Emotion:** The overall emotional tone is mixed. While the sentiment is mostly neutral, there are both positive and negative emotions present. Some express frustration and negativity regarding the competitiveness and low quality, while others remain positive, emphasizing the overall growth and progress of the field.
*  **Top 3 Points of View:**
    *   The field is highly saturated with low-quality papers, making it difficult to find valuable research.
    *   The high competition makes it difficult for researchers to publish and advance their careers.
    *   The saturation is a natural consequence of the field's growth and importance, ultimately driving innovation.

**[[P] I built a transformer that skips layers per token based on semantic importance (Score: 103)](https://www.reddit.com/r/MachineLearning/comments/1kpalhd/p_i_built_a_transformer_that_skips_layers_per/)**
*  **Summary:** A user shares a project where they built a transformer model that skips layers per token based on semantic importance. Other users provide feedback, comparisons to existing techniques, and suggestions for further experimentation.
*  **Emotion:** The overall emotion is positive and neutral. Commenters are generally supportive and encouraging.
*  **Top 3 Points of View:**
    *   The project is interesting and a good idea, especially for a high school student.
    *   The approach is similar to existing techniques like input pruning and mixture of depths.
    *   Further evaluation and benchmarking are needed to demonstrate the effectiveness of the approach.

**[[D] Can we possibly construct an AlphaEvolve@HOME? (Score: 33)](https://www.reddit.com/r/MachineLearning/comments/1kp4nxq/d_can_we_possibly_construct_an_alphaevolvehome/)**
*  **Summary:** The discussion explores the feasibility of creating a distributed computing project similar to AlphaEvolve for home users.
*  **Emotion:**  The overall emotional tone is neutral. There is cautious optimism mixed with realistic concerns about the challenges of distributed computing.
*  **Top 3 Points of View:**
    *   The idea of a distributed AlphaEvolve project is appealing.
    *   Network connectivity issues and the orchestration of distributed work are significant challenges.
    *   Existing projects attempting similar concepts have not made significant progress.

**[[D] Inspired by Anthropic’s Biology of an LLM: Exploring Prompt Cues in Two LLMs (Score: 10)](https://www.reddit.com/gallery/1kpfwfb)**
*  **Summary:** A user shares work inspired by Anthropic's research, exploring prompt cues in LLMs.
*  **Emotion:** The overall emotional tone is positive. There is interest in the work.
*  **Top 3 Points of View:**
    *   Inquiry on how the user measured confidence.
    *   Suggestion to submit the work as a plugin to an open-source project.

**[[R] First Paper Submission (Score: 8)](https://www.reddit.com/r/MachineLearning/comments/1kp4fud/r_first_paper_submission/)**
*  **Summary:** The thread discusses whether or not reviewers actually look at the code submission with a paper.
*  **Emotion:**  The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   It's likely exceptionally rare for a reviewer to actually fully run code.
    *   Including the code is a "show of good faith".
    *   Some reviewers will run the code briefly just to make sure it runs.

**[[D] Complete Analysis of System Prompt Leaks from Major LLMs (Score: 8)](https://www.reddit.com/r/MachineLearning/comments/1kphqkb/d_complete_analysis_of_system_prompt_leaks_from/)**
*  **Summary:** A user shares a complete analysis of system prompt leaks from major LLMs and another user shares a fix for the English translation.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   User provides an analysis of the System Prompt Leaks.
    *   User provides a fix to the English translation.

**[[D] Is python ever the bottle neck? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1kpg89p/d_is_python_ever_the_bottle_neck/)**
*  **Summary:** Users discuss whether Python can be a bottleneck in machine learning workflows.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Python is not a bottleneck for boilerplate code.
    *   Python can be a bottleneck for custom implementations with long loops.
    *   Using optimized libraries like NumPy, PyTorch, and TensorFlow can mitigate Python bottlenecks.

**[[D] ML for Aerospace: any course? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1kpj59u/d_ml_for_aerospace_any_course/)**
*  **Summary:** A user inquires about relevant courses for applying machine learning in aerospace.
*  **Emotion:** The overall emotional tone is negative.
*  **Top 3 Points of View:**
    *   Focus on research papers instead of courses.
    *   Networking on LinkedIn is valuable.
    *   Gain experience with sensor data and time-series analysis.

**[[P] Project Feedback Request: Tackling Catastrophic Forgetting with a Modular LLM Approach (PEFT Router + CL) (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1kpax4u/p_project_feedback_request_tackling_catastrophic/)**
*  **Summary:** A user requests feedback on a project addressing catastrophic forgetting in LLMs.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   A similar implementation exists in an open-source project.
    *   Careful evaluation and comparison to existing techniques are important.

**[[D] Hardware Stuff : Nvidia P104-100 for Machine Learning? (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1kpdqt7/d_hardware_stuff_nvidia_p104100_for_machine/)**
*  **Summary:**  Users share experiences with the Nvidia P104-100 GPU for machine learning.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 3 Points of View:**
    *   P104-100 is good for inference.
    *   P104-100 has limitations for training.
    *   There might be compatibility issues with newer Python libraries.

**[[D] Best tools for academic writing (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1kpi1w9/d_best_tools_for_academic_writing/)**
*  **Summary:** The thread discusses best tools for academic writing.
*  **Emotion:**  The overall emotional tone is negative.
*  **Top 3 Points of View:**
    *   Math written by GPT is sketchy at best.
    *   Research takes time if you do it solo.

**[[R] What if only final output of Neural ODE is available for supervision? (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1kpr5pa/r_what_if_only_final_output_of_neural_ode_is/)**
*  **Summary:** A theoretical question is asked and answered regarding Neural ODE.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Redundant. Under very mild conditions you should be able to do it with Fourier series.

**[[D] Training RT-DETR with MPS on M4 Max) (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1kpj446/d_training_rtdetr_with_mps_on_m4_max/)**
*  **Summary:** Users discuss the limitations of training RT-DETR with MPS on M4 Max.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 3 Points of View:**
    *   Compatibility issues can cause CPU fallbacks.
    *   RTX cards are faster for practical purposes.
    *   Inference is good due to higher VRAM memory.

**[[D] Gemini's Long Context MoE Architecture (Hypothesized) (Score: 0)](https://i.redd.it/zs928kisik1f1.png)**
*  **Summary:** Shared context can act as independent shards of (mini) contexts. It can operate somewhat independently and then scale up into a larger global attention.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Shared context that can act as independent shards of (mini) contexts.
    *   Sub-global attention blocks can operate somewhat independently and then scale up or compose into a larger global attention.

**[[D] ACL ARR May 2025 Discussion (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kpeo4i/d_acl_arr_may_2025_discussion/)**
*  **Summary:** The thread posts important dates and deadlines regarding the ACL ARR cycle.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   ACL ARR May 2025 Deadlines

**[[D] What to expect next for ICCV 2025? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1kpmlz8/d_what_to_expect_next_for_iccv_2025/)**
*  **Summary:** The thread discusses what to expect next regarding ICCV 2025.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The next communication will be the decision.
