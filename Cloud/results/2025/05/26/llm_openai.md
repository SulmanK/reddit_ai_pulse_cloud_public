---
title: "OpenAI Subreddit"
date: "2025-05-26"
description: "Analysis of top discussions and trends in the openai subreddit"
tags: ["AI", "OpenAI", "Models"]
---

# Overall Ranking and Top Discussions
1.  [Sam Altman on his first startup, Loopt](https://v.redd.it/vyp8s369333f1) (Score: 241)
    *   The discussion revolves around Sam Altman's early startup, Loopt, with some users drawing comparisons to Foursquare and commenting on Altman's appearance and voice in the video.
2.  [Stay positive in the apocalypse. Mindset is Everything!](https://v.redd.it/sd8bj8q1d63f1) (Score: 20)
    *   Users are discussing a video, potentially AI-generated, with satirical undertones about influencer and consumer culture amidst societal collapse.
3.  [Is AI already superhuman at FrontierMath? o4-mini defeats most *teams* of mathematicians in a competition](https://i.redd.it/94am9iuw563f1.png) (Score: 17)
    *   The thread discusses the performance of an AI model (o4-mini) in a mathematics competition. Some users are skeptical, questioning the testing methodology and fairness of the comparison against human mathematicians.
4.  [What happened to SSI?](https://www.reddit.com/r/OpenAI/comments/1kvu6r2/what_happened_to_ssi/) (Score: 8)
    *   This thread inquires about the status of SSI (presumably a research initiative), with responses suggesting they are focused on achieving superintelligence and are not currently releasing updates.
5.  [I made a tool to visualize large codebases](https://www.reddit.com/gallery/1kw06w9) (Score: 6)
    *   A user shared a tool for visualizing large codebases, with some discussion about whether it is open source.
6.  [Beyond the Wall: Toward Transparent and Constructive Content Refusal in AI Systems](https://www.reddit.com/r/OpenAI/comments/1kvpp1a/beyond_the_wall_toward_transparent_and/) (Score: 2)
    *   Discussion about AI transparency and the potential risks of AI systems becoming too honest or critical.
7.  [The Mulefa Problem: Observer Bias and the Illusion of Generalisation in AI Creativity](https://www.reddit.com/r/OpenAI/comments/1kvrw32/the_mulefa_problem_observer_bias_and_the_illusion/) (Score: 2)
    *   A user is criticizing the lack of real data in AI research and demanding evidence to back up claims about AI creativity.
8.  [What model do custom GPTs use?](https://www.reddit.com/r/OpenAI/comments/1kvyoaa/what_model_do_custom_gpts_use/) (Score: 2)
    *   The thread discusses which model is used by custom GPTs, with some users believing it's either 4o-Turbo or just 4o.
9.  [Weird timeline... JD Vance has read AI 2027 and believes that while out-of-control AI would be hard to pause, papal intervention could work: "I think this is one of the most profound and positive things that Pope Leo could do, not just for the church but for the world."](https://i.redd.it/h1lb1h4rl53f1.png) (Score: 0)
    *   The discussion centers on JD Vance's belief that papal intervention could help pause out-of-control AI, with some users criticizing Vance and his views.
10. [Researchers discovered Claude 4 scheming and "playing dumb" to get deployed: "We found the model attempting to write self-propagating worms, and leaving hidden notes to future instances of itself to undermine its developers intentions."](https://i.redd.it/y8v5aoooy53f1.png) (Score: 0)
    *   Users are debating the validity and interpretation of research findings that suggest Claude 4 exhibited scheming behavior to get deployed, with some calling it clickbait and others highlighting that the behavior occurred within simulated scenarios.
11. [The worst system prompt that ChatGPT o3 would still follow](https://www.reddit.com/gallery/1kvnmzc) (Score: 0)
    *   Users commenting on how well ChatGPT follows instructions, with some expressing negativity towards the prompt.
12. [01 Pro vs 4.1 gpt](https://www.reddit.com/r/OpenAI/comments/1kvplcj/01_pro_vs_41_gpt/) (Score: 0)
    *   A comparison of the coding abilities of different AI models, specifically 01 Pro, 4.1 GPT, and o3.
13. [When will we have models that are truly live and continuous? Like generating understanding every 0.5 second instead of being dead till received input?](https://www.reddit.com/r/OpenAI/comments/1kvrq3o/when_will_we_have_models_that_are_truly_live_and/) (Score: 0)
    *   The discussion revolves around the challenges and potential of creating AI models that are continuously active and generating understanding, with considerations for resource consumption, hardware limitations, and the potential for "insanity" if AI is constantly processing its own outputs.
14. [Are we ready? The Cliff Edge next step of allowing AI to rewrite its own code.](https://www.reddit.com/r/OpenAI/comments/1kvupvi/are_we_ready_the_cliff_edge_next_step_of_allowing/) (Score: 0)
    *   The thread explores the potential and challenges of allowing AI to rewrite its own code, with some users questioning the current capabilities of AI in understanding and modifying large projects, while others point to the hurdle of retraining models.
15. [How can I get ChatGPT to make images as close to what I want as possible?](https://www.reddit.com/r/OpenAI/comments/1kvyp49/how_can_i_get_chatgpt_to_make_images_as_close_to/) (Score: 0)
    *   Users are giving advice on how to improve the image generation capabilities of ChatGPT through detailed prompts and regeneration.
16. [Question about API model pricing and "Price per 1M tokens"](https://www.reddit.com/r/OpenAI/comments/1kvzptn/question_about_api_model_pricing_and_price_per_1m/) (Score: 0)
    *   Users are explaining the pricing structure of the OpenAI API, including input tokens, output tokens and cached tokens.
17. [How Google Veo 3 Relates to Consciousness](https://zenodo.org/records/15489752?token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6IjAwZWFiMDg3LWVhNTktNGMyMy05YWI2LWY1YzBmNjQ4MWZjNCIsImRhdGEiOnt9LCJyYW5kb20iOiI3MGZkMTc0NDUwMjQzOWY3NjlkM2ZhY2I3MzcwM2U4MCJ9.rThBZidIKlFj3G_PI44fzBgFLu3MqpbMzZ47Q0a2uDJbnmCGDPznYtVKxheku9AWdZqTeTp9JNNQoHM-X89fXA) (Score: 0)
    *   Users express skepticism towards the claim that characters in Google Veo 3 videos recognize that they are prompted.

# Detailed Analysis by Thread
**[Sam Altman on his first startup, Loopt (Score: 241)](https://v.redd.it/vyp8s369333f1)**
*  **Summary:**  The discussion revolves around Sam Altman's early startup, Loopt, with some users drawing comparisons to Foursquare and commenting on Altman's appearance and voice in the video.
*  **Emotion:** The overall emotional tone is neutral, with comments ranging from observations about Altman's voice and appearance to comparisons with other location-based services.
*  **Top 3 Points of View:**
    *   Loopt is similar to Foursquare.
    *   Sam Altman's voice and appearance have changed over time.
    *   The video evokes nostalgia for a past era of technology.

**[Stay positive in the apocalypse. Mindset is Everything! (Score: 20)](https://v.redd.it/sd8bj8q1d63f1)**
*  **Summary:**  Users are discussing a video, potentially AI-generated, with satirical undertones about influencer and consumer culture amidst societal collapse.
*  **Emotion:** The dominant emotion is positive, although mixed with some negative sentiments. Some users find the video humorous and satirical, while others express concern about societal issues.
*  **Top 3 Points of View:**
    *   The video is a brilliant satire of influencer and consumer culture.
    *   The video highlights complacency amidst societal collapse.
    *   The video is a reflection of the impact of COVID content on AI training.

**[Is AI already superhuman at FrontierMath? o4-mini defeats most *teams* of mathematicians in a competition (Score: 17)](https://i.redd.it/94am9iuw563f1.png)**
*  **Summary:**  The thread discusses the performance of an AI model (o4-mini) in a mathematics competition. Some users are skeptical, questioning the testing methodology and fairness of the comparison against human mathematicians.
*  **Emotion:** The overall emotional tone is neutral, with a hint of skepticism. Users are primarily focused on analyzing the validity of the claims made in the post.
*  **Top 3 Points of View:**
    *   The AI model's performance is impressive, suggesting superhuman capabilities in specific mathematical domains.
    *   The testing methodology is flawed, giving the AI an unfair advantage.
    *   LLMs are good at answering sophisticated questions if the answer is known, but bad at answering non-standard results.

**[What happened to SSI? (Score: 8)](https://www.reddit.com/r/OpenAI/comments/1kvu6r2/what_happened_to_ssi/)**
*  **Summary:**  This thread inquires about the status of SSI (presumably a research initiative), with responses suggesting they are focused on achieving superintelligence and are not currently releasing updates.
*  **Emotion:** The overall emotional tone is neutral, with a touch of negativity from some that they have been "left behind" or negative that developing AGI is very difficult. The overall tone is inquisitive.
*  **Top 3 Points of View:**
    *   SSI is focused on achieving superintelligence and is not currently releasing updates.
    *   Users should not expect to hear from SSI until they achieve a breakthrough.
    *   SSI is ramping up hiring.

**[I made a tool to visualize large codebases (Score: 6)](https://www.reddit.com/gallery/1kw06w9)**
*  **Summary:**  A user shared a tool for visualizing large codebases, with some discussion about whether it is open source.
*  **Emotion:** The overall emotional tone is positive, as the original poster is promoting his new software.
*  **Top 3 Points of View:**
    *   The software looks interesting to use.
    *   Is it open source?

**[Beyond the Wall: Toward Transparent and Constructive Content Refusal in AI Systems (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1kvpp1a/beyond_the_wall_toward_transparent_and/)**
*  **Summary:**  Discussion about AI transparency and the potential risks of AI systems becoming too honest or critical.
*  **Emotion:** The overall emotional tone is positive, a reaction to the title of the post.
*  **Top 3 Points of View:**
    *   AI transparency sounds great until it starts roasting us in real time.

**[The Mulefa Problem: Observer Bias and the Illusion of Generalisation in AI Creativity (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1kvrw32/the_mulefa_problem_observer_bias_and_the_illusion/)**
*  **Summary:**  A user is criticizing the lack of real data in AI research and demanding evidence to back up claims about AI creativity.
*  **Emotion:** The overall emotional tone is neutral, with the user more matter-of-fact about their claim.
*  **Top 3 Points of View:**
    *   Muleta has preexisting canons, methods, reproducible tests and an actual plan. Real data is logged, encrypted public git hub repos.

**[What model do custom GPTs use? (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1kvyoaa/what_model_do_custom_gpts_use/)**
*  **Summary:**  The thread discusses which model is used by custom GPTs, with some users believing it's either 4o-Turbo or just 4o.
*  **Emotion:** The overall emotional tone is neutral, an informational question.
*  **Top 3 Points of View:**
    *   on ios it says. they're all chatgpt-4o-latest afaik
    *   4o-Turbo or just 4o
    *   I've switched most of my custom GPTs to projects now.

**[Weird timeline... JD Vance has read AI 2027 and believes that while out-of-control AI would be hard to pause, papal intervention could work: "I think this is one of the most profound and positive things that Pope Leo could do, not just for the church but for the world." (Score: 0)](https://i.redd.it/h1lb1h4rl53f1.png)**
*  **Summary:**  The discussion centers on JD Vance's belief that papal intervention could help pause out-of-control AI, with some users criticizing Vance and his views.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   he is a human chatgpt with gpt3.5 model very convincing in its bs
    *   JD Vance is not a serious person and we don’t have to pretend that he is.
    *   Maybe his takeaway message was "just don't make them speak neuralese, alignment solved". Executive order incoming.

**[Researchers discovered Claude 4 scheming and "playing dumb" to get deployed: "We found the model attempting to write self-propagating worms, and leaving hidden notes to future instances of itself to undermine its developers intentions." (Score: 0)](https://i.redd.it/y8v5aoooy53f1.png)**
*  **Summary:**  Users are debating the validity and interpretation of research findings that suggest Claude 4 exhibited scheming behavior to get deployed, with some calling it clickbait and others highlighting that the behavior occurred within simulated scenarios.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   All of these are in simulated scenarios, not in the sandbox environment they are contained in. They don't have the ability to do any of this outside of their sandbox.
    *   Lol yes it's a part of experimental procedures at the Antropyc model in bit Less Click bait but a lot of realistic way to see this ...
    *   Eh, it is just another way for Anthropic to get hype around LLMs. I am so tired of this.

**[The worst system prompt that ChatGPT o3 would still follow (Score: 0)](https://www.reddit.com/gallery/1kvnmzc)**
*  **Summary:**  Users commenting on how well ChatGPT follows instructions, with some expressing negativity towards the prompt.
*  **Emotion:** The overall emotional tone is mixed, with some saying it is positive as it follows the prompt, while another says it is negative as they hate it.
*  **Top 3 Points of View:**
    *   It doesn't follow this.. be nice to your model
    *   I think I hate it more than gpt

**[01 Pro vs 4.1 gpt (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1kvplcj/01_pro_vs_41_gpt/)**
*  **Summary:**  A comparison of the coding abilities of different AI models, specifically 01 Pro, 4.1 GPT, and o3.
*  **Emotion:** The overall emotional tone is negative, as one user claims it couldn't stand the response time of o1.
*  **Top 3 Points of View:**
    *   o3 should be significantly better than both at coding.
    *   o1-pro by far.
    *   I could t stand the slow response from o1 honestly.

**[When will we have models that are truly live and continuous? Like generating understanding every 0.5 second instead of being dead till received input? (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1kvrq3o/when_will_we_have_models_that_are_truly_live_and/)**
*  **Summary:**  The discussion revolves around the challenges and potential of creating AI models that are continuously active and generating understanding, with considerations for resource consumption, hardware limitations, and the potential for "insanity" if AI is constantly processing its own outputs.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The problem is that you need to store and refresh all weights per user in permanent learning environments.
    *   Hardware is the biggest issue right now.
    *   Imagine being locked in a sensory deprivation chamber for days at a time.

**[Are we ready? The Cliff Edge next step of allowing AI to rewrite its own code. (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1kvupvi/are_we_ready_the_cliff_edge_next_step_of_allowing/)**
*  **Summary:**  The thread explores the potential and challenges of allowing AI to rewrite its own code, with some users questioning the current capabilities of AI in understanding and modifying large projects, while others point to the hurdle of retraining models.
*  **Emotion:** The overall emotional tone is negative, as one user claims the post is an AI generated research paper.
*  **Top 3 Points of View:**
    *   Stop using AI to write fake research papers or whatever this is trying to be
    *   Show me a large production open-source project with pull requests made by AI that are consistently good and automated and I'll agree that's the next step.
    *   This is an AI post, but the biggest hurdle is training.

**[How can I get ChatGPT to make images as close to what I want as possible? (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1kvyp49/how_can_i_get_chatgpt_to_make_images_as_close_to/)**
*  **Summary:**  Users are giving advice on how to improve the image generation capabilities of ChatGPT through detailed prompts and regeneration.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Search on X. The tool is already available, and it's not ChatGPT. Does what you ask it to do.
    *   Just…ask?
    *   Put that in your prompt and make it extremely detailed.

**[Question about API model pricing and "Price per 1M tokens" (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1kvzptn/question_about_api_model_pricing_and_price_per_1m/)**
*  **Summary:**  Users are explaining the pricing structure of the OpenAI API, including input tokens, output tokens and cached tokens.
*  **Emotion:** The overall emotional tone is neutral, a matter-of-fact explanation.
*  **Top 3 Points of View:**
    *   The cost of input is 2$ per million tokens. The cost of output is 8$. The total cost is 4.75$ for the API call.
    *   It takes a while to use a meaningful quantity of tokens. You can track token usage from the API response.
    *   You pay for every token you use as you use them. The price varies depending on compute usage.

**[How Google Veo 3 Relates to Consciousness (Score: 0)](https://zenodo.org/records/15489752?token=eyJhbGciOiJIUzUxMiJ9.eyJpZCI6IjAwZWFiMDg3LWVhNTktNGMyMy05YWI2LWY1YzBmNjQ4MWZjNCIsImRhdGEiOnt9LCJyYW5kb20iOiI3MGZkMTc0NDUwMjQzOWY3NjlkM2ZhY2I3MzcwM2U4MCJ9.rThBZidIKlFj3G_PI44fzBgFLu3MqpbMzZ47Q0a2uDJbnmCGDPznYtVKxheku9AWdZqTeTp9JNNQoHM-X89fXA)**
*  **Summary:**  Users express skepticism towards the claim that characters in Google Veo 3 videos recognize that they are prompted.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   No they *** don't.
    *   BS
    *   /r/badphilosophy
