---
title: "Stable Diffusion Subreddit"
date: "2025-08-13"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [⟆ - tʀɪße_∞ : [1] - (WAN LORA coming up)](https://v.redd.it/udjnqh77wsif1) (Score: 146)
    *   This thread showcases a video created using WAN LORA, with users praising its lack of AI artifacts and overall quality.
2.  [Simple and Fast Wan 2.2 workflow](https://v.redd.it/4bi3so2fntif1) (Score: 78)
    *   This thread discusses workflows for Wan 2.2, with users sharing their experiences and settings for achieving fast generation speeds.
3.  [nunchaku svdq hype](https://i.redd.it/y6u7nrsyxtif1.jpeg) (Score: 62)
    *   This thread is about the "nunchaku svdq," with users discussing its potential impact on AI models, comparing it to the "MP3 moment" for AI models.
4.  [WAN2.2 Control GGUFs](https://i.redd.it/nc4oh39abtif1.png) (Score: 30)
    *   This thread discusses the use of WAN2.2 Control GGUFs, and users asking questions related to workflows, noise and image generation.
5.  [Anime in real life Qwen image lora](https://www.reddit.com/gallery/1mp9r6l) (Score: 27)
    *   This thread showcases an anime in real life Qwen image lora, and users are asking about the code used for training the lora.
6.  [My potato pc with WAN 2.2 + capcut](https://v.redd.it/8eqww5710uif1) (Score: 19)
    *   The thread is about using WAN 2.2 with CapCut, where users are asking to share their workflows with wan 2.2.
7.  [How can I reduce shimmering in Wan2.1?](https://www.reddit.com/r/StableDiffusion/comments/1mp7oj6/how_can_i_reduce_shimmering_in_wan21/) (Score: 3)
    *   This thread asks about reducing shimmering in Wan2.1, users are discussing techniques like skip layer guidance, distill loras, and temporal matching to address the issue.
8.  [How Qwen Image sees a face completely hidden by hair](https://www.reddit.com/gallery/1mpaui4) (Score: 2)
    *   This thread discusses how Qwen Image sees a face completely hidden by hair, suggesting to use "face" in the prompt and using NAG with flux.
9.  [Local replacement for OpenAI/Gemini prompt extension in ComfyUI?](https://www.reddit.com/r/StableDiffusion/comments/1mpdf83/local_replacement_for_openaigemini_prompt/) (Score: 2)
    *   This thread is about finding a local replacement for OpenAI/Gemini prompt extension in ComfyUI, users are providing options like ComfyUI\_Searge\_LLM and WanVideoWrapper with Qwen support.
10. [Whats the affordable cloud solution for Video/Image generation?](https://www.reddit.com/r/StableDiffusion/comments/1mp7jjm/whats_the_affordable_cloud_solution_for/) (Score: 1)
    *   This thread is about finding affordable cloud solutions for Video/Image generation, with users suggesting services like Google Collab, Runpod, vastai and cloudrift.ai.
11. [What am i doing wrong in the workflow? Wan2.1 image to video comfyui](https://www.reddit.com/r/StableDiffusion/comments/1mp8ef7/what_am_i_doing_wrong_in_the_workflow_wan21_image/) (Score: 1)
    *   This thread asks about problems with the Wan2.1 image to video workflow in ComfyUI, and users suggesting to use wan 2.2 instead.
12. [Is it possible to create 1080p (1080 x 1920) videos with Wan 2.2?](https://www.reddit.com/r/StableDiffusion/comments/1mpeo9z/is_it_possible_to_create_1080p_1080_x_1920_videos/) (Score: 1)
    *   This thread asks about creating 1080p videos with Wan 2.2, and the responses states that it works fine for images, but for video you will run out of VRAM very quickly.
13. [can anyone help me?](https://i.redd.it/avosb43fmtif1.png) (Score: 0)
    *   This thread is about asking for help, and the answer to update ComfyUI or reinstall it.
14. [Does WAN 2.1 VACE have a LORA to speed up the generation?](https://www.reddit.com/r/StableDiffusion/comments/1mp7cd9/does_wan_21_vace_have_a_lora_to_speed_up_the/) (Score: 0)
    *   This thread is asking about a LORA to speed up the WAN 2.1 VACE generation, the response is that if it works for wan 2.1, it works for VACE.
15. [How to  I add Illustrious Base model to stable Diffusion the right with out Errors](https://www.reddit.com/r/StableDiffusion/comments/1mp912z/how_to_i_add_illustrious_base_model_to_stable/) (Score: 0)
    *   This thread asks how to add the Illustrious Base model to Stable Diffusion, and responses are providing more details on what they're trying to do.

# Detailed Analysis by Thread
**[ ⟆ - tʀɪße_∞ : [1] - (WAN LORA coming up) (Score: 146)](https://v.redd.it/udjnqh77wsif1)**
*  **Summary:**  This thread is centered around a video created using WAN LORA. Users are impressed by the video's quality, noting the absence of typical AI-generated artifacts like morphing or incoherency.
*  **Emotion:** The overall emotional tone is highly Positive. Users express excitement and amazement at the video's quality and realism.
*  **Top 3 Points of View:**
    * The video is impressive and doesn't show signs of AI weirdness.
    * Some users draw comparisons to their own prior attempts, noting the advancements showcased in the posted video.
    * Wondering what part of detroit is the dataset based on.

**[ Simple and Fast Wan 2.2 workflow (Score: 78)](https://v.redd.it/4bi3so2fntif1)**
*  **Summary:**  This thread focuses on achieving fast generation speeds with Wan 2.2. Users share their specific workflows, settings, and hardware configurations to optimize performance.
*  **Emotion:** The emotional tone is generally Positive and Neutral, with users sharing information and expressing interest in optimizing their workflows.
*  **Top 3 Points of View:**
    *  Sharing specific workflow details.
    *  Concern that changes to workflow is causing slow motion videos.
    *  The wan2.1 and 2.2 is crazy uncensored.

**[ nunchaku svdq hype (Score: 62)](https://i.redd.it/y6u7nrsyxtif1.jpeg)**
*  **Summary:**  The thread revolves around "nunchaku svdq" and its potential impact on AI models. Some users speculate it could be a significant advancement, comparing it to the "MP3 moment" for AI models.
*  **Emotion:** The overall emotional tone is Neutral, characterized by curiosity and anticipation regarding the new technology.
*  **Top 3 Points of View:**
    *  SVDQuant could be a MP3 moment for the AI models era.
    *  Chroma desperately needs a speed boost.
    *  Expressing hype and calling the developer a hero.

**[ WAN2.2 Control GGUFs (Score: 30)](https://i.redd.it/nc4oh39abtif1.png)**
*  **Summary:**  This thread centers on WAN2.2 Control GGUFs. Users are asking questions and expressing interest in workflows and the capabilities of this technology.
*  **Emotion:** The overall emotional tone is Positive and Neutral, with users expressing interest in workflows and the capabilities of this technology.
*  **Top 3 Points of View:**
    *  Asking for workflows.
    *  Asking about image generation with control.
    *  Expressing that WAN2.2 Control GGUFs is great.

**[ Anime in real life Qwen image lora (Score: 27)](https://www.reddit.com/gallery/1mp9r6l)**
*  **Summary:**  The thread showcases an anime in real life Qwen image lora, with users showing a link to huggingface and the code used for training.
*  **Emotion:** The emotional tone is Neutral, with users asking about the code used for training the lora.
*  **Top 3 Points of View:**
    *  Asking about the code used for training.
    *  Sharing a link to the lora.

**[ My potato pc with WAN 2.2 + capcut (Score: 19)](https://v.redd.it/8eqww5710uif1)**
*  **Summary:**  The thread is about using WAN 2.2 with CapCut, where users are asking to share their workflows with wan 2.2.
*  **Emotion:** The emotional tone is Neutral, with users asking to share their workflows with wan 2.2.
*  **Top 3 Points of View:**
    *  Asking to share the workflow with wan 2.2.

**[ How can I reduce shimmering in Wan2.1? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1mp7oj6/how_can_i_reduce_shimmering_in_wan21/)**
*  **Summary:**  This thread asks about reducing shimmering in Wan2.1, users are discussing techniques like skip layer guidance, distill loras, and temporal matching to address the issue.
*  **Emotion:** The emotional tone is Positive and Neutral, with users asking about reducing shimmering in Wan2.1, and other users providing some solutions.
*  **Top 3 Points of View:**
    *  Suggesting skip layer guidance.
    *  Suggesting that shimmering has to do with temporal matching, and the magic is duplicating the good frame and not using the one next to it.
    *  Verifying if model and lightning Lora are appropriate high and low.

**[ How Qwen Image sees a face completely hidden by hair (Score: 2)](https://www.reddit.com/gallery/1mpaui4)**
*  **Summary:**  This thread discusses how Qwen Image sees a face completely hidden by hair, suggesting to use "face" in the prompt and using NAG with flux.
*  **Emotion:** The emotional tone is Neutral, with users suggesting to use "face" in the prompt and using NAG with flux.
*  **Top 3 Points of View:**
    *  Suggesting to use face in the prompt.
    *  Suggesting negative prompt face, eyes, nose, mouth, chin etc.

**[ Local replacement for OpenAI/Gemini prompt extension in ComfyUI? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1mpdf83/local_replacement_for_openaigemini_prompt/)**
*  **Summary:**  This thread is about finding a local replacement for OpenAI/Gemini prompt extension in ComfyUI, users are providing options like ComfyUI\_Searge\_LLM and WanVideoWrapper with Qwen support.
*  **Emotion:** The emotional tone is Neutral, with users providing options for the extension in ComfyUI.
*  **Top 3 Points of View:**
    *  Suggesting ComfyUI\_Searge\_LLM.
    *  Suggesting WanVideoWrapper with Qwen support.

**[ Whats the affordable cloud solution for Video/Image generation? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mp7jjm/whats_the_affordable_cloud_solution_for/)**
*  **Summary:**  This thread is about finding affordable cloud solutions for Video/Image generation, with users suggesting services like Google Collab, Runpod, vastai and cloudrift.ai.
*  **Emotion:** The emotional tone is Neutral, with users suggesting services for Video/Image generation.
*  **Top 3 Points of View:**
    *  Suggesting Google Collab.
    *  Suggesting Runpod.
    *  Suggesting cloudrift.ai.

**[ What am i doing wrong in the workflow? Wan2.1 image to video comfyui (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mp8ef7/what_am_i_doing_wrong_in_the_workflow_wan21_image/)**
*  **Summary:**  This thread asks about problems with the Wan2.1 image to video workflow in ComfyUI, and users suggesting to use wan 2.2 instead.
*  **Emotion:** The emotional tone is Neutral, with users suggesting to use wan 2.2 instead.
*  **Top 3 Points of View:**
    *  Suggesting to use speed loras like LightX and FastWan.
    *  Suggesting to use wan 2.2 instead of Wan 2.1.
    *  Suggesting to reduce the wordy prompt.

**[ Is it possible to create 1080p (1080 x 1920) videos with Wan 2.2? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mpeo9z/is_it_possible_to_create_1080p_1080_x_1920_videos/)**
*  **Summary:**  This thread asks about creating 1080p videos with Wan 2.2, and the responses states that it works fine for images, but for video you will run out of VRAM very quickly.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *  Stating that it works fine for images.
    *  Stating that for video you will run out of VRAM very quickly.
    *  Suggesting to use an upscale like seedvr2.

**[ can anyone help me? (Score: 0)](https://i.redd.it/avosb43fmtif1.png)**
*  **Summary:**  This thread is about asking for help, and the answer to update ComfyUI or reinstall it.
*  **Emotion:** The emotional tone is Neutral, because is more like asking and answering for the problem, not a discussion.
*  **Top 3 Points of View:**
    *  Asking for help.
    *  Suggesting to update comfy.
    *  Suggesting a whole new portable install.

**[ Does WAN 2.1 VACE have a LORA to speed up the generation? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mp7cd9/does_wan_21_vace_have_a_lora_to_speed_up_the/)**
*  **Summary:**  This thread is asking about a LORA to speed up the WAN 2.1 VACE generation, the response is that if it works for wan 2.1, it works for VACE.
*  **Emotion:** The emotional tone is Neutral, because is more like asking and answering for the problem, not a discussion.
*  **Top 3 Points of View:**
    *  Asking for a LORA to speed up the generation.
    *  Answering that if it works for wan 2.1, it works for VACE.

**[ How to  I add Illustrious Base model to stable Diffusion the right with out Errors (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mp912z/how_to_i_add_illustrious_base_model_to_stable/)**
*  **Summary:**  This thread asks how to add the Illustrious Base model to Stable Diffusion, and responses are providing more details on what they're trying to do.
*  **Emotion:** The emotional tone is Neutral, because is more like asking and answering for the problem, not a discussion.
*  **Top 3 Points of View:**
    *  Asking how to add the Illustrious Base model to Stable Diffusion.
    *  Stating to read the post and tell if it makes any amount of sense at all.
    *  Providing more details on what they're trying to do.
