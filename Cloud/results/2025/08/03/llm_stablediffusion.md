---
title: "Stable Diffusion Subreddit"
date: "2025-08-03"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] Wan is everything I had hoped Animatediff would be 2 years ago](https://v.redd.it/05uaes56jugf1) (Score: 134)
    *   This thread discusses the capabilities of Wan, comparing it favorably to Animatediff and other AI tools, and anticipating future advancements in AI video generation.
2.  [WAN 2.2 Simple multi prompt / video looper](https://i.redd.it/glsh03uzaugf1.png) (Score: 16)
    *   This thread is about a simple multi prompt/video looper made with WAN 2.2.
3.  [Wan 2.2 t2i 1080p with gigapixel upscale to 8k, down to 4k](https://i.redd.it/pueu87txtugf1.jpeg) (Score: 8)
    *   The post showcases an image generated with Wan 2.2, upscaled to 8k and then downscaled to 4k, and people are asking about the purpose of the upscaling and downscaling.
4.  [Wan 2.2 - T2V - Higher Quality Workflow for 12GB VRAM GPUs](https://v.redd.it/abght4w6kugf1) (Score: 6)
    *   This thread discusses a higher quality workflow for Wan 2.2 T2V, specifically for GPUs with 12GB of VRAM, and someone comments about the sudden character changes in the video.
5.  [Made this with Wan 2.2 TI2V-5B](https://v.redd.it/7eryzxafvugf1) (Score: 5)
    *   A user shares a creation made with Wan 2.2 TI2V-5B and users comment about the quality and some minor animation quirks.
6.  [Does my data set for WAN 2.2 Lora need to be square (512x512) or can I have them at 512x768 etc?](https://www.reddit.com/r/StableDiffusion/comments/1mgp9ix/does_my_data_set_for_wan_22_lora_need_to_be/) (Score: 4)
    *   This thread asks about the required dimensions of the dataset for WAN 2.2 Lora training, with users providing different experiences and suggestions.
7.  [Wan2.2 gets stuck mid-generation](https://www.reddit.com/r/StableDiffusion/comments/1mgowxj/wan22_gets_stuck_midgeneration/) (Score: 2)
    *   Users are discussing the issue of Wan2.2 getting stuck during generation, with suggestions regarding system RAM, ComfyUI settings and the use of the --cache-none argument.
8.  [Flux Krea vs Flux Dev – Prompt Adherence Difference After Equal Training?](https://www.reddit.com/r/StableDiffusion/comments/1mgqjf2/flux_krea_vs_flux_dev_prompt_adherence_difference/) (Score: 1)
    *   The thread explores the differences in prompt adherence between Flux Krea and Flux Dev models after equal training, discussing the training process and model behavior.
9.  [Could someone explain to me why the template for WAN2.2-T2V in Comfyui ...](https://www.reddit.com/r/StableDiffusion/comments/1mgqrc5/could_someone_explain_to_me_why_the_template_for/) (Score: 1)
    *   A user asks about the reason behind the ComfyUI template for WAN2.2-T2V and its dual ksampler setup, with responses explaining the division of steps and the roles of high and low noise samplers.
10. [[AMD] how to fix weird slowdowns](https://www.reddit.com/r/StableDiffusion/comments/1mgrlnt/amd_how_to_fix_weird_slowdowns/) (Score: 1)
    *   This thread discusses how to fix the slowdowns, and ask if the user is running out of system memory.
11. [Need help deciding: run AI models locally or use online services?](https://www.reddit.com/r/StableDiffusion/comments/1mgrnc0/need_help_deciding_run_ai_models_locally_or_use/) (Score: 1)
    *   The discussion revolves around the decision to run AI models locally versus using online services, focusing on GPU recommendations (4090 vs 3090) and the benefits of waiting for newer models.
12. ["Numpy is not available" when trying WAN 2.2](https://www.reddit.com/r/StableDiffusion/comments/1mgqcxs/numpy_is_not_available_when_trying_wan_22/) (Score: 0)
    *   The user has an issue with numpy not being available when trying to use WAN 2.2.

# Detailed Analysis by Thread
**[Wan is everything I had hoped Animatediff would be 2 years ago (Score: 134)](https://v.redd.it/05uaes56jugf1)**
*  **Summary:**  The main point of discussion is about the advancements in AI video generation, particularly with "Wan," and comparing it to previous models like Animatediff and Midjourney. Users are discussing the capabilities, potential, and future impact of these technologies on movie and video game production.
*  **Emotion:** The overall emotional tone is positive, with users expressing excitement and optimism about the progress and potential of AI in video creation. While some comments express neutral observations, the general sentiment is one of anticipation and enthusiasm.
*  **Top 3 Points of View:**
    *   "Wan" represents significant progress compared to older AI models like Animatediff.
    *   AI video generation is still in its early stages but has the potential to revolutionize movie and video game production.
    *   There is a continuous cycle of new technologies emerging, with rapid advancements happening weekly.

**[WAN 2.2 Simple multi prompt / video looper (Score: 16)](https://i.redd.it/glsh03uzaugf1.png)**
*  **Summary:**  The discussion is about WAN 2.2, a simple multi prompt / video looper. Users are expressing gratitude and asking questions about the software's functionality and performance.
*  **Emotion:** The emotional tone is mostly positive, with expressions of gratitude and appreciation. However, there are also some negative sentiments regarding the image quality deteriorating over time.
*  **Top 3 Points of View:**
    *   Users appreciate the availability of WAN 2.2.
    *   Some users are experiencing issues with image quality degrading over time.
    *   Users are inquiring about the capabilities of different versions of WAN 2.2.

**[Wan 2.2 t2i 1080p with gigapixel upscale to 8k, down to 4k (Score: 8)](https://i.redd.it/pueu87txtugf1.jpeg)**
*  **Summary:**  The thread is centered around an image created using Wan 2.2, which was upscaled to 8k and then downscaled to 4k. The discussion focuses on the relevance and purpose of the gigapixel upscaling and downscaling process.
*  **Emotion:** The overall emotion is neutral, with users primarily seeking clarification and providing observations. There are some positive comments about the lighting and creativity of the image, but the main focus is on technical aspects.
*  **Top 3 Points of View:**
    *   Wan 2.2 has more detail than version 2.1.
    *   There is curiosity about the purpose of upscaling and then downscaling the image.
    *   The inclusion of "gigapixel" in the title is questioned for its meaningfulness.

**[Wan 2.2 - T2V - Higher Quality Workflow for 12GB VRAM GPUs (Score: 6)](https://v.redd.it/abght4w6kugf1)**
*  **Summary:**  The discussion is about a higher quality workflow for Wan 2.2 T2V, aimed at users with GPUs that have 12GB of VRAM.
*  **Emotion:** The emotional tone is mostly negative, with the user pointing out a bug where the character suddenly changes to look like a completely different character.
*  **Top 1 Points of View:**
    *   The character is suddenly switching to look like a completely different character, which makes it look buggy.

**[Made this with Wan 2.2 TI2V-5B (Score: 5)](https://v.redd.it/7eryzxafvugf1)**
*  **Summary:**  A user shares a video created with Wan 2.2 TI2V-5B, and the comments focus on the quality of the output and humorous observations about the animation.
*  **Emotion:** The emotional tone is generally neutral to positive, with appreciation for the quality of the model and amusement at certain quirks in the animation.
*  **Top 1 Points of View:**
    *   The quality is good for such a small model.

**[Does my data set for WAN 2.2 Lora need to be square (512x512) or can I have them at 512x768 etc? (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1mgp9ix/does_my_data_set_for_wan_22_lora_need_to_be/)**
*  **Summary:**  The discussion is about the required dimensions for the dataset used in training WAN 2.2 LoRA models, with users sharing their experiences and recommendations.
*  **Emotion:** The emotional tone is mostly neutral, with users providing and seeking technical advice.
*  **Top 3 Points of View:**
    *   The dataset doesn't necessarily need to be square.
    *   The dimensions depend on whether the training software uses buckets.
    *   Sharing the WAN 2.2 LoRA and workflow is desired.

**[Wan2.2 gets stuck mid-generation (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1mgowxj/wan22_gets_stuck_midgeneration/)**
*  **Summary:**  The thread discusses the issue of Wan2.2 getting stuck during generation, and offers potential solutions related to RAM usage and ComfyUI settings.
*  **Emotion:** The emotional tone is neutral, as users are mainly focused on troubleshooting and providing technical assistance.
*  **Top 3 Points of View:**
    *   The issue might be due to running out of system RAM.
    *   A potential fix is to run ComfyUI with the "--cache-none" argument.
    *   The problem might be a bug specific to certain workflows or UIs.

**[Flux Krea vs Flux Dev – Prompt Adherence Difference After Equal Training? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mgqjf2/flux_krea_vs_flux_dev_prompt_adherence_difference/)**
*  **Summary:**  The thread is centered around the differences in prompt adherence between Flux Krea and Flux Dev models after training, discussing the training process and model behavior.
*  **Emotion:** The overall emotional tone is neutral, with a focus on technical details and observations.
*  **Top 1 Points of View:**
    *   The first epochs of the fluxdev model are progressive, but then it looks like it's overtrained and the following epochs will improve.

**[Could someone explain to me why the template for WAN2.2-T2V in Comfyui ... (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mgqrc5/could_someone_explain_to_me_why_the_template_for/)**
*  **Summary:**  A user seeks explanation for the ComfyUI template for WAN2.2-T2V, particularly regarding the dual ksampler setup.
*  **Emotion:** The overall emotional tone is neutral, with users primarily offering technical explanations.
*  **Top 3 Points of View:**
    *   The template uses 20 steps split between two ksamplers.
    *   The first ksampler handles the major movement/composition/scene, while the second focuses on fine details.
    *   The split allows for different configurations and control over the sampling process.

**[[AMD] how to fix weird slowdowns (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mgrlnt/amd_how_to_fix_weird_slowdowns/)**
*  **Summary:** This thread asks if the user is running out of system memory, and if that is what is causing slowdowns.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 1 Points of View:**
    *   The user might be running out of system memory.

**[Need help deciding: run AI models locally or use online services? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mgrnc0/need_help_deciding_run_ai_models_locally_or_use/)**
*  **Summary:**  The discussion revolves around whether to run AI models locally or use online services.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Buy the 4090.
    *   Wait for 5070TI or 5080 24GB.
    *   Rent 4090 and 5090 online.

**["Numpy is not available" when trying WAN 2.2 (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mgqcxs/numpy_is_not_available_when_trying_wan_22/)**
*  **Summary:** The user has an issue with numpy not being available when trying to use WAN 2.2.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 1 Points of View:**
    *   To paste the text from the top all the way down to where it lists available VRAM into chatbots to troubleshoot.
