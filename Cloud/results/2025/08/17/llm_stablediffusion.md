---
title: "Stable Diffusion Subreddit"
date: "2025-08-17"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "video generation"]
---

# Overall Ranking and Top Discussions
1.  [Maximum Wan 2.2 Quality? This is the best I've personally ever seen](https://v.redd.it/menba491amjf1) (Score: 192)
    *  The thread discusses the impressive quality of the Wan 2.2 model for video generation, with users comparing it to other models and sharing tips for achieving optimal results.
2.  [Prompting Guide - Create different light and shadow effects without using Loras](https://www.reddit.com/gallery/1mt0965) (Score: 20)
    *  A user shares a guide on creating various lighting and shadow effects without using LoRAs, which was well received.
3.  [AI video generator recommendation](https://www.reddit.com/r/StableDiffusion/comments/1msyx58/ai_video_generator_recommendation/) (Score: 19)
    *  Users discuss and recommend AI video generators, particularly ComfyUI with Wan2.2, and provide installation advice.
4.  [Any new tips for Camera and Scene Control you have found for wan2.2?](https://v.redd.it/3088vcjommjf1) (Score: 7)
    *  Users share tips and tricks for camera and scene control within the Wan2.2 video generation model, including adding motion blur in image editors.
5.  [Am I just, dumb?](https://www.reddit.com/r/StableDiffusion/comments/1mswqhs/am_i_just_dumb/) (Score: 4)
    *  A user seeks advice on improving their Stable Diffusion image generation results, and other users provide detailed feedback and techniques.
6.  [WAN 2.2 continuous surrealism test (with subgraphs and 4 step lightning lora)](https://v.redd.it/mnx77dlc6mjf1) (Score: 3)
    *  A user showcases a surrealism test using WAN 2.2 and discusses their process for joining the video parts.
7.  [Wan 2.2 T2V and audio](https://www.reddit.com/r/StableDiffusion/comments/1mszdja/wan_22_t2v_and_audio/) (Score: 3)
    *  Users discuss how to add audio to videos generated with Wan 2.2 and share workflows for achieving this.
8.  [Reading and playing partitions ?](https://i.redd.it/6sqtroxttmjf1.jpeg) (Score: 2)
    *  A user links to a discussion about Optical Music Recognition (OMR) software for sheet music.
9.  [Best text-to-video for 12gb VRAM? (RTX 5070, 32gb RAM)](https://www.reddit.com/r/StableDiffusion/comments/1mt09uk/best_texttovideo_for_12gb_vram_rtx_5070_32gb_ram/) (Score: 1)
    *  Users recommend ComfyUI with WAN T2V for text-to-video generation on systems with 12GB VRAM and offer setup tips.
10. [Full Workflow for your own LORA](https://i.redd.it/x8xh8rj3bljf1.jpeg) (Score: 0)
    * A user shares a full workflow for LORA.
11. [She-Venom using Wan2.2 - I2V](https://v.redd.it/ttybi2vslljf1) (Score: 0)
    * A user shares a She-Venom creation using Wan2.2.
12. [Package Manager Artworks](https://www.reddit.com/r/StableDiffusion/comments/1mssywu/package_manager_artworks/) (Score: 0)
    *  Users discuss package managers for AI programs.
13. [Can't install packages on ComfyUI Desktop (Python issues)](https://www.reddit.com/r/StableDiffusion/comments/1mst7bj/cant_install_packages_on_comfyui_desktop_python/) (Score: 0)
    *  Users troubleshoot issues with installing packages on ComfyUI Desktop, focusing on Python environment setup.
14. [How can i use myself as a mode?](https://www.reddit.com/r/StableDiffusion/comments/1msxgbo/how_can_i_use_myself_as_a_mode/) (Score: 0)
    *  Users provide advice on how to use oneself as a model in Stable Diffusion, including training a LoRA or using img2vid with WAN.

# Detailed Analysis by Thread
**[Maximum Wan 2.2 Quality? This is the best I've personally ever seen (Score: 192)](https://v.redd.it/menba491amjf1)**
*  **Summary:** The thread is centered around the high quality of videos generated using the Wan 2.2 model. Users are impressed with its capabilities and discuss settings, comparisons to other models like Kling 2.1 and Veo3, and the use of tools like Topaz for enhancing the final output.
*  **Emotion:** The overall emotional tone is positive, expressing excitement and admiration for the model's capabilities.
*  **Top 3 Points of View:**
    *   Wan 2.2 produces impressive quality videos, rivaling or surpassing other models.
    *   The quality is highly dependent on detailed prompting and post-processing tools like Topaz.
    *   There's confusion about why Wan 2.2 isn't ranked higher compared to models like Kling 2.1.

**[Prompting Guide - Create different light and shadow effects without using Loras (Score: 20)](https://www.reddit.com/gallery/1mt0965)**
*   **Summary:** This thread shares a prompting guide focused on achieving diverse lighting and shadow effects in Stable Diffusion without relying on LoRAs. The original poster (OP) provides tips and techniques for manipulating light within the software.
*   **Emotion:** The emotional tone is overwhelmingly positive, with users expressing gratitude and excitement for the helpful guide.
*   **Top 3 Points of View:**
    *   The guide is useful and informative.
    *   The techniques are valuable for achieving specific visual effects.

**[AI video generator recommendation (Score: 19)](https://www.reddit.com/r/StableDiffusion/comments/1msyx58/ai_video_generator_recommendation/)**
*   **Summary:** The discussion revolves around recommending AI video generators, particularly focusing on ComfyUI with the Wan2.2 workflow. Users provide advice on installation, hardware requirements, and model selection.
*   **Emotion:** The emotional tone is generally positive and helpful, with users offering guidance and support.
*   **Top 3 Points of View:**
    *   ComfyUI with Wan2.2 is a good recommendation for AI video generation.
    *   Good hardware, especially VRAM, is crucial for optimal performance.
    *   Setup can be complex, but resources and community support are available.

**[Any new tips for Camera and Scene Control you have found for wan2.2? (Score: 7)](https://v.redd.it/3088vcjommjf1)**
*   **Summary:** This thread is about sharing tips and tricks for controlling camera angles and scenes when using the Wan2.2 model for video generation. Users provide practical advice, including using motion blur in image editors to influence movement in the generated video.
*   **Emotion:** The emotional tone is positive and helpful, with users sharing their knowledge and appreciation for the model's capabilities.
*   **Top 3 Points of View:**
    *   Adding motion blur in image editors can effectively control movement in Wan2.2.
    *   Studying the WAN guide is essential for understanding prompting techniques.
    *   Experimentation and prompt sharing are encouraged.

**[Am I just, dumb? (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1mswqhs/am_i_just_dumb/)**
*   **Summary:** A user expresses frustration with their Stable Diffusion results and seeks advice. Other users respond with detailed critiques of the user's techniques, providing guidance on prompting, iteration, and the use of tools like ControlNet and Inpainting.
*   **Emotion:** The overall emotional tone is mixed, ranging from frustration to helpfulness and encouragement. While the original poster is likely feeling discouraged, the responses are supportive and constructive.  There is also some negativity expressed at the "epidemic of delusion" where people expect perfect images from single prompts.
*   **Top 3 Points of View:**
    *   Effective prompting is crucial and requires understanding how prompts work rather than relying solely on AI-generated prompts.
    *   Iterative refinement using tools like Inpainting is more effective than re-rolling repeatedly.
    *   Planning and understanding the tools are essential for achieving desired results.

**[WAN 2.2 continuous surrealism test (with subgraphs and 4 step lightning lora) (Score: 3)](https://v.redd.it/mnx77dlc6mjf1)**
*   **Summary:** A user shares a surreal video created using WAN 2.2, subgraphs, and a 4-step lightning Lora, and mentions using an external solution for joining video parts.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Use of WAN 2.2 is good for surreal videos.
    *   Subgraphs and 4 step lightning lora is helpful for the video creation process.
    *   External solution is good for joining the video parts.

**[Wan 2.2 T2V and audio (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1mszdja/wan_22_t2v_and_audio/)**
*   **Summary:** This thread discusses how to add audio to videos generated using Wan 2.2. Users share workflows and resources for integrating audio with the video output.
*   **Emotion:** The overall emotional tone is neutral and informative, focused on providing solutions and resources.
*   **Top 3 Points of View:**
    *   WAN is primarily for video generation and requires separate tools for audio.
    *   Workflows exist to combine WAN video with audio using tools like Ollama, Gemma, and Chatterbox.
    *   The process requires combining multiple tools to achieve the final result.

**[Reading and playing partitions ? (Score: 2)](https://i.redd.it/6sqtroxttmjf1.jpeg)**
*   **Summary:** This is a simple link to a discussion about OMR software.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Software is needed for OMR.

**[Best text-to-video for 12gb VRAM? (RTX 5070, 32gb RAM) (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mt09uk/best_texttovideo_for_12gb_vram_rtx_5070_32gb_ram/)**
*   **Summary:** A user asks for recommendations for text-to-video software suitable for a system with 12GB VRAM. Other users suggest ComfyUI with WAN T2V and provide setup instructions and workflow optimizations.
*   **Emotion:** The overall emotional tone is neutral, focused on providing practical recommendations and technical advice.
*   **Top 3 Points of View:**
    *   ComfyUI with WAN T2V is a viable option for 12GB VRAM.
    *   Specific workflow adjustments can improve performance and output quality.

**[Full Workflow for your own LORA (Score: 0)](https://i.redd.it/x8xh8rj3bljf1.jpeg)**
*   **Summary:** A user shares a full workflow for LORA.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   N/A

**[She-Venom using Wan2.2 - I2V (Score: 0)](https://v.redd.it/ttybi2vslljf1)**
*   **Summary:** A user shares a She-Venom creation using Wan2.2
*   **Emotion:** Positive.
*   **Top 3 Points of View:**
    *   N/A

**[Package Manager Artworks (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mssywu/package_manager_artworks/)**
*   **Summary:** Users discuss package managers for AI programs.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Pinokio is a potential program for managing different AI programs.

**[Can't install packages on ComfyUI Desktop (Python issues) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mst7bj/cant_install_packages_on_comfyui_desktop_python/)**
*   **Summary:** This thread focuses on troubleshooting Python-related issues when installing packages on ComfyUI Desktop. Users provide detailed instructions and suggestions for resolving installation problems.
*   **Emotion:** The overall emotional tone is neutral, focusing on providing technical solutions to a specific problem.
*   **Top 3 Points of View:**
    *   Installing the latest portable version of ComfyUI is recommended.
    *   Proper installation of GIT and the ComfyUI Manager is crucial.
    *   Understanding and using Python virtual environments (venvs) is important.

**[How can i use myself as a mode? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1msxgbo/how_can_i_use_myself_as_a_mode/)**
*   **Summary:** A user asks how to use themself as a model in Stable Diffusion. Other users suggest training a LoRA, using img2vid with WAN, or exploring face-pasting technologies.
*   **Emotion:** The overall emotional tone is neutral, providing options and resources.
*   **Top 3 Points of View:**
    *   Training a LoRA is the best option for high quality results.
    *   Img2vid with WAN is a simpler option for fun.
    *   Face-pasting technologies offer alternative methods.
