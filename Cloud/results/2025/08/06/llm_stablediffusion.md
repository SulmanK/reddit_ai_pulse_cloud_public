---
title: "Stable Diffusion Subreddit"
date: "2025-08-06"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] My thoughts on QWEN - Great model but lacks realism](https://www.reddit.com/r/StableDiffusion/comments/1mjdh7l/my_thoughts_on_qwen_great_model_but_lacks_realism/) (Score: 12)
    *   The thread discusses the QWEN model, with users sharing their experiences and opinions on its realism and potential fixes.
2.  [What do we think of Qwen-Image-Distill-Full?](https://www.reddit.com/gallery/1mjbh0b) (Score: 9)
    *   Users share their opinions about Qwen-Image-Distill-Full model, with comments regarding blurriness, speed, and hardware utilization.
3.  [how can i train a lora for wan 2.2?](https://www.reddit.com/r/StableDiffusion/comments/1mjc8y2/how_can_i_train_a_lora_for_wan_22/) (Score: 8)
    *   The thread discusses how to train a LoRA (Low-Rank Adaptation) for the WAN 2.2 model, with users seeking guidance on the process and related tools.
4.  [Qwen Image for editing like Flux Kontext?](https://i.redd.it/dqt19s54gghf1.jpeg) (Score: 3)
    *   The thread asks if Qwen Image can be used for image editing. The responses stated that it's not released yet.
5.  [Wan 2.2 Poor Video Quality](https://www.reddit.com/r/StableDiffusion/comments/1mjat8f/wan_22_poor_video_quality/) (Score: 3)
    *   The thread discusses poor video quality issues with Wan 2.2 and seeks advice on improving the output, including parameters, resolution, and workflows.
6.  [I built a free tool to create highly detailed LLM prompts for AI models and influencers.](https://www.reddit.com/r/StableDiffusion/comments/1mjc4ua/i_built_a_free_tool_to_create_highly_detailed_llm/) (Score: 3)
    *   Users ask if the free tool to create prompts is for Midjourney.
7.  [Content Fill Ai for After effect - Plugin Open source with fal.ai](https://v.redd.it/mv7iah35ufhf1) (Score: 2)
    *   The user is wondering if the plugin can run locally, without using fal.
8.  [Need help turning a simple gun render to a Stalker 2 icon render style (Flux Kontext)](https://www.reddit.com/gallery/1mjbqby) (Score: 2)
    *   User is seeking guidance on turning a simple gun render into a Stalker 2 icon render style using Flux Kontext.
9.  [Qwen Image on an RTC 3060](https://www.reddit.com/r/StableDiffusion/comments/1mjefq8/qwen_image_on_an_rtc_3060/) (Score: 2)
    *   User is asking for information on how to run Qwen Image on a RTC 3060.
10. [What would you recommend to create highly realistic images of a person?](https://www.reddit.com/r/StableDiffusion/comments/1mj9r80/what_would_you_recommend_to_create_highly/) (Score: 1)
    *   Users discuss the creation of highly realistic images of a person using Stable Diffusion, with suggestions for checkpoints, LoRAs, and tools.
11. [Training Flux](https://www.reddit.com/r/StableDiffusion/comments/1mjbvwi/training_flux/) (Score: 1)
    *   The user is wondering if training steps to improve the quality of Flux also apply to Kontext.
12. [Changing skin tone while keeping a consistent face.](https://www.reddit.com/r/StableDiffusion/comments/1mjc4xs/changing_skin_tone_while_keeping_a_consistent_face/) (Score: 1)
    *   User are suggesting to try res4lyf nodes in comfy UI in order to keep the structure of the image without the detail.
13. [wan 2.2 14b VS WAN 2.2 5B](https://www.reddit.com/r/StableDiffusion/comments/1mjcazm/wan_22_14b_vs_wan_22_5b/) (Score: 1)
    *   The users are comparing the WAN 2.2 14b and WAN 2.2 5B models.
14. [What is the difference between ComfyUI and ComfyUI Portable?](https://www.reddit.com/r/StableDiffusion/comments/1mjce63/what_is_the_difference_between_comfyui_and/) (Score: 1)
    *   Users are explaining the difference between ComfyUI and ComfyUI Portable.
15. [Krea fp16, DetailAmplifier Flux v1 lora, Detail Daemon Sampler + SeedVR2 + sd1.5 tiled (juggernaut and two detail loras)](https://www.reddit.com/gallery/1mjcohn) (Score: 0)
    *   User is complaining about the picture compression on Reddit.
16. [New Text-to-Image Model King is Qwen Image - FLUX DEV vs FLUX Krea vs Qwen Image Realism vs Qwen Image Max Quality - Swipe images for bigger comparison and also check oldest comment for more info](https://www.reddit.com/gallery/1mjcqz0) (Score: 0)
    *   Users are comparing Qwen Image, FLUX DEV, and FLUX Krea and questioning the claim of Qwen Image being the "king" due to blurriness and other issues.
17. [gradio.live 504 Gateway Time-out](https://www.reddit.com/r/StableDiffusion/comments/1mjabhq/gradiolive_504_gateway_timeout/) (Score: 0)
    *   Users are acknowledging that the time-out is normal.
18. [Can you use Wan 2.2 with 12gb vRAM?](https://www.reddit.com/r/StableDiffusion/comments/1mjcoqe/can_you_use_wan_22_with_12gb_vram/) (Score: 0)
    *   Users are discussing the possibility of using WAN 2.2 with 12GB of VRAM and ways to speed up the process.

# Detailed Analysis by Thread
**[[D] My thoughts on QWEN - Great model but lacks realism (Score: 12)](https://www.reddit.com/r/StableDiffusion/comments/1mjdh7l/my_thoughts_on_qwen_great_model_but_lacks_realism/)**
*   **Summary:**  The thread is about the QWEN model and its lack of realism in image generation. Users are discussing possible solutions, such as using refiners, LoRAs, and prompting in Chinese. They are also sharing their settings and experiences.
*   **Emotion:** The overall emotional tone is neutral, with a mix of curiosity, and positivity as users discuss potential fixes and share their positive experiences with the model and related tools.
*   **Top 3 Points of View:**
    *   QWEN produces blurry images that lack realism.
    *   Using refiners and LoRAs can improve the realism of QWEN images.
    *   Prompting in Chinese may lead to more realistic results.

**[What do we think of Qwen-Image-Distill-Full? (Score: 9)](https://www.reddit.com/gallery/1mjbh0b)**
*   **Summary:**  This thread is about Qwen-Image-Distill-Full model, where users are sharing their thoughts on its performance, speed, and hardware requirements, particularly for low-VRAM systems.
*   **Emotion:** The overall emotional tone is neutral, with some positivity as users share experiences and provide links to resources.
*   **Top 3 Points of View:**
    *   The "Distill" version seems blurrier than the original Qwen-Image.
    *   The gguf quants are useful for users with low VRAM.
    *   It doesn't provide a significant speed boost compared to the original model.

**[how can i train a lora for wan 2.2? (Score: 8)](https://www.reddit.com/r/StableDiffusion/comments/1mjc8y2/how_can_i_train_a_lora_for_wan_22/)**
*   **Summary:**  The thread discusses the process of training a LoRA (Low-Rank Adaptation) for the WAN 2.2 video generation model. Users are seeking guidance on using tools like kohya\_ss and diffusion-pipe.
*   **Emotion:** The overall emotional tone is neutral, with users seeking help and guidance.
*   **Top 3 Points of View:**
    *   Training LoRAs for Wan 2.2 requires creating LoRAs for both high and low noise.
    *   Using tools like kohya\_ss is a starting point for LoRA creation.
    *   diffusion-pipe appears more complicated for Wan 2.2 LoRA training.

**[Qwen Image for editing like Flux Kontext? (Score: 3)](https://i.redd.it/dqt19s54gghf1.jpeg)**
*   **Summary:** The thread asks if Qwen Image can be used for image editing.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Qwen Image is not yet released for editing.

**[Wan 2.2 Poor Video Quality (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1mjat8f/wan_22_poor_video_quality/)**
*   **Summary:** The thread discusses poor video quality issues with Wan 2.2 and seeks advice on improving the output. Suggestions include adjusting generation parameters, resolution, and workflows, as well as providing example images and parameters when asking for help.
*   **Emotion:** The overall emotional tone is mixed. There is frustration regarding the poor quality, but also helpfulness.
*   **Top 3 Points of View:**
    *   Lowering the resolution and simplifying the workflow can improve video quality.
    *   Posting generation parameters and sample images is crucial for getting helpful advice.
    *   Using ggufs, particularly above Q3, can improve quality.

**[I built a free tool to create highly detailed LLM prompts for AI models and influencers. (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1mjc4ua/i_built_a_free_tool_to_create_highly_detailed_llm/)**
*   **Summary:** User is asking if the free tool to create prompts is for Midjourney.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Tool may be related to Midjourney.

**[Content Fill Ai for After effect - Plugin Open source with fal.ai (Score: 2)](https://v.redd.it/mv7iah35ufhf1)**
*   **Summary:** User is asking if there is a way to run the plugin locally, without using fal.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Unclear whether the plugin can run without fal.

**[Need help turning a simple gun render to a Stalker 2 icon render style (Flux Kontext) (Score: 2)](https://www.reddit.com/gallery/1mjbqby)**
*   **Summary:** User is seeking guidance on turning a simple gun render into a Stalker 2 icon render style using Flux Kontext.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Using Kontext lora with AI toolkit is recommended.
    *   Renting a 4090/5090 in runpod for training the LoRA could be cost-effective.
    *   The resulting LoRA and workflow could be shared with the S2 modding community.

**[Qwen Image on an RTC 3060 (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1mjefq8/qwen_image_on_an_rtc_3060/)**
*   **Summary:** User is asking for information on how to run Qwen Image on a RTC 3060.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Use [the Q4\_0 GGUF](https://huggingface.co/city96/Qwen-Image-gguf/tree/main) on a 4070 (same size VRAM).
    *   Running out of RAM.
    *   Edit paging file.

**[What would you recommend to create highly realistic images of a person? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mj9r80/what_would_you_recommend_to_create_highly/)**
*   **Summary:** Users discuss the creation of highly realistic images of a person using Stable Diffusion, with suggestions for checkpoints, LoRAs, and tools. The conversation includes techniques for achieving realistic skin and sharp details.
*   **Emotion:** Predominantly neutral, with positive undertones as users share tips and express excitement about the possibilities.
*   **Top 3 Points of View:**
    *   Use SDXL with a photorealistic checkpoint and ControlNet reference images.
    *   Train a fresh LoRA on selfies to avoid waxy skin.
    *   Use InstantID or the face detailer node in ComfyUI to keep eyes and teeth sharp.

**[Training Flux (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mjbvwi/training_flux/)**
*   **Summary:** The user is wondering if training steps to improve the quality of Flux also apply to Kontext.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Unclear whether the training steps for Flux will apply to Kontext.

**[Changing skin tone while keeping a consistent face. (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mjc4xs/changing_skin_tone_while_keeping_a_consistent_face/)**
*   **Summary:** User are suggesting to try res4lyf nodes in comfy UI in order to keep the structure of the image without the detail.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Use res4lyf nodes in comfy UI.

**[wan 2.2 14b VS WAN 2.2 5B (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mjcazm/wan_22_14b_vs_wan_22_5b/)**
*   **Summary:** The users are comparing the WAN 2.2 14b and WAN 2.2 5B models.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   WAN 2.2 14b can run without any problem.
    *   Use gguf and the lightx2v Lora.

**[What is the difference between ComfyUI and ComfyUI Portable? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mjce63/what_is_the_difference_between_comfyui_and/)**
*   **Summary:** Users are explaining the difference between ComfyUI and ComfyUI Portable.
*   **Emotion:** The overall emotional tone is slightly positive, as users are providing helpful information.
*   **Top 3 Points of View:**
    *   Portable has everything needed to get running in one download.
    *   Embedded python is the main difference.
    *   Portable versions have independent settings.

**[Krea fp16, DetailAmplifier Flux v1 lora, Detail Daemon Sampler + SeedVR2 + sd1.5 tiled (juggernaut and two detail loras) (Score: 0)](https://www.reddit.com/gallery/1mjcohn)**
*   **Summary:** User is complaining about the picture compression on Reddit.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Reddit compresses images.

**[New Text-to-Image Model King is Qwen Image - FLUX DEV vs FLUX Krea vs Qwen Image Realism vs Qwen Image Max Quality - Swipe images for bigger comparison and also check oldest comment for more info (Score: 0)](https://www.reddit.com/gallery/1mjcqz0)**
*   **Summary:** Users are comparing Qwen Image, FLUX DEV, and FLUX Krea and questioning the claim of Qwen Image being the "king" due to blurriness and other issues. Render times and hardware requirements are also discussed.
*   **Emotion:** The overall emotional tone is negative, as users are criticizing the model's blurriness.
*   **Top 3 Points of View:**
    *   Qwen Image produces soft/blurry images with high frequency artifacts.
    *   Krea looks better.
    *   Qwen Image needs text-based image editing capabilities a la Flux Kontext.

**[gradio.live 504 Gateway Time-out (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mjabhq/gradiolive_504_gateway_timeout/)**
*   **Summary:** Users are acknowledging that the time-out is normal.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   Time-outs on gradio.live are normal.

**[Can you use Wan 2.2 with 12gb vRAM? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mjcoqe/can_you_use_wan_22_with_12gb_vram/)**
*   **Summary:** Users are discussing the possibility of using WAN 2.2 with 12GB of VRAM and ways to speed up the process. The conversation includes quantization, RAM requirements, and the use of speed LoRAs.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   WAN 2.2 can be used with 12GB of VRAM through quantization.
    *   More RAM is important to avoid unloading and loading models.
    *   Speed LoRAs, heavy quantization, and low resolution can potentially get generation times under 60 seconds.
