---
title: "Stable Diffusion Subreddit"
date: "2025-08-19"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1. [Today I found this integrated wan2.2](https://www.reddit.com/r/StableDiffusion/comments/1muqkd9/today_i_found_this_integrated_wan22/) (Score: 16)
    * Discusses an integrated version related to "wan2.2" and its potential uses.
2. [Local Qwen 2.5 Omni hears music and calls out chords](https://v.redd.it/t5rzupsbm0kf1) (Score: 10)
    * Showcases local Qwen 2.5 Omni's ability to listen to music and identify chords.
3. [OmniPart Huggingface Space -- Combining 2D to 3D with image segmentation](https://huggingface.co/spaces/omnipart/OmniPart) (Score: 6)
    *  Highlights the OmniPart Huggingface Space, a tool for combining 2D to 3D images using segmentation, emphasizing its local usability and promising workflow.
4. [Illustrious VS Qwen Image VS Wan 2.2 T2I for anime?](https://www.reddit.com/r/StableDiffusion/comments/1mupjgr/illustrious_vs_qwen_image_vs_wan_22_t2i_for_anime/) (Score: 1)
    * Compares Illustrious, Qwen Image, and Wan 2.2 for text-to-image generation, specifically for anime.
5. [TextEncodeQwenImageEdit missing...](https://www.reddit.com/r/StableDiffusion/comments/1musnbu/textencodeqwenimageedit_missing/) (Score: 1)
    * Addresses an issue where TextEncodeQwenImageEdit is missing.
6. [pythorch returns False, how should i fix it?](https://www.reddit.com/r/StableDiffusion/comments/1muspzw/pythorch_returns_false_how_should_i_fix_it/) (Score: 1)
    * Asks for help fixing a "pythorch returns False" error.
7. [What about AI videos ***?](https://www.reddit.com/r/StableDiffusion/comments/1mut6b9/what_about_ai_videos_suck/) (Score: 1)
    * Discusses the current state of AI videos.
8. [Pixelated Noisy Video Output on Wan2.2 without Lora!!](https://www.reddit.com/r/StableDiffusion/comments/1muq92y/pixelated_noisy_video_output_on_wan22_without_lora/) (Score: 1)
    * Seeks help with pixelated and noisy video output when using Wan2.2 without Lora.
9. [WAN 2.2 default workflow i2v generating blurry stuff, please help!](https://v.redd.it/3fyiq4zhu0kf1) (Score: 0)
    * Requests assistance with blurry video generation using WAN 2.2's default i2v workflow.
10. [Worse performance after GPU upgrade](https://www.reddit.com/r/StableDiffusion/comments/1mupesz/worse_performance_after_gpu_upgrade/) (Score: 0)
    * Discusses experiencing worse performance after upgrading a GPU.
11. [how do you make text2 image using wan?](https://www.reddit.com/r/StableDiffusion/comments/1mupjpv/how_do_you_make_text2_image_using_wan/) (Score: 0)
    * Asks for guidance on generating images from text using WAN.
12. [Does SD image metadata contain any information about the computer it was generated on?](https://www.reddit.com/r/StableDiffusion/comments/1mupu86/does_sd_image_metadata_contain_any_information/) (Score: 0)
    * Inquires whether Stable Diffusion image metadata contains information about the computer used for generation.
13. [What is the relationship between Qwen_Image and Wan 2.2, and why did their teams release two similar models?](https://www.reddit.com/r/StableDiffusion/comments/1mur8r4/what_is_the_relationship_between_qwen_image_and/) (Score: 0)
    * Asks about the relationship between Qwen_Image and Wan 2.2 and the reasons for releasing two similar models.

# Detailed Analysis by Thread
**[Today I found this integrated wan2.2 (Score: 16)](https://www.reddit.com/r/StableDiffusion/comments/1muqkd9/today_i_found_this_integrated_wan22/)**
*  **Summary:** The thread discusses an integrated version of wan2.2, with a user clarifying that it's actually wan 2.1 mixed with elements of wan 2.2 and other LoRAs, advising not to mistake it for pure wan 2.2. Another user reports issues with I2v, noting excessive face changes, shaking, and poor prompt adherence.
*  **Emotion:** Predominantly Neutral, with some Negative sentiment expressed regarding I2v performance.
*  **Top 3 Points of View:**
    * The integrated version is not a true wan 2.2.
    * The integrated version might be good for some use cases.
    * I2v changes faces too much, causes shaking, and lacks prompt adherence.

**[Local Qwen 2.5 Omni hears music and calls out chords (Score: 10)](https://v.redd.it/t5rzupsbm0kf1)**
*  **Summary:** The thread showcases local Qwen 2.5 Omni's capability to listen to music and call out chords. Users express thanks for the functionality and inquire about its compatibility with specific hardware.
*  **Emotion:** Predominantly Positive, with some Neutral questions regarding compatibility.
*  **Top 3 Points of View:**
    * Appreciation for the Qwen 2.5 Omni's functionality.
    * Question about compatibility with a 5070 ti.

**[OmniPart Huggingface Space -- Combining 2D to 3D with image segmentation (Score: 6)](https://huggingface.co/spaces/omnipart/OmniPart)**
*  **Summary:** This thread introduces the OmniPart Huggingface Space, a tool that combines 2D to 3D image processing through image segmentation. The tool is described as locally runnable and is considered a promising approach for 2D to 3D image workflows.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  OmniPart is a promising tool for 2D to 3D image workflows.
    *  The tool is locally runnable.

**[Illustrious VS Qwen Image VS Wan 2.2 T2I for anime? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mupjgr/illustrious_vs_qwen_image_vs_wan_22_t2i_for_anime/)**
*  **Summary:**  The thread compares Illustrious, Qwen Image, and Wan 2.2 for text-to-image generation for anime. It discusses the need for fine-tuning base models for anime and the challenges in achieving perfect images with multiple characters.
*  **Emotion:** Predominantly Positive, with a slight hint of frustration about the challenges of generating anime images.
*  **Top 3 Points of View:**
    * Both models can generate good details, but they can be further enhanced with finetuning.
    * Illustrious was trained on millions of anime images for many epoches.

**[TextEncodeQwenImageEdit missing... (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1musnbu/textencodeqwenimageedit_missing/)**
*  **Summary:** This thread discusses the issue of the "TextEncodeQwenImageEdit" function missing, with users sharing potential solutions.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  Updating the system might be required for it to appear.
    *  Try refreshing using "R" or "ctrl+shift+r".
    *  Restarting the terminal from scratch might be necessary.

**[pythorch returns False, how should i fix it? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1muspzw/pythorch_returns_false_how_should_i_fix_it/)**
*  **Summary:** This thread is asking for help for pythorch problems.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  Buy a real pc with a cuda card and use an other tutorial.

**[What about AI videos ***? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1mut6b9/what_about_ai_videos_suck/)**
*  **Summary:** This thread is discussing the current state of AI videos.
*  **Emotion:** Contains Negative and Neutral opinions.
*  **Top 3 Points of View:**
    * AI videos get increasingly unstable after five seconds
    * Generating videos locally is slow

**[Pixelated Noisy Video Output on Wan2.2 without Lora!! (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1muq92y/pixelated_noisy_video_output_on_wan22_without_lora/)**
*  **Summary:**  The thread discusses troubleshooting pixelated and noisy video output on Wan2.2 without Lora. Users are providing detailed questions regarding graphics card usage, step counts, CFG settings, and other parameters to diagnose the problem.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Users need to give more information about what they are using.

**[WAN 2.2 default workflow i2v generating blurry stuff, please help! (Score: 0)](https://v.redd.it/3fyiq4zhu0kf1)**
*  **Summary:** This thread is asking for help on default workflow.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Number of frames.
    * Try playing with the steps number.

**[Worse performance after GPU upgrade (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mupesz/worse_performance_after_gpu_upgrade/)**
*  **Summary:** This thread talks about having worse performance after upgrading a GPU
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Reinstall dependencies.

**[how do you make text2 image using wan? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mupjpv/how_do_you_make_text2_image_using_wan/)**
*  **Summary:**  The thread seeks guidance on creating images from text using WAN.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Wan 2.2 [https://youtu.be/AKYUPnYOn-8](https://youtu.be/AKYUPnYOn-8)
    * Wan 2.1 [https://youtu.be/eJ8xiY-xBWk](https://youtu.be/eJ8xiY-xBWk)

**[Does SD image metadata contain any information about the computer it was generated on? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mupu86/does_sd_image_metadata_contain_any_information/)**
*  **Summary:** The thread asks about metadata for stable diffusion images.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Some custom node creators used to let users add API access tokens directly into a node to connect with services like ChatGPT.
    * maybe use software to get rid of the metadata like for example 'exiftools' or 'exifcleaner'.

**[What is the relationship between Qwen_Image and Wan 2.2, and why did their teams release two similar models? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1mur8r4/what_is_the_relationship_between_qwen_image_and/)**
*  **Summary:**  The thread explores the connection between Qwen_Image and Wan 2.2 and the reasoning behind releasing two distinct models. Users emphasize their different architectures, training purposes, and ultimate applications.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * They aren't similar models though.
    * Qwen-image started with the VAE from Wan 2.1 instead of creating a new one.
    * Qwen could be trained for Qwen Image Edit and WAN for VACE.
