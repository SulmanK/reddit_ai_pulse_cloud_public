---
title: "Stable Diffusion Subreddit"
date: "2025-11-18"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[Gallery] LocalGen is released. Now you can run SDXL locally on your iPhone.](https://www.reddit.com/gallery/1p0egf8) (Score: 117)
    * This thread discusses the release of LocalGen, an application that allows users to run SDXL locally on their iPhones.
2.  [Anything2real (Qwen)](https://i.redd.it/h4up0xxo602g1.jpeg) (Score: 84)
    * This thread discusses the Anything2real model (Qwen), with users sharing their opinions and results using the model.
3.  [Wan 2.2 T2I Orc´s Lora + VibeVoice](https://v.redd.it/dpnhon5or12g1) (Score: 20)
    * This thread features a demonstration using Wan 2.2 T2I Orc's Lora + VibeVoice for voice-driven animation.
4.  [Help with WAN 2.2 TI2V 5B on RTX 3060Ti](https://www.reddit.com/r/StableDiffusion/comments/1p0fipk/help_with_wan_22_ti2v_5b_on_rtx_3060ti/) (Score: 5)
    *  A user seeks help with running WAN 2.2 TI2V 5B on an RTX 3060Ti.
5.  [My first ai video](https://v.redd.it/zqlfod1e812g1) (Score: 5)
    * A user shares their first AI-generated video and asks about the tools and prompts used.
6.  [Illustrious inpainting in ComfyUI](https://i.redd.it/493qb4lwg12g1.png) (Score: 3)
    * This thread discusses inpainting techniques in ComfyUI using the Illustrious model.
7.  [Prevent Background zoom in Animate](https://v.redd.it/kruwb6bcq22g1) (Score: 3)
    * This thread explores methods to prevent background zooming when using Animate.
8.  [Qwen Lora - artistic styles - the model learns the patterns/characters/content BUT doesn't learn the texture of the painting, it doesn't look like painting. Has anyone else had this problem ?](https://www.reddit.com/r/StableDiffusion/comments/1p0bt5y/qwen_lora_artistic_styles_the_model_learns_the/) (Score: 2)
    * A user describes the problems they are having with Qwen Lora not learning the texture of the painting.
9.  [How to Use Flux, IPAdapter, and Qwen to Transfer Image Styles While Keeping Character Consistency](https://www.reddit.com/r/StableDiffusion/comments/1p0mxg2/how_to_use_flux_ipadapter_and_qwen_to_transfer/) (Score: 1)
    * This thread is about how to use Flux, IPAdapter, and Qwen to transfer image styles while keeping character consistency.
10. [Qwen-Image-Edit. What am I doing wrong?](https://i.redd.it/cqdqbn00012g1.png) (Score: 1)
    * A user is asking for advice on how to properly utilize the Qwen-Image-Edit.
11. [Video-Editing/ Video to Video - Is the following possible: replace colours (low/mid VRAM)](https://www.reddit.com/r/StableDiffusion/comments/1p08lks/videoediting_video_to_video_is_the_following/) (Score: 1)
    * A user is inquiring about the possibility of replacing colors in video editing with low/mid VRAM.
12. [ChatGPT being honest.](https://i.redd.it/6hvamcs8i12g1.png) (Score: 0)
    * This thread shows a picture of ChatGPT being honest about it limitations.
13. [AI may already pose more harm than good in the e-commerce sector.](https://i.redd.it/8lnzezujs12g1.jpeg) (Score: 0)
    * This thread is about the potential harms of AI in e-commerce, such as using AI to fake product quality issues.
14. [Seeking LoRA/Model for TikTok Horror Comic Style](https://www.reddit.com/r/StableDiffusion/comments/1p0e9p4/seeking_loramodel_for_tiktok_horror_comic_style/) (Score: 0)
    * This thread is a request for a specific LoRA/Model for a TikTok horror comic style.
15. [LORA training](https://www.reddit.com/r/StableDiffusion/comments/1p0foxf/lora_training/) (Score: 0)
    * This thread is about LORA training.
16. [Best human Lora](https://www.reddit.com/r/StableDiffusion/comments/1p0ipro/best_human_lora/) (Score: 0)
    * This thread is about best human Lora.

# Detailed Analysis by Thread
**[ [Gallery] LocalGen is released. Now you can run SDXL locally on your iPhone. (Score: 117)](https://www.reddit.com/gallery/1p0egf8)**
*  **Summary:** The thread discusses the release of LocalGen, an app for running SDXL locally on iPhones. Users are giving it a try and commenting on features, limitations (like the inability to generate NSFW content), and performance. Some compare it to existing alternatives like Draw Things.
*  **Emotion:** The overall emotional tone is neutral, with a mix of positive feedback regarding the app's functionality and neutral/negative comments regarding its limitations (cost, NSFW restrictions, feature parity with other apps). There is some excitement about local image generation.
*  **Top 3 Points of View:**
    *   Local image generation is beneficial because it avoids power-hungry data centers.
    *   LocalGen is not much different than SDXL Turbo converted to CoreML and charges money.
    *   The inability to generate NSFW art, despite being local, is a major disadvantage.

**[Anything2real (Qwen) (Score: 84)](https://i.redd.it/h4up0xxo602g1.jpeg)**
*  **Summary:** The thread features an image generated with the Anything2real (Qwen) model. People are sharing their opinions on the model's output, comparing it to other models like Anime2real, and discussing the quality of the generated images, particularly regarding facial expressions and overall realism.
*  **Emotion:** The overall emotional tone is neutral. While some users express positive sentiments about the results, others are critical of the model's output, describing it as emotionless or "crappy."
*  **Top 3 Points of View:**
    *   Anime2real is better than Anything2real, especially when combined with the Samsung LoRA.
    *   The generated images often lack emotion and fail to evoke the initial intended feeling.
    *   Anything2real seems to have greatly improved the results.

**[Wan 2.2 T2I Orc´s Lora + VibeVoice (Score: 20)](https://v.redd.it/dpnhon5or12g1)**
*  **Summary:**  The thread discusses the usage of Wan 2.2 T2I Orc's Lora and VibeVoice, focusing on its capabilities for voice-driven animation. Users are asking about its features, comparing it to other tools like InfiniteTalk, and requesting improvements like deeper voice generation.
*  **Emotion:** The overall emotional tone is positive, with users expressing excitement about the technology and offering suggestions for improvement.
*  **Top 3 Points of View:**
    *   Vanilla Wan 2.2 can match audio.
    *   The liras should be put to use to make his voice deeper.
    *   Is 2.2 s2v better than infiniteTalk, for lets say 60 sec video?

**[Help with WAN 2.2 TI2V 5B on RTX 3060Ti (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1p0fipk/help_with_wan_22_ti2v_5b_on_rtx_3060ti/)**
*  **Summary:** A user is seeking help with running WAN 2.2 TI2V 5B on an RTX 3060Ti. Advice is given regarding using FastWan distillation, ComfyUI-GGUF custom node and RAM requirements.
*  **Emotion:** The emotional tone is neutral, as the discussion is primarily technical and informational.
*  **Top 3 Points of View:**
    *   The FastWan distillation lets you generate in very few steps.
    *   3060 Ti runs with 48GB of ram and 96GB of RAM now.
    *   The model download scripts are specific to the Runpod setup

**[My first ai video (Score: 5)](https://v.redd.it/zqlfod1e812g1)**
*  **Summary:** A user shares their first AI-generated video, and other users are asking about the tools and prompts used.
*  **Emotion:** The emotional tone is neutral with positive opinions of the video.
*  **Top 3 Points of View:**
    *   The video looks really good except the grainy quality.
    *   The user use pykaso ai for such videos which is not free but its doing the job very well.
    *   User is asking about the tools used to make it.

**[Illustrious inpainting in ComfyUI (Score: 3)](https://i.redd.it/493qb4lwg12g1.png)**
*  **Summary:** This thread discusses inpainting techniques in ComfyUI using the Illustrious model. The conversation revolves around optimal settings and workflows for inpainting, including denoising strength, the use of inpainting models and ControlNet, and considerations for image composition.
*  **Emotion:** The overall tone is neutral and informative.
*  **Top 3 Points of View:**
    *  Denoising strength of 1.0 should be used.
    *  Inpainting model and CN inpaint should not be used together with Image Composite Masked node.
    *  Use Crop and stitch nodes to help with details.

**[Prevent Background zoom in Animate (Score: 3)](https://v.redd.it/kruwb6bcq22g1)**
*  **Summary:** This thread is discussing the issue of background zoom in animation videos and seeking solutions to prevent it. It touches on potential issues with multiple characters in the input image and inquiries about the voice syncing method used in the video.
*  **Emotion:** Neutral tone.
*  **Top 3 Points of View:**
    * What happens if the input image has 2 or more people.
    * What you use for the characters voice and how you managed to sync it to the video?
    * Is that part of Animate or something else?

**[Qwen Lora - artistic styles - the model learns the patterns/characters/content BUT doesn't learn the texture of the painting, it doesn't look like painting. Has anyone else had this problem ? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1p0bt5y/qwen_lora_artistic_styles_the_model_learns_the/)**
*  **Summary:** A user is asking a question on Qwen Lora not learning the texture of the painting and see if anyone has had this problem. One user suggests specifying the texture in the prompt. Another details the training pipeline.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *  You have to specify the texture, or even include it as trigger word.
    *  Most of the recent pipelines are using sigm distribution for timescale.
    *  Most of the training is done around ts of 0.5 with bell like curve centered around it.

**[How to Use Flux, IPAdapter, and Qwen to Transfer Image Styles While Keeping Character Consistency (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1p0mxg2/how_to_use_flux_ipadapter_and_qwen_to_transfer/)**
*  **Summary:** This thread is about how to use Flux, IPAdapter, and Qwen to transfer image styles while keeping character consistency.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  Included image from Image2
    *  Included image from Qwen Image Edit
    *  I just prompted it to replace the character and maintain style.

**[Qwen-Image-Edit. What am I doing wrong? (Score: 1)](https://i.redd.it/cqdqbn00012g1.png)**
*  **Summary:** A user is asking for advice on how to properly utilize the Qwen-Image-Edit.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  Have you tried setting scheduler in KSampler to "simple" as in 8-steps Lightning workflow
    *  Tell it in the prompt to keep all the other details the same.
    *  Well, you can try to inpaint it instead.

**[Video-Editing/ Video to Video - Is the following possible: replace colours (low/mid VRAM) (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1p08lks/videoediting_video_to_video_is_the_following/)**
*  **Summary:** A user is inquiring about the possibility of replacing colors in video editing with low/mid VRAM
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   There's a built-in template for video inpainting with wan 2.1 vace that should be a good place to start.

**[ChatGPT being honest. (Score: 0)](https://i.redd.it/6hvamcs8i12g1.png)**
*   **Summary:** This thread shows a picture of ChatGPT being honest about it limitations.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Why bother with ChatBFD?
    *   That's exactly the kind of answer AIs should give... if they don't know, don't invent.
    *   Because what you ask is impossible.

**[AI may already pose more harm than good in the e-commerce sector. (Score: 0)](https://i.redd.it/8lnzezujs12g1.jpeg)**
*   **Summary:** This thread is about the potential harms of AI in e-commerce, such as using AI to fake product quality issues.
*   **Emotion:** Neutral, leaning towards negative due to the discussion of potential harms.
*   **Top 3 Points of View:**
    *   You fell for some anti-AI propaganda, since this is not how things are handled in Chinese e-commerce culture.
    *   Criminals will always be criminals.
    *   I don't see how this is the fault of AI as a technology and not once again, exploitation of that technology corporations for profit at the expense of quality and user safety?

**[Seeking LoRA/Model for TikTok Horror Comic Style (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1p0e9p4/seeking_loramodel_for_tiktok_horror_comic_style/)**
*   **Summary:** This thread is a request for a specific LoRA/Model for a TikTok horror comic style.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *  They are made in imagefx.
    *  You can try this Lora Flux: https://civitai.com/models/2055511/darkpanel-gritty-dark-comic-horror

**[LORA training (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1p0foxf/lora_training/)**
*   **Summary:** This thread is about LORA training.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *  What model? and OS
    *  Instead of ComfyUI, think about OneTrainer and AI Toolkit.

**[Best human Lora (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1p0ipro/best_human_lora/)**
*   **Summary:** This thread is about best human Lora.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *  Character Lora or training Lora? Tensor.Art to me personally has the best selection of human character Lora’s.
