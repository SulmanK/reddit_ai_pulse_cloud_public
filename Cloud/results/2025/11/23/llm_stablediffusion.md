---
title: "Stable Diffusion Subreddit"
date: "2025-11-23"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "video generation"]
---

# Overall Ranking and Top Discussions
1.  [[Release] ComfyUI-MotionCapture â€” Full 3D Human Motion Capture from Video (GVHMR)](https://v.redd.it/25r23butz03g1) (Score: 87)
    *   Discussion about a new ComfyUI tool for 3D human motion capture from video, including potential uses in Blender and Mikumikudance.
2.  [My testing of HunyuanVideo 1.5 and Wan 2.2 on I2V](https://v.redd.it/euk4vcyxx03g1) (Score: 74)
    *   A comparison between HunyuanVideo 1.5 and Wan 2.2 for image-to-video generation, discussing prompt structures, speed, and output quality.
3.  [Updated I2V Wan 2.2 vs. HunyuanVideo 1.5 (with correct settings now)](https://v.redd.it/4txepl8sf13g1) (Score: 61)
    *   An updated comparison of I2V Wan 2.2 and HunyuanVideo 1.5, focusing on the ability to handle simple tasks and prompting details.
4.  [Full Music Video generated with AI - Wan2.1 Infinitetalk](https://www.youtube.com/watch?v=T45wb8henL4) (Score: 48)
    *   Discussion of a music video generated using AI, specifically Wan2.1 Infinitetalk, with comments on the music, video quality, and creative aspects.
5.  [[Release] ComfyUI-GeometryPack â€” (semi)Professional 3D Geometry Tools for ComfyUI (Remesh, UV, Repair, Analyze)](https://v.redd.it/h9j5irfaz03g1) (Score: 15)
    *   Discussion about new semi-professional 3D Geometry Tools for ComfyUI.
6.  [High Variation Qwen Workflow](https://www.reddit.com/gallery/1p4pv8w) (Score: 9)
    *   Discussion regarding the High Variation Qwen Workflow, with users requesting direct links to the workflow.
7.  [The general recommendation is 100 steps per image. However, when training LoRa on relatively larger datasets, more than 100 images, the model gets completely burned out at 100 steps. Any explanation? Above 100 images is it 50 steps per image?](https://www.reddit.com/r/StableDiffusion/comments/1p4s6yg/the_general_recommendation_is_100_steps_per_image/) (Score: 4)
    *   A question about the recommended number of steps per image when training LoRAs on larger datasets and why models get burned out.
8.  [Can you have too many LoRAs?](https://www.reddit.com/r/StableDiffusion/comments/1p4qfs5/can_you_have_too_many_loras/) (Score: 2)
    *   Discussion on whether using too many LoRAs can negatively impact image quality.
9.  [Qwen is locally slower at generating 1 image than Wan is at generating a 5 second video, is this normal or am I doing something wrong?](https://www.reddit.com/r/StableDiffusion/comments/1p4xnw3/qwen_is_locally_slower_at_generating_1_image_than/) (Score: 1)
    *   A question about the performance difference between Qwen and Wan in image and video generation.
10. [ðŸ˜­](https://www.reddit.com/gallery/1p4re78) (Score: 0)
    *   A post with the title "ðŸ˜­" and a comment about image 2 image since SD1.5.
11. [Can someone give a quick status on (animated) AI these days?](https://www.reddit.com/r/StableDiffusion/comments/1p4sg3a/can_someone_give_a_quick_status_on_animated_ai/) (Score: 0)
    *   Asking for a quick status update on animated AI, including information on Qwen, Wan, and related technologies.
12. [Make a video banner for a site](https://www.reddit.com/r/StableDiffusion/comments/1p4vdkt/make_a_video_banner_for_a_site/) (Score: 0)
    *   A question regarding creation of a video banner for a site.
13. [time for video generation](https://www.reddit.com/r/StableDiffusion/comments/1p4qdkd/time_for_video_generation/) (Score: 0)
    *   The post mentions the user's computer specifications and asks if it's a good setup for video generation.
14. [What would you use to create a pet as X image?](https://i.redd.it/45l3w668f13g1.png) (Score: 0)
    *   A question about tools to create a pet as X image, and the discussion explores options like LoRAs, Flux, IP-Adapter, and ControlNet.
15. [WE NOW HAVE ATOMIC-PRECISION F32 UPSCALING, THANKS TO ME. :D](https://huggingface.co/spaces/AEUPH/COSMOS-AI-ATOMIC-PRECISION-UPSCALE-ENGINE) (Score: 0)
    *   The post is advertising atomic-precision F32 upscaling.

# Detailed Analysis by Thread
**[[Release] ComfyUI-MotionCapture â€” Full 3D Human Motion Capture from Video (Score: 87)](https://v.redd.it/25r23butz03g1)**
*  **Summary:** Discussion about a new ComfyUI tool for 3D human motion capture from video (GVHMR). Users are exploring its potential applications and compatibility with other software like Blender and Mikumikudance.
*  **Emotion:** Predominantly Neutral, with some Positive sentiments expressing excitement.
*  **Top 3 Points of View:**
    *   The tool could be a game-changer if it allows exporting to Blender for game development and animated series.
    *   The tool's usefulness is limited if it only works within ComfyUI.
    *   Users are interested in using the tool for dance animations in Mikumikudance if it can export to the .vmd format.

**[My testing of HunyuanVideo 1.5 and Wan 2.2 on I2V (Score: 74)](https://v.redd.it/euk4vcyxx03g1)**
*  **Summary:** A comparison between HunyuanVideo 1.5 and Wan 2.2 for image-to-video generation. The discussion revolves around prompt structures, speed, output quality, and usability.
*  **Emotion:** A mix of Positive and Neutral sentiments, with some Negative comments regarding the comparison's validity.
*  **Top 3 Points of View:**
    *   HunyuanVideo 1.5 looks smoother and better out of the box compared to Wan 2.2.
    *   The comparison is pointless because Wan requires different and more detailed prompts to get desired results.
    *   HunyuanVideo 1.5 has usability wins over Wan 2.2 with 24fps, 8B parameters, and a single model.

**[Updated I2V Wan 2.2 vs. HunyuanVideo 1.5 (with correct settings now) (Score: 61)](https://v.redd.it/4txepl8sf13g1)**
*  **Summary:** An updated comparison of I2V Wan 2.2 and HunyuanVideo 1.5, focusing on their ability to handle simple tasks. Users discuss prompting details and the overall quality of the models.
*  **Emotion:** Mostly Positive, with some Negative comments about Wan's performance.
*  **Top 3 Points of View:**
    *   Hunyuan excels at "realistic realism", making videos look more alive and spontaneous than Wan.
    *   Previous tests were flawed and did not showcase Wan's capabilities adequately.
    *   Hunyuan needs more detailed prompting to work better.

**[Full Music Video generated with AI - Wan2.1 Infinitetalk (Score: 48)](https://www.youtube.com/watch?v=T45wb8henL4)**
*  **Summary:** Discussion of a music video generated using AI, specifically Wan2.1 Infinitetalk. Comments focus on the music, video quality, creative aspects, and generation process.
*  **Emotion:** Predominantly Positive, with users praising the music and video. Some Neutral comments inquiring about the generation time and model comparisons.
*  **Top 3 Points of View:**
    *   The music and video are fantastic, with a bossa nova vibe.
    *   The creative through line of the video gets confused, with a transition to an old-timey theme that doesn't quite fit the initial concept.
    *   Wan2.1 Infinitetalk allows prompting character and movement, making it suitable for music videos.

**[[Release] ComfyUI-GeometryPack â€” (semi)Professional 3D Geometry Tools for ComfyUI (Score: 15)](https://v.redd.it/h9j5irfaz03g1)**
*  **Summary:** A user expressing admiration for the creator of the ComfyUI-GeometryPack.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   The user is impressed with the ComfyUI-GeometryPack.

**[High Variation Qwen Workflow (Score: 9)](https://www.reddit.com/gallery/1p4pv8w)**
*  **Summary:** Users sharing tips and requesting the workflow for High Variation Qwen Workflow.
*  **Emotion:** Positive.
*  **Top 3 Points of View:**
    *   The user appreciates the tips shared, others are also interested in a direct workflow link.
    *   The user suggest change style and prompt midway to get unexpected results
    *  Other users also suggest that the user inject more random noise

**[The general recommendation is 100 steps per image. However, when training LoRa on relatively larger datasets, more than 100 images, the model gets completely burned out at 100 steps. Any explanation? Above 100 images is it 50 steps per image? (Score: 4)](https://www.reddit.com/r/StableDiffusion/comments/1p4s6yg/the_general_recommendation_is_100_steps_per_image/)**
*  **Summary:** A question about the recommended number of steps per image when training LoRAs on larger datasets and why models get burned out.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   The recommendation of 100 steps per image is useless, what matters is the total number of steps of training
    *   When the model gets burned out, it is most likely a too high learning rate.
    *   The number of epochs is better for fine-tuning.

**[Can you have too many LoRAs? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1p4qfs5/can_you_have_too_many_loras/)**
*  **Summary:** Discussion on whether using too many LoRAs can negatively impact image quality.
*  **Emotion:** Negative.
*  **Top 3 Points of View:**
    *   Several LoRAs decrease quality a lot.
    *   Always depends what weights they influence.
    *   In SDXL it's less noticeable, but for some reason in newer models like Flux, Qwen, Chroma, more negative effects are usually seen.

**[Qwen is locally slower at generating 1 image than Wan is at generating a 5 second video, is this normal or am I doing something wrong? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1p4xnw3/qwen_is_locally_slower_at_generating_1_image_than/)**
*  **Summary:** A question about the performance difference between Qwen and Wan in image and video generation.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   The performance difference is most likely due to the resolution of the images being generated.

**[ðŸ˜­ (Score: 0)](https://www.reddit.com/gallery/1p4re78)**
*  **Summary:** A post with the title "ðŸ˜­" and a comment about image 2 image since SD1.5.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   Can you describe what exactly is going on here?

**[Can someone give a quick status on (animated) AI these days? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1p4sg3a/can_someone_give_a_quick_status_on_animated_ai/)**
*  **Summary:** Asking for a quick status update on animated AI, including information on Qwen, Wan, and related technologies.
*  **Emotion:** Negative.
*  **Top 3 Points of View:**
    *   The user needs more information regarding the current status of animated AI.
    *   People are obsessed with their Realism around here. It's so boring.
    *   Wan models are GGUF models with mixed precision.

**[Make a video banner for a site (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1p4vdkt/make_a_video_banner_for_a_site/)**
*  **Summary:** A question regarding creation of a video banner for a site.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   If letters in motion are involved you can do it with AI but there will be a lot of clean up in other programs before it can be ready for delivery.

**[time for video generation (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1p4qdkd/time_for_video_generation/)**
*  **Summary:** The post mentions the user's computer specifications and asks if it's a good setup for video generation.
*  **Emotion:** Positive.
*  **Top 3 Points of View:**
    *   The setup seems good and flexible and it's a decent amount of memory to run just about anything.
    *   Pretty low specs, not gunna be genning anything worth while with this.
    *   The user should throw a 5090 or a pro 6000 when their budget allow it and they have a killer setup.

**[What would you use to create a pet as X image? (Score: 0)](https://i.redd.it/45l3w668f13g1.png)**
*  **Summary:** A question about tools to create a pet as X image, and the discussion explores options like LoRAs, Flux, IP-Adapter, and ControlNet.
*  **Emotion:** Neutral.
*  **Top 3 Points of View:**
    *   The user is looking for tools to create a pet as X image.
    *   The most straightforward solution would be to have a style LoRA for Qwen Image Edit.
    *   There is USO for Flux thing: [https://comfyui-wiki.com/en/tutorial](https://comfyui-wiki.com/en/tutorial)

**[WE NOW HAVE ATOMIC-PRECISION F32 UPSCALING, THANKS TO ME. :D (Score: 0)](https://huggingface.co/spaces/AEUPH/COSMOS-AI-ATOMIC-PRECISION-UPSCALE-ENGINE)**
*  **Summary:** The post is advertising atomic-precision F32 upscaling.
*  **Emotion:** Negative.
*  **Top 3 Points of View:**
    *   The site doesn't work... Hitting generate throws login error.
