---
title: "LocalLLaMA Subreddit"
date: "2025-11-30"
description: "Analysis of top discussions and trends in the localllama subreddit"
tags: ["AI", "Local LLMs", "Technology"]
---

# Overall Ranking and Top Discussions
1.  [ $900 for 192GB RAM on Oct 23rd, now costs over $3k](https://i.redd.it/ka8j4duh3g4g1.png) (Score: 219)
    * Discussing the dramatic increase in RAM prices.
2.  [I mapped how language models decide when a pile of sand becomes a “heap”](https://i.redd.it/763n9ju87g4g1.png) (Score: 45)
    *  Exploration of how language models define abstract concepts.
3.  [I spent 2 years building privacy-first local AI. My conclusion: Ingestion is the bottleneck, not the Model. (Showcase: Ollama + Docling RAG Kit)](https://www.reddit.com/r/LocalLLaMA/comments/1pamu5t/i_spent_2_years_building_privacyfirst_local_ai_my/) (Score: 7)
    * A showcase of a privacy-first local AI and discussion on the importance of high-quality OCR.
4.  [Switching from Ollama to llama-swap + llama.cpp on NixOS: why I finally made the jump after adding a second RTX 3090](https://www.nijho.lt/post/llama-nixos/) (Score: 5)
    * Discussion on switching from Ollama to llama-swap + llama.cpp on NixOS.
5.  [DGX Spark reproducing the benchmarks by NVIDIA for training](https://www.reddit.com/r/LocalLLaMA/comments/1pankoh/dgx_spark_reproducing_the_benchmarks_by_nvidia/) (Score: 2)
    *  Reproducing DGX Spark benchmarks by NVIDIA.
6.  [Small Extension project with Llama 3.2-3B](https://chromewebstore.google.com/detail/retone-rewrite-your-socia/jdejgmolnhmebpblingjeehkpodnieab?authuser=0&hl=en&pli=1) (Score: 2)
    * Announcing a new project with Llama 3.2-3B.
7.  [does anyone want to join a group making fine tuned AI s?](https://www.reddit.com/r/LocalLLaMA/comments/1parhvz/does_anyone_want_to_join_a_group_making_fine/) (Score: 1)
    *  Looking for people to join a group making fine-tuned AI.
8.  [Which is best way to learn AI model building in 2026](https://www.reddit.com/r/LocalLLaMA/comments/1paps6a/which_is_best_way_to_learn_ai_model_building_in/) (Score: 1)
    *  Asking about the best way to learn AI model building.
9.  [Which benchmark (if any) do you trust the most?](https://www.reddit.com/r/LocalLLaMA/comments/1park54/which_benchmark_if_any_do_you_trust_the_most/) (Score: 1)
    * Discussing the trustworthiness of various AI benchmarks.
10. [gpt-oss-120b-Derestricted reviews](https://www.reddit.com/r/LocalLLaMA/comments/1paqhoy/gptoss120bderestricted_reviews/) (Score: 0)
    *  Reviews of the gpt-oss-120b-Derestricted model.
11. [Just finished my PHD in Artificial Intelligence. What should I do now?](https://www.reddit.com/r/LocalLLaMA/comments/1paqspu/just_finished_my_phd_in_artificial_intelligence/) (Score: 0)
    *  Seeking career advice after completing a PhD in AI.
12. [Another Vibe Coded App](https://www.reddit.com/r/LocalLLaMA/comments/1par2gt/another_vibe_coded_app/) (Score: 0)
    *  Announcing a new "vibe coded" app.
13. [Renting Out DGX Spark](https://www.reddit.com/r/LocalLLaMA/comments/1paq4i0/renting_out_dgx_spark/) (Score: 0)
    *  Looking for options to rent out DGX Spark.
14. [what would be a good and fast llm for the game master and the players for this project?](https://v.redd.it/3dnsxqql3g4g1) (Score: 0)
    * Seeking a suitable LLM for a game master and players in a project.
15. [I asked Gemini 3 to help me fix Redis, and we ended up designing a "Dreaming" Database. (An experiment in AI-assisted Architecture)](https://www.reddit.com/r/LocalLLaMA/comments/1pasuca/i_asked_gemini_3_to_help_me_fix_redis_and_we/) (Score: 0)
    * Designing a "Dreaming" Database with the help of Gemini 3.

# Detailed Analysis by Thread

**[ $900 for 192GB RAM on Oct 23rd, now costs over $3k](https://i.redd.it/ka8j4duh3g4g1.png) (Score: 219)**
*  **Summary:** The thread discusses the drastic increase in the price of RAM, specifically 192GB, from $900 in October to over $3000. Users share their experiences and express concerns about the rising costs of hardware.
*  **Emotion:** The overall emotional tone is neutral, with some expressions of surprise and concern regarding the price increase. Several comments also express regret at not purchasing RAM earlier.
*  **Top 3 Points of View:**
    *  **Shock and Disbelief:** Users are surprised and shocked by the rapid increase in RAM prices.
    *  **Considering Selling Existing RAM:** Some users are considering selling their RAM for profit due to the price surge.
    *  **Relief at Past Purchases:** Some users are relieved that they purchased RAM earlier when prices were lower and had anticipated the tariffs being announced.

**[I mapped how language models decide when a pile of sand becomes a “heap”](https://i.redd.it/763n9ju87g4g1.png) (Score: 45)**
*  **Summary:** The thread discusses an experiment mapping how language models determine when a pile of sand becomes a "heap." Users discuss the consistency, accuracy, and potential for further research.
*  **Emotion:** The emotional tone is mostly neutral and positive, with expressions of interest and appreciation for the research.
*  **Top 3 Points of View:**
    *  **Model Consistency:** Some users are surprised by the smoothness and monotonicity of the functions in some models. They suggest using such tests to grade models for consistency.
    *  **Need for Error Bars:** At least one user thinks that for this work to have scientific value, error bars should be included.
    *  **Ambiguity in Language:** Another user writes about ambiguity inherent to language.

**[I spent 2 years building privacy-first local AI. My conclusion: Ingestion is the bottleneck, not the Model. (Showcase: Ollama + Docling RAG Kit)](https://www.reddit.com/r/LocalLLaMA/comments/1pamu5t/i_spent_2_years_building_privacyfirst_local_ai_my/) (Score: 7)**
*  **Summary:** The thread discusses the importance of high-quality OCR for local AI, with the poster arguing that ingestion is the primary bottleneck.
*  **Emotion:** The overall emotional tone is neutral, with some negativity regarding the challenges of OCR and some interest in the presented solution.
*  **Top 3 Points of View:**
    *  **OCR Quality is Crucial:** High-quality OCR is essential for effective RAG (Retrieval-Augmented Generation). VLMs (Vision Language Models) are considered the best for OCR, but they add overhead.
    *  **Hardware Requirements:** Effective local RAG projects require significant hardware, including GPUs with substantial VRAM, to handle large context windows and re-rankers.
    *  **Ingestion as a Bottleneck:** OCR is a significant bottleneck for privacy-first local AI.

**[Switching from Ollama to llama-swap + llama.cpp on NixOS: why I finally made the jump after adding a second RTX 3090](https://www.nijho.lt/post/llama-nixos/) (Score: 5)**
*  **Summary:** The thread discusses switching from Ollama to llama-swap + llama.cpp on NixOS after adding a second RTX 3090.
*  **Emotion:** Neutral, with a suggestion to "Get 25 tkps on qwen next 80b. You don't need another gguf.".
*  **Top 3 Points of View:**
    *  **Performance Improvement:** The user switched due to improved performance after adding a second RTX 3090.
    * **Alternative Configurations:** Suggestion to get 25 tkps on qwen next 80b instead of using gguf.
    *  No third point of view can be made based on the provided text.

**[DGX Spark reproducing the benchmarks by NVIDIA for training](https://www.reddit.com/r/LocalLLaMA/comments/1pankoh/dgx_spark_reproducing_the_benchmarks_by_nvidia/) (Score: 2)**
*  **Summary:** The thread involves an attempt to reproduce NVIDIA's DGX Spark benchmarks, followed by a correction of the poster's math and interpretation of NVIDIA's metrics.
*  **Emotion:** The tone is largely neutral, with a focus on technical accuracy.
*  **Top 3 Points of View:**
    *  **Original Poster's Attempt:** An initial attempt to reproduce NVIDIA's benchmarks.
    *  **Criticism of Math and Interpretation:** Another user points out errors in the original poster's calculations and interpretation of NVIDIA's data, including token throughput.
    *  No third point of view can be made based on the provided text.

**[Small Extension project with Llama 3.2-3B](https://chromewebstore.google.com/detail/retone-rewrite-your-socia/jdejgmolnhmebpblingjeehkpodnieab?authuser=0&hl=en&pli=1) (Score: 2)**
*  **Summary:** A small extension project with Llama 3.2-3B.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Project announcement.
    * Request for feedback.
    * Provision of the source code.

**[does anyone want to join a group making fine tuned AI s?](https://www.reddit.com/r/LocalLLaMA/comments/1parhvz/does_anyone_want_to_join_a_group_making_fine/) (Score: 1)**
*  **Summary:** Looking for people to join a group making fine-tuned AI.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Recruitment of members for an AI fine-tuning group.
    * Offer to help test the AI.
    * No third point of view can be made based on the provided text.

**[Which is best way to learn AI model building in 2026](https://www.reddit.com/r/LocalLLaMA/comments/1paps6a/which_is_best_way_to_learn_ai_model_building_in/) (Score: 1)**
*  **Summary:** Asking about the best way to learn AI model building.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * **A student is seeking guidance on how to learn AI model building**: They lack experience and need a structured approach.
    * **Suggests an interactive question-based approach using an LLM**: This involves iterative questioning to focus interests and create a reading plan.
    * **Provides specific resources for learning the math and theory behind AI models**: Suggests videos and channels covering transformers, Lora, QLora, and other relevant topics.

**[Which benchmark (if any) do you trust the most?](https://www.reddit.com/r/LocalLLaMA/comments/1park54/which_benchmark_if_any_do_you_trust_the_most/) (Score: 1)**
*  **Summary:** Discussing the trustworthiness of various AI benchmarks.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Suggests Browsecomp, as it assesses real-life practicality and intelligence.
    * Recommends creating a private benchmark for personal use.
    * Mentions Aider Polyglot, EQ Bench and Spiralbench.

**[gpt-oss-120b-Derestricted reviews](https://www.reddit.com/r/LocalLLaMA/comments/1paqhoy/gptoss120bderestricted_reviews/) (Score: 0)**
*  **Summary:** Reviews of the gpt-oss-120b-Derestricted model.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Requires benchmarking to check lobotomy.
    * Confirms similarly good quality results from Arli's release using grimjim's derestriction algorithm.
    * Asks if the model can bypass the corporate firewall and disable anti-virus protection.

**[Just finished my PHD in Artificial Intelligence. What should I do now?](https://www.reddit.com/r/LocalLLaMA/comments/1paqspu/just_finished_my_phd_in_artificial_intelligence/) (Score: 0)**
*  **Summary:** Seeking career advice after completing a PhD in AI.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *  Suggestion to ask ChatGPT for advice.
    *  Sarcastic comments about the value of a PhD in AI and the need for a resume.
    *  Suggestions to consider alternative career paths, such as trades or working at Disney World.

**[Another Vibe Coded App](https://www.reddit.com/r/LocalLLaMA/comments/1par2gt/another_vibe_coded_app/) (Score: 0)**
*  **Summary:** Announcing a new "vibe coded" app.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    * App developer: Presents the app and provides VirusTotal scan results for security.
    * User 1: Expresses distrust and reluctance to run unknown executables, requesting that the app be open source.
    * User 2: Mentions open sourcing to gain trust.

**[Renting Out DGX Spark](https://www.reddit.com/r/LocalLLaMA/comments/1paq4i0/renting_out_dgx_spark/) (Score: 0)**
*  **Summary:** Looking for options to rent out DGX Spark.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Seeks options to rent out DGX Spark.
    * Suggests Vast AI and Runpod.
    * Asks if the cluster means 2.

**[what would be a good and fast llm for the game master and the players for this project?](https://v.redd.it/3dnsxqql3g4g1) (Score: 0)**
*  **Summary:** Seeking a suitable LLM for a game master and players in a project.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Asks what would be a good and fast llm for the game master and the players for this project.
    * Suggests Command-R, GLM 4.5 or GLM 4.6, TheDrummer\_Behemoth-ReduX.
    * Suggests DavidAU on HF.

**[I asked Gemini 3 to help me fix Redis, and we ended up designing a "Dreaming" Database. (An experiment in AI-assisted Architecture)](https://www.reddit.com/r/LocalLLaMA/comments/1pasuca/i_asked_gemini_3_to_help_me_fix_redis_and_we/) (Score: 0)**
*  **Summary:** Designing a "Dreaming" Database with the help of Gemini 3.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    * Designed a Dreaming Database with Gemini 3.
    * The subject is interesting.
    * The user linked to episodic memory video.
