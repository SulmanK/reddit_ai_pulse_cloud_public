---
title: "Machine Learning Subreddit"
date: "2025-11-29"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "transformers"]
---

# Overall Ranking and Top Discussions
1.  [[D] [ICLR 2026] Clarification: Your responses will not go to waste!](https://www.reddit.com/r/MachineLearning/comments/1p9d661/d_iclr_2026_clarification_your_responses_will_not/) (Score: 49)
    * Discussion around ICLR 2026, specifically about how responses to reviewers will be handled after the discussion period was shortened.
2.  [[D] Heavy ML workflow: M4 Max or incoming M5 lineup ?](https://www.reddit.com/r/MachineLearning/comments/1p9pj4n/d_heavy_ml_workflow_m4_max_or_incoming_m5_lineup/) (Score: 4)
    *  Users are debating whether to invest in the M4 Max or wait for the M5 lineup for heavy machine learning workflows.
3.  [[R] What AI may learn from the brain in adapting to continuously changing environments](https://www.reddit.com/r/MachineLearning/comments/1p9qzfn/r_what_ai_may_learn_from_the_brain_in_adapting_to/) (Score: 3)
    *  Discussion on replicating a human brain with AI.
4.  [[D] Right approach for my Thesis Methodology? (Robust Bayesian VARs, DRO, Diffusion Models)](https://www.reddit.com/r/MachineLearning/comments/1p9b6oc/d_right_approach_for_my_thesis_methodology_robust/) (Score: 2)
    *  A student seeks advice on their thesis methodology, considering Robust Bayesian VARs, DRO, and Diffusion Models.
5.  [[P] A new framework for causal transformer models on non-language data: sequifier](https://www.reddit.com/r/MachineLearning/comments/1p9pk1b/p_a_new_framework_for_causal_transformer_models/) (Score: 2)
    *  Introducing a new framework called "sequifier" for causal transformer models on non-language data.
6.  [[P] I built a compositional DSL for transformer experimentation and want some feedback](https://www.reddit.com/r/MachineLearning/comments/1p9e12w/p_i_built_a_compositional_dsl_for_transformer/) (Score: 0)
    *  A user is seeking feedback on a compositional Domain Specific Language (DSL) they built for transformer experimentation.
7.  [[D] designing neural network before reading](https://www.reddit.com/r/MachineLearning/comments/1p99wbn/d_designing_neural_network_before_reading/) (Score: 0)
    *  Discussion on the benefits of designing neural networks before diving into extensive reading on the subject.

# Detailed Analysis by Thread
**[[D] [ICLR 2026] Clarification: Your responses will not go to waste! (Score: 49)](https://www.reddit.com/r/MachineLearning/comments/1p9d661/d_iclr_2026_clarification_your_responses_will_not/)**
*  **Summary:** The thread discusses the ICLR 2026 clarification regarding reviewer responses after the discussion period was shortened, with concerns raised about potential biases, collusion, and the impact on paper acceptance.
*  **Emotion:** The emotional tone is predominantly Neutral, with hints of negativity and annoyance expressed by some users regarding the review process.
*  **Top 3 Points of View:**
    *   ACs will estimate how reviewer impressions would have changed.
    *   Some believe paper acceptance depends on being part of a "collusion ring".
    *   A student author is annoyed by a reviewer's harsh criticism of their paper.

**[[D] Heavy ML workflow: M4 Max or incoming M5 lineup ? (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1p9pj4n/d_heavy_ml_workflow_m4_max_or_incoming_m5_lineup/)**
*  **Summary:** Users are debating whether to invest in the M4 Max or wait for the M5 lineup for heavy machine learning workflows, considering factors such as GPU architecture, memory, and potential cost-effectiveness.
*  **Emotion:** The emotional tone is Neutral, with users presenting arguments for and against each option.
*  **Top 3 Points of View:**
    *   Get 3090 RTX or 4090 instead.
    *   The M5 lineup will have tangible improvements for ML workloads.
    *   Max out your RAM on the M4 instead of spending more.

**[[R] What AI may learn from the brain in adapting to continuously changing environments (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1p9qzfn/r_what_ai_may_learn_from_the_brain_in_adapting_to/)**
*   **Summary:** A discussion about replicating a human brain with AI.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Someone wondering if AI is taking a different direction than trying to replicate a human brain.

**[[D] Right approach for my Thesis Methodology? (Robust Bayesian VARs, DRO, Diffusion Models) (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1p9b6oc/d_right_approach_for_my_thesis_methodology_robust/)**
*   **Summary:** A student seeks advice on their thesis methodology.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Clarification that three semesters is possible for graduation.

**[[P] A new framework for causal transformer models on non-language data: sequifier (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1p9pk1b/p_a_new_framework_for_causal_transformer_models/)**
*   **Summary:** Introducing a new framework for causal transformer models.
*   **Emotion:** The emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Question about the use of RMSNorm implementation.
    *   Request for benchmarks.

**[[P] I built a compositional DSL for transformer experimentation and want some feedback (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1p9e12w/p_i_built_a_compositional_dsl_for_transformer/)**
*   **Summary:** A user is seeking feedback on a compositional Domain Specific Language (DSL) they built for transformer experimentation.
*   **Emotion:** The emotional tone is mixed, with neutral questioning, a hint of positive encouragement, and some critical observations.
*   **Top 3 Points of View:**
    *   Questioning how this is any better than Python+PyTorch with predefined modules?
    *   Is there support for blocks that are not trained/gradients aren't propogated?
    *   Concerns about expressing skip/residual connections.

**[[D] designing neural network before reading (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1p99wbn/d_designing_neural_network_before_reading/)**
*   **Summary:** Discussion on the benefits of designing neural networks before reading.
*   **Emotion:** Mixed positive and neutral sentiments.
*   **Top 3 Points of View:**
    *   Thinking through the rationale is better than copy pasting.
    *   Professor made them use MS excel to make a neural network.
    *   Thatâ€™s the best way to do things.
