---
title: "Machine Learning Subreddit"
date: "2025-11-27"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "ICLR", "OpenReview"]
---

# Overall Ranking and Top Discussions
1.  [[D] Got burned by an Apple ICLR paper — it was withdrawn after my Public Comment.](https://www.reddit.com/r/MachineLearning/comments/1p82cto/d_got_burned_by_an_apple_iclr_paper_it_was/) (Score: 715)
    *   A user's public comment led to the withdrawal of an Apple ICLR paper, sparking discussion about the quality of reviews and the importance of open source science.
2.  [[D] Reminder for ICLR: Sharing your paper's OpenReview page on Social Media gets you desk rejected](https://www.reddit.com/r/MachineLearning/comments/1p82dc2/d_reminder_for_iclr_sharing_your_papers/) (Score: 72)
    *   A reminder that sharing an OpenReview page on social media can lead to desk rejection at ICLR.
3.  [[D] ICLR 2026 vs. LLMs - Discussion Post](https://www.reddit.com/r/MachineLearning/comments/1p7me4r/d_iclr_2026_vs_llms_discussion_post/) (Score: 68)
    *   A discussion about the implications of Large Language Models (LLMs) on ICLR 2026, specifically regarding AI-generated papers and reviews.
4.  [[D] Openreview All Information Leaks](https://www.reddit.com/r/MachineLearning/comments/1p85vs0/d_openreview_all_information_leaks/) (Score: 52)
    *   A discussion of the OpenReview information leaks that allowed users to see the names of reviewers, authors, and area chairs.
5.  [[D] Inverse hyperbolic sine as an activation function and its anti-derivative as a loss function](https://www.reddit.com/r/MachineLearning/comments/1p7pmq8/d_inverse_hyperbolic_sine_as_an_activation/) (Score: 14)
    *   A thread exploring the use of the inverse hyperbolic sine function as an activation function and its anti-derivative as a loss function.
6.  [[D] Anyone here actively using or testing an NVIDIA DGX Spark?](https://www.reddit.com/r/MachineLearning/comments/1p7m9nk/d_anyone_here_actively_using_or_testing_an_nvidia/) (Score: 9)
    *   Users discuss their experiences using the NVIDIA DGX Spark, with some noting limitations related to unified memory and bandwidth.
7.  [[D] How do you know if regression metrics like MSE/RMSE are “good” on their own?](https://www.reddit.com/r/MachineLearning/comments/1p7v5y2/d_how_do_you_know_if_regression_metrics_like/) (Score: 6)
    *   A discussion on how to interpret regression metrics like MSE and RMSE, emphasizing the importance of comparison and context.
8.  [[R] Any VLMs that are fully reproducible with clear documentation on how to do so?](https://www.reddit.com/r/MachineLearning/comments/1p813js/r_any_vlms_that_are_fully_reproducible_with_clear/) (Score: 3)
    *   A request for Vision Language Models (VLMs) that are fully reproducible with clear documentation.
9.  [[D] Point Cloud Completion: Prototype First or Read Papers First?](https://www.reddit.com/r/MachineLearning/comments/1p80bo8/d_point_cloud_completion_prototype_first_or_read/) (Score: 2)
    *   A question on whether to prototype first or read papers first when working on point cloud completion tasks.
10. [[D] MICCAI 2026 still has no call for papers with <3 mo to go](https://www.reddit.com/r/MachineLearning/comments/1p81mrw/d_miccai_2026_still_has_no_call_for_papers_with_3/) (Score: 0)
    *   A user points out that MICCAI 2026 has not released a call for papers with less than 3 months to go.
11. [[D] Why do we consider the distance between the Support Vector and hyperplane 1/||w|| ?](https://www.reddit.com/r/MachineLearning/comments/1p85tju/d_why_do_we_consider_the_distance_between_the/) (Score: 0)
    *   A question about the formula for the distance between the Support Vector and hyperplane in SVM.

# Detailed Analysis by Thread
**[[D] Got burned by an Apple ICLR paper — it was withdrawn after my Public Comment. (Score: 715)](https://www.reddit.com/r/MachineLearning/comments/1p82cto/d_got_burned_by_an_apple_iclr_paper_it_was/)**
*   **Summary:** A Reddit user's public comment led to the withdrawal of an Apple ICLR paper. The thread discusses the importance of rigorous review, reproducibility, and the potential for errors in even high-profile publications.
*   **Emotion:** The dominant emotion is Neutral, but there is also a notable presence of Negative and Positive emotions. Many comments express support for the original poster's actions and criticize the lack of rigor in some ML paper reviews. Some comments are also negative, expressing annoyance and frustration about the issues in the paper.
*   **Top 3 Points of View:**
    *   The OP's work in identifying the flaws in the paper is commendable and highlights the value of public scrutiny.
    *   Many Machine Learning papers don't stand up to scrutiny and lack proper data analysis.
    *   Open-source science and code release are crucial for identifying and correcting errors in published research.

**[[D] Reminder for ICLR: Sharing your paper's OpenReview page on Social Media gets you desk rejected (Score: 72)](https://www.reddit.com/r/MachineLearning/comments/1p82dc2/d_reminder_for_iclr_sharing_your_papers/)**
*   **Summary:** The thread serves as a reminder that sharing an ICLR paper's OpenReview page on social media can result in desk rejection. Commenters generally agree with this policy, citing concerns about anonymity and potential for bias.
*   **Emotion:** The dominant emotion is Neutral, with some Positive sentiment as well. People seem to find the situation amusing or self-inflicted.
*   **Top 3 Points of View:**
    *   Sharing OpenReview pages on social media is a violation of ICLR's anonymity policy.
    *   The rule is common sense and easily avoidable.
    *   It is better to avoid boasting about work on social media before results are released.

**[[D] ICLR 2026 vs. LLMs - Discussion Post (Score: 68)](https://www.reddit.com/r/MachineLearning/comments/1p7me4r/d_iclr_2026_vs_llms_discussion_post/)**
*   **Summary:** The discussion revolves around the impact of Large Language Models (LLMs) on the ICLR 2026 conference, particularly regarding AI-generated papers and reviews. Concerns are raised about the difficulty of detecting AI-generated content and the potential for biased or low-quality reviews. Some suggest that the focus should be on reproducibility and the quality of the research, regardless of authorship.
*   **Emotion:** The emotional tone is primarily Neutral, with some presence of Positive sentiments. There are opinions that detection tools for AI generated content are scams.
*   **Top 3 Points of View:**
    *   It is important to have clear evidence that papers are AI-generated before rejecting them.
    *   The focus should be on the reproducibility and validity of research findings, regardless of who or what generated the paper.
    *   The size and structure of the conference are fundamental problems that need addressing, since there are no incentives to do a good job on reviews.

**[[D] Openreview All Information Leaks (Score: 52)](https://www.reddit.com/r/MachineLearning/comments/1p85vs0/d_openreview_all_information_leaks/)**
*   **Summary:** This thread discusses a software bug on OpenReview that leaked the identities of authors, reviewers, and area chairs. The community expresses concern over the breach of anonymity and the potential consequences, including desk rejections and multi-year bans for exploiting the leak. There are calls for transparency and accountability.
*   **Emotion:** The overall tone is Neutral, with a notable presence of Negative sentiment. There is disappointment that the leak was fixed.
*   **Top 3 Points of View:**
    *   The OpenReview information leak is a serious issue that compromises the anonymity of the review process.
    *   Exploitation or sharing of the leaked information should be met with severe penalties.
    *   The bug highlights potential issues in the peer review process, such as reviewers potentially being in competing fields and the lack of accountability in reviews.

**[[D] Inverse hyperbolic sine as an activation function and its anti-derivative as a loss function (Score: 14)](https://www.reddit.com/r/MachineLearning/comments/1p7pmq8/d_inverse_hyperbolic_sine_as_an_activation/)**
*   **Summary:** The thread is a discussion about the potential uses of the inverse hyperbolic sine function (asinh) as an activation and loss function in machine learning models. Users discuss its properties, potential benefits (such as non-zero gradients and usefulness for heavy-tailed data), and potential drawbacks (such as the need for large activations).
*   **Emotion:** Predominantly Neutral in tone, with some Positive sentiment as well. There is intrigue around this specific activation function.
*   **Top 3 Points of View:**
    *   Asinh can be useful for plotting log-scaled data with negatives and zeros, and for feature normalization of heavy-tailed data.
    *   Custom activation functions may not perform as well as standard ones.
    *   Asinh may be interesting in GLU variants.

**[[D] Anyone here actively using or testing an NVIDIA DGX Spark? (Score: 9)](https://www.reddit.com/r/MachineLearning/comments/1p7m9nk/d_anyone_here_actively_using_or_testing_an_nvidia/)**
*   **Summary:** This thread asks for experiences using the NVIDIA DGX Spark. Responses suggest that it's not great for training regular models due to its unified memory concept making it significantly slower than traditional GPU memory, and that bandwidth is criminally low.
*   **Emotion:** The dominant emotion is Neutral, with some Negative comments about the hardware's performance.
*   **Top 3 Points of View:**
    *   The NVIDIA DGX Spark is not great for training regular models.
    *   The unified memory concept makes it horrible for training regular models.
    *   Bandwidth is criminally low.

**[[D] How do you know if regression metrics like MSE/RMSE are “good” on their own? (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1p7v5y2/d_how_do_you_know_if_regression_metrics_like/)**
*   **Summary:** Users discuss how to interpret regression metrics like MSE and RMSE. The consensus is that these metrics are only meaningful in context and should be compared to baselines, domain expectations, or the scale of the target variable. They aren't as intuitive and objective as classification.
*   **Emotion:** The dominant emotion is Neutral, which many thoughtful and informative responses.
*   **Top 3 Points of View:**
    *   Regression metrics are only meaningful in comparison to other models or baselines.
    *   Absolute values of MSE/RMSE are meaningless without considering the scale of the target variable.
    *   The focus should be on the cost of errors and the impact on business outcomes.

**[[R] Any VLMs that are fully reproducible with clear documentation on how to do so? (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1p813js/r_any_vlms_that_are_fully_reproducible_with_clear/)**
*   **Summary:** The user is asking for suggestions for Vision Language Models (VLMs) that are fully reproducible and have clear documentation.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   The Qwen3-VL Technical Report is fairly detailed in its architecture/implementation.
    *   The original llava codebase and data is published and is relatively cheap to train.
    *   A more modern VLM is Molmo, which also provides all code, data, tech report, etc

**[[D] Point Cloud Completion: Prototype First or Read Papers First? (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1p80bo8/d_point_cloud_completion_prototype_first_or_read/)**
*   **Summary:** A user asks whether they should prototype a point cloud completion task first or read papers first.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Prototype first, that reading papers won't really help because ML papers are all about using techniques X, Y and Z to solve problems A and B.

**[[D] MICCAI 2026 still has no call for papers with <3 mo to go (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1p81mrw/d_miccai_2026_still_has_no_call_for_papers_with_3/)**
*   **Summary:** A user points out that MICCAI 2026 has not released a call for papers with less than 3 months to go.
*   **Emotion:** Neutral
*   **Top 2 Points of View:**
    *   MICCAI is in oct 2026
    *   In all seriousness, it does not change anything for the writing of the paper.

**[[D] Why do we consider the distance between the Support Vector and hyperplane 1/||w|| ? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1p85tju/d_why_do_we_consider_the_distance_between_the/)**
*   **Summary:** A question about the formula for the distance between the Support Vector and hyperplane in SVM.
*   **Emotion:** Neutral
*   **Top 2 Points of View:**
    *   Read the svm chapter of Andrew Ng's ML script for example
    *   Try and compute the distance from the origin to the hyperplane w\^T \* x = 1
