---
title: "Machine Learning Subreddit"
date: "2025-11-12"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions

1.  [[D] <ICLR review comment> Is this real?](https://www.reddit.com/r/MachineLearning/comments/1ov7qs2/d_iclr_review_comment_is_this_real/) (Score: 88)
    *   The thread discusses a potentially outrageous review comment from the ICLR conference, questioning its authenticity and the behavior of the reviewer.
2.  [[D] Is anonymous peer review outdated for AI conferences](https://www.reddit.com/r/MachineLearning/comments/1ov6lg6/d_is_anonymous_peer_review_outdated_for_ai/) (Score: 13)
    *   The thread explores whether anonymous peer review is outdated for AI conferences, with discussions around potential security risks and the quality of reviewers.
3.  [[D] How should i handle extreme class imbalance in a classification?](https://www.reddit.com/r/MachineLearning/comments/1oulw5c/d_how_should_i_handle_extreme_class_imbalance_in/) (Score: 12)
    *   This thread discusses ways to handle extreme class imbalance in a classification problem, with suggestions including focal loss, weighted cross-entropy, and oversampling techniques.
4.  [[D] Best CV/AI journal to submit an extended CVPR paper](https://www.reddit.com/r/MachineLearning/comments/1ouvqbq/d_best_cvai_journal_to_submit_an_extended_cvpr/) (Score: 9)
    *   The discussion revolves around finding the best computer vision/AI journal to submit an extended version of a CVPR paper, with recommendations for journals like IJCV, JMLR, ACM TIST, and IEEE TCSVT.
5.  [[R][P] CellARC: cellular automata based abstraction and reasoning benchmark (paper + dataset + leaderboard + baselines)](https://www.reddit.com/r/MachineLearning/comments/1ovchkp/rp_cellarc_cellular_automata_based_abstraction/) (Score: 7)
    *   The thread introduces CellARC, a new benchmark for abstraction and reasoning based on cellular automata, designed to decouple generalization from anthropomorphic priors.
6.  [[P] NeuralFlight: I rebuilt my 7-year-old BCI drone project with modern ML - now featuring 73% cross-subject motor imagery accuracy](https://www.reddit.com/r/MachineLearning/comments/1ov0rhr/p_neuralflight_i_rebuilt_my_7yearold_bci_drone/) (Score: 6)
    *   A user shares their rebuilt BCI drone project called NeuralFlight, showcasing improved accuracy with modern ML techniques. The discussion includes a link to the original project video and a comment on a naming conflict with another paper.
7.  [[R] How can I combine SAM, Yolo, DepthAny et. al. as features to improve a trainable vision model for action detection?](https://www.reddit.com/r/MachineLearning/comments/1ov1318/r_how_can_i_combine_sam_yolo_depthany_et_al_as/) (Score: 3)
    *   The user is seeking ways to combine different AI models like SAM, Yolo, and DepthAny to enhance a vision model for action detection.
8.  [[D] Safety of Imaged Editing Tools](https://www.reddit.com/r/MachineLearning/comments/1ouvdef/d_safety_of_imaged_editing_tools/) (Score: 0)
    *   The thread discusses the safety of image editing tools and the limitations companies impose on these tools, particularly concerning social commentary and critical arts.

# Detailed Analysis by Thread

**[[D] <ICLR review comment> Is this real? (Score: 88)](https://www.reddit.com/r/MachineLearning/comments/1ov7qs2/d_iclr_review_comment_is_this_real/)**
*   **Summary:**  The thread discusses a potentially outrageous review comment from the ICLR conference. Users are questioning the authenticity and the ethics of the review.
*   **Emotion:** The overall emotional tone is mixed. Some comments are negative due to the harshness of the review comment, while others are neutral, simply providing links or expressing amusement. One comment expresses positivity.
*   **Top 3 Points of View:**
    *   The review comment is considered extremely harsh and unprofessional.
    *   The review comment is authentic.
    *   There is amusement at the absurdity of the review and the situation.

**[[D] Is anonymous peer review outdated for AI conferences (Score: 13)](https://www.reddit.com/r/MachineLearning/comments/1ov6lg6/d_is_anonymous_peer_review_outdated_for_ai/)**
*   **Summary:** The thread explores whether anonymous peer review is outdated for AI conferences. It covers arguments for and against anonymity, discussing potential biases, security risks, and the overall quality of the review process.
*   **Emotion:** The overall emotional tone is somewhat negative, primarily reflecting concerns about the reviewing process and its potential flaws, although some comments are neutral.
*   **Top 3 Points of View:**
    *   Anonymity is crucial to protect reviewers from angry authors and potential career repercussions.
    *   Double-blind review is not truly blind, as reviewers often identify authors and tailor reviews accordingly.
    *   De-anonymizing reviewers would create a security risk and decimate the pool of legitimate reviewers.

**[[D] How should i handle extreme class imbalance in a classification? (Score: 12)](https://www.reddit.com/r/MachineLearning/comments/1oulw5c/d_how_should_i_handle_extreme_class_imbalance_in/)**
*   **Summary:** This thread discusses ways to handle extreme class imbalance in a classification problem. Users are recommending various techniques and approaches.
*   **Emotion:** The overall emotional tone is neutral. The comments are mostly informative and providing technical advice.
*   **Top 3 Points of View:**
    *   Focal loss is a good option for handling class imbalance.
    *   Oversampling techniques or synthetic data generation for the minority class.
    *   When using weighted binary cross-entropy loss, the weight of the positive class should be adjusted carefully, often starting with a lower value than the negative:positive ratio.

**[[D] Best CV/AI journal to submit an extended CVPR paper (Score: 9)](https://www.reddit.com/r/MachineLearning/comments/1ouvqbq/d_best_cvai_journal_to_submit_an_extended_cvpr/)**
*   **Summary:** The discussion revolves around finding the best computer vision/AI journal to submit an extended version of a CVPR paper. Users are suggesting different journals and sharing their experiences with them.
*   **Emotion:** The overall emotional tone is positive and neutral. Users are offering advice and congratulations.
*   **Top 3 Points of View:**
    *   IJCV is a good option.
    *   Journal of Machine Learning Research is another option that accepts extended conference papers.
    *   ACM TOMM/TIST and IEEE TCSVT are worth considering depending on the topic.

**[[R][P] CellARC: cellular automata based abstraction and reasoning benchmark (paper + dataset + leaderboard + baselines) (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1ovchkp/rp_cellarc_cellular_automata_based_abstraction/)**
*   **Summary:** The thread introduces CellARC, a new benchmark for abstraction and reasoning based on cellular automata. The benchmark is designed to address the limitations of existing benchmarks like ARC-AGI by decoupling generalization from anthropomorphic priors.
*   **Emotion:** The emotional tone is primarily neutral. The discussion is focused on the technical aspects of the benchmark.
*   **Top 3 Points of View:**
    *   CellARC is a better alternative to ARC-AGI 1 and 2 because it decouples generalization from anthropomorphic priors.
    *   ARC-AGI 1 and 2 are flawed due to reliance on anthropomorphic priors.
    *   It's unclear whether CellARC is too simple and can be solved by non-ML methods.

**[[P] NeuralFlight: I rebuilt my 7-year-old BCI drone project with modern ML - now featuring 73% cross-subject motor imagery accuracy (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1ov0rhr/p_neuralflight_i_rebuilt_my_7yearold_bci_drone/)**
*   **Summary:** A user shares their rebuilt BCI drone project called NeuralFlight, showcasing improved accuracy with modern ML techniques. The discussion includes a link to the original project video and a comment on a naming conflict with another paper.
*   **Emotion:** The emotional tone is predominantly neutral, with elements of curiosity and mild concern regarding the naming similarity.
*   **Top 3 Points of View:**
    *   The project has achieved improved accuracy compared to its original version.
    *   The project's name, NeuralFlight, is similar to a well-known drone control paper called NeuralFly.
    *   The original project video is available on YouTube.

**[[R] How can I combine SAM, Yolo, DepthAny et. al. as features to improve a trainable vision model for action detection? (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1ov1318/r_how_can_i_combine_sam_yolo_depthany_et_al_as/)**
*   **Summary:** The user is seeking ways to combine different AI models like SAM, Yolo, and DepthAny to enhance a vision model for action detection.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Transfer learning may help.

**[[D] Safety of Imaged Editing Tools (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1ouvdef/d_safety_of_imaged_editing_tools/)**
*   **Summary:** The thread discusses the safety of image editing tools and the limitations companies impose on these tools, particularly concerning social commentary and critical arts.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Companies should not limit image editing and generation models for their own benefits.
    *   Only real unsafe content should be limited.
