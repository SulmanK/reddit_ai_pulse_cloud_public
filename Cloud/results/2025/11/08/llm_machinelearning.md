---
title: "Machine Learning Subreddit"
date: "2025-11-08"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "TPU", "GPU", "coding assistant"]
---

# Overall Ranking and Top Discussions
1.  [[D] Why TPUs are not as famous as GPUs](https://www.reddit.com/r/MachineLearning/comments/1ornns5/d_why_tpus_are_not_as_famous_as_gpus/) (Score: 79)
    *   The thread discusses why TPUs are not as widely used as GPUs in the machine learning field, citing factors like limited availability, vendor lock-in, software support, and the general-purpose nature of GPUs.
2.  [[R] Brief History of Post Training of LLMs Slide Deck](https://www.reddit.com/r/MachineLearning/comments/1or9qqy/r_brief_history_of_post_training_of_llms_slide/) (Score: 18)
    *   A brief history of Post Training of LLMs Slide Deck.
3.  [[D] What would change in your ML workflow if Jupyter or VS Code opened in seconds on a cloud-hosted OS?](https://www.reddit.com/r/MachineLearning/comments/1or7vzt/d_what_would_change_in_your_ml_workflow_if/) (Score: 0)
    *   The thread discusses the potential impact of cloud-hosted OS environments with near-instant startup times for Jupyter or VS Code on machine learning workflows.
4.  [[D] Best AI coding assistant](https://www.reddit.com/r/MachineLearning/comments/1orttl3/d_best_ai_coding_assistant/) (Score: 0)
    *   A discussion about the best AI coding assistants, comparing tools like ChatGPT, Cursor, and Claude, and discussing their strengths in different areas like handling repositories, generating mathematical formulas, and coding abilities.

# Detailed Analysis by Thread
**[[D] Why TPUs are not as famous as GPUs (Score: 79)](https://www.reddit.com/r/MachineLearning/comments/1ornns5/d_why_tpus_are_not_as_famous_as_gpus/)**
*   **Summary:** The discussion revolves around why TPUs haven't achieved the same level of popularity as GPUs in the machine learning community. Factors mentioned include limited availability, vendor lock-in with Google, ease of use, software support, the general-purpose nature of GPUs making them more adaptable to new innovations, and potentially not being as profitable for companies to sell.
*   **Emotion:** The overall emotional tone is neutral. While some comments express positive sentiment, the dominant sentiment is neutral.
*   **Top 3 Points of View:**
    *   TPUs are not as famous because Google primarily uses them internally and doesn't sell them widely. This limits their accessibility.
    *   GPUs are more versatile and general-purpose, adapting better to new innovations in machine learning, whereas TPUs are specialized. The CUDA ecosystem is also a big advantage.
    *   Vendor lock-in and software support are barriers to TPU adoption. Nvidia GPUs have broader availability and support.

**[[R] Brief History of Post Training of LLMs Slide Deck (Score: 18)](https://www.reddit.com/r/MachineLearning/comments/1or9qqy/r_brief_history_of_post_training_of_llms_slide/)**
*   **Summary:** A user shares a slide deck about the brief history of Post Training of LLMs. The response to the post is positive.
*   **Emotion:** Positive due to the comment "Very nice" with a high sentiment score.
*   **Top 3 Points of View:**
    *   The slide deck is well-received.
    *   (There are not enough distinct viewpoints to extract 3.)

**[[D] What would change in your ML workflow if Jupyter or VS Code opened in seconds on a cloud-hosted OS? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1or7vzt/d_what_would_change_in_your_ml_workflow_if/)**
*   **Summary:** Users discuss the impact of near-instant startup times for development environments (Jupyter/VS Code) in a cloud setting on their ML workflows. Many already use cloud-based environments. Some express skepticism about the feasibility and hidden complexities of such a system, comparing it to an advertisement. There are concerns about stability, debugging, and the underlying infrastructure.
*   **Emotion:** The overall emotional tone is mixed, leaning towards neutral. While some comments are neutral, others express skepticism and negative sentiment, particularly regarding the practical challenges and potential downsides of such a system.
*   **Top 3 Points of View:**
    *   For some, it wouldn't change much as they are already using cloud-hosted OS environments.
    *   Others are skeptical, seeing it as an ad and highlighting the hidden complexities and maintenance burden.
    *   Some are wary of the technical challenges in on-demand environments, such as driver version discrepancies and debugging difficulties.

**[[D] Best AI coding assistant (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1orttl3/d_best_ai_coding_assistant/)**
*   **Summary:** The discussion focuses on comparing different AI coding assistants like ChatGPT, Claude, and Cursor. Users discuss their strengths and weaknesses, with some favoring Claude for handling entire repositories and contexts, and others preferring GPT for mathematical formulas and scientific applications. The importance of understanding the code generated by AI and not relying on it as a crutch is also highlighted.
*   **Emotion:** The overall emotional tone is neutral. The sentiment scores are relatively close to neutral.
*   **Top 3 Points of View:**
    *   Claude excels at handling large codebases and long contexts.
    *   GPT is better at generating mathematical formulas and tackling complex mathematics.
    *   AI should be used as an amplifier, not a replacement for understanding the code and logic.
