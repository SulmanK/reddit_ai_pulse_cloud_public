---
title: "Stable Diffusion Subreddit"
date: "2025-06-20"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stable diffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Vibe filmmaking for free](https://v.redd.it/93k8t6jfy38f1) (Score: 38)
    *   Discussion around using Blender for "vibe filmmaking" with AI, performance expectations on different hardware, and whether it's Windows only.
2.  [Spend another all day testing chroma about prompt follow...also with controlnet](https://www.reddit.com/gallery/1lg72v9) (Score: 25)
    *   User shares results of testing Chroma, a model known for uncensored image generation, focusing on prompt following and ControlNet integration. Other users requested workflow details. The post contains images with potentially explicit content.
3.  [I created a cheatsheet to help make labels in various Art Nouveau styles](https://i.redd.it/em3q41nil38f1.png) (Score: 22)
    *   A user created and shared a cheat sheet for generating Art Nouveau styles in Stable Diffusion. People found it very helpful and asked what model was used. Others shared links to related LoRAs for specific artists.
4.  [ByteDance-SeedVR2 implementation for ComfyUI](https://v.redd.it/al465wqvn48f1) (Score: 16)
    *   Discussion about the implementation of ByteDance-SeedVR2 in ComfyUI. Some users noted that it is good and better than STAR, while others were not able to see the difference.
5.  [Why are my PonyDiffusionXL generations so bad?](https://www.reddit.com/r/StableDiffusion/comments/1lg9v2o/why_are_my_ponydiffusionxl_generations_so_bad/) (Score: 16)
    *   Users discuss the difficulties of using PonyDiffusionXL, suggesting the use of specific LoRAs, negative prompts, and alternative models like Illustrious for better results.
6.  [Is there anything that can help me turn a 2D image into a virtual tool using comfy? I want to generate images of a room and then combine them together for a 360 tour](https://i.redd.it/m97koadop48f1.jpeg) (Score: 4)
    *   A user is asking for solutions to convert a 2D image into a virtual tool for creating 360 tours using ComfyUI.
7.  [Train lora with CPU + GPU?](https://www.reddit.com/r/StableDiffusion/comments/1lga7ty/train_lora_with_cpu_gpu/) (Score: 2)
    *   Users discuss training LoRAs using both CPU and GPU, with a user providing a Colab link as a guide and suggesting how to reduce VRAM consumption.
8.  [Missed a shot in my film](https://www.reddit.com/r/StableDiffusion/comments/1lgcj9x/missed_a_shot_in_my_film/) (Score: 2)
    *   A user is asking for a solution to recreate a missed shot in their film.
9.  [Is Flux Schnell's architecture inherently inferior than Flux Dev's? (Chroma-related)](https://www.reddit.com/r/StableDiffusion/comments/1lg8y6f/is_flux_schnells_architecture_inherently_inferior/) (Score: 1)
    *   Users discuss the architectural differences and relative performance of Flux Schnell and Flux Dev models.
10. [How to train an ai image model?](https://www.reddit.com/r/StableDiffusion/comments/1lgbrxy/how_to_train_an_ai_image_model/) (Score: 1)
    *   A user is asking for guidance on training an AI image model.
11. [Wan 2.1 on a 16gb card](https://www.reddit.com/r/StableDiffusion/comments/1lgdf18/wan_21_on_a_16gb_card/) (Score: 1)
    *   A user is asking about running Wan 2.1 on a 16gb card.
12. [How are these Fake Instagrammer videos created?](https://www.reddit.com/gallery/1lg9n95) (Score: 0)
    *   Users discuss how fake Instagrammer videos are created, with one suggesting the use of Veo 3.
13. [Most Photorealistic Model WITH LoRA compatibility?](https://www.reddit.com/r/StableDiffusion/comments/1lgb0ln/most_photorealistic_model_with_lora_compatibility/) (Score: 0)
    *   A user is asking about the most photorealistic model with LoRA compatibility.

# Detailed Analysis by Thread
**[Vibe filmmaking for free (Score: 38)](https://v.redd.it/93k8t6jfy38f1)**
*   **Summary:** Discussion around using Blender for "vibe filmmaking" with AI, performance expectations on different hardware, and whether it's Windows only.
*   **Emotion:** Mostly neutral, with some negative sentiment expressed towards the term "vibe coding."
*   **Top 3 Points of View:**
    *   The use of "vibe" as a descriptor is criticized.
    *   Users are curious about performance on specific hardware (e.g., an 8GB 1070).
    *   Users are asking why it's being built in Blender instead of a web interface.

**[Spend another all day testing chroma about prompt follow...also with controlnet (Score: 25)](https://www.reddit.com/gallery/1lg72v9)**
*   **Summary:** User shares results of testing Chroma, a model known for uncensored image generation, focusing on prompt following and ControlNet integration. Other users requested workflow details. The post contains images with potentially explicit content.
*   **Emotion:** The sentiment is mainly neutral.
*   **Top 3 Points of View:**
    *   The model is complete uncen.
    *   Users request the workflow used.
    *   Flux union v2 control net is surprisingly good.

**[I created a cheatsheet to help make labels in various Art Nouveau styles (Score: 22)](https://i.redd.it/em3q41nil38f1.png)**
*   **Summary:** A user created and shared a cheat sheet for generating Art Nouveau styles in Stable Diffusion. People found it very helpful and asked what model was used. Others shared links to related LoRAs for specific artists.
*   **Emotion:** The overall emotion is positive, with users expressing appreciation and excitement about the cheat sheet.
*   **Top 3 Points of View:**
    *   The cheat sheet is helpful for visual styles.
    *   Using custom LoRAs for specific artists yields better results.
    *   Users are interested in knowing which model was used to create the cheat sheet.

**[ByteDance-SeedVR2 implementation for ComfyUI (Score: 16)](https://v.redd.it/al465wqvn48f1)**
*   **Summary:** Discussion about the implementation of ByteDance-SeedVR2 in ComfyUI. Some users noted that it is good and better than STAR, while others were not able to see the difference.
*   **Emotion:** The sentiment is generally positive with some neutral viewpoints.
*   **Top 3 Points of View:**
    *   The implementation is good and better than STAR.
    *   The difference in the sample video is not noticeable.
    *   The processing time is quite long.

**[Why are my PonyDiffusionXL generations so bad? (Score: 16)](https://www.reddit.com/r/StableDiffusion/comments/1lg9v2o/why_are_my_ponydiffusionxl_generations_so_bad/)**
*   **Summary:** Users discuss the difficulties of using PonyDiffusionXL, suggesting the use of specific LoRAs, negative prompts, and alternative models like Illustrious for better results.
*   **Emotion:** The sentiment is largely neutral.
*   **Top 3 Points of View:**
    *   PonyDiffusionXL requires specific LoRAs and settings.
    *   Using a negative prompt is essential for avoiding style bleeding.
    *   Illustrious models offer better prompt adherence and results out-of-the-box.

**[Is there anything that can help me turn a 2D image into a virtual tool using comfy? I want to generate images of a room and then combine them together for a 360 tour (Score: 4)](https://i.redd.it/m97koadop48f1.jpeg)**
*   **Summary:** A user is asking for solutions to convert a 2D image into a virtual tool for creating 360 tours using ComfyUI.
*   **Emotion:** Neutral Sentiment
*   **Top 3 Points of View:**
    *   I found this website but I aint paying for anything which can be done on open source and to which I vave totall control over
    *   You think client won't see that this is a total ***?

**[Train lora with CPU + GPU? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1lga7ty/train_lora_with_cpu_gpu/)**
*   **Summary:** Users discuss training LoRAs using both CPU and GPU, with a user providing a Colab link as a guide and suggesting how to reduce VRAM consumption.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Train using Flux.
    *   Increase the --blocks\_to\_swap value to 13 to reduce VRAM consumption.
    *   decrease --network\_dim 16 to 4.

**[Missed a shot in my film (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1lgcj9x/missed_a_shot_in_my_film/)**
*   **Summary:** A user is asking for a solution to recreate a missed shot in their film.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Flux kontext + Veo 3 would be the easiest, but probably the most expensive choice too.

**[Is Flux Schnell's architecture inherently inferior than Flux Dev's? (Chroma-related) (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1lg8y6f/is_flux_schnells_architecture_inherently_inferior/)**
*   **Summary:** Users discuss the architectural differences and relative performance of Flux Schnell and Flux Dev models.
*   **Emotion:** Mostly Neutral.
*   **Top 3 Points of View:**
    *   Flux Schnell and Flux Dev are literally identical models architecturally.
    *   Schnell has a superior license.
    *   Flux Schnell's architecture is inferior than Flux Dev's

**[How to train an ai image model? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1lgbrxy/how_to_train_an_ai_image_model/)**
*   **Summary:** A user is asking for guidance on training an AI image model.
*   **Emotion:** Mostly Neutral.
*   **Top 3 Points of View:**
    *   A user provides links to guides on Civitai.
    *   A user asks about the kind of hardware they have.

**[Wan 2.1 on a 16gb card (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1lgdf18/wan_21_on_a_16gb_card/)**
*   **Summary:** A user is asking about running Wan 2.1 on a 16gb card.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   who knows.

**[How are these Fake Instagrammer videos created? (Score: 0)](https://www.reddit.com/gallery/1lg9n95)**
*   **Summary:** Users discuss how fake Instagrammer videos are created, with one suggesting the use of Veo 3.
*   **Emotion:** Mostly Neutral.
*   **Top 3 Points of View:**
    *   Veo 3 is likely being used.
    *   The videos are poorly made.

**[Most Photorealistic Model WITH LoRA compatibility? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lgb0ln/most_photorealistic_model_with_lora_compatibility/)**
*   **Summary:** A user is asking about the most photorealistic model with LoRA compatibility.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Flux pro ultra is available only via API.
    *   I have never used Flux Ultra. Are you sure it is not possible to train LoRAs for that model?
