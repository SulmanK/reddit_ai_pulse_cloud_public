---
title: "Data Engineering Subreddit"
date: "2025-06-28"
description: "Analysis of top discussions and trends in the dataengineering subreddit"
tags: ["data engineering", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions
1.  [[D] What is happening in the Swedish job market right now?](https://www.reddit.com/r/dataengineering/comments/1lm5zle/what_is_happening_in_the_swedish_job_market_right/) (Score: 69)
    *   Discusses the state of the data engineering job market in Sweden, including the need for Swedish language skills and the rise of hybrid/in-office positions.
2.  [Semantic layer vs Semantic model](https://www.reddit.com/r/dataengineering/comments/1lmdw0p/semantic_layer_vs_semantic_model/) (Score: 44)
    *   Compares and contrasts semantic layers and semantic models, discussing their purpose, components, and relationship to business logic and data governance.
3.  [Will DuckLake overtake Iceberg?](https://www.reddit.com/r/dataengineering/comments/1lmmhz4/will_ducklake_overtake_iceberg/) (Score: 36)
    *   Asks whether DuckLake will become more popular than Iceberg, focusing on its suitability for the DuckDB ecosystem, handling of large datasets, and support from other engines.
4.  [Comparison of modern CDC tools Debezium vs Estuary Flow](https://dataheimer.substack.com/p/the-ultimate-guide-to-change-data) (Score: 24)
    *   A link to an article that discusses CDC tools.
5.  [Looking for an alternative to BigQuery/DataFlow](https://www.reddit.com/r/dataengineering/comments/1lmj0fq/looking_for_an_alternative_to_bigquerydataflow/) (Score: 15)
    *   Seeks alternatives to BigQuery/DataFlow due to high data volume, and offers cost reduction strategies within BigQuery, slot reservations and ClickHouse.
6.  [How do you deal with (and remember) all the jargon?](https://www.reddit.com/r/dataengineering/comments/1lmoulq/how_do_you_deal_with_and_remember_all_the_jargon/) (Score: 13)
    *   Discusses strategies for learning and remembering data engineering jargon, including looking up terms, using ChatGPT, and focusing on practical application.
7.  [Fast spatial query db?](https://www.reddit.com/r/dataengineering/comments/1lm7j6u/fast_spatial_query_db/) (Score: 12)
    *   Asks for recommendations on fast spatial query databases, with suggestions including DuckDB, Postgres/PostGIS, and Apache Sedona.
8.  [Best use of spare time in company](https://www.reddit.com/r/dataengineering/comments/1lmj6lf/best_use_of_spare_time_in_company/) (Score: 12)
    *   Seeks advice on how to best utilize spare time at work, and focuses on mastering tools, automation, and learning new skills such as CI/CD, Databricks, containers, and cloud technologies.
9.  [Prefect Self-Hosted Server?](https://www.reddit.com/r/dataengineering/comments/1lm5s13/prefect_selfhosted_server/) (Score: 10)
    *   Inquires about using a self-hosted Prefect server, with users sharing their experiences with Windows setups and suggesting Prefect Cloud as an alternative.
10. [Wanting to copy csv files from SharePoint to Azure Blob storage](https://www.reddit.com/r/dataengineering/comments/1lmaqrx/wanting_to_copy_csv_files_from_sharepoint_to/) (Score: 8)
    *   Asks about copying CSV files from SharePoint to Azure Blob storage. Data Factory and Logic Apps are recommended.
11. [Best way to schedule python job in azure](https://www.reddit.com/r/dataengineering/comments/1lm44es/best_way_to_schedule_python_job_in_azure/) (Score: 7)
    *   Seeks recommendations on the best way to schedule Python jobs in Azure, Azure Functions with schedule triggers is suggested.
12. [When did conda-forge start to carry PySpark](https://www.reddit.com/r/dataengineering/comments/1lm69l1/when_did_condaforge_start_to_carry_pyspark/) (Score: 4)
    *   Discusses PySpark with suggestions to avoid using Conda and use a Docker container.
13. [Considering a Career Move to Ireland: Master's in Data Analytics – Need Insights](https://www.reddit.com/r/dataengineering/comments/1lmpbzs/considering_a_career_move_to_ireland_masters_in/) (Score: 4)
    *   Discusses career move to Ireland, housing issues and job market.
14. [S3 catalogue options](https://www.reddit.com/r/dataengineering/comments/1lmgcgr/s3_catalogue_options/) (Score: 3)
    *   Seeks options for cataloging S3 data. Open Metadata, Amundsen, Datahub and Glue Catalog are suggested.
15. [dbt Cloud w/o deployments?](https://www.reddit.com/r/dataengineering/comments/1lmd9m4/dbt_cloud_wo_deployments/) (Score: 2)
    *   Asks about using dbt Cloud without deployments, with suggestions to use the zero copy DBT clone feature.
16. [How to set up open data lakehouse using Spark, External HIve Metastore and S3?](https://www.reddit.com/r/dataengineering/comments/1lmmqc0/how_to_set_up_open_data_lakehouse_using_spark/) (Score: 2)
    *   Asks how to set up open data lakehouse using Spark. Suggests that issue is that Iceberg is trying to write locally because it thinks the table isn’t backed by S3.
17. [AWS vs Azure vs GCP](https://www.reddit.com/r/dataengineering/comments/1lmu9g6/aws_vs_azure_vs_gcp/) (Score: 2)
    *   A discussion on different Cloud Providers.
18. [CSV transformation into Postgres datatables using Python confusion (beginner-intermediate) question](https://www.reddit.com/r/dataengineering/comments/1lmp4gd/csv_transformation_into_postgres_datatables_using/) (Score: 1)
    *   Discusses transforming CSV data into Postgres datatables using Python.

# Detailed Analysis by Thread
**[[D] What is happening in the Swedish job market right now? (Score: 69)](https://www.reddit.com/r/dataengineering/comments/1lm5zle/what_is_happening_in_the_swedish_job_market_right/)**
*   **Summary:** The thread discusses the current state of the data engineering job market in Sweden. Topics include whether speaking Swedish is a requirement, which companies are hiring, compensation, and the prevalence of hybrid or in-office work arrangements. A hiring manager in Sweden provided advice on focusing on building solid skills and experience.
*   **Emotion:** The overall emotional tone is Positive. A hiring manager is congratulating someone on getting a job.
*   **Top 3 Points of View:**
    *   It is necessary to speak Swedish to get a job.
    *   Norway is booming a bit and lots of talent is needed in oil & gas there.
    *   Bigger companies are willing to bet on junior talent, but smaller companies still won't generally.

**[Semantic layer vs Semantic model (Score: 44)](https://www.reddit.com/r/dataengineering/comments/1lmdw0p/semantic_layer_vs_semantic_model/)**
*   **Summary:**  This thread explores the differences between semantic layers and semantic models. It defines them, explains their purpose, and outlines their core components. Key distinctions include the semantic model being a conceptual blueprint, while the semantic layer is the functional implementation.
*   **Emotion:** The overall emotional tone is Neutral. Most comments provide definitions.
*   **Top 3 Points of View:**
    *   Semantic Model: Conceptual Blueprint, The "What" and "How." Semantic Layer: Functional Implementation, The "Serving" Layer.
    *   Semantic layer will generally be logical layer(driven by views), which will have all sorts of joins and aggregation between different tables.
    *   It is another fake word to get people to spend more money on their computers and the people who maintain their computers.

**[Will DuckLake overtake Iceberg? (Score: 36)](https://www.reddit.com/r/dataengineering/comments/1lmmhz4/will_ducklake_overtake_iceberg/)**
*   **Summary:**  The discussion revolves around whether DuckLake will surpass Iceberg as the preferred technology. Participants discuss DuckLake's suitability for the DuckDB ecosystem, its ability to handle large data volumes, and its adoption by other engines like Snowflake, Trino, and Spark.
*   **Emotion:** The overall emotional tone is Neutral. Most comments were making comparisons between DuckLake and Iceberg.
*   **Top 3 Points of View:**
    *   If you’re in the duckdb ecosystem or want that ecosystem, use ducklake. If you’re not using duckdb… then ducklake doesn’t seem to make sense.
    *   How it handles large data volume (they said they tested on a petabyte dataset with no issues) and adoption by other engines will really be its test.
    *   Iceberg already has different ways to implement catalogs and data files, and metadata will so be written in parquet.

**[Comparison of modern CDC tools Debezium vs Estuary Flow (Score: 24)](https://dataheimer.substack.com/p/the-ultimate-guide-to-change-data)**
*   **Summary:**  This thread is a link to an article.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   N/A

**[Looking for an alternative to BigQuery/DataFlow (Score: 15)](https://www.reddit.com/r/dataengineering/comments/1lmj0fq/looking_for_an_alternative_to_bigquerydataflow/)**
*   **Summary:**  The thread discusses alternatives to BigQuery/DataFlow for handling large data volumes. Participants suggest exploring cost reduction strategies within BigQuery, such as slot reservations, capacity pricing, and ClickHouse.
*   **Emotion:** The overall emotional tone is Positive. Some helpful suggestions.
*   **Top 3 Points of View:**
    *   Before switching to a new tech which gives overhead and has opportunity cost (not building features) you should look into reducing your massiv waste there.
    *   Have you already explored any cost reduction strategies within BigQuery before deciding to replatform?
    *   Before you reengineer, look at slot reservations.

**[How do you deal with (and remember) all the jargon? (Score: 13)](https://www.reddit.com/r/dataengineering/comments/1lmoulq/how_do_you_deal_with_and_remember_all_the_jargon/)**
*   **Summary:**  The thread discusses how data engineers deal with and remember the extensive jargon in the field. It suggests looking up terms when needed, using resources like ChatGPT, and focusing on understanding the concepts rather than memorizing definitions.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   Everyone is looking up terms they don’t know all the time.
    *   Jargons are needed to be polished only when we are preparing for interviews.
    *   There is more value in communication skill and knowing jargon than technical skill.

**[Fast spatial query db? (Score: 12)](https://www.reddit.com/r/dataengineering/comments/1lm7j6u/fast_spatial_query_db/)**
*   **Summary:**  The thread asks for recommendations on fast spatial query databases. Participants suggest DuckDB, Postgres/PostGIS, and Spark with Apache Sedona, depending on the scale and performance requirements.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   DuckDB and Postgres with the PostGIS extensions are the best geospatial databases out there.
    *   Postgres with PostGIS extension works very well for gis data.
    *   It depends on the scale and what performance you need.

**[Best use of spare time in company (Score: 12)](https://www.reddit.com/r/dataengineering/comments/1lmj6lf/best_use_of_spare_time_in_company/)**
*   **Summary:** The thread explores how to best utilize spare time at work. Participants suggest mastering the tools they use, learning about CI/CD, Databricks, containers, and cloud technologies. Some also focus on automation, monitoring, and documentation.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   Go play some video games and grab a beer or two the closer it gets to 5.
    *   Id suggest mastering the tools you use, then about cicd, databricks, containers (docker and kubernetes).
    *   Learn more about data pipelines, data architectures, solid CI/CD and GitOps/DevOps practices, and some good software engineering skills.

**[Prefect Self-Hosted Server? (Score: 10)](https://www.reddit.com/r/dataengineering/comments/1lm5s13/prefect_selfhosted_server/)**
*   **Summary:**  The thread discusses the use of a self-hosted Prefect server. Participants share their experiences with Windows setups and suggest Prefect Cloud as an alternative due to authentication issues with the self-hosted version.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   I run it on a windows box. It works great.
    *   We ended up using Prefect Cloud’s free version though since self-hosted was missing auth.

**[Wanting to copy csv files from SharePoint to Azure Blob storage (Score: 8)](https://www.reddit.com/r/dataengineering/comments/1lmaqrx/wanting_to_copy_csv_files_from_sharepoint_to/)**
*   **Summary:**  The thread asks for advice on copying CSV files from SharePoint to Azure Blob storage. Participants suggest using Data Factory and Logic Apps.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   I would suggest Logic App: 1 Trigger and a couple of Actions and the job is done.
    *   Use a Web activity in data factory to call the Microsoft graph api endpoint with your share point tenent site to return the site Id.

**[Best way to schedule python job in azure (Score: 7)](https://www.reddit.com/r/dataengineering/comments/1lm44es/best_way_to_schedule_python_job_in_azure/)**
*   **Summary:** The thread seeks recommendations on the best way to schedule Python jobs in Azure. Participants suggest using Azure Functions with a schedule trigger.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   I'd go with an Azure Function using python with a schedule trigger.
    *   Python stored proc in Snowflake? Azure Function with a timer trigger?
    *   I would run it manually as needed and babysit it.

**[When did conda-forge start to carry PySpark (Score: 4)](https://www.reddit.com/r/dataengineering/comments/1lm69l1/when_did_condaforge_start_to_carry_pyspark/)**
*   **Summary:**  The thread discusses PySpark and suggests avoiding Conda by using a Docker container image provided by Apache.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   You can avoid the drag of setting up pyspark entirely by just using a docker container image provided by apache.

**[Considering a Career Move to Ireland: Master's in Data Analytics – Need Insights (Score: 4)](https://www.reddit.com/r/dataengineering/comments/1lmpbzs/considering_a_career_move_to_ireland_masters_in/)**
*   **Summary:** The thread is about a career move to Ireland, Participants discuss housing issues and the job market.
*   **Emotion:** The overall emotional tone is Negative.
*   **Top 3 Points of View:**
    *   In Ireland the university does not matter at all.
    *   It's hard to find affordable housing and the job market for data engineers is quite saturated.

**[S3 catalogue options (Score: 3)](https://www.reddit.com/r/dataengineering/comments/1lmgcgr/s3_catalogue_options/)**
*   **Summary:**  The thread seeks options for cataloging S3 data. Participants suggest Open Metadata, Amundsen, Datahub, and Glue Catalog.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Open Metadata is an open source option
    *   Amundsen and datahub crawl s3 and make stuff searchable.
    *   Have you consider Glue Catalog?

**[dbt Cloud w/o deployments? (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1lmd9m4/dbt_cloud_wo_deployments/)**
*   **Summary:**  The thread asks about using dbt Cloud without deployments, with a suggestion to use the zero copy DBT clone feature.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   The zero copy DBT clone feature allows you to copy prod assets to test at nil cost/time to use in the cicd process.

**[How to set up open data lakehouse using Spark, External HIve Metastore and S3? (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1lmmqc0/how_to_set_up_open_data_lakehouse_using_spark/)**
*   **Summary:** The thread asks how to set up open data lakehouse using Spark. Suggests that issue is that Iceberg is trying to write locally because it thinks the table isn’t backed by S3.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   That error typically means Iceberg is trying to write locally because it thinks the table isn’t backed by S3.

**[AWS vs Azure vs GCP (Score: 2)](https://www.reddit.com/r/dataengineering/comments/1lmu9g6/aws_vs_azure_vs_gcp/)**
*   **Summary:** The thread is a discussion on different Cloud Providers.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Aws - most comprehensive, gcp - most intuitive, azure - most easily integrated with most companies workflows
    *   Focus on the basics and concepts, then pick any cloud, if you want to get very specific just search which one is more requested in your country/region.

**[CSV transformation into Postgres datatables using Python confusion (beginner-intermediate) question (Score: 1)](https://www.reddit.com/r/dataengineering/comments/1lmp4gd/csv_transformation_into_postgres_datatables_using/)**
*   **Summary:**  The thread discusses transforming CSV data into Postgres datatables using Python.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   I think what you need is a surrogate key.
    *   The pattern of “match to an existing id or if it doesn’t exist, create it” is called “upsert”.

