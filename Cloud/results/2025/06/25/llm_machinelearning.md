---
title: "Machine Learning Subreddit"
date: "2025-06-25"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machine learning", "AI", "research"]
---

# Overall Ranking and Top Discussions
1.  [[D] ICCV 2025 Results Discussion](https://www.reddit.com/r/MachineLearning/comments/1lk38sf/d_iccv_2025_results_discussion/) (Score: 44)
    *   Users discuss their experiences and outcomes with the ICCV 2025 conference submissions, sharing their scores and acceptance/rejection statuses.
2.  [[D] Extremely low(<0.2) train/val loss after 1.96 billion tokens when pretraining GPT-2 small](https://www.reddit.com/r/MachineLearning/comments/1ljnfzy/d_extremely_low02_trainval_loss_after_196_billion/) (Score: 38)
    *   A user is experiencing extremely low train/val loss and seeks advice on potential causes and debugging strategies.
3.  [[R] Is it true that most of AI is just data cleaning and not fancy models?](https://www.reddit.com/r/MachineLearning/comments/1lk71h6/r_is_it_true_that_most_of_ai_is_just_data/) (Score: 36)
    *   The discussion revolves around the importance of data cleaning and preparation in AI projects, and whether it outweighs the significance of complex models.
4.  [[R] OMEGA: Can LLMs Reason Outside the Box in Math?](https://www.reddit.com/r/MachineLearning/comments/1ljsyzg/r_omega_can_llms_reason_outside_the_box_in_math/) (Score: 26)
    *   The discussion centers on the ability of Large Language Models (LLMs) to perform mathematical reasoning and whether they can go beyond familiar skills to discover new reasoning abilities.
5.  [[D] Old school must read papers in the field](https://www.reddit.com/r/MachineLearning/comments/1ljo5c1/d_old_school_must_read_papers_in_the_field/) (Score: 23)
    *   Users recommend classic papers that are considered essential reading for understanding the fundamentals of machine learning, specifically recommending the original Word2vec paper.
6.  [[D] Paperswithcode has been compromised](https://www.reddit.com/r/MachineLearning/comments/1lkedb8/d_paperswithcode_has_been_compromised/) (Score: 23)
    *   The discussion notes that the Paperswithcode website was down for a week.
7.  [[D] Visa sponsorship for AI research roles in America/Europe](https://www.reddit.com/r/MachineLearning/comments/1ljyhny/d_visa_sponsorship_for_ai_research_roles_in/) (Score: 10)
    *   Users discuss the availability of visa sponsorships for AI research positions in America and Europe.
8.  [[D] Do you guy still have access to paperswithcode.com ?](https://www.reddit.com/r/MachineLearning/comments/1lk4m92/d_do_you_guy_still_have_access_to/) (Score: 5)
    *   Users discuss problems accessing paperswithcode.com.
9.  [[D] Why are there no text auto encoders with reconstruction loss as a primary training objective?](https://www.reddit.com/r/MachineLearning/comments/1lkbsic/d_why_are_there_no_text_auto_encoders_with/) (Score: 5)
    *   The discussion revolves around why text autoencoders aren't commonly trained with reconstruction loss as the primary objective.
10. [[D] how much time do you spend designing your ML problem before starting?](https://www.reddit.com/r/MachineLearning/comments/1ljp4cg/d_how_much_time_do_you_spend_designing_your_ml/) (Score: 4)
    *   The discussion is about how much time should be spent designing a machine learning problem before starting.
11. [[D] How to disagree without arguing with a reviewer](https://www.reddit.com/r/MachineLearning/comments/1lkdt1k/d_how_to_disagree_without_arguing_with_a_reviewer/) (Score: 3)
    *   The discussion focuses on strategies for respectfully disagreeing with a reviewer's comments or suggestions during the paper review process.
12. [[D] Thinking of starting an initiative tracing the origin and impact of different ML practices – feedback requested](https://www.reddit.com/r/MachineLearning/comments/1lk9731/d_thinking_of_starting_an_initiative_tracing_the/) (Score: 2)
    *   The discussion is around an initiative to trace the origin and impact of different ML practices and requesting feedback.

# Detailed Analysis by Thread
**[[D] ICCV 2025 Results Discussion (Score: 44)](https://www.reddit.com/r/MachineLearning/comments/1lk38sf/d_iccv_2025_results_discussion/)**
*   **Summary:** Users are sharing their ICCV 2025 paper review scores and outcomes (acceptance/rejection). Many are expressing anticipation and anxiety while awaiting final decisions. There's discussion about rebuttal impact.
*   **Emotion:** The emotional tone is primarily positive, with elements of anxiety and disappointment interspersed. Many express hopefulness and excitement, while others convey frustration or disappointment with rejection.
*   **Top 3 Points of View:**
    *   Sharing review scores and hoping for acceptance.
    *   Expressing frustration with the review system despite seemingly good scores after rebuttal.
    *   Celebrating acceptances and sharing score improvements after rebuttal.

**[[D] Extremely low(<0.2) train/val loss after 1.96 billion tokens when pretraining GPT-2 small (Score: 38)](https://www.reddit.com/r/MachineLearning/comments/1ljnfzy/d_extremely_low02_trainval_loss_after_196_billion/)**
*   **Summary:** A user reports an extremely low training/validation loss after pretraining a GPT-2 small model and is looking for reasons why this might be happening. Suggestions include checking for data leakage, incorrect loss calculations, and issues with padding or masking.
*   **Emotion:** The overall emotional tone is neutral and inquisitive, focused on problem-solving and seeking technical advice.
*   **Top 3 Points of View:**
    *   Suggesting the problem might be an error in the training loop, such as incorrect application of the causal mask or not shifting training labels correctly.
    *   Suggesting that the crossentropy loss might be calculated per token and the model is memorizing data.
    *   Recommending checking the generation output of the model to see if it is working correctly.

**[[R] Is it true that most of AI is just data cleaning and not fancy models? (Score: 36)](https://www.reddit.com/r/MachineLearning/comments/1lk71h6/r_is_it_true_that_most_of_ai_is_just_data/)**
*   **Summary:** The thread discusses the claim that data cleaning and preparation are the most crucial aspects of AI, more so than the development of sophisticated models. The conversation covers various perspectives, including the importance of data engineering skills, the distinction between research and engineering roles, and the impact of data quality on model performance.
*   **Emotion:** The overall emotional tone is neutral and informative, with users sharing their experiences and insights into the field.
*   **Top 3 Points of View:**
    *   Data cleaning and preparation are essential for building valid and useful AI models. It's "garbage-in, garbage-out."
    *   Statistical modeling is a small part of the value creating pipeline. Data engineering skills are crucial.
    *   In large companies, data scientists or QA roles often involve extensive data preprocessing.

**[[R] OMEGA: Can LLMs Reason Outside the Box in Math? (Score: 26)](https://www.reddit.com/r/MachineLearning/comments/1ljsyzg/r_omega_can_llms_reason_outside_the_box_in_math/)**
*   **Summary:** The discussion revolves around a research paper (OMEGA) investigating the ability of LLMs to reason outside the box in mathematical problem-solving. The discussion highlights limitations in current RL approaches, specifically difficulties in integrating individual skills into flexible reasoning policies.
*   **Emotion:** The emotional tone is primarily neutral, focusing on analysis and critical evaluation of LLM capabilities.
*   **Top 3 Points of View:**
    *   Questioning why this is a question, given AlphaZero's ability to discover new approaches in games.
    *   Agreeing with the paper's findings that LLMs struggle with complex reasoning chains, often spiraling into errors.
    *   LLMs are effective at optimizing for well-scoped, atomic skills but struggle to induce flexible reasoning policies that generalize across skill boundaries.

**[[D] Old school must read papers in the field (Score: 23)](https://www.reddit.com/r/MachineLearning/comments/1ljo5c1/d_old_school_must_read_papers_in_the_field/)**
*   **Summary:** The discussion suggests reading the original Word2vec paper to build a strong intuition about embeddings.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   The original Word2vec paper is recommended reading to build a strong intuition about embeddings.

**[[D] Paperswithcode has been compromised (Score: 23)](https://www.reddit.com/r/MachineLearning/comments/1lkedb8/d_paperswithcode_has_been_compromised/)**
*   **Summary:** The discussion notes that the Paperswithcode website was down for a week.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   The website was down for a week.

**[[D] Visa sponsorship for AI research roles in America/Europe (Score: 10)](https://www.reddit.com/r/MachineLearning/comments/1ljyhny/d_visa_sponsorship_for_ai_research_roles_in/)**
*   **Summary:** The thread discusses the feasibility of obtaining visa sponsorship for AI research roles in the US and Europe. It suggests that while competitive, sponsorship is possible for highly qualified candidates.
*   **Emotion:** The overall emotional tone is neutral, with a mix of hope and realism.
*   **Top 3 Points of View:**
    *   Visa sponsorship is readily available for top-tier AI researchers, as companies are willing to go to great lengths to secure their talent.
    *   While companies will sponsor talented individuals, they naturally prefer candidates who do not require visa sponsorship due to the added hassle.
    *   If you have an offer from a company in the level of openAI/anthropic visa will never be a problem for you.

**[[D] Do you guy still have access to paperswithcode.com ? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1lk4m92/d_do_you_guy_still_have_access_to/)**
*   **Summary:** Users discuss their problems accessing paperswithcode.com.
*   **Emotion:** Negative
*   **Top 3 Points of View:**
    *   Users are having gateway issues.

**[[D] Why are there no text auto encoders with reconstruction loss as a primary training objective? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1lkbsic/d_why_are_there_no_text_auto_encoders_with/)**
*   **Summary:** The thread explores the reasons behind the lack of text autoencoders trained primarily with reconstruction loss. The discussion mentions limitations of representing semantic information in a single vector and the triviality of the task with full attentional observability.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   The idea of encoding text into a single vector and then decoding related text was how the first machine translation models worked.
    *   Autoencoders with full attentional observability of the target learn nothing.
    *   BERT is similar to autoencoders.

**[[D] how much time do you spend designing your ML problem before starting? (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1ljp4cg/d_how_much_time_do_you_spend_designing_your_ml/)**
*   **Summary:** The thread discusses how much time should be spent designing a machine learning problem before starting. It mentions the design part is the most significant part nowdays
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   The best bang for the buck is to hit the ground running and keep iterating.
    *   The design part of an LLM is the most significant part nowadays.
    *   For more routine or well-specified projects, design time is much higher leverage.

**[[D] How to disagree without arguing with a reviewer (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1lkdt1k/d_how_to_disagree_without_arguing_with_a_reviewer/)**
*   **Summary:** This thread is about how to disagree with a reviewer politely without arguing, bringing a good argument, or adding a bit of explanation/clarification somewhere in the paper.
*   **Emotion:** Neutral
*   **Top 3 Points of View:**
    *   Putting the requested information in the appendix might be a good middle ground.
    *   Seek clarification by explaining what you understand is the point of the reviewer's request and why you chose not to address it in the initial submission.
    *   Add a small bit of explanation/clarification somewhere in the paper.

**[[D] Thinking of starting an initiative tracing the origin and impact of different ML practices – feedback requested (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1lk9731/d_thinking_of_starting_an_initiative_tracing_the/)**
*   **Summary:** The discussion is around an initiative to trace the origin and impact of different ML practices and requesting feedback.
*   **Emotion:** Positive
*   **Top 3 Points of View:**
    *   P values and confidence intervals are easy to abuse/misuse/misunderstand.
