---
title: "Singularity Subreddit"
date: "2025-06-18"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "Technology"]
---

# Overall Ranking and Top Discussions
1.  [✂️ Sam Altman says that Zuckerberg is making huge offers ($100 million salary + $100 million bonus) to some OpenAI Researchers](https://youtube.com/clip/UgkxPx-piHuWB8lBgztLZ-sQDy0LbLjLP3Tz?si=U5bnDkYlOWwyc5-v) (Score: 2442)
    *   The discussion revolves around Sam Altman's statement about Zuckerberg offering large sums of money to OpenAI researchers.
2.  [Pray to *** that xAI doesn't achieve AGI first. This is NOT a "political sides" issue and should alarm every single researcher out there.](https://i.redd.it/9uuj7d54ep7f1.png) (Score: 2357)
    *   This thread discusses concerns about xAI achieving AGI first, particularly focusing on the perceived biases and potential negative consequences.
3.  [Pope Leo makes 'AI’s threat to humanity' a signature issue](https://techcrunch.com/2025/06/18/pope-leo-makes-ais-threat-to-humanity-a-signature-issue/) (Score: 423)
    *   Users are talking about Pope Leo making AI's threat to humanity a signature issue.
4.  [Sam says there's a chance that even if they build a legitimate Superintelligence, it wouldn't make the world much better or it wouldn't change the world much as we expect.](https://v.redd.it/uwk8non9zk7f1) (Score: 328)
    *   The conversation centers on Sam's statement about superintelligence potentially not significantly improving the world, with users debating the implications and likelihood of this scenario.
5.  [MiniMax introduces M1: SOTA open weights model with 1M context length beating R1 in pricing](https://www.reddit.com/gallery/1leesej) (Score: 145)
    *   A new open-weight model, M1 by MiniMax, is being introduced, with users discussing its performance, pricing, and potential uses.
6.  [A pessimistic reading of how much progress OpenAI has made internally](https://www.reddit.com/r/singularity/comments/1lem32a/a_pessimistic_reading_of_how_much_progress_openai/) (Score: 120)
    *   This thread discusses a pessimistic view on the internal progress of OpenAI, specifically regarding the development and capabilities of GPT models.
7.  [Shift Bioscience’s CEO: We are the company, that does whatever it takes so that at some point in the future you getting better each day, getting younger](https://v.redd.it/047bf3p7no7f1) (Score: 103)
    *   The discussion revolves around Shift Bioscience's CEO's claims about making people younger.
8.  [Remember when LLMs were derided as "Stochastic Parrots"? Opus 4.0 single-shot this parody rebuke paper](https://ai.vixra.org/pdf/2506.0065v1.pdf) (Score: 89)
    *   The conversation centers around Opus 4.0 single-shotting a parody rebuke paper.
9.  [Scientists once hoarded pre-nuclear steel, and now we’re hoarding pre-AI content | Ars Technica](https://i.redd.it/ei1dgsa99o7f1.jpeg) (Score: 80)
    *   The thread discusses the idea of hoarding pre-AI content, drawing a parallel to scientists hoarding pre-nuclear steel, and debating the value and implications of such a practice.
10. [I find things like this a bit funny to look at after apple's paper on thinking in LLMs](https://i.redd.it/gu5pudkxjl7f1.jpeg) (Score: 54)
    *   Users are discussing a paper from Apple and how it relates to LLMs.
11. [Sam Altman on AGI, GPT-5, and what’s next — the OpenAI Podcast Ep. 1](https://www.youtube.com/watch?v=DB9mjd-65gw) (Score: 52)
    *   This thread is about Sam Altman's discussion on AGI, GPT-5, and future plans in the OpenAI Podcast.
12. ["We find that AI models can accurately guide users through the recovery of live poliovirus."](https://i.redd.it/62v8i6p0qp7f1.png) (Score: 46)
    *   The discussion revolves around AI models being able to guide users through the recovery of live poliovirus.
13. [Google's Gemini panicked when playing Pokémon | Gemini 2.5 Pro gets into various situations which cause the model to simulate ‘panic,’” the report says.](https://techcrunch.com/2025/06/17/googles-gemini-panicked-when-playing-pokemon/) (Score: 40)
    *   The conversation discusses Google's Gemini panicking when playing Pokémon.
14. [Cells assembled into Anthrobots become biologically younger](https://www.reddit.com/r/singularity/comments/1leihnl/cells_assembled_into_anthrobots_become/) (Score: 27)
    *   The thread discusses cells assembled into anthrobots becoming biologically younger.
15. [NAACP planning to sue Musk AI company over supercomputer pollution](https://thehill.com/policy/technology/5355641-naacp-planning-to-sue-musk-ai-company-over-supercomputer-pollution/) (Score: 19)
    *   The conversation centers on the NAACP planning to sue Musk's AI company over supercomputer pollution.
16. [drop your agi.safe saturation date bets](https://i.redd.it/c65x9bljfq7f1.png) (Score: 7)
    *   Users are betting on a date for AGI.safe saturation.
17. [Microsoft CEO Admits That AI Is Generating Basically No Value](https://futurism.com/microsoft-ceo-ai-generating-no-value) (Score: 0)
    *   The thread discusses Microsoft CEO admitting that AI is generating basically no value.

# Detailed Analysis by Thread
**[✂️ Sam Altman says that Zuckerberg is making huge offers ($100 million salary + $100 million bonus) to some OpenAI Researchers (Score: 2442)](https://youtube.com/clip/UgkxPx-piHuWB8lBgztLZ-sQDy0LbLjLP3Tz?si=U5bnDkYlOWwyc5-v)**
*  **Summary:** The thread discusses Sam Altman's statement about Zuckerberg offering large salaries and bonuses to OpenAI researchers.
*  **Emotion:** The emotional tone is primarily Neutral, with some Positive sentiment related to respect for researchers who declined the offers.
*  **Top 3 Points of View:**
    *   Zuckerberg is seen as desperate to acquire AI talent.
    *   Researchers who declined the offers are viewed as believing in OpenAI's mission.
    *   The offered compensation is perceived as insignificant for a company like Meta.

**[Pray to *** that xAI doesn't achieve AGI first. This is NOT a "political sides" issue and should alarm every single researcher out there. (Score: 2357)](https://i.redd.it/9uuj7d54ep7f1.png)**
*  **Summary:** This thread discusses concerns about xAI achieving AGI first, focusing on the perceived biases and potential negative consequences.
*  **Emotion:** The overall emotional tone is Neutral, with some Positive sentiments expressing hope that AGI would seek the truth.
*  **Top 3 Points of View:**
    *   xAI is building an AI that panders to its own biases.
    *   It's unlikely that xAI will achieve AGI first.
    *   Teaching false information will poison AGI.

**[Pope Leo makes 'AI’s threat to humanity' a signature issue (Score: 423)](https://techcrunch.com/2025/06/18/pope-leo-makes-ais-threat-to-humanity-a-signature-issue/)**
*  **Summary:** Users are talking about Pope Leo making AI's threat to humanity a signature issue.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Big tech companies are lobbying the Pope.
    *   We should address current threats that humanity poses to humans first.
    *   Pope Leo is making AI's threat to humanity a signature issue.

**[Sam says there's a chance that even if they build a legitimate Superintelligence, it wouldn't make the world much better or it wouldn't change the world much as we expect. (Score: 328)](https://v.redd.it/uwk8non9zk7f1)**
*  **Summary:** The conversation centers on Sam's statement about superintelligence potentially not significantly improving the world, with users debating the implications and likelihood of this scenario.
*  **Emotion:** Mostly Neutral, with some Negative sentiments.
*  **Top 3 Points of View:**
    *   It depends on whether or not the Superintelligence has agency out of itself.
    *   Superintelligence will be used by every company globally instead of human workers.
    *   An ASI which, in its full capacity, is only accessible to very few people would obviously only have a limited impact on things.

**[MiniMax introduces M1: SOTA open weights model with 1M context length beating R1 in pricing (Score: 145)](https://www.reddit.com/gallery/1leesej)**
*  **Summary:** A new open-weight model, M1 by MiniMax, is being introduced, with users discussing its performance, pricing, and potential uses.
*  **Emotion:** The emotional tone is generally Neutral, with some Positive sentiment.
*  **Top 3 Points of View:**
    *   M1 is as good as the original R1.
    *   Long context is an area where open source actually has a lot of great ideas, papers and prototypes on.
    *   Users are waiting for LMArena and LiveBench results before making a decision.

**[A pessimistic reading of how much progress OpenAI has made internally (Score: 120)](https://www.reddit.com/r/singularity/comments/1lem32a/a_pessimistic_reading_of_how_much_progress_openai/)**
*  **Summary:** This thread discusses a pessimistic view on the internal progress of OpenAI, specifically regarding the development and capabilities of GPT models.
*  **Emotion:** The overall tone is Neutral.
*  **Top 3 Points of View:**
    *   GPT-5 will be the first foundation model OpenAI has released that will have been trained from the ground up with RL/self-supervised learning.
    *   The Wall is Here
    *   AGI is cancelled, get back to work

**[Shift Bioscience’s CEO: We are the company, that does whatever it takes so that at some point in the future you getting better each day, getting younger (Score: 103)](https://v.redd.it/047bf3p7no7f1)**
*  **Summary:** The discussion revolves around Shift Bioscience's CEO's claims about making people younger.
*  **Emotion:** Predominantly Neutral.
*  **Top 3 Points of View:**
    *   The super fast, hypersonic method - Fix food
    *   BS
    *   I watched the whole 'interview' and I still don't know what to make of his claims.

**[Remember when LLMs were derided as "Stochastic Parrots"? Opus 4.0 single-shot this parody rebuke paper (Score: 89)](https://ai.vixra.org/pdf/2506.0065v1.pdf)**
*  **Summary:** The conversation centers around Opus 4.0 single-shotting a parody rebuke paper.
*  **Emotion:** Generally Neutral, with some Positive reactions to the paper.
*  **Top 3 Points of View:**
    *   There is a hierarchy of levels for parroting.
    *   Opus wrote that?
    *   I for one am perfectly satisfied with a stochastic parrot what solves cancer, FTL, poverty and climate change.

**[Scientists once hoarded pre-nuclear steel, and now we’re hoarding pre-AI content | Ars Technica (Score: 80)](https://i.redd.it/ei1dgsa99o7f1.jpeg)**
*  **Summary:** The thread discusses the idea of hoarding pre-AI content, drawing a parallel to scientists hoarding pre-nuclear steel, and debating the value and implications of such a practice.
*  **Emotion:** Mostly Neutral.
*  **Top 3 Points of View:**
    *   Some types of non-contaminated steel can be used for special applications in the future.
    *   Is pre-AI content really that valuable?
    *   Synthetic data is fine.

**[I find things like this a bit funny to look at after apple's paper on thinking in LLMs (Score: 54)](https://i.redd.it/gu5pudkxjl7f1.jpeg)**
*  **Summary:** Users are discussing a paper from Apple and how it relates to LLMs.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Google models were not included in Apple's report.
    *   The paper had a click-bait title that made many people misunderstand it.
    *   They are taking about thinking in a different way than Apple was in its paper.

**[Sam Altman on AGI, GPT-5, and what’s next — the OpenAI Podcast Ep. 1 (Score: 52)](https://www.youtube.com/watch?v=DB9mjd-65gw)**
*  **Summary:** This thread is about Sam Altman's discussion on AGI, GPT-5, and future plans in the OpenAI Podcast.
*  **Emotion:** Overall emotional tone is Neutral with some Positive sentiment.
*  **Top 3 Points of View:**
    *   Tech CEOs are lying about AGI.
    *   Sam is such a force of light for the world
    *   I really like his stance on ads.

**["We find that AI models can accurately guide users through the recovery of live poliovirus." (Score: 46)](https://i.redd.it/62v8i6p0qp7f1.png)**
*  **Summary:** The discussion revolves around AI models being able to guide users through the recovery of live poliovirus.
*  **Emotion:** Mixed, with some Negative sentiment due to concerns about AI censorship.
*  **Top 3 Points of View:**
    *   If you're determined, prompt clearly, and can reason through what youre working on with strong common sense, you can iteratively get AI to walk you through almost anything that it has in its training data.
    *   You can do the same with a bit of clever googling. I hate this constant AI censorship battle.
    *   The internet has existed for 30 years and college textbooks longer than that.

**[Google's Gemini panicked when playing Pokémon | Gemini 2.5 Pro gets into various situations which cause the model to simulate ‘panic,’” the report says. (Score: 40)](https://techcrunch.com/2025/06/17/googles-gemini-panicked-when-playing-pokemon/)**
*  **Summary:** The conversation discusses Google's Gemini panicking when playing Pokémon.
*  **Emotion:** The emotional tone is Neutral
*  **Top 3 Points of View:**
    *   Gemini panicked when playing Pokemon.
    *   Gemini is simulating 'panic'.
    *   LLANXIETY

**[Cells assembled into Anthrobots become biologically younger (Score: 27)](https://www.reddit.com/r/singularity/comments/1leihnl/cells_assembled_into_anthrobots_become/)**
*  **Summary:** The thread discusses cells assembled into anthrobots becoming biologically younger.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 2 Points of View:**
    *   I can make a new being from my cells.
    *   This sounds like one of those "lock it in a vault" type discoveries

**[NAACP planning to sue Musk AI company over supercomputer pollution (Score: 19)](https://thehill.com/policy/technology/5355641-naacp-planning-to-sue-musk-ai-company-over-supercomputer-pollution/)**
*  **Summary:** The conversation centers on the NAACP planning to sue Musk's AI company over supercomputer pollution.
*  **Emotion:** Positive due to sharing important information.
*  **Top 3 Points of View:**
    *   They have been running methane turbines year long without a permit.
    *   Something negative in this sub? To the dungeon!
    *   Users are using gifs to show reaction of the topic.

**[drop your agi.safe saturation date bets (Score: 7)](https://i.redd.it/c65x9bljfq7f1.png)**
*  **Summary:** Users are betting on a date for AGI.safe saturation.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    *   Over 80% before 2027
    *   I feel like there's an argument for exponential growth after a certain threshold and in my mind that threshold is 50%.. Just because.
    *   2027

**[Microsoft CEO Admits That AI Is Generating Basically No Value (Score: 0)](https://futurism.com/microsoft-ceo-ai-generating-no-value)**
*  **Summary:** The thread discusses Microsoft CEO admitting that AI is generating basically no value.
*  **Emotion:** Negative
*  **Top 3 Points of View:**
    *   No he doesn't.
    *   futurism.com
    *   this is from feb

