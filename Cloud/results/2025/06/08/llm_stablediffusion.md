---
title: "Stable Diffusion Subreddit"
date: "2025-06-08"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [I dunno how to call this lora, UltraReal - Flux.dev lora](https://www.reddit.com/gallery/1l6inva) (Score: 159)
    *   Discussion about a new LoRA (Low-Rank Adaptation) model called UltraReal, with users praising its realistic output and requesting prompts and workflow details.
2.  [Beneath pyramid secrets - Found footage!](https://v.redd.it/cbixnl9zdq5f1) (Score: 67)
    *   A video showcasing AI-generated found footage related to pyramid secrets. Users discussed the tools used, the quality of the work, and the AI narration.
3.  [Why cant we use 2 GPU's the same way RAM offloading works?](https://www.reddit.com/r/StableDiffusion/comments/1l6j4y9/why_cant_we_use_2_gpus_the_same_way_ram/) (Score: 15)
    *   A discussion about the limitations of using multiple GPUs for Stable Diffusion, explaining why it's not as simple as RAM offloading due to the sequential nature of diffusion models and PCI-E bandwidth limitations.
4.  [Upscaling and adding tons of details with Flux? Similar to "tile" controlnet in SD 1.5](https://www.reddit.com/r/StableDiffusion/comments/1l6hhaz/upscaling_and_adding_tons_of_details_with_flux/) (Score: 3)
    *   Users discussed using a technique similar to "tile" controlnet in SD 1.5 for upscaling and adding details to images, mentioning the use of Flux and low denoising values.
5.  [Where to start to get dimensionally accurate objects?](https://www.reddit.com/r/StableDiffusion/comments/1l6fvko/where_to_start_to_get_dimensionally_accurate/) (Score: 2)
    *   The thread revolves around how to generate dimensionally accurate objects in Stable Diffusion.
6.  [Looking for workflows to test the power of an RTX PRO 6000 96GB](https://www.reddit.com/r/StableDiffusion/comments/1l6ilc7/looking_for_workflows_to_test_the_power_of_an_rtx/) (Score: 2)
    *   A user is seeking workflows to test the capabilities of their RTX PRO 6000 96GB graphics card, particularly in terms of VRAM usage and performance with different Stable Diffusion tasks.
7.  [Slow generate](https://www.reddit.com/r/StableDiffusion/comments/1l6hxxk/slow_generate/) (Score: 1)
    *   Discussion about slow generation speeds in Stable Diffusion, particularly related to using AMD GPUs.
8.  [Papers or reading material on ChatGPT image capabilities?](https://www.reddit.com/r/StableDiffusion/comments/1l6k28o/papers_or_reading_material_on_chatgpt_image/) (Score: 1)
    *   User is asking for resources regarding ChatGPT's image generation process.
9.  [K A J S A ðŸ‡¸ðŸ‡ª](https://i.redd.it/awx1ozrffq5f1.jpeg) (Score: 0)
    *   A user posted an image and another user inquired about the model and checkpoint used to create it.
10. [update workflow] VACE 1.3B multi-traj control is awesome now](https://v.redd.it/u6a3amnmdq5f1) (Score: 0)
    *   A user posted about an updated workflow. Other users consider it spam.
11. [How small prompt changes can completely change your outputs](https://v.redd.it/yke3pc81dr5f1) (Score: 0)
    *   A user attempted to demonstrate how small prompt changes impact outputs, but it seems like the post encountered some issues.
12. [Grit Portrait ðŸ”³ - New Flux LoRA](https://www.reddit.com/gallery/1l6e2xr) (Score: 0)
    *   The thread promotes a new Flux LoRA for generating grit portraits, highlighting its features and providing download links.
13. [How do I achieve such results? Image "generated" via Perplexity](https://www.reddit.com/gallery/1l6fe75) (Score: 0)
    *   A user asks how to achieve similar image generation results as those produced by Perplexity AI.
14. [SD installation, unable to disable path length limit](https://www.reddit.com/r/StableDiffusion/comments/1l6edlz/sd_installation_unable_to_disable_path_length/) (Score: 0)
    *   A user is experiencing issues with disabling the path length limit during Stable Diffusion installation and is seeking advice on how to resolve it.

# Detailed Analysis by Thread
**[I dunno how to call this lora, UltraReal - Flux.dev lora (Score: 159)](https://www.reddit.com/gallery/1l6inva)**
*   **Summary:** The post introduces a new LoRA model called UltraReal, designed for generating realistic images. Users express admiration for the results and request information about the prompts and workflow used to create them.
*   **Emotion:** The overall emotional tone is overwhelmingly Positive. There's excitement and appreciation for the realistic images generated by the UltraReal LoRA.
*   **Top 3 Points of View:**
    *   The UltraReal LoRA produces impressive, realistic images.
    *   Users are eager to learn the prompts and workflow used to create the showcased images.
    *   Some users compare the aesthetic to photos from older iPhones or specific styles like Mirror's Edge.

**[Beneath pyramid secrets - Found footage! (Score: 67)](https://v.redd.it/cbixnl9zdq5f1)**
*   **Summary:** This thread features a video presenting "found footage" related to pyramid secrets, generated using AI. The discussion revolves around the video's quality, the tools used in its creation, and critiques of the AI narration.
*   **Emotion:** The overall emotional tone is mixed, with both Positive and Neutral sentiments. Some users express amazement and love for the content, while others are critical of the AI narration and watermark.
*   **Top 3 Points of View:**
    *   The video is a creative and well-executed piece of AI-generated content.
    *   The AI narration detracts from the experience for some viewers.
    *   The prominent watermark is distracting and hinders enjoyment.

**[Why cant we use 2 GPU's the same way RAM offloading works? (Score: 15)](https://www.reddit.com/r/StableDiffusion/comments/1l6j4y9/why_cant_we_use_2_gpus_the_same_way_ram/)**
*   **Summary:** This thread explains why using multiple GPUs for Stable Diffusion is not as straightforward as RAM offloading. It highlights the sequential nature of diffusion models and the limitations of PCI-E bandwidth on consumer motherboards.
*   **Emotion:** The overall emotional tone is Neutral. The discussion is primarily technical and informative, aiming to explain the limitations and complexities of multi-GPU setups for Stable Diffusion.
*   **Top 3 Points of View:**
    *   RAM offloading primarily speeds up model loading and doesn't directly enhance processing.
    *   Diffusion models are sequential, limiting the benefits of using multiple GPUs for a single image.
    *   NVLink or IF are required for proper multi-GPU utilization, but are typically unavailable on consumer cards.

**[Upscaling and adding tons of details with Flux? Similar to "tile" controlnet in SD 1.5 (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1l6hhaz/upscaling_and_adding_tons_of_details_with_flux/)**
*   **Summary:** The discussion centers on techniques for upscaling and adding details to images, specifically using Flux and comparing it to "tile" controlnet in Stable Diffusion 1.5.
*   **Emotion:** The overall emotional tone is Positive, with users sharing successful methods and expressing positive experiences with Flux.
*   **Top 3 Points of View:**
    *   Using a mixture of diffusers with low denoising values (up to 0.3) can effectively upscale images.
    *   Flux is effective at "sticking" to the image during upscaling, which led to the release of Flux Fill for inpainting.
    *   This method can achieve awesome results without controlnets.

**[Where to start to get dimensionally accurate objects? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1l6fvko/where_to_start_to_get_dimensionally_accurate/)**
*   **Summary:** This thread asks for guidance on how to generate dimensionally accurate objects using Stable Diffusion.
*   **Emotion:** The overall emotional tone is Positive.
*   **Top 3 Points of View:**
    *   Start with a generic image.
    *   Use inpainting for smaller corrections.
    *   LoRA is overkill unless the product has a very specific vibe.

**[Looking for workflows to test the power of an RTX PRO 6000 96GB (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1l6ilc7/looking_for_workflows_to_test_the_power_of_an_rtx/)**
*   **Summary:** A user seeks recommendations for workflows that can effectively utilize the capabilities of an RTX PRO 6000 96GB graphics card for Stable Diffusion tasks.
*   **Emotion:** The overall emotional tone is Neutral, with a focus on providing technical recommendations.
*   **Top 3 Points of View:**
    *   The RTX PRO 6000 offers a dramatically larger batch size and super efficiency.
    *   Workflows like Skyreels DF can push VRAM usage to its limits.
    *   High-resolution LoRA training and non-CausVid workflows are also good options.

**[Slow generate (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1l6hxxk/slow_generate/)**
*   **Summary:** This thread discusses the issue of slow generation speeds in Stable Diffusion, particularly when using AMD GPUs.
*   **Emotion:** The overall emotional tone is Negative due to users having problems with slow speeds using AMD cards.
*   **Top 3 Points of View:**
    *   Using AMD for SD is difficult.
    *   Nvidia cards have fewer issues.
    *   Running SD without issues on Nvidia is considered lucky.

**[Papers or reading material on ChatGPT image capabilities? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1l6k28o/papers_or_reading_material_on_chatgpt_image/)**
*   **Summary:** A user is requesting reading material or papers about ChatGPT image capabilities.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   ChatGPT uses its LLM skills to communicate with Dallee.
    *   ChatGPT gives the prompt and Dallee creates the image.
    *   User suggests asking ChatGPT what prompt was sent.

**[K A J S A ðŸ‡¸ðŸ‡ª (Score: 0)](https://i.redd.it/awx1ozrffq5f1.jpeg)**
*   **Summary:** A user posted an image. A second user asked which model and checkpoint were used.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   N/A. Only one viewpoint was made.

**[[update workflow] VACE 1.3B multi-traj control is awesome now (Score: 0)](https://v.redd.it/u6a3amnmdq5f1)**
*   **Summary:** A user shares an updated workflow. Other users claim it's spam.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   The original poster thinks their workflow is awesome.
    *   Other users think it is spam.
    *   There are concerns that the link leads to a dodgy sign-up site.

**[How small prompt changes can completely change your outputs (Score: 0)](https://v.redd.it/yke3pc81dr5f1)**
*   **Summary:** A user attempted to demonstrate how small prompt changes can completely change outputs but the post had issues.
*   **Emotion:** The overall emotional tone is Negative, due to issues with the post.
*   **Top 3 Points of View:**
    *   N/A - No clear viewpoints.

**[Grit Portrait ðŸ”³ - New Flux LoRA (Score: 0)](https://www.reddit.com/gallery/1l6e2xr)**
*   **Summary:** A thread promoting a new Flux LoRA for generating grit portraits, highlighting its features and providing download links.
*   **Emotion:** The overall emotional tone is Positive due to promoting a LoRA.
*   **Top 3 Points of View:**
    *   The LoRA is good for generating close-up faces with intense lighting and emotional expressions.
    *   The LoRA was trained as part of glif.app's #loradex project.
    *   A user is thankful and think it is very interesting.

**[How do I achieve such results? Image "generated" via Perplexity (Score: 0)](https://www.reddit.com/gallery/1l6fe75)**
*   **Summary:** A user asks how to achieve similar image generation results as those produced by Perplexity AI.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Use img2img with a prompt about position and expression.
    *   Setting the img2img noise multiplier to zero can remove details.
    *   The images are generated by OpenAI GPT4o model that Perplexity is using.

**[SD installation, unable to disable path length limit (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1l6edlz/sd_installation_unable_to_disable_path_length/)**
*   **Summary:** A user is experiencing issues with disabling the path length limit during Stable Diffusion installation and is seeking advice on how to resolve it.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   Uninstall and reinstall Python.
    *   Enabling the option is recommended to avoid issues with plugins or updates.
    *   Issues are not guaranteed to happen if you do not enable the option.
