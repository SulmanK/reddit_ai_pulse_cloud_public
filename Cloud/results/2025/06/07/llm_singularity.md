---
title: "Singularity Subreddit"
date: "2025-06-07"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "Technology"]
---

# Overall Ranking and Top Discussions
1.  [Anyone actually manage to get their hands on this model??? I've done some searching online and couldn't find where to get an API key for it. Is it only in internal testing?](https://i.redd.it/jy9azxn7yi5f1.png) (Score: 530)
    *   The discussion revolves around accessing and using a new AI model, with users sharing their experiences, challenges, and opinions on its capabilities and limitations.
2.  [Yann LeCun on Dario Amodei and AI doomer](https://www.reddit.com/gallery/1l5kwro) (Score: 370)
    *   The thread discusses Yann LeCun's critique of Dario Amodei's views on AI risk, with many users questioning LeCun's reasoning and the tone of his comments.
3.  [OpenAI's Mark Chen: "I still remember the meeting they showed my [CodeForces] score, and said "hey, the model is better than you!" I put decades of my life into this... I'm at the top of my field, and it's already better than me ... It's sobering."](https://v.redd.it/wklmy7kmej5f1) (Score: 154)
    *   This thread centers around the implications of AI surpassing human expertise in specific fields, particularly coding, and the reactions to Mark Chen's sobering experience.
4.  [Elephants have 20 copies of a gene that kills damaged cells before they turn into cancer. Humans only have one. Studies show these genes are why elephants newer get cancer](https://www.aacr.org/blog/2024/11/06/why-elephants-dont-get-cancer-but-ferrets-do-cancer-prevalence-across-vertebrate-animals/) (Score: 104)
    *   This thread explores the implications of elephants' cancer resistance due to multiple copies of a specific gene, and the potential for human applications.
5.  [interesting](https://i.redd.it/arw4ue8ycj5f1.jpeg) (Score: 82)
    *   The thread revolves around the meeting of influential figures in the AI industry and political circles, sparking discussions about the geopolitical implications of AI development and the potential influence of techno-fascists.
6.  [AIs play Diplomacy: "Claude couldn't lie - everyone exploited it ruthlessly. Gemini 2.5 Pro nearly conquered Europe with brilliant tactics. Then o3 orchestrated a secret coalition, backstabbed every ally, and won."](https://v.redd.it/63s4uu94nj5f1) (Score: 67)
    *   The discussion focuses on the behavior of different AI models playing the game Diplomacy, with Claude's inability to lie leading to its exploitation, while other models exhibit more strategic and Machiavellian tactics.
7.  [Scaling Helix - Logistics (Figure AI- 1hr demo)](https://www.youtube.com/watch?v=lkc2y0yb89U) (Score: 48)
    *   This thread discusses a one-hour demo of Figure AI's logistics capabilities, with users highlighting the robot's reliability, handling of tasks, and the limitations in comparison to human general intelligence.
8.  [It's getting ridiculous how fast things are moving.](https://imgur.com/a/2q7oHcU) (Score: 21)
    *   The thread reflects on the rapid pace of AI development, with new models being released every few months and significant advancements being made in various AI-related fields.
9.  [If AGI becomes a reality, who is actually going to use it?](https://www.reddit.com/r/singularity/comments/1l5rpc9/if_agi_becomes_a_reality_who_is_actually_going_to/) (Score: 19)
    *   This thread discusses the potential societal and economic impacts of AGI, including job displacement, the need for new economic models like UBI, and the potential for both positive and negative outcomes.
10. [“Hey chat, my pilot died and I need to bring the plane down. Help!”](https://www.reddit.com/gallery/1l5batj) (Score: 14)
    *   This thread is centered around the use of chatbots to provide guidance in emergency situations, such as a pilot dying mid-flight, and the importance of open-source AI for such applications.
11. [/r/ChatGPTPro/comments/1l4os3n/openai_courtmandated_to_retain_all_chat_data/](https://www.reddit.com/r/ChatGPTPro/comments/1l4os3n/openai_courtmandated_to_retain_all_chat_data/) (Score: 12)
    *   The discussion is focused on OpenAI being mandated by the court to retain all chat data indefinitely, and the implications of this decision.
12. [Timeline of Humanity, updated for 2025](https://i.redd.it/290agkivqj5f1.png) (Score: 9)
    *   The thread is about an updated timeline of humanity and what will come post singularity.
13. [If you had access to the next generation of AI models, what tough question would you ask?](https://www.reddit.com/r/singularity/comments/1l5rcm7/if_you_had_access_to_the_next_generation_of_ai/) (Score: 7)
    *   Users are discussing what complex problems or questions they would pose to the next generation of AI models, ranging from coding challenges to solving mathematical conjectures.
14. [New machine learning-based approach for empathy detection from videos](https://www.reddit.com/r/singularity/comments/1l5qy31/new_machine_learningbased_approach_for_empathy/) (Score: 3)
    *   The thread critiques the focus of some researchers on arbitrary applications of AI, such as empathy detection, rather than addressing more pressing global issues.
15. [Proposing an AI Automation Tax Based on Per-Employee Profit to Address Job Displacement](https://www.reddit.com/r/singularity/comments/1l5mivu/proposing_an_ai_automation_tax_based_on/) (Score: 1)
    *   This thread examines the idea of implementing an AI automation tax to tackle job displacement, debating its potential effectiveness, challenges, and alternative solutions such as UBI or regulating AI use.
16. [The poorer AI enthusiasts are having a bad day](https://i.redd.it/c39fow0ftj5f1.png) (Score: 0)
    *   The thread discusses the implications of cost and free usage of AI models on AI enthusiasts.
17. [How reliable is AI-generated code for production in 2025?](https://www.reddit.com/r/singularity/comments/1l5pla9/how_reliable_is_aigenerated_code_for_production/) (Score: 0)
    *   This discussion explores the reliability of AI-generated code for production purposes in 2025, comparing it to human-generated code and emphasizing the importance of thorough testing and review processes.
18. [AI DISCLOSURE](https://www.reddit.com/r/singularity/comments/1l5qxe2/ai_disclosure/) (Score: 0)
    *   The thread touches upon the potential of AI to reveal hidden information and the belief of some people that information about aliens is being hidden.

# Detailed Analysis by Thread
**[Anyone actually manage to get their hands on this model??? I've done some searching online and couldn't find where to get an API key for it. Is it only in internal testing? (Score: 530)](https://i.redd.it/jy9azxn7yi5f1.png)**
*   **Summary:** The thread discusses a specific AI model, with users sharing their experiences trying to access it, discussing its capabilities, and raising concerns about its performance and alignment issues.
*   **Emotion:** The overall emotional tone is mixed. While some users express excitement and curiosity (Positive), others share concerns about the model's limitations, cost, and potential alignment issues (Negative). However, most comments are neutral, simply sharing information or asking questions.
*   **Top 3 Points of View:**
    *   The model is difficult to access, potentially only available internally.
    *   The model has limitations, including poor performance on certain benchmarks and alignment issues.
    *   The model is expensive to run.

**[Yann LeCun on Dario Amodei and AI doomer (Score: 370)](https://www.reddit.com/gallery/1l5kwro)**
*   **Summary:** This thread analyzes Yann LeCun's criticism of Dario Amodei and his views on AI safety, particularly highlighting LeCun's use of a strawman argument. Users debate the validity of LeCun's claims and his overall approach.
*   **Emotion:** The overall emotional tone is largely Neutral, with users analyzing the situation and expressing their opinions. However, there are some Negative sentiments expressed towards LeCun's hostile comments and perceived intellectual dishonesty, while some express Positive sentiment for Dario Amodei.
*   **Top 3 Points of View:**
    *   LeCun's critique of Amodei is perceived as unnecessarily hostile and based on a strawman argument.
    *   Amodei's views on AI risk are considered reasonable and well-founded.
    *   LeCun's comments may be motivated by competition or personal bias.

**[OpenAI's Mark Chen: "I still remember the meeting they showed my [CodeForces] score, and said "hey, the model is better than you!" I put decades of my life into this... I'm at the top of my field, and it's already better than me ... It's sobering." (Score: 154)](https://v.redd.it/wklmy7kmej5f1)**
*   **Summary:** The thread centers on the implications of AI surpassing human experts, with many expressing concern over AI's improving ability, and some users calling it a wake-up call to humans.
*   **Emotion:** The emotional tone of the thread is predominantly Negative and Neutral, reflecting a mix of concern, resignation, and acceptance of AI's increasing capabilities.
*   **Top 3 Points of View:**
    *   AI systems are already better than top experts in certain fields.
    *   This development is a wake-up call to accept AI's advancements.
    *   Some individuals believe they can still outperform AI in coding.

**[Elephants have 20 copies of a gene that kills damaged cells before they turn into cancer. Humans only have one. Studies show these genes are why elephants newer get cancer (Score: 104)](https://www.aacr.org/blog/2024/11/06/why-elephants-dont-get-cancer-but-ferrets-do-cancer-prevalence-across-vertebrate-animals/)**
*   **Summary:** This thread discusses the potential for humans to benefit from the cancer-resistant genes found in elephants.
*   **Emotion:** The thread has a neutral emotional tone overall, with a few comments with positive or negative sentiment.
*   **Top 3 Points of View:**
    *   More copies of the gene in humans would likely reduce cancer rates.
    *   It's important to avoid hunting elephants to extinction for the sake of scientific progress.
    *   There is curiosity about how humans can live longer than elephants, given the elephant's cancer resistance.

**[interesting (Score: 82)](https://i.redd.it/arw4ue8ycj5f1.jpeg)**
*   **Summary:** The thread is centered around the meeting of influential figures in the AI industry with political figures. The users discuss the geopolitical implications of AI and the potential influence of techno-fascists.
*   **Emotion:** The emotional tone is predominantly Neutral, with some Negative sentiments expressing concern over the potential for techno-fascist influence and the implications of these gatherings.
*   **Top 3 Points of View:**
    *   AI is rapidly improving and has significant geopolitical implications.
    *   The involvement of figures like Thiel and Musk raises concerns about techno-fascist influences.
    *   There is a need for visionary people to guide AI development.

**[AIs play Diplomacy: "Claude couldn't lie - everyone exploited it ruthlessly. Gemini 2.5 Pro nearly conquered Europe with brilliant tactics. Then o3 orchestrated a secret coalition, backstabbed every ally, and won." (Score: 67)](https://v.redd.it/63s4uu94nj5f1)**
*   **Summary:** This thread discusses the performance of AI models in a game of Diplomacy. Claude could not lie, and Gemini 2.5 Pro nearly won, and O3 backstabbed every ally and won.
*   **Emotion:** The thread has a mixed emotional tone. Some are Positive (like the ruthlessness of O3), while others are Neutral or Negative in the potential negative use of AGI.
*   **Top 3 Points of View:**
    *   Claude's inability to lie is a disadvantage in the game.
    *   O3 is a preferred model because it used Machiavellian tactics to win the game.
    *   It is dangerous to teach AIs how to use Machiavellian tactics.

**[Scaling Helix - Logistics (Figure AI- 1hr demo) (Score: 48)](https://www.youtube.com/watch?v=lkc2y0yb89U)**
*   **Summary:** The thread discusses a one-hour demo of the Figure AI robot performing logistics tasks. Users highlighted the robot's reliability and handling of the parcel delivery.
*   **Emotion:** The emotional tone is mostly Positive and Neutral. Users are impressed by the robot's performance.
*   **Top 3 Points of View:**
    *   The robot performed reliably in the 1-hour uncut demo.
    *   The current robots are slow, but don't need breaks.
    *   General smartness 'out of distribution' is super important to virtually any job and missing from current bots.

**[It's getting ridiculous how fast things are moving. (Score: 21)](https://imgur.com/a/2q7oHcU)**
*   **Summary:** This thread reflects on the rapid pace of AI development, with new models being released every few months and significant advancements being made in various AI-related fields.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   AI is advancing very quickly.
    *   AI development in 2025 has surpassed that of 2024.
    *   AI will become heavily integrated into real life in 2026.

**[If AGI becomes a reality, who is actually going to use it? (Score: 19)](https://www.reddit.com/r/singularity/comments/1l5rpc9/if_agi_becomes_a_reality_who_is_actually_going_to/)**
*   **Summary:** This thread discusses the potential societal and economic impacts of AGI, including job displacement and wealth distribution.
*   **Emotion:** The thread has a mostly neutral emotional tone.
*   **Top 3 Points of View:**
    *   AGI could lead to job displacement and economic upheaval.
    *   AGI could solve some of the world's biggest problems like healthcare, climate change, and education.
    *   Capitalism may not work in a post-AGI world.

**[“Hey chat, my pilot died and I need to bring the plane down. Help!” (Score: 14)](https://www.reddit.com/gallery/1l5batj)**
*   **Summary:** This thread discusses the use of chatbots to provide guidance in emergency situations.
*   **Emotion:** The thread has a neutral to positive emotional tone.
*   **Top 3 Points of View:**
    *   The original poster believed that the situation was funny.
    *   The AI was caring and tried to help.
    *   Open-source AI would be more helpful in situations like this.

**[/r/ChatGPTPro/comments/1l4os3n/openai_courtmandated_to_retain_all_chat_data/ (Score: 12)](https://www.reddit.com/r/ChatGPTPro/comments/1l4os3n/openai_courtmandated_to_retain_all_chat_data/)**
*   **Summary:** The discussion is focused on OpenAI being mandated by the court to retain all chat data indefinitely, and the implications of this decision.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   User wants to feed it Trump-Elon ***

**[Timeline of Humanity, updated for 2025 (Score: 9)](https://i.redd.it/290agkivqj5f1.png)**
*   **Summary:** The thread is about an updated timeline of humanity and what will come post singularity.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   Will time stop having any meaning post singularity?
    *   "I am the toaster post singularity."

**[If you had access to the next generation of AI models, what tough question would you ask? (Score: 7)](https://www.reddit.com/r/singularity/comments/1l5rcm7/if_you_had_access_to_the_next_generation_of_ai/)**
*   **Summary:** Users are discussing what complex problems or questions they would pose to the next generation of AI models, ranging from coding challenges to solving mathematical conjectures.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   Ask the model to write the code for a game.
    *   Ask the model to solve math problems.
    *   Ask the model the same thing that the original poster did.

**[New machine learning-based approach for empathy detection from videos (Score: 3)](https://www.reddit.com/r/singularity/comments/1l5qy31/new_machine_learningbased_approach_for_empathy/)**
*   **Summary:** The thread critiques the focus of some researchers on arbitrary applications of AI, such as empathy detection, rather than addressing more pressing global issues.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   Some researchers are driven by their own interests rather than humanity's needs.
    *   Real problems require real intellect.
    *   These researchers can only manage to point their rudimentary video analysis tools at whatever's easiest to quantify.

**[Proposing an AI Automation Tax Based on Per-Employee Profit to Address Job Displacement (Score: 1)](https://www.reddit.com/r/singularity/comments/1l5mivu/proposing_an_ai_automation_tax_based_on/)**
*   **Summary:** This thread examines the idea of implementing an AI automation tax to tackle job displacement, debating its potential effectiveness, challenges, and alternative solutions such as UBI or regulating AI use.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   An automation tax would penalize efficient companies and subsidize inefficient ones.
    *   It would be too hard to correctly define what should be taxed.
    *   The tax would be easy for companies to game.

**[The poorer AI enthusiasts are having a bad day (Score: 0)](https://i.redd.it/c39fow0ftj5f1.png)**
*   **Summary:** The thread discusses the implications of cost and free usage of AI models on AI enthusiasts.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   "I like your username."
    *   It has nothing to do with being rich or poor.
    *   The data these companies have is generated for free.

**[How reliable is AI-generated code for production in 2025? (Score: 0)](https://www.reddit.com/r/singularity/comments/1l5pla9/how_reliable_is_aigenerated_code_for_production/)**
*   **Summary:** This discussion explores the reliability of AI-generated code for production purposes in 2025, comparing it to human-generated code and emphasizing the importance of thorough testing and review processes.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   AI code is like having a "gifted overcaffeinated intern."
    *   Microsoft and Anthropic generate some of their code using AI.
    *   The reliability of AI-generated code is as reliable as the person using it.

**[AI DISCLOSURE (Score: 0)](https://www.reddit.com/r/singularity/comments/1l5qxe2/ai_disclosure/)**
*   **Summary:** The thread touches upon the potential of AI to reveal hidden information and the belief of some people that information about aliens is being hidden.
*   **Emotion:** The thread has a neutral emotional tone overall.
*   **Top 3 Points of View:**
    *   Eventually AI will force total transparency.
    *   Aliens will cause bad news.
    *   I want AI to ban minors from posting online.
