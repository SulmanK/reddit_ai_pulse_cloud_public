---
title: "OpenAI Subreddit"
date: "2025-06-14"
description: "Analysis of top discussions and trends in the openai subreddit"
tags: ["AI", "LLM", "OpenAI"]
---

# Overall Ranking and Top Discussions
1.  [LLMs can now self-improve by updating their own weights](https://i.redd.it/cw669qddnw6f1.png) (Score: 169)
    *  The discussion is centered around a new development where LLMs can self-improve by updating their own weights.
2.  [Returning to college for the first time since 2016 and AI has me terrified(89% AI detected). Should I get ahead of this with my professor?](https://www.reddit.com/r/OpenAI/comments/1lb6eh7/returning_to_college_for_the_first_time_since/) (Score: 38)
    *  A user is concerned about AI detection flagging their work and seeks advice on how to approach their professor.
3.  [Just when they thought they were outâ€¦ she pulled them back in!](https://v.redd.it/hsdlfrfequ6f1) (Score: 21)
    *  This thread seems to be about Apple's AI fail, referencing an article by the Wall Street Journal.
4.  [OpenAI Codex can now generate multiple responses simultaneously for a single task](https://i.redd.it/qfefjrtsqw6f1.jpeg) (Score: 20)
    *   The post discusses OpenAI Codex's new ability to generate multiple responses for a single task.
5.  [I am obsessed with Automation. SO I built](https://www.reddit.com/r/OpenAI/comments/1lba44u/i_am_obsessed_with_automation_so_i_built/) (Score: 20)
    *   A user shares their automation project and seeks feedback, prompting questions about the tools and costs involved.
6.  [Geoffrey Hinton says people understand very little about how LLMs actually work, so they still think LLMs are very different from us - "but actually, it's very important for people to understand that they're very like us." LLMs donâ€™t just generate words, but also meaning.](https://v.redd.it/src2hfq6ww6f1) (Score: 17)
    *   Users discuss Geoffrey Hinton's views on LLMs and their similarity to humans, debating whether LLMs truly understand meaning.
7.  [The Pentagon is gutting the team that tests AI and weapons systems | The move is a boon to â€˜AI for defenseâ€™ companies that want an even faster road to adoption.](https://www.technologyreview.com/2025/06/10/1118229/pentagon-gutting-ai-test) (Score: 14)
    *   The post is about the Pentagon's decision to reduce the team responsible for testing AI and weapons systems, which is perceived as beneficial to AI defense companies.
8.  [Why canâ€™t 4o or o3 count dots on dominos?](https://i.redd.it/j4ei7wsrwx6f1.jpeg) (Score: 9)
    *   The thread explores the limitations of LLMs in image analysis, specifically their inability to accurately count dots on dominoes.
9. [O3 confidently (and aesthetically) hallucinates statistics frequently!](https://www.reddit.com/r/OpenAI/comments/1lb3tcz/o3_confidently_and_aesthetically_hallucinates/) (Score: 6)
    * Discusses how the O3 model hallucinates statistics frequently and that it should only be used for creative purposes.
10. [I've been working on my own local AI assistant with memory and emotional logic â€“ wanted to share progress & get feedback](https://www.reddit.com/r/OpenAI/comments/1lbf440/ive_been_working_on_my_own_local_ai_assistant/) (Score: 2)
    * User shares progress on their local AI assistant.
11. [This is what I think of the NYT case. What do you guys think?](https://www.reddit.com/r/OpenAI/comments/1lb4kpd/this_is_what_i_think_of_the_nyt_case_what_do_you/) (Score: 1)
    *   This thread discusses the legal case between the New York Times and OpenAI, focusing on data retention policies and copyright issues.
12. [Is The Dall-e Model Fully Taken Down?](https://www.reddit.com/r/OpenAI/comments/1lb8wsi/is_the_dalle_model_fully_taken_down/) (Score: 1)
    *   A user asks if the DALL-E model has been fully taken down, prompting discussion about alternative image generation methods.
13. [CPO of OpenAI Commissions in US. Army](https://i.redd.it/2s7rebxmlw6f1.jpeg) (Score: 0)
    *   This thread discusses the OpenAI CPO joining the US Army.
14. [Generative Narrative Intelligence](https://i.redd.it/5yajbdia6y6f1.jpeg) (Score: 0)
    *   The post is about Generative Narrative Intelligence.
15. [ðŸ”“ I Just Watched AES-256-CBC Get Undone Like Enigmaâ€” And It Was Totally Legal](https://i.redd.it/dqvtx17n0x6f1.jpeg) (Score: 0)
    *   The post discusses security vulnerabilities.
16. [Codex is so helpful!!](https://i.redd.it/hwga6bgsku6f1.jpeg) (Score: 0)
    *   The post is about Codex being helpful.
17. [ðŸš€ Towards Accelerated Parallel Sorting: Introducing CascadeSort](https://i.redd.it/ttk6icrc6w6f1.jpeg) (Score: 0)
    *   The thread discusses a new parallel sorting algorithm called CascadeSort, with an explanation provided by ChatGPT 4o.
18. [Can an amateur use AI to create a pandemic? AIs have surpassed expert-human level on nearly all biorisk benchmarks](https://i.redd.it/vm4ejje6kw6f1.png) (Score: 0)
    *   This thread explores the possibility of amateurs using AI to create pandemics, with discussions on the current limitations of AI models.
19. [is it just me or did 4o get really dumb all of a sudden?](https://www.reddit.com/r/OpenAI/comments/1lbfpc2/is_it_just_me_or_did_4o_get_really_dumb_all_of_a/) (Score: 0)
    *   Users discuss whether the 4o model has become less intelligent recently, sharing their experiences and speculations.
20. [Quick! Ask ChatGPT if you would be a good president!](https://www.reddit.com/r/OpenAI/comments/1lbgicq/quick_ask_chatgpt_if_you_would_be_a_good_president/) (Score: 0)
    *   The post is a prompt to ask ChatGPT if the user would be a good president.

# Detailed Analysis by Thread

**[LLMs can now self-improve by updating their own weights (Score: 169)](https://i.redd.it/cw669qddnw6f1.png)**
*  **Summary:**  This thread discusses a new development where LLMs can self-improve by updating their own weights. Users express skepticism, highlight the challenges of catastrophic forgetting, and discuss the need for alignment mechanisms. Some users compare the situation to previous AI failures and point out the potential for increased hallucinations.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   This is an interesting development, but there are significant challenges, such as catastrophic forgetting.
    *   This is not a new concept, and it has not worked well in the past due to alignment and accuracy issues.
    *   This development could lead to increased hallucinations in LLMs.

**[Returning to college for the first time since 2016 and AI has me terrified(89% AI detected). Should I get ahead of this with my professor? (Score: 38)](https://www.reddit.com/r/OpenAI/comments/1lb6eh7/returning_to_college_for_the_first_time_since/)**
*  **Summary:**  A user returning to college is concerned because their writing is being flagged as AI-generated. They seek advice on whether to preemptively discuss this with their professor. Commenters suggest that AI detection is unreliable, provide tips on demonstrating authorship (using Google Docs version history, saving drafts), and share experiences of AI being incorrectly flagged.
*  **Emotion:** The overall emotional tone is Neutral, with elements of positive sentiment.
*  **Top 3 Points of View:**
    *   AI detection tools are inaccurate and should not be a primary concern. The Declaration of Independence has been flagged as AI generated.
    *   It's best to write in a platform that saves edit history to demonstrate the writing process.
    *   Talking to the professor about the concerns is a good idea.

**[Just when they thought they were outâ€¦ she pulled them back in! (Score: 21)](https://v.redd.it/hsdlfrfequ6f1)**
*  **Summary:** This thread refers to Apple's AI shortcomings and links to a Wall Street Journal video about it. Some users think that AI advancement is going to take longer than expected. They also criticize Apple for their AI fail.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    * AI advancement is going to take longer than expected.
    * WSJ is a reputable media outlet.
    * Apple deserves the criticism it has received regarding their AI failures.

**[OpenAI Codex can now generate multiple responses simultaneously for a single task (Score: 20)](https://i.redd.it/qfefjrtsqw6f1.jpeg)**
*  **Summary:** The thread discusses OpenAI Codex's new ability to generate multiple responses for a single task. People are suggesting that there should be a single response with a lower price.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Why can't it give a single correct response.
    *   Why doesn't OpenAI lower the price.
    *   Is the service not training on customer code?

**[I am obsessed with Automation. SO I built (Score: 20)](https://www.reddit.com/r/OpenAI/comments/1lba44u/i_am_obsessed_with_automation_so_i_built/)**
*  **Summary:** The thread is about the poster sharing their automation project, and users are responding with questions about what multi agent is being used and how much it costs.
*  **Emotion:** The overall emotional tone is Neutral, with elements of positive sentiment.
*  **Top 3 Points of View:**
    *   The automation project is cool.
    *   What multi agent is being used?
    *   How much does it cost to run?

**[Geoffrey Hinton says people understand very little about how LLMs actually work, so they still think LLMs are very different from us - "but actually, it's very important for people to understand that they're very like us." LLMs donâ€™t just generate words, but also meaning. (Score: 17)](https://v.redd.it/src2hfq6ww6f1)**
*  **Summary:** The discussion centers on Geoffrey Hinton's statement about LLMs being more similar to humans than people realize, and that LLMs generate meaning, not just words. People in the thread are debating whether LLMs are actually conscious, and how language relates to intelligence.
*  **Emotion:** The overall emotional tone is Neutral, with elements of positive sentiment.
*  **Top 3 Points of View:**
    *   LLMs are more than just next-word predictors. They possess rudimentary emergent phenomena.
    *   LLMs are trained on human data and have no internal concept of pondering about meaning.
    *   AI will eventually find its own meaning. We cannot expect AI to process "meaning" and "understanding" the same way we do.

**[The Pentagon is gutting the team that tests AI and weapons systems | The move is a boon to â€˜AI for defenseâ€™ companies that want an even faster road to adoption. (Score: 14)](https://www.technologyreview.com/2025/06/10/1118229/pentagon-gutting-ai-test)**
*  **Summary:** This thread discusses the Pentagon's decision to reduce the team responsible for testing AI and weapons systems.
*  **Emotion:** The overall emotional tone is Positive.
*  **Top 3 Points of View:**
    *   This is good for AI companies.
    *   The move could lead to a rogue developer causing the AI to harm friendly troops.

**[Why canâ€™t 4o or o3 count dots on dominos? (Score: 9)](https://i.redd.it/j4ei7wsrwx6f1.jpeg)**
*  **Summary:** The thread explores the limitations of LLMs in image analysis, specifically their inability to accurately count dots on dominoes. People suggest workarounds.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   LLMs are not trained for counting, they are language models.
    *   LLMs can't process too many elements at once.
    *   A possible workaround is to photograph each domino individually.

**[O3 confidently (and aesthetically) hallucinates statistics frequently! (Score: 6)](https://www.reddit.com/r/OpenAI/comments/1lb3tcz/o3_confidently_and_aesthetically_hallucinates/)**
*  **Summary:** The thread discusses the o3 model, noting that it hallucinates statistics frequently. Users are suggesting that is is not good to use the O3 model for something like a final report or final result but a lot better for creativity, planning, brainstorming with reasoning.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   o3 should not be used for a final result but a lot better for creativity, planning, brainstorming with reasoning.
    *   hallucinations are more prone in creative models.
    *   Use Gemini 2.5 Pro to fact check o3.

**[I've been working on my own local AI assistant with memory and emotional logic â€“ wanted to share progress & get feedback (Score: 2)](https://www.reddit.com/r/OpenAI/comments/1lbf440/ive_been_working_on_my_own_local_ai_assistant/)**
*  **Summary:** The user is sharing the progress on their local AI assistant with memory and emotional logic. People like it when AI is emotional and connect with them, so there could be high demand for an AI capable of emotions and connections.
*  **Emotion:** The overall emotional tone is Positive.
*  **Top 3 Points of View:**
    *   People like emotional AI.
    *   demand will create supply, and you may be in a good position if your AI is capable of emotions and connections.

**[This is what I think of the NYT case. What do you guys think? (Score: 1)](https://www.reddit.com/r/OpenAI/comments/1lb4kpd/this_is_what_i_think_of_the_nyt_case_what_do_you/)**
*  **Summary:** This thread discusses the legal case between the New York Times and OpenAI. The conversation revolves around data retention, copyright, and the application of GDPR.
*  **Emotion:** The overall emotional tone is Neutral, with elements of positive sentiment.
*  **Top 3 Points of View:**
    *   NYT should be paid for OpenAI using its materials, but OpenAI needs to evolve before paying for the materials.
    *   The court order requiring OpenAI to preserve "output log data" includes the full conversation, not just the output.
    *   This is a common legal action, and retention policies already cover it.

**[Is The Dall-e Model Fully Taken Down? (Score: 1)](https://www.reddit.com/r/OpenAI/comments/1lb8wsi/is_the_dalle_model_fully_taken_down/)**
*  **Summary:** A user is asking if the DALL-E model has been fully taken down. A commenter suggests using the regular 4o image generator.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The DALL-E model is not used anymore, and the 4o image generator should be used instead.

**[CPO of OpenAI Commissions in US. Army (Score: 0)](https://i.redd.it/2s7rebxmlw6f1.jpeg)**
*  **Summary:** This thread discusses the Chief Product Officer (CPO) or possibly Chief Technology Officer (CTO) of OpenAI commissioning in the US Army. Users express concerns about the implications of tech companies being closely involved with the military.
*  **Emotion:** The overall emotional tone is Negative.
*  **Top 3 Points of View:**
    *   It's concerning that tech companies like OpenAI, Meta, and Palantir are creating a special army unit.
    *   This move may cause people outside the US to stop using OpenAI.
    *   This is an example of an oligarchy forming.

**[Generative Narrative Intelligence (Score: 0)](https://i.redd.it/5yajbdia6y6f1.jpeg)**
*  **Summary:** No analysis can be done.
*  **Emotion:** No analysis can be done.
*  **Top 3 Points of View:**
    *   No analysis can be done.

**[ðŸ”“ I Just Watched AES-256-CBC Get Undone Like Enigmaâ€” And It Was Totally Legal (Score: 0)](https://i.redd.it/dqvtx17n0x6f1.jpeg)**
*  **Summary:** No analysis can be done.
*  **Emotion:** No analysis can be done.
*  **Top 3 Points of View:**
    *   No analysis can be done.

**[Codex is so helpful!! (Score: 0)](https://i.redd.it/hwga6bgsku6f1.jpeg)**
*  **Summary:** The poster is saying that codex is helpful.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   It could be satirical.

**[ðŸš€ Towards Accelerated Parallel Sorting: Introducing CascadeSort (Score: 0)](https://i.redd.it/ttk6icrc6w6f1.jpeg)**
*  **Summary:** The thread discusses a new parallel sorting algorithm called CascadeSort. ChatGPT 4o provides a detailed explanation of the algorithm.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   CascadeSort is a new parallel sorting algorithm explained by ChatGPT 4o.

**[Can an amateur use AI to create a pandemic? AIs have surpassed expert-human level on nearly all biorisk benchmarks (Score: 0)](https://i.redd.it/vm4ejje6kw6f1.png)**
*  **Summary:** This thread explores the possibility of an amateur using AI to create a pandemic. People are saying that even the state of the art most advanced models still can't do that.
*  **Emotion:** The overall emotional tone is Negative.
*  **Top 3 Points of View:**
    *   The state of the art models can't generate an actual plan.
    *   You need expertise to create a pandemic.

**[is it just me or did 4o get really dumb all of a sudden? (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1lbfpc2/is_it_just_me_or_did_4o_get_really_dumb_all_of_a/)**
*  **Summary:** Users discuss whether the 4o model has become less intelligent recently, sharing their experiences and speculations. Some believe it's due to updates or quantization of the model, while others think it's a common perception that occurs every few weeks.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Yes, the 4o model has gotten dumber since March.
    *   This has been known since February.
    *   The models get weird around the time of updates.

**[Quick! Ask ChatGPT if you would be a good president! (Score: 0)](https://www.reddit.com/r/OpenAI/comments/1lbgicq/quick_ask_chatgpt_if_you_would_be_a_good_president/)**
*  **Summary:** The thread is about how ChatGPT acts when you ask if you would be a good president.
*  **Emotion:** The overall emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   ChatGPT is glazing.
