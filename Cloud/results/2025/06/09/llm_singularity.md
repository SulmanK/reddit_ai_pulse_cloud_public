---
title: "Singularity Subreddit"
date: "2025-06-09"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "LLM"]
---

# Overall Ranking and Top Discussions
1.  [Shipment lost. We’ll get em next time](https://v.redd.it/ngglq0clbv5f1) (Score: 556)
    *   This thread discusses a video of a robot failing at a shipping task, with commenters joking about the robot being overworked and comparing it to Will Smith eating spaghetti.
2.  [o5 is in training….](https://x.com/dylan522p/status/1931858578748690518) (Score: 221)
    *   The thread discusses a tweet suggesting that OpenAI's o5 model is in training, with commenters questioning the source and speculating about its capabilities.
3.  New SOTA on aider polyglot coding benchmark - Gemini with 32k thinking tokens.](https://i.redd.it/d41kmdpwnw5f1.png) (Score: 204)
    *   The thread discusses the new state-of-the-art performance of Gemini on a coding benchmark, with commenters focusing on the cost and comparing it to other models like o3 and o4-mini.
4.  [The Apple "Illusion of Thinking" Paper Maybe Corporate Damage Control](https://www.reddit.com/r/singularity/comments/1l73qne/the_apple_illusion_of_thinking_paper_maybe/) (Score: 189)
    *   The thread revolves around Apple's research paper critiquing the "thinking" capabilities of LLMs, with some suggesting it's a form of corporate damage control.
5.  [Breaking: OpenAI Hits $10B in Reoccurring Annualized Revenue, ahead of Forecasts, up from $3.7B last year per CNBC](https://i.redd.it/uyqrtp449y5f1.jpeg) (Score: 151)
    *   This thread discusses OpenAI's impressive revenue growth, with commenters debating whether the company is profitable and how it compares to competitors like Google and Microsoft.
6.  [What’s with everyone obsessing over that apple paper? It’s obvious that CoT RL training results in better performance which is undeniable!](https://www.reddit.com/r/singularity/comments/1l77u6t/whats_with_everyone_obsessing_over_that_apple/) (Score: 93)
    *   The thread discusses the ongoing obsession with Apple's research paper on LLMs, with many users suggesting that the paper's findings are not novel or particularly insightful.
7.  [Why are so many people so obsessed with AGI, when current AI will still be revolutionary?](https://www.reddit.com/r/singularity/comments/1l7b91a/why_are_so_many_people_so_obsessed_with_agi_when/) (Score: 91)
    *   The thread explores the reasons behind the focus on Artificial General Intelligence (AGI), despite the revolutionary potential of current AI technologies.
8.  [Scientists Grow Human Teeth In A Lab For The First Time](https://www.techbusinessnews.com.au/news/scientists-grow-human-teeth-in-a-lab-for-the-first-time/) (Score: 84)
    *   This thread discusses the recent breakthrough in growing human teeth in a lab, with some users expressing excitement about its potential applications in dentistry.
9.  [We're still pretty far from embodied intelligence... (Gemini 2.5 Flash plays Final Fantasy)](https://v.redd.it/1anm2g5ymt5f1) (Score: 79)
    *   The discussion revolves around a video of Gemini 2.5 Flash attempting to play Final Fantasy, with commenters noting that while the AI's performance is impressive, it still has a long way to go before achieving embodied intelligence.
10. [Scaling Reinforcement Learning: Environments, Reward Hacking, Agents, Scaling Data (o4/o5 leaked info behind paywall)](https://semianalysis.com/2025/06/08/scaling-reinforcement-learning-environments-reward-hacking-agents-scaling-data/) (Score: 69)
    *   The thread discusses a paywalled article about scaling reinforcement learning, with commenters seeking access to the leaked information about o4 and o5 models.
11. [Researchers pointing out their critiques of the Apple reasoning paper on Twitter (tldr; Context length limits seem the be the major road block, among other insights pointing to a poor methodology)](https://x.com/RyanPGreenblatt/status/1931823002649542658?t=LFIet-126kGwblmrXbtHYg&s=19) (Score: 46)
    *   This thread discusses criticisms of Apple's reasoning paper, particularly regarding context length limits and methodology.
12. [Do the researchers at Apple, actually understand computational complexity?](https://www.reddit.com/r/singularity/comments/1l6xmxf/do_the_researchers_at_apple_actually_understand/) (Score: 44)
    *   The thread questions the understanding of computational complexity by Apple's researchers in their recent paper.
13. [For some recent graduates in the US, the AI job apocalypse may already be here](https://www.thestar.com.my/tech/tech-news/2025/06/08/for-some-recent-graduates-in-the-us-the-ai-job-apocalypse-may-already-be-here) (Score: 37)
    *   The thread discusses the impact of AI on recent graduates' job prospects.
14. ["Embedding high-resolution touch across robotic hands enables adaptive human-like grasping"](https://www.reddit.com/r/singularity/comments/1l7aqkm/embedding_highresolution_touch_across_robotic/) (Score: 22)
    *   The thread highlights advancements in robotic hands, specifically high-resolution touch technology, and discusses the implications of achieving human-like grasping capabilities.
15. [What do you think the odds of RSI being achievable are?](https://www.reddit.com/r/singularity/comments/1l6xg9l/what_do_you_think_the_odds_of_rsi_being/) (Score: 19)
    *   The discussion revolves around the possibility of achieving recursive self-improvement (RSI) in AI, with varying opinions on the likelihood and the current state of LLMs.
16. [A lot of people talking about Apple's paper, but this one is way more important (Robust agents learn causal world models)](https://www.reddit.com/r/singularity/comments/1l7cbf5/a_lot_of_people_talking_about_apples_paper_but/) (Score: 12)
    *   The thread suggests that a paper on robust agents learning causal world models is more significant than Apple's paper, discussing the role of world models in LLMs.
17. [DeepSeek R1 0528 hits 71% (+14.5 points from R1) on the Aider Polyglot Coding Leaderboard. How long will the Western lab justify its pricing?](/r/LocalLLaMA/comments/1l76ab7/deepseek_r1_0528_hits_71_145_pts_from_r1_on_aider/) (Score: 9)
    *   The thread compares the performance and pricing of DeepSeek R1 with models from "Western labs" on the Aider coding benchmark.
18. Counterpoint: "Apple doesn't see reasoning models as a major breakthrough over standard LLMs - new study"](https://www.reddit.com/r/singularity/comments/1l7dvn8/counterpoint_apple_doesnt_see_reasoning_models_as/) (Score: 9)
    *   This thread challenges the idea that Apple doesn't see reasoning models as a breakthrough, referencing their new study and prompting discussion on LLM capabilities.

# Detailed Analysis by Thread
**[Shipment lost. We’ll get em next time (Score: 556)](https://v.redd.it/ngglq0clbv5f1)**
*   **Summary:** This thread discusses a video of a robot failing at a shipping task, with commenters joking about the robot being overworked.
*   **Emotion:** The overall emotional tone is Neutral, with some comments expressing negative sentiment due to the perceived overworking of the robot and some users express positive emotion for laughing at the robots error.
*   **Top 3 Points of View:**
    *   The robot is overworked.
    *   The video highlights the limitations of current robotics technology.
    *   The robot will improve over time, without the need for breaks or pay raises.

**[o5 is in training…. (Score: 221)](https://x.com/dylan522p/status/1931858578748690518)**
*   **Summary:** The thread discusses a tweet suggesting that OpenAI's o5 model is in training, with commenters questioning the source and speculating about its capabilities.
*   **Emotion:** The overall emotional tone is Neutral, with users primarily seeking information and expressing curiosity. One user expresses negative sentiment because they hate the naming convention.
*   **Top 3 Points of View:**
    *   It is uncertain whether o5 is actually in training.
    *   The tweet may not be a reliable source of information.
    *   OpenAI may be shifting its reinforcement learning training for o4 and o5.

**[New SOTA on aider polyglot coding benchmark - Gemini with 32k thinking tokens. (Score: 204)](https://i.redd.it/d41kmdpwnw5f1.png)**
*   **Summary:** The thread discusses the new state-of-the-art performance of Gemini on a coding benchmark, with commenters focusing on the cost and comparing it to other models.
*   **Emotion:** The overall emotional tone is Neutral, with users expressing interest in the performance and cost-effectiveness of Gemini compared to other models.
*   **Top 3 Points of View:**
    *   Gemini's 32k thinking tokens significantly reduce failures in coding tasks.
    *   The cost of using Gemini is a key factor in its adoption.
    *   Google released something on par with OpenAI, maybe 2% better.

**[The Apple "Illusion of Thinking" Paper Maybe Corporate Damage Control (Score: 189)](https://www.reddit.com/r/singularity/comments/1l73qne/the_apple_illusion_of_thinking_paper_maybe/)**
*   **Summary:** The thread revolves around Apple's research paper critiquing the "thinking" capabilities of LLMs, with some suggesting it's a form of corporate damage control.
*   **Emotion:** The overall emotional tone is Neutral, with some users expressing skepticism towards Apple's motives and others defending the paper's findings.
*   **Top 3 Points of View:**
    *   Apple's paper is an attempt to downplay the capabilities of LLMs due to their own shortcomings in AI development.
    *   The paper is a fair analysis of the limitations of current LLMs, regardless of Apple's motivations.
    *   LLMs are being forced to perform tasks they are not designed for, leading to flawed results.

**[Breaking: OpenAI Hits $10B in Reoccurring Annualized Revenue, ahead of Forecasts, up from $3.7B last year per CNBC (Score: 151)](https://i.redd.it/uyqrtp449y5f1.jpeg)**
*   **Summary:** This thread discusses OpenAI's impressive revenue growth, with commenters debating whether the company is profitable and how it compares to competitors like Google and Microsoft.
*   **Emotion:** The overall emotional tone is Neutral, with some users expressing positive sentiment about OpenAI's success and others questioning its profitability.
*   **Top 3 Points of View:**
    *   OpenAI's revenue growth is a positive sign for the company and the AI industry as a whole.
    *   It is important to consider OpenAI's net balance (profitability) in addition to its revenue.
    *   OpenAI is ahead of revenue predictions and Google needs a strong competitor.

**[What’s with everyone obsessing over that apple paper? It’s obvious that CoT RL training results in better performance which is undeniable! (Score: 93)](https://www.reddit.com/r/singularity/comments/1l77u6t/whats_with_everyone_obsessing_over_that_apple/)**
*   **Summary:** The thread discusses the ongoing obsession with Apple's research paper on LLMs, with many users suggesting that the paper's findings are not novel or particularly insightful.
*   **Emotion:** The overall emotional tone is Neutral, with some users expressing annoyance at the continued focus on the Apple paper.
*   **Top 3 Points of View:**
    *   The Apple paper simply shows the limitations of AI and doesn't attack anyone.
    *   Studying the boundaries and shortcomings is a useful way to direct efforts and research.
    *   It is important to understand the regimes where AI works effectively and where it does not.

**[Why are so many people so obsessed with AGI, when current AI will still be revolutionary? (Score: 91)](https://www.reddit.com/r/singularity/comments/1l7b91a/why_are_so_many_people_so_obsessed_with_agi_when/)**
*   **Summary:** The thread explores the reasons behind the focus on Artificial General Intelligence (AGI), despite the revolutionary potential of current AI technologies.
*   **Emotion:** The overall emotional tone is Neutral, with some users expressing positive sentiment towards the potential of AGI and others focusing on the practical applications of current AI.
*   **Top 3 Points of View:**
    *   AGI is seen as a symbol of hope and a potential solution to many of the world's problems.
    *   AGI will be much more revolutionary and disrupt the status quo.
    *   Current AI will be revolutionary.

**[Scientists Grow Human Teeth In A Lab For The First Time (Score: 84)](https://www.techbusinessnews.com.au/news/scientists-grow-human-teeth-in-a-lab-for-the-first-time/)**
*   **Summary:** This thread discusses the recent breakthrough in growing human teeth in a lab, with some users expressing excitement about its potential applications in dentistry.
*   **Emotion:** The overall emotional tone is Positive, with users expressing excitement and hope about the implications of the breakthrough.
*   **Top 3 Points of View:**
    *   Growing human teeth in a lab is a significant breakthrough with potential for treating dental problems.
    *   There is a pill that blocks the protein that you started to manufacture after wisdom teeth and regrow your own.
    *   Finally some good news here that's not about AI!

**[We're still pretty far from embodied intelligence... (Gemini 2.5 Flash plays Final Fantasy) (Score: 79)](https://v.redd.it/1anm2g5ymt5f1)**
*   **Summary:** The discussion revolves around a video of Gemini 2.5 Flash attempting to play Final Fantasy, with commenters noting that while the AI's performance is impressive, it still has a long way to go before achieving embodied intelligence.
*   **Emotion:** The overall emotional tone is Neutral, with some users expressing positive sentiment about the progress of AI and others emphasizing the challenges that remain.
*   **Top 3 Points of View:**
    *   The fact that Gemini 2.5 Flash can play Final Fantasy at all is a significant achievement.
    *   We are still far from achieving true embodied intelligence.
    *   The delay between the LLM sending a receiving data affects game play.

**[Scaling Reinforcement Learning: Environments, Reward Hacking, Agents, Scaling Data (o4/o5 leaked info behind paywall) (Score: 69)](https://semianalysis.com/2025/06/08/scaling-reinforcement-learning-environments-reward-hacking-agents-scaling-data/)**
*   **Summary:** The thread discusses a paywalled article about scaling reinforcement learning, with commenters seeking access to the leaked information about o4 and o5 models.
*   **Emotion:** The overall emotional tone is Neutral, with users primarily expressing interest in accessing the paywalled content and discussing the credibility of the source.
*   **Top 3 Points of View:**
    *   There is interest in accessing the information about o4 and o5 models.
    *   It is unknown whether this source is credible.
    *   Scaling Reinforcement Learning: Environments, Reward Hacking, Agents, Scaling Data contains actual leaks.

**[Researchers pointing out their critiques of the Apple reasoning paper on Twitter (tldr; Context length limits seem the be the major road block, among other insights pointing to a poor methodology) (Score: 46)](https://x.com/RyanPGreenblatt/status/1931823002649542658?t=LFIet-126kGwblmrXbtHYg&s=19)**
*   **Summary:** This thread discusses criticisms of Apple's reasoning paper, particularly regarding context length limits and methodology.
*   **Emotion:** The overall emotional tone is Neutral, with researchers pointing out their critiques of the Apple reasoning paper.
*   **Top 3 Points of View:**
    *  Marcus' entire study is domain limited to employment of singular LLMs
    *  This isn’t a great objection and the authors pointed out that for the river crossing problem Claude 3.7 Sonnet stopped way short of its theoretical max reasoning tokens.
    * Apple is just trying to make noise to distract from the fact they are cooked.

**[Do the researchers at Apple, actually understand computational complexity? (Score: 44)](https://www.reddit.com/r/singularity/comments/1l6xmxf/do_the_researchers_at_apple_actually_understand/)**
*   **Summary:** The thread questions the understanding of computational complexity by Apple's researchers in their recent paper.
*   **Emotion:** The overall emotional tone is Neutral, with some expressing positive sentiment and some expressing negative sentiment.
*   **Top 3 Points of View:**
    *  Researchers at Apple are smarter than you.
    *  The research is factually flawed and no one bothered to check it.
    *  But the tower of Hanoi shows us that doubling the task size from n to 2n requires n squared resources.

**[For some recent graduates in the US, the AI job apocalypse may already be here (Score: 37)](https://www.thestar.com.my/tech/tech-news/2025/06/08/for-some-recent-graduates-in-the-us-the-ai-job-apocalypse-may-already-be-here)**
*   **Summary:** The thread discusses the impact of AI on recent graduates' job prospects.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *   What happens when they just can't repay student debt?

**["Embedding high-resolution touch across robotic hands enables adaptive human-like grasping" (Score: 22)](https://www.reddit.com/r/singularity/comments/1l7aqkm/embedding_highresolution_touch_across_robotic/)**
*   **Summary:** The thread highlights advancements in robotic hands, specifically high-resolution touch technology, and discusses the implications of achieving human-like grasping capabilities.
*   **Emotion:** The overall emotional tone is Positive, expressing excitement about the advancement.
*   **Top 3 Points of View:**
    *   >enables F-TAC to perform all 33 grasping types that the human hand can perform
    *   Cool to hear it quantified like that, I'm impressed
    *   Sexbots incoming

**[What do you think the odds of RSI being achievable are? (Score: 19)](https://www.reddit.com/r/singularity/comments/1l6xg9l/what_do_you_think_the_odds_of_rsi_being/)**
*   **Summary:** The discussion revolves around the possibility of achieving recursive self-improvement (RSI) in AI, with varying opinions on the likelihood and the current state of LLMs.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *  I think 100 all the big labs are focused on SWE so that Moses can write their own code. And RL is coming along nicely.
    *  100% RSI is achievable.
    *  AI has become great at generating photos, videos and text responses. It's decent at coding, but it doesn't reach the threshold where it surpasses human intelligence.

**[A lot of people talking about Apple's paper, but this one is way more important (Robust agents learn causal world models) (Score: 12)](https://www.reddit.com/r/singularity/comments/1l7cbf5/a_lot_of_people_talking_about_apples_paper_but/)**
*   **Summary:** The thread suggests that a paper on robust agents learning causal world models is more significant than Apple's paper, discussing the role of world models in LLMs.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *  LLMs have an internal world model that can predict game board states in Othello.
    *  This one is almost a year ago. Even before the wheel was invented.

**[DeepSeek R1 0528 hits 71% (+14.5 points from R1) on the Aider Polyglot Coding Leaderboard. How long will the Western lab justify its pricing? (Score: 9)](/r/LocalLLaMA/comments/1l76ab7/deepseek_r1_0528_hits_71_145_pts_from_r1_on_aider/)**
*   **Summary:** The thread compares the performance and pricing of DeepSeek R1 with models from "Western labs" on the Aider coding benchmark.
*   **Emotion:** The overall emotional tone is Neutral with some users expressing positive sentiment and some expressing negative sentiment.
*   **Top 3 Points of View:**
    *   i will always love open source models no matter who made them
    *   The marginal cost of intelligence is high with humans too in software.
    *  “The western lab” sets price according to how expensive the model is.

**[Counterpoint: "Apple doesn't see reasoning models as a major breakthrough over standard LLMs - new study" (Score: 9)](https://www.reddit.com/r/singularity/comments/1l7dvn8/counterpoint_apple_doesnt_see_reasoning_models_as/)**
*   **Summary:** This thread challenges the idea that Apple doesn't see reasoning models as a breakthrough, referencing their new study and prompting discussion on LLM capabilities.
*   **Emotion:** The overall emotional tone is Neutral.
*   **Top 3 Points of View:**
    *  The model can easily solve a ten disk instance of Hanoi. (They claim reasoning models collapse there). With ChatGPT code Interpreter (which is always included in ChatGPT if needed) it's trivial.
    * TLDR: LLMs are not capable to come up with an answer that doesn't already exist in the training set, and Apple proved that. What's controversial about it?
    * reasoning models *** for coding
