---
title: "Stable Diffusion Subreddit"
date: "2025-07-21"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] Krita AI is wonderful](https://v.redd.it/hu59oyyvy8ef1) (Score: 92)
    *   Users are discussing the Krita AI plugin, its capabilities, and its potential as a tool for artists.
2.  [The Gory Details of Finetuning SDXL and Wasting $16k](https://www.reddit.com/r/StableDiffusion/comments/1m5rn8h/the_gory_details_of_finetuning_sdxl_and_wasting/) (Score: 80)
    *   A user details their experience and the costs associated with fine-tuning SDXL, prompting discussion about the process and alternative models.
3.  [Wan text to image character sheet. Workflow in comments](https://i.redd.it/ggl2p897r9ef1.png) (Score: 54)
    *   Users are sharing and discussing workflows for generating character sheets using Wan, including hardware requirements and image-to-image applications.
4.  [FLOAT - Lip-sync model from a few months ago that you may have missed](https://v.redd.it/esjiq6r7j8ef1) (Score: 27)
    *   Users are testing and discussing a lip-sync model called FLOAT, its performance compared to other models, and its potential applications in video-to-video solutions.
5.  [[Kontext-Dev] Line art to photograph like image](https://www.reddit.com/gallery/1m5k7er) (Score: 17)
    *   Users are examining and commenting on the Kontext-Dev model's ability to transform line art into realistic images, with comparisons to Stable Diffusion.
6.  [ControlNet material generator for KKS](https://www.reddit.com/gallery/1m5kf63) (Score: 11)
    *   Users are pointing out that the ControlNet material generator for KKS is being sold.
7.  [3D Virtual Drone Video](https://v.redd.it/01k9o6dz69ef1) (Score: 8)
    *   Users are pointing the creator of the video to content previously posted to the subreddit that may provide help.
8.  [Is there any library/lora flux that helps with the words, ad sign/ cloth brands defect?](https://www.reddit.com/gallery/1m5pnwq) (Score: 7)
    *   Users are discussing solutions for fixing defects in generated images, such as words, ads, and cloth brands, recommending Photoshop, inpainting, and Flux Kontext.
9.  [Can Kontext take an image, and keep the face, clothing and background the same, but just change the pose (with better than 10% success rate)? Some people say it changes the face.](https://i.redd.it/3pjtirps0aef1.jpeg) (Score: 7)
    *   Users are discussing the limitations of using Kontext to change poses while preserving facial features, clothing, and backgrounds, and are sharing prompting guides.
10. [Wan2.1 prompt help to keep a second subject offscreen except hands/arms?](https://www.reddit.com/r/StableDiffusion/comments/1m5mo2s/wan21_prompt_help_to_keep_a_second_subject/) (Score: 2)
    *   Users suggest generating both subjects, then cropping and upscaling the image.
11. [Is there a more general sub like this, not specifically for SD?](https://www.reddit.com/r/StableDiffusion/comments/1m5rrmd/is_there_a_more_general_sub_like_this_not/) (Score: 1)
    *   Users are discussing whether this subreddit has evolved into one for open-source AI, not specifically SD.
12. [Shoujo anime made with AI](https://v.redd.it/lxtdvnn0i9ef1) (Score: 0)
    *   User points out that the post violates the rules of the subreddit.
13. [Here we are guys, AI is about to change UGC forever !](https://www.reddit.com/gallery/1m5jo0v) (Score: 0)
    *   Users are questioning the purpose of the post and requesting the poster provides more images.
14. [Wan2.1 first time](https://www.reddit.com/r/StableDiffusion/comments/1m5kajy/wan21_first_time/) (Score: 0)
    *   Users help the poster fix an error by using the umt5-xxl-fp8-e4m3fn-SCALED text encoder with a fp8 version of Wan2.1-fp8
15. [Help needed with T2V + I2V flow. (Wan 2.1, ComfyUI)](https://www.reddit.com/r/StableDiffusion/comments/1m5pjiu/help_needed_with_t2v_i2v_flow_wan_21_comfyui/) (Score: 0)
    *   Users provide a video to help the poster figure out what is going wrong.

# Detailed Analysis by Thread
**[Krita AI is wonderful (Score: 92)](https://v.redd.it/hu59oyyvy8ef1)**
*  **Summary:**  Users are discussing the Krita AI plugin, its capabilities, and its potential as a tool for artists. They express admiration for its ability to enhance human creativity and integrate with workflows like ComfyUI. There's also discussion about managing layers and the desire for similar integration in other programs like ProCreate.
*  **Emotion:** The overall emotional tone is positive, with users expressing excitement and appreciation for Krita AI. There are also neutral comments asking questions and seeking clarification.
*  **Top 3 Points of View:**
    *   Krita AI is a powerful tool that enhances the creative process for artists.
    *   Integration with ComfyUI and layer management are important aspects of using Krita AI effectively.
    *   There's a desire for similar AI integration in other art programs.

**[The Gory Details of Finetuning SDXL and Wasting $16k (Score: 80)](https://www.reddit.com/r/StableDiffusion/comments/1m5rn8h/the_gory_details_of_finetuning_sdxl_and_wasting/)**
*  **Summary:**  A user shares their experience and the financial cost ($16k) of fine-tuning SDXL, detailing the process and challenges. The post sparks a conversation about the efficiency and viability of fine-tuning, with users offering encouragement, asking for comparisons, and suggesting alternative models.
*  **Emotion:** The emotional tone is mixed. There's a sense of shared experience and learning, along with some humor and encouragement. The sentiment scores are largely neutral, reflecting factual reporting and questions.
*  **Top 3 Points of View:**
    *   Fine-tuning SDXL can be expensive and challenging.
    *   Comparisons with other models and datasets are valuable for understanding the results of fine-tuning.
    *   The community appreciates shared experiences and lessons learned, even from costly endeavors.

**[Wan text to image character sheet. Workflow in comments (Score: 54)](https://i.redd.it/ggl2p897r9ef1.png)**
*  **Summary:**  Users are sharing and discussing workflows for generating character sheets using Wan. The discussion includes expressing appreciation for shared workflows, questioning the hardware requirements for such workflows, and discussing the nuances of how the text to image generation works.
*  **Emotion:** The emotional tone is mostly positive with some neutral comments.
*  **Top 3 Points of View:**
    *   Shared workflows are valuable to the community.
    *   Hardware requirements are an important consideration for running these workflows.
    *   Users modify and improve upon existing workflows.

**[FLOAT - Lip-sync model from a few months ago that you may have missed (Score: 27)](https://v.redd.it/esjiq6r7j8ef1)**
*  **Summary:** Users are testing and discussing a lip-sync model called FLOAT. The discussion includes opinions that other models are better in some cases, the need for video-to-video solutions, and the desire for AI to be able to generate audio, lip sync, and understand context.
*  **Emotion:** The emotional tone is generally positive with neutral comments.
*  **Top 3 Points of View:**
    *   Lip-sync models are a valuable tool for video generation.
    *   Video-to-video solutions are still lacking.
    *   There is a desire to combine multiple AI technologies to create more immersive experiences.

**[[Kontext-Dev] Line art to photograph like image (Score: 17)](https://www.reddit.com/gallery/1m5k7er)**
*  **Summary:** Users are examining and commenting on the Kontext-Dev model's ability to transform line art into realistic images, with comparisons to Stable Diffusion. They are also wondering if it will work on plain 3D wireframes.
*  **Emotion:** The emotional tone is positive with neutral comments.
*  **Top 3 Points of View:**
    *   Kontext-Dev model does a better job converting line art into realistic images than SD.
    *   The community is asking about other applications for this model.
    *   The community appreciates well put-together posts.

**[ControlNet material generator for KKS (Score: 11)](https://www.reddit.com/gallery/1m5kf63)**
*  **Summary:** Users are pointing out that the ControlNet material generator for KKS is being sold.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The ControlNet material generator is being sold here [https://koikatsumodshop.booth.pm/](https://koikatsumodshop.booth.pm/).

**[3D Virtual Drone Video (Score: 8)](https://v.redd.it/01k9o6dz69ef1)**
*  **Summary:** Users are pointing the creator of the video to content previously posted to the subreddit that may provide help.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Creator may find the following link helpful: [https://www.reddit.com/r/StableDiffusion/comments/1m401m1/trained\_a\_kotext\_lora\_that\_transforms\_google/](https://www.reddit.com/r/StableDiffusion/comments/1m401m1/trained_a_kotext_lora_that_transforms_google/)

**[Is there any library/lora flux that helps with the words, ad sign/ cloth brands defect? (Score: 7)](https://www.reddit.com/gallery/1m5pnwq)**
*  **Summary:** Users are discussing solutions for fixing defects in generated images, such as words, ads, and cloth brands, recommending Photoshop, inpainting, and Flux Kontext.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Fix it in Photoshop.
    *   Use inpainting.
    *   Use Flux Kontext.

**[Can Kontext take an image, and keep the face, clothing and background the same, but just change the pose (with better than 10% success rate)? Some people say it changes the face. (Score: 7)](https://i.redd.it/3pjtirps0aef1.jpeg)**
*  **Summary:** Users are discussing the limitations of using Kontext to change poses while preserving facial features, clothing, and backgrounds, and are sharing prompting guides.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Kontext prompting works only with proper prompting. The team has put out a prompting guide for certain words.
    *   Black Forest Labs has a detailed prompting guide here: [https://docs.bfl.ai/guides/prompting\_guide\_kontext\_i2i](https://docs.bfl.ai/guides/prompting_guide_kontext_i2i).
    *   Training with multiple input images isn't available in the main training repos for making LORAs.

**[Wan2.1 prompt help to keep a second subject offscreen except hands/arms? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1m5mo2s/wan21_prompt_help_to_keep_a_second_subject/)**
*  **Summary:** Users suggest generating both subjects, then cropping and upscaling the image.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   You could generate both subjects in frame, crop it, then upscale it. Would probably be the easiest way.

**[Is there a more general sub like this, not specifically for SD? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m5rrmd/is_there_a_more_general_sub_like_this_not/)**
*  **Summary:** Users are discussing whether this subreddit has evolved into one for open-source AI, not specifically SD.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   This sub encompasses basically everything local gen AI that is not an LLM.
    *   The main rule on this subreddit is non-commercial tools.
    *   R/Stable Diffusion is a forum for open source AI generation topics.

**[Shoujo anime made with AI (Score: 0)](https://v.redd.it/lxtdvnn0i9ef1)**
*  **Summary:** User points out that the post violates the rules of the subreddit.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The post violates Rule #1.

**[Here we are guys, AI is about to change UGC forever ! (Score: 0)](https://www.reddit.com/gallery/1m5jo0v)**
*  **Summary:** Users are questioning the purpose of the post and requesting the poster provides more images.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   What is the purpose of this post?
    *   Pls post more of the first girl. Where can I find more?

**[Wan2.1 first time (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m5kajy/wan21_first_time/)**
*  **Summary:** Users help the poster fix an error by using the umt5-xxl-fp8-e4m3fn-SCALED text encoder with a fp8 version of Wan2.1-fp8
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Make sure to use the umt5-xxl-fp8-e4m3fn-SCALED text encoder with a fp8 version of Wan2.1-fp8

**[Help needed with T2V + I2V flow. (Wan 2.1, ComfyUI) (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m5pjiu/help_needed_with_t2v_i2v_flow_wan_21_comfyui/)**
*  **Summary:** Users provide a video to help the poster figure out what is going wrong.
*  **Emotion:** The emotional tone is positive.
*  **Top 3 Points of View:**
    *   This video was simple: [https://youtu.be/1Xaa-5YHq\_U?si=Jd2p-c527QrgdlSa](https://youtu.be/1Xaa-5YHq_U?si=Jd2p-c527QrgdlSa) hope it gives you an idea what went wrong.
