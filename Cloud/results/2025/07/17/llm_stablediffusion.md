---
title: "Stable Diffusion Subreddit"
date: "2025-07-17"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stable diffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [[D] They actually implemented it, thanks Radial Attention teams !!](https://i.redd.it/1yjdcfiffgdf1.png) (Score: 47)
    *   The discussion is about the implementation of Radial Attention for efficiently training AI models on long videos.
2.  [Average shot length in modern movies is around 2.5 seconds](https://www.reddit.com/r/StableDiffusion/comments/1m2dqjn/average_shot_length_in_modern_movies_is_around_25/) (Score: 39)
    *   The discussion centers around the average shot length in modern movies and how it relates to AI video generation, particularly regarding controllability, consistency, and the challenges of creating coherent scenes.
3.  [LoRa Block Weights (SDXL)](https://www.reddit.com/r/StableDiffusion/comments/1m2fpx7/lora_block_weights_sdxl/) (Score: 5)
    *   A user asks about LoRa Block Weights for SDXL, and another user believes they are meant to be used with the Flux model, not SDXL.
4.  [Subject Replacement using WAN 2.1 & VACE (for free)](https://v.redd.it/hx77vrjufgdf1) (Score: 2)
    *   The post showcases subject replacement using WAN 2.1 & VACE. The creator provides details on the pipeline, rendering time, and the functionalities of the discord bot.
5.  [What am I doing wrong when choosing a GPU setup? Or is it AUTOMATIC1111 issue?](https://www.reddit.com/r/StableDiffusion/comments/1m2dytk/what_am_i_doing_wrong_when_choosing_a_gpu_setup/) (Score: 2)
    *   Users are troubleshooting GPU setup issues with AUTOMATIC1111, suggesting the use of Forge UI as an alternative and discussing the maintenance status of A1111.
6.  [Lora training help](https://www.reddit.com/r/StableDiffusion/comments/1m2dc11/lora_training_help/) (Score: 1)
    *   The discussion revolves around using generated images for further training or retraining LoRA models, emphasizing the importance of image variety, especially when the original dataset is limited.
7.  [How important is RAM speed (not VRAM) for Stable Diffusion performance?](https://www.reddit.com/r/StableDiffusion/comments/1m2ddng/how_important_is_ram_speed_not_vram_for_stable/) (Score: 1)
    *   The post is about how important RAM speed (not VRAM) is for Stable Diffusion performance.
8.  [Help! LoRA training on Citai keeps failing with Wan 2.1 - Anyone experienced similar issues?](https://www.reddit.com/r/StableDiffusion/comments/1m2e1bu/help_lora_training_on_citai_keeps_failing_with/) (Score: 1)
    *   A user is seeking help with LoRA training failures on Citai using Wan 2.1, providing a screenshot of the error.
9.  [Rock the Ridiculous](https://i.redd.it/8wsn1pyxwgdf1.png) (Score: 0)
    *   The post seems to be an ad which is not well received.
10. [Fix plastic-looking character](https://i.redd.it/fi16om3uwgdf1.jpeg) (Score: 0)
    *   A user is seeking advice on how to fix a "plastic-looking character" in Stable Diffusion. Another user recommends tiling upscale based on SDXL and adding a little bit of grain in ComfyUI.
11. [Can I created a LoRA model for this?](https://www.reddit.com/gallery/1m2b0ik) (Score: 0)
    *   The user is asking if they can create a LoRA model, and another user suggests using Flux Redux instead.
12. [Systemwide slowdowns after diffusion? GPU degradation?](https://www.reddit.com/r/StableDiffusion/comments/1m29r45/systemwide_slowdowns_after_diffusion_gpu/) (Score: 0)
    *   The post discusses system-wide slowdowns after using diffusion software, and users suggest potential causes and solutions such as memory leaks, Windows issues, and checking CPU temperatures.
13. [Using Krita AI Diffusion utilized 100% of my GPU](https://www.reddit.com/r/StableDiffusion/comments/1m2c8pv/using_krita_ai_diffusion_utilized_100_of_my_gpu/) (Score: 0)
    *   The post discusses GPU utilization when using Krita AI Diffusion, with users sharing their experiences and suggesting that having sufficient VRAM and RAM can prevent lags caused by disk swapping.
14. [Onetrainer not creating caption files](https://www.reddit.com/r/StableDiffusion/comments/1m2cc47/onetrainer_not_creating_caption_files/) (Score: 0)
    *   A user is having issues with Onetrainer not creating caption files, and another user recommends using better captioning tools like JoyCaption or TagGUI instead of the outdated BLIP.
15. [Websites that recreate styles](https://www.reddit.com/r/StableDiffusion/comments/1m2f70v/websites_that_recreate_styles/) (Score: 0)
    *   The user is asking about websites that recreate styles and another user suggested to train style LoRAs for free on civitai and tensor. art or use Flux-Kontext by using an image as a reference style.
16. [Can someone tell me how Higgsfield are making such high quality images, model?](https://www.reddit.com/r/StableDiffusion/comments/1m2gk89/can_someone_tell_me_how_higgsfield_are_making/) (Score: 0)
    *   A user asks how Higgsfield creates high quality images, and another user suspects the post is a bot ad.
17. [Another Attempt at a Music Video - “Just Need My 5090”](https://youtu.be/bYhXr7E7u08?si=XAJB8WkyOljBv8K3) (Score: 0)
    *   A user shares a music video created using AI and asks about the lip sync process.

# Detailed Analysis by Thread
**[[D] They actually implemented it, thanks Radial Attention teams !! (Score: 47)](https://i.redd.it/1yjdcfiffgdf1.png)**
*  **Summary:** The discussion is about the implementation of Radial Attention, a new method that efficiently trains AI models on long videos, reducing training costs and enabling faster generation of longer videos while using existing LoRAs.
*  **Emotion:** The overall emotional tone is neutral, with comments mainly focusing on understanding and discussing the technical aspects of the implementation. One comment shows positive sentiment hoping for SageAttention 2 soon.
*  **Top 3 Points of View:**
    * Radial Attention reduces training costs by 4x.
    * Users can generate 4x longer videos faster while using existing LoRAs.
    * Some users are wondering about implementation details and comparisons with other methods like SA 2++ and Nunchaku.

**[Average shot length in modern movies is around 2.5 seconds (Score: 39)](https://www.reddit.com/r/StableDiffusion/comments/1m2dqjn/average_shot_length_in_modern_movies_is_around_25/)**
*  **Summary:** The discussion revolves around the average shot length in modern movies (around 2.5 seconds) and its implications for AI-generated video. Participants discuss controllability, consistency, repeatability, and the challenges of creating coherent scenes with AI.
*  **Emotion:** The overall emotional tone is neutral to slightly negative, with a focus on the limitations and challenges of current AI video generation technology.
*  **Top 3 Points of View:**
    * Modern movies use short shot lengths, making controllability and consistency more important than long, continuous shots in AI video generation.
    * Creating coherent scenes with AI is challenging due to character and environment consistency issues.
    * While the technical requirements for making full-length movies with AI are almost met, the quality and ability to generate dialogue and music on consumer hardware still lag commercial platforms.

**[LoRa Block Weights (SDXL) (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1m2fpx7/lora_block_weights_sdxl/)**
*  **Summary:** A user asks about LoRa Block Weights for SDXL, and another user believes they are meant to be used with the Flux model, not SDXL.
*  **Emotion:** Neutral. The discussion is short and informational.
*  **Top 3 Points of View:**
    * LoRa Block Weights may be intended for the Flux model rather than SDXL.

**[Subject Replacement using WAN 2.1 & VACE (for free) (Score: 2)](https://v.redd.it/hx77vrjufgdf1)**
*  **Summary:** The post showcases subject replacement using WAN 2.1 & VACE. The creator provides details on the pipeline, rendering time, and the functionalities of the discord bot.
*  **Emotion:** Neutral, focusing on providing information and seeking feedback.
*  **Top 3 Points of View:**
    * The pipeline adjusts the lightning to the corresponding scene before it goes into the WAN 2.1 Pipeline.
    *  It takes 4 minutes to render a 5 second shot (max. 81 frames) on the same hardware.
    * Current discord bot needs prompt for context, face reference (or body) and a video reference. Atm only does body swap.

**[What am I doing wrong when choosing a GPU setup? Or is it AUTOMATIC1111 issue? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1m2dytk/what_am_i_doing_wrong_when_choosing_a_gpu_setup/)**
*  **Summary:** Users are troubleshooting GPU setup issues with AUTOMATIC1111, suggesting the use of Forge UI as an alternative and discussing the maintenance status of A1111.
*  **Emotion:** Neutral, with a problem-solving focus.
*  **Top 3 Points of View:**
    * Troubleshooting A1111 is difficult.
    * Forge UI is a good alternative to A1111.
    * A1111 is no longer actively maintained.

**[Lora training help (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m2dc11/lora_training_help/)**
*  **Summary:** The discussion revolves around using generated images for further training or retraining LoRA models, emphasizing the importance of image variety, especially when the original dataset is limited.
*  **Emotion:** Positive, offering encouragement and advice.
*  **Top 3 Points of View:**
    * It is acceptable to use generated images for further training LoRA models.
    * Image variety is important, especially with limited datasets.

**[How important is RAM speed (not VRAM) for Stable Diffusion performance? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m2ddng/how_important_is_ram_speed_not_vram_for_stable/)**
*  **Summary:** The post is about how important RAM speed (not VRAM) is for Stable Diffusion performance.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Faster RAM helps load/unload models faster.
    * DDR5 5400 MHz speed is generally enough for a PCI-E 4.0 x16 link.
    * You do not especially need fast ram, just plenty of it choose more ram not the fastest ram within your budget.

**[Help! LoRA training on Citai keeps failing with Wan 2.1 - Anyone experienced similar issues? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m2e1bu/help_lora_training_on_citai_keeps_failing_with/)**
*  **Summary:** A user is seeking help with LoRA training failures on Citai using Wan 2.1, providing a screenshot of the error.
*  **Emotion:** Neutral, a user asking for help.
*  **Top 3 Points of View:**
    * The user is experiencing errors during LoRA training with Citai and Wan 2.1.

**[Rock the Ridiculous (Score: 0)](https://i.redd.it/8wsn1pyxwgdf1.png)**
*  **Summary:** The post seems to be an ad which is not well received.
*  **Emotion:** Negative
*  **Top 3 Points of View:**
    * The user is not happy with the ad.

**[Fix plastic-looking character (Score: 0)](https://i.redd.it/fi16om3uwgdf1.jpeg)**
*  **Summary:** A user is seeking advice on how to fix a "plastic-looking character" in Stable Diffusion. Another user recommends tiling upscale based on SDXL and adding a little bit of grain in ComfyUI.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Use tiling upscale based on SDXL.
    * Adding a little bit of grain in ComfyUI.

**[Can I created a LoRA model for this? (Score: 0)](https://www.reddit.com/gallery/1m2b0ik)**
*  **Summary:** The user is asking if they can create a LoRA model, and another user suggests using Flux Redux instead.
*  **Emotion:** Positive
*  **Top 3 Points of View:**
    * You can create endless revisions with Flux Redux

**[Systemwide slowdowns after diffusion? GPU degradation? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m29r45/systemwide_slowdowns_after_diffusion_gpu/)**
*  **Summary:** The post discusses system-wide slowdowns after using diffusion software, and users suggest potential causes and solutions such as memory leaks, Windows issues, and checking CPU temperatures.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Windows is junk.
    * If you have a spare disk or can make a partition, install Linux Mint Cinnamon with n Nvidia drivers.
    * Check the temps of your CPU.

**[Using Krita AI Diffusion utilized 100% of my GPU (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m2c8pv/using_krita_ai_diffusion_utilized_100_of_my_gpu/)**
*  **Summary:** The post discusses GPU utilization when using Krita AI Diffusion, with users sharing their experiences and suggesting that having sufficient VRAM and RAM can prevent lags caused by disk swapping.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * 12GB VRAM and 64GB RAM gives enough space so it doesn't need to disk swap anything.
    * RX 5060 seems to have only 8GB VRAM, which is below the minimum if you use big model.

**[Onetrainer not creating caption files (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m2cc47/onetrainer_not_creating_caption_files/)**
*  **Summary:** A user is having issues with Onetrainer not creating caption files, and another user recommends using better captioning tools like JoyCaption or TagGUI instead of the outdated BLIP.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * You really shouldn't use blip as your captioning tool.
    * Use TagGUI from github, which autoinstalls any you pick.

**[Websites that recreate styles (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m2f70v/websites_that_recreate_styles/)**
*  **Summary:** The user is asking about websites that recreate styles and another user suggested to train style LoRAs for free on civitai and tensor. art or use Flux-Kontext by using an image as a reference style.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * Train style LoRAs for free on civitai and tensor. art.
    * Use Flux-Kontext by using an image as a reference style.

**[Can someone tell me how Higgsfield are making such high quality images, model? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m2gk89/can_someone_tell_me_how_higgsfield_are_making/)**
*  **Summary:** A user asks how Higgsfield creates high quality images, and another user suspects the post is a bot ad.
*  **Emotion:** Negative
*  **Top 3 Points of View:**
    * The user is not happy and suspects the post is an ad.

**[Another Attempt at a Music Video - “Just Need My 5090” (Score: 0)](https://youtu.be/bYhXr7E7u08?si=XAJB8WkyOljBv8K3)**
*  **Summary:** A user shares a music video created using AI and asks about the lip sync process.
*  **Emotion:** Neutral
*  **Top 3 Points of View:**
    * The user is asking how the lip sync was done.
