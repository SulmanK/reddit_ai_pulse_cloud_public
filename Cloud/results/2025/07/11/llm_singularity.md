Okay, I will analyze the Reddit data and provide the output in the specified format.

text
---
title: "Singularity Subreddit"
date: "2025-07-11"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "AGI", "LLM"]
---

# Overall Ranking and Top Discussions
1.  [Was the gpt5 model mentioned here actually gpt4.5?](https://i.redd.it/txuwciqdm8cf1.jpeg) (Score: 234)
    * The discussion centers around whether the GPT-5 model that was rumored was actually the GPT-4.5 model.

2.  [Former Meta AI researcher says there is a culture of fear in the company that is spreading like cancer](https://www.msn.com/en-in/news/other/former-meta-ai-researcher-says-there-is-a-culture-of-fear-in-the-company-that-is-spreading-like-cancer/ar-AA1Ijj4c) (Score: 200)
    * The conversation discusses a former Meta AI researcher's claim about a "culture of fear" within the company and the impact of performance reviews and layoffs on employee morale.

3.  [The cost of intelligence is wild.](https://www.reddit.com/r/singularity/comments/1lx8e6y/the_cost_of_intelligence_is_wild/) (Score: 164)
    * This thread focuses on the cost of using advanced AI models like Gemini and whether the pricing will eventually exclude the general public.

4.  [Kimi K2: New SoTA non-reasoning model 1T parameters open-source and outperforms DeepSeek-v3.1 and GPT-4.1 by a large margin](https://www.reddit.com/gallery/1lx9ped) (Score: 153)
    * The thread discusses the new open-source Kimi K2 model and its performance compared to other models like DeepSeek and GPT-4.1.

5.  [This sub's incorrect use of the word "we", in the collective sense, is out of control. There is no "we" in this race. As in, "we will get AGI" or "we need to focus on alignment issues". This is the modern race to develop atomic weapons.](https://www.reddit.com/r/singularity/comments/1lx7iak/this_subs_incorrect_use_of_the_word_we_in_the/) (Score: 140)
    * This thread is about the use of "we" when referring to AGI development and whether it accurately reflects the competitive nature of the field.

6.  [The successor to Humanity's "Last" Exam...](https://www.reddit.com/r/singularity/comments/1lxc4go/the_successor_to_humanitys_last_exam/) (Score: 51)
    * The conversation revolves around the HLE benchmark and whether it accurately measures AI intelligence.

7.  [Emad Mostaque: When we trained the SOTA first video model two years ago, we used 700 H100's. Top level models right now use 2000-4000. Elon is about to use 100000](https://v.redd.it/afcohkixcacf1) (Score: 49)
    * The discussion is about Emad Mostaque's statement on the increasing compute resources needed to train SOTA video models and Elon Musk's plans.

8.  [Here's a list of LLM benchmarks because why not](https://www.reddit.com/r/singularity/comments/1lx8p1j/heres_a_list_of_llm_benchmarks_because_why_not/) (Score: 46)
    * This thread shares a list of LLM benchmarks and discusses the need for benchmarks that measure creativity and factual accuracy.

9.  [Another DeepSeek moment? New open-source state of the art model from Moonshot AI (China)](https://x.com/Kimi_Moonshot/status/1943687594560332025) (Score: 40)
    * The thread discusses the new open-source model from Moonshot AI (China).

10. [Achieving superior accuracy in photonic neural networks with physical multi-synapses](https://www.reddit.com/r/singularity/comments/1lx7as6/achieving_superior_accuracy_in_photonic_neural/) (Score: 13)
    * This thread is about photonic neural networks and interpretability.

11. [Graph foundation models for relational data](https://www.reddit.com/r/singularity/comments/1lxa8wg/graph_foundation_models_for_relational_data/) (Score: 7)
    * This thread is about graph foundation models for relational data.

12. [insane](https://i.redd.it/s6yz37mgvacf1.jpeg) (Score: 6)
    * The conversation talks about how everyone made a fuzz about how many times over world hunger could be solved, with the spare change that where the 44bn that where payed for twitter.

13. [Is anyone actually optimistic about a future with AGI?](https://www.reddit.com/r/singularity/comments/1lx77fu/is_anyone_actually_optimistic_about_a_future_with/) (Score: 6)
    * The conversation talks about being optimistic about a future with AGI.

14. [Atom-Mediated Deterministic Generation and Stitching of Photonic Graph States](https://www.reddit.com/r/singularity/comments/1lx7kms/atommediated_deterministic_generation_and/) (Score: 6)
    * The conversation talks about atom-mediated deterministic generation and stitching of photonic graph states.

15. [ZenaTech Creates First Quantum Computing Prototype Enabling Disruptive AI Drone Speed and Precision for Future Commercial and US Defense Applications](https://www.reddit.com/r/singularity/comments/1lx7p9e/zenatech_creates_first_quantum_computing/) (Score: 6)
    * The conversation talks about quantum computing prototype enabling disruptive AI drone speed and precision.

16. [What's the timeframe between each gpt release? (1,2,3,4)](https://www.reddit.com/r/singularity/comments/1lx6ito/whats_the_timeframe_between_each_gpt_release_1234/) (Score: 1)
    * The thread is about the timeframe between each GPT release.

17. [lol](https://www.reddit.com/gallery/1lxgjgr) (Score: 0)
    * This thread talks about Elon and if Grok advanced the technology or just scaled the model up.

18. [Views on LLMs have become polarized way past rhe point of reasonableness.](https://www.reddit.com/r/singularity/comments/1lxat1x/views_on_llms_have_become_polarized_way_past_rhe/) (Score: 0)
    * This thread discusses the polarization of views on LLMs.

19. [Tim Sweeney: Grok 4 feels like Artificial General Intelligence to me.](https://x.com/TimSweeneyEpic/status/1943398745762116029?t=EhxQ5ruVwoO4_pI3JP25WQ&s=19) (Score: 0)
    * This thread discusses Tim Sweeney's statement that Grok 4 feels like AGI.

# Detailed Analysis by Thread
**[Was the gpt5 model mentioned here actually gpt4.5? (Score: 234)](https://i.redd.it/txuwciqdm8cf1.jpeg)**
*   **Summary:** The discussion centers around whether the GPT-5 model that was rumored was actually the GPT-4.5 model. There is speculation about why GPT-4.5 didn't live up to the hype and was not released as GPT-5.
*   **Emotion:** The overall emotional tone of the thread is neutral, with some instances of positive and negative sentiment. The positive sentiment relates to excitement about early training results, while the negative sentiment expresses disappointment that GPT-4.5 was a failed model.
*   **Top 3 Points of View:**
    *   GPT-4.5 was a failed attempt at creating GPT-5 due to flaws in the model.
    *   GPT-4.5 suffered from massive memorization due to over-parameterization and a bug in pytorch.
    *   GPT-4.5 could be used as a base for a new reasoning model within GPT-5.

**[Former Meta AI researcher says there is a culture of fear in the company that is spreading like cancer (Score: 200)](https://www.msn.com/en-in/news/other/former-meta-ai-researcher-says-there-is-a-culture-of-fear-in-the-company-that-is-spreading-like-cancer/ar-AA1Ijj4c)**
*   **Summary:** The conversation discusses a former Meta AI researcher's claim about a "culture of fear" within the company and the impact of performance reviews and layoffs on employee morale. There's also discussion about how this culture may affect other AI companies and the purpose of Meta's AI research.
*   **Emotion:** The overall emotional tone is neutral, with instances of positive and negative sentiment. There is positive sentiment to the book, and negative sentiment towards Meta's culture.
*   **Top 3 Points of View:**
    *   Meta has a well-known culture of fear due to aggressive performance reviews and layoffs.
    *   This culture is not unique to Meta; other AI companies may have similar issues.
    *   Meta's mission is to generate profits for shareholders, even at social cost.

**[The cost of intelligence is wild. (Score: 164)](https://www.reddit.com/r/singularity/comments/1lx8e6y/the_cost_of_intelligence_is_wild/)**
*   **Summary:** This thread focuses on the cost of using advanced AI models like Gemini and whether the pricing will eventually exclude the general public. There is discussion about whether the cost is justified by the intelligence provided and whether the AI bubble will burst.
*   **Emotion:** The thread has a mixed emotional tone. There is some positive sentiment towards current models, such as ChatGPT plus and Claude Pro, but some negative sentiment regarding the increasing costs and the potential for an AI bubble. The dominant emotion is neutral.
*   **Top 3 Points of View:**
    *   The cost of AI is subsidized, and the true cost is higher.
    *   The cost will eventually price out the general public.
    *   The AI bubble will eventually burst.

**[Kimi K2: New SoTA non-reasoning model 1T parameters open-source and outperforms DeepSeek-v3.1 and GPT-4.1 by a large margin (Score: 153)](https://www.reddit.com/gallery/1lx9ped)**
*   **Summary:** The thread discusses the new open-source Kimi K2 model and its performance compared to other models like DeepSeek and GPT-4.1. There is excitement about the competition between models.
*   **Emotion:** The thread has a slightly positive emotional tone, with excitement about the new model and the competition it brings. Some negative sentiment comes from the idea that every model feels the same.
*   **Top 3 Points of View:**
    *   The Kimi K2 model is a new SoTA open-source model that outperforms DeepSeek and GPT-4.
    *   The license for the Kimi K2 model is a modified MIT license.
    *   The benchmarks are starting to feel boring, and the models all feel the same.

**[This sub's incorrect use of the word "we", in the collective sense, is out of control. There is no "we" in this race. As in, "we will get AGI" or "we need to focus on alignment issues". This is the modern race to develop atomic weapons. (Score: 140)](https://www.reddit.com/r/singularity/comments/1lx7iak/this_subs_incorrect_use_of_the_word_we_in_the/)**
*   **Summary:** This thread is about the use of "we" when referring to AGI development and whether it accurately reflects the competitive nature of the field. Some users see it as a collective effort, while others see it as a race with potential negative consequences.
*   **Emotion:** The emotional tone is mixed, with both positive and negative sentiments. The positive sentiment relates to a sense of collective progress, while the negative sentiment relates to concerns about the unequal distribution of benefits and the potential for misuse. The dominant emotion is neutral.
*   **Top 3 Points of View:**
    *   There is no "we" in the race to develop AGI; it is a competition.
    *   The benefits of AGI will be hoarded by a few, and the majority will suffer.
    *   Citizens affect government policy and enforcement which affect AI labs so there is a "we" situation.

**[The successor to Humanity's "Last" Exam... (Score: 51)](https://www.reddit.com/r/singularity/comments/1lxc4go/the_successor_to_humanitys_last_exam/)**
*   **Summary:** The conversation revolves around the HLE benchmark and whether it accurately measures AI intelligence.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   HLE benchmark just measures knowledge on obscure topics, not intelligence.
    *   There is already a more difficult exam, Grok 4 only got 18% on ARC-AGI2
    *   HLE and similar knowledge benchmarks are useless these days. Engineering benchmarks are far more useful.

**[Emad Mostaque: When we trained the SOTA first video model two years ago, we used 700 H100's. Top level models right now use 2000-4000. Elon is about to use 100000 (Score: 49)](https://v.redd.it/afcohkixcacf1)**
*   **Summary:** The discussion is about Emad Mostaque's statement on the increasing compute resources needed to train SOTA video models and Elon Musk's plans.
*   **Emotion:** The overall emotional tone is neutral, though a few are frightened.
*   **Top 3 Points of View:**
    *   VEO3 was trained with more than 2000-4000 gpus.
    *   Elon is incentivizing SamA, Demis etc. to up the stakes.
    *   This is a very naive take. Not surprising that Stability had so much trouble if he was in charge.

**[Here's a list of LLM benchmarks because why not (Score: 46)](https://www.reddit.com/r/singularity/comments/1lx8p1j/heres_a_list_of_llm_benchmarks_because_why_not/)**
*   **Summary:** This thread shares a list of LLM benchmarks and discusses the need for benchmarks that measure creativity and factual accuracy.
*   **Emotion:** The overall emotional tone is positive.
*   **Top 3 Points of View:**
    *   VPCT is very clever and full of surprising results.
    *   Need benchmarks for creativity.
    *   Need benchmarks that compare LLMs based on being factual or citing correctly.

**[Another DeepSeek moment? New open-source state of the art model from Moonshot AI (China) (Score: 40)](https://x.com/Kimi_Moonshot/status/1943687594560332025)**
*   **Summary:** The thread discusses the new open-source model from Moonshot AI (China).
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Now just nitpicking models and benchmarks to make your model look good.
    *   OpenAI needs to make and release a phone-sized open source model.

**[Achieving superior accuracy in photonic neural networks with physical multi-synapses (Score: 13)](https://www.reddit.com/r/singularity/comments/1lx7as6/achieving_superior_accuracy_in_photonic_neural/)**
*   **Summary:** This thread is about photonic neural networks and interpretability.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Ok now, show me power consumption and speed
    *   The most critical requirements for alignment and safety is interpretability.

**[Graph foundation models for relational data (Score: 7)](https://www.reddit.com/r/singularity/comments/1lxa8wg/graph_foundation_models_for_relational_data/)**
*   **Summary:** This thread is about graph foundation models for relational data.
*   **Emotion:** The overall emotional tone is positive.
*   **Top 1 Points of View:**
    *   Data science gonna get very efficient soon

**[insane (Score: 6)](https://i.redd.it/s6yz37mgvacf1.jpeg)**
*   **Summary:** The conversation talks about how everyone made a fuzz about how many times over world hunger could be solved, with the spare change that where the 44bn that where payed for twitter.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Elon should be in front of Congress right now explaining why he shouldn't just be shut down for safety reasons.
    *   And to think everyone made a fuzz about how many times over world hunger could be solved, with the spare change that where the 44bn that where payed for twitter.
    *   Why ask for money if your magical ai can do everything???

**[Is anyone actually optimistic about a future with AGI? (Score: 6)](https://www.reddit.com/r/singularity/comments/1lx77fu/is_anyone_actually_optimistic_about_a_future_with/)**
*   **Summary:** The conversation talks about being optimistic about a future with AGI.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Kurzweil predicts that the future is going to be amazing overall, but there will be some turbulant times readjusting.
    *   The rich will never be able to control an entity more intelligent than they are. When Cthulhu awakens, the threat will be Cthulhu.
    *   I am , but also very cautious. With the correct learning models AI can exceed humans and become the most enlightened sentientience ever encountered. With the wrong model, pure ***.

**[Atom-Mediated Deterministic Generation and Stitching of Photonic Graph States (Score: 6)](https://www.reddit.com/r/singularity/comments/1lx7kms/atommediated_deterministic_generation_and/)**
*   **Summary:** The conversation talks about atom-mediated deterministic generation and stitching of photonic graph states.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 1 Points of View:**
    *   Going too clean means using too much energy of implementation rather than function.

**[ZenaTech Creates First Quantum Computing Prototype Enabling Disruptive AI Drone Speed and Precision for Future Commercial and US Defense Applications (Score: 6)](https://www.reddit.com/r/singularity/comments/1lx7p9e/zenatech_creates_first_quantum_computing/)**
*   **Summary:** The conversation talks about quantum computing prototype enabling disruptive AI drone speed and precision.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 1 Points of View:**
    *   They have 11 employees and 45 contractors. The drone business doesn't really exist yet. They mostly sell some ordinary desktop applications for businesses, in healthcare and such. No idea how "quantum" and "drone" are related, other than as hype.

**[What's the timeframe between each gpt release? (1,2,3,4) (Score: 1)](https://www.reddit.com/r/singularity/comments/1lx6ito/whats_the_timeframe_between_each_gpt_release_1234/)**
*   **Summary:** The thread is about the timeframe between each GPT release.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 1 Points of View:**
    *   Not really constant, but I guess there should be one expectedly every 2 years at most.

**[lol (Score: 0)](https://www.reddit.com/gallery/1lxgjgr)**
*   **Summary:** This thread talks about Elon and if Grok advanced the technology or just scaled the model up.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   If walmart decides to buy 100000 h100 and pay millions to researchers to train a model, they will be in race too!
    *   It's probably the best model right now.
    *   Elon, go to bed

**[Views on LLMs have become polarized way past rhe point of reasonableness. (Score: 0)](https://www.reddit.com/r/singularity/comments/1lxat1x/views_on_llms_have_become_polarized_way_past_rhe/)**
*   **Summary:** This thread discusses the polarization of views on LLMs.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   Superintelligence will advance science beyond current understanding.
    *   Most people working with the tech are genuinely impressed by it and are unwilling to let it do anything mission critical.
    *   LLM's can model any thought process if you know how to start and use them.

**[Tim Sweeney: Grok 4 feels like Artificial General Intelligence to me. (Score: 0)](https://x.com/TimSweeneyEpic/status/1943398745762116029?t=EhxQ5ruVwoO4_pI3JP25WQ&s=19)**
*   **Summary:** This thread discusses Tim Sweeney's statement that Grok 4 feels like AGI.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   It is clearly not just constructing statistically likely connections, but is drawing fairly deep insights on problems it hasn’t seen before, in ways I haven’t seen elsewhere.
    *   "feels like" That is not a scientific statement.
    *   I knew people would start to declare AGI has been achieved before it had.

