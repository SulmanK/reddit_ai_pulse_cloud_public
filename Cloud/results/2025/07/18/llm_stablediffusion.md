---
title: "Stable Diffusion Subreddit"
date: "2025-07-18"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [InScene: Flux Kontext LoRA for generating consistent shots in a scene - link below](https://i.redd.it/652mqvtukndf1.png) (Score: 183)
    *   The thread discusses a new LoRA called InScene for generating consistent shots in a scene using Flux Kontext.
2.  [HiDream-E1-1 is the new best open source image editing model, beating FLUX Kontext Dev by 50 ELO on Artificial Analysis](https://www.reddit.com/r/StableDiffusion/comments/1m374dc/hidreame11_is_the_new_best_open_source_image/) (Score: 123)
    *   The thread is about the release of HiDream-E1-1, a new open-source image editing model, and compares it to FLUX Kontext Dev.
3.  [PusaV1 just released on HuggingFace.](https://huggingface.co/RaphaelLiu/PusaV1) (Score: 80)
    *   The thread discusses the release of PusaV1 on HuggingFace and its potential uses as a LoRA or extension for improving image and video quality.
4.  [I made one more storybook (using Flux), for my daughter #2, with her as main character. Included the suggestions many of you made in my last post. She loves playing dentist, so her reaction after seeing this was really fun and heartwarming. Please share ideas on improvements. :)](https://v.redd.it/33vfyp9ltmdf1) (Score: 33)
    *   The thread showcases a storybook created using Flux for the author's daughter and seeks feedback for improvements.
5.  [Wan 2.1 Woman surfing in the Pacific Ocean.](https://v.redd.it/ccradbmbgndf1) (Score: 14)
    *   The thread shows a video generated using Wan 2.1 of a woman surfing and discusses its quality and potential issues.
6.  [Kontext Flux Watermark/text/chatbubble removal WF](https://www.reddit.com/gallery/1m3adm5) (Score: 12)
    *   This thread discusses a workflow for removing watermarks and text from images using Kontext Flux.
7.  [Flux Kontext Mask Inpainting Workflow](https://i.redd.it/rsc1l8rdiodf1.png) (Score: 1)
    *   This thread shares a ComfyUI workflow for mask inpainting using Flux Kontext.
8.  [Need Advice From ComfyUI Pro - Best img2img model For Realism?](https://www.reddit.com/r/StableDiffusion/comments/1m37btt/need_advice_from_comfyui_pro_best_img2img_model/) (Score: 1)
    *   The thread seeks advice on the best img2img model for achieving realism in ComfyUI.
9.  [What is the difference between these 2 nunchaku models?](https://www.reddit.com/r/StableDiffusion/comments/1m37mz0/what_is_the_difference_between_these_2_nunchaku/) (Score: 1)
    *   The thread asks about the differences between two versions of the Nunchaku model for Stable Diffusion.
10. [Multiple (5 image) concatenate workflow for Kontext?](https://www.reddit.com/r/StableDiffusion/comments/1m399bo/multiple_5_image_concatenate_workflow_for_kontext/) (Score: 1)
    *   The thread inquires about a workflow for concatenating multiple images (specifically 5) for use with Kontext.
11. [How to convert own models for nunchaku?](https://www.reddit.com/r/StableDiffusion/comments/1m39e3p/how_to_convert_own_models_for_nunchaku/) (Score: 1)
    *   The thread asks about how to convert custom models for use with Nunchaku.
12. [AI Prompt Roulette](https://blush-noami-71.tiiny.site/?mode=suggestions) (Score: 0)
    *   The thread shares an AI prompt roulette tool and gathers feedback.
13. [How can I create images like this using stable diffusion. (what model+loras)](https://i.redd.it/sbrykuovkndf1.jpeg) (Score: 0)
    *   The thread asks for recommendations on models and LoRAs to create images similar to a given example.
14. [Is this the best model to generate +18 Anime/***?](https://www.reddit.com/r/StableDiffusion/comments/1m37z0j/is_this_the_best_model_to_generate_18_animehentai/) (Score: 0)
    *   This thread asks for the best model to create +18 Anime.
15. [SD 1.5 Are Tan Lines (or Tan Skin) Even Possible?](https://www.reddit.com/r/StableDiffusion/comments/1m3aieg/sd_15_are_tan_lines_or_tan_skin_even_possible/) (Score: 0)
    *   The thread questions whether tan lines or tan skin can be generated in SD 1.5.
16. [Which ai model does this creator use?](https://www.reddit.com/r/StableDiffusion/comments/1m3ak7j/which_ai_model_does_this_creator_use/) (Score: 0)
    *   The thread asks for identification of the AI model used by a specific creator.
17. [So I started studying/taking courses for 3D animation a few months ago, and I would like this community's opinion on the future.](https://www.reddit.com/r/StableDiffusion/comments/1m3chl3/so_i_started_studyingtaking_courses_for_3d/) (Score: 0)
    *   The thread seeks opinions on the future of 3D animation in the context of AI advancements.

# Detailed Analysis by Thread
**[InScene: Flux Kontext LoRA for generating consistent shots in a scene - link below (Score: 183)](https://i.redd.it/652mqvtukndf1.png)**
*  **Summary:** This thread is centered around the release of a new LoRA called "InScene" designed for creating consistent shots within a scene using Flux Kontext. The comments express excitement and gratitude towards the creator, with users eager to try it out and share their results. Some comments also seek clarification on specific usage instructions.
*  **Emotion:** The overall emotional tone of the thread is positive. The comments express appreciation and excitement about the new LoRA.
*  **Top 3 Points of View:**
    *   Users are thankful for the contribution and express excitement to try the LoRA.
    *   Some users are seeking clarification on the correct prompting method.
    *   Users believe the LoRA will be helpful for maintaining consistency in generated content.

**[HiDream-E1-1 is the new best open source image editing model, beating FLUX Kontext Dev by 50 ELO on Artificial Analysis (Score: 123)](https://www.reddit.com/r/StableDiffusion/comments/1m374dc/hidreame11_is_the_new_best_open_source_image/)**
*  **Summary:** The thread discusses the announcement of HiDream-E1-1 as a new open-source image editing model that outperforms FLUX Kontext Dev in artificial analysis. Commenters are discussing its VRAM requirements, the availability of ComfyUI workflows, and comparing its performance and features with FLUX Kontext.
*  **Emotion:** The emotional tone is mixed. While there is excitement about the new model, there is also skepticism and concern about VRAM usage and whether it truly surpasses existing solutions like FLUX Kontext. There is positive sentiment for the competition this creates.
*  **Top 3 Points of View:**
    *   Some users are excited to try the new model and see how it performs.
    *   Some users are concerned about the VRAM requirements, particularly for those with less powerful hardware.
    *   Some users are skeptical about whether it is truly better than FLUX Kontext.

**[PusaV1 just released on HuggingFace. (Score: 80)](https://huggingface.co/RaphaelLiu/PusaV1)**
*  **Summary:** This thread announces the release of PusaV1 on HuggingFace. Commenters are discussing its potential uses, comparing it to existing tools like Wan2.1 and VACE, and trying to understand its functionalities, such as video completion and transition. Some users are reporting poor initial results.
*  **Emotion:** The overall emotional tone is neutral to slightly negative. While the announcement sparks curiosity, some early users express disappointment with the quality of results. There is also confusion regarding its functionality.
*  **Top 3 Points of View:**
    *   Some users are curious about its specific features and how it compares to existing tools.
    *   Some users are reporting poor quality results after trying it.
    *   Some users are trying to understand how it works and what it's intended to do.

**[I made one more storybook (using Flux), for my daughter #2, with her as main character. Included the suggestions many of you made in my last post. She loves playing dentist, so her reaction after seeing this was really fun and heartwarming. Please share ideas on improvements. :) (Score: 33)](https://v.redd.it/33vfyp9ltmdf1)**
*  **Summary:** The thread showcases a storybook created using Flux, featuring the author's daughter. The author seeks feedback and suggestions for improvements. Commenters praise the idea and the heartwarming results and ask about the process of creating consistent characters.
*  **Emotion:** The overall emotional tone is positive and heartwarming. Comments express admiration for the project and appreciation for the creator's effort.
*  **Top 3 Points of View:**
    *   Users praise the idea of creating personalized storybooks for children.
    *   Users inquire about the techniques used to achieve consistent character generation.
    *   Users offer suggestions, such as creating a physical book and sharing tutorials.

**[Wan 2.1 Woman surfing in the Pacific Ocean. (Score: 14)](https://v.redd.it/ccradbmbgndf1)**
*  **Summary:** The thread features a video generated using Wan 2.1, depicting a woman surfing in the Pacific Ocean. Comments range from praising the result to finding it comical or technically flawed. Some users also discuss the prompt and the use of i2v.
*  **Emotion:** The emotional tone is mixed. Some find the video impressive, while others find it humorous or technically unconvincing.
*  **Top 3 Points of View:**
    *   Some users find the results technically impressive.
    *   Some users, particularly surfers, find the results comical or unrealistic.
    *   Users discuss the prompt and the use of i2v in generating the video.

**[Kontext Flux Watermark/text/chatbubble removal WF (Score: 12)](https://www.reddit.com/gallery/1m3adm5)**
*  **Summary:** This thread focuses on a workflow designed to remove watermarks, text, and chat bubbles from images using Kontext Flux. The poster also shares the exact prompt: "remove watermark while maintaining all other aspects of the original image".
*  **Emotion:** The emotional tone is overall positive, indicating the workflow is useful.
*  **Top 3 Points of View:**
    *   The workflow is considered useful.
    *   The provided prompt is effective.
    *   Kontext Flux is a viable option for removing watermarks and other unwanted elements.

**[Flux Kontext Mask Inpainting Workflow (Score: 1)](https://i.redd.it/rsc1l8rdiodf1.png)**
*  **Summary:** This post shares a ComfyUI workflow for mask inpainting using Flux Kontext. The only comment is a link to download the workflow.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Flux Kontext can be used for mask inpainting tasks.

**[Need Advice From ComfyUI Pro - Best img2img model For Realism? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m37btt/need_advice_from_comfyui_pro_best_img2img_model/)**
*  **Summary:** This thread is a request for advice from experienced ComfyUI users on the best img2img model for achieving realistic results.
*  **Emotion:** The overall emotional tone is neutral, as it's a question-based post seeking information.
*  **Top 3 Points of View:**
    *   The user is looking for a model that can generate realistic images using img2img.

**[What is the difference between these 2 nunchaku models? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m37mz0/what_is_the_difference_between_these_2_nunchaku/)**
*  **Summary:** The thread asks about the difference between two specific Nunchaku models, 'svdq-int4\_r32-flux.1-dev' and its variants, for use in stable diffusion. The comments explain the difference lies in the file format (diffuser vs. safetensors), hardware compatibility (FP4 for Blackwell GPUs and INT4 for others), and whether they are the same model.
*  **Emotion:** The overall emotional tone is neutral and informative.
*  **Top 3 Points of View:**
    *   The models are essentially the same, but with different file formats (folder vs safetensor).
    *   FP4 models are intended for Blackwell GPUs, while INT4 models are for other GPUs.
    *   The safetensor version is a more convenient, packed version of the model.

**[Multiple (5 image) concatenate workflow for Kontext? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m399bo/multiple_5_image_concatenate_workflow_for_kontext/)**
*  **Summary:** The thread is a question about how to create a workflow for concatenating multiple images (specifically 5) for use with Kontext. The comments offer solutions such as using Comfyui-LayerForge, photobashing, Place it Lora, and chaining stitch image nodes together.
*  **Emotion:** The overall emotional tone is neutral, as it's a question-based post seeking technical advice.
*  **Top 3 Points of View:**
    *   Comfyui-LayerForge is a good option for concatenating images.
    *   Photobashing and the 'Place it Lora' technique are viable alternatives.
    *   The default workflow with chained stitch image nodes can be used to concatenate more than two images.

**[How to convert own models for nunchaku? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m39e3p/how_to_convert_own_models_for_nunchaku/)**
*  **Summary:** The thread is a question about converting custom models for use with Nunchaku. Commenters suggest using the deepcompressor tool, but mention that it may not support chroma models.
*  **Emotion:** The overall emotional tone is slightly negative, due to the lack of a straightforward solution and potential limitations.
*  **Top 3 Points of View:**
    *   The deepcompressor tool is a potential option for conversion.
    *   The conversion process may not be easy or well-documented.
    *   Chroma models may not be supported by the conversion tools.

**[AI Prompt Roulette (Score: 0)](https://blush-noami-71.tiiny.site/?mode=suggestions)**
*   **Summary:** This thread shares a link to an AI prompt roulette tool and invites feedback. Commenters find the tool handy and fun for inspiration and offer suggestions to improve the user experience, such as automatic transitions and easier prompt copying.
*   **Emotion:** The overall tone is positive.
*   **Top 3 Points of View:**
    *   The tool is useful for prompt inspiration.
    *   Automatic transitions would improve user experience.
    *   Making the final prompt easily copyable would be beneficial.

**[How can I create images like this using stable diffusion. (what model+loras) (Score: 0)](https://i.redd.it/sbrykuovkndf1.jpeg)**
*   **Summary:** The thread asks for recommendations on models and LoRAs to recreate a specific image style, resembling Image Comics (Spawn). The comment suggests using a Comics SDXL model, a medieval engraving Lora, and potentially a Darkest Dungeon Lora, along with specific prompting techniques.
*   **Emotion:** The overall tone is neutral.
*   **Top 3 Points of View:**
    *   The image style resembles Image Comics (Spawn).
    *   A Comics SDXL model combined with specific LoRAs (medieval engraving, Darkest Dungeon) can help recreate the style.
    *   Prompt engineering plays a crucial role in achieving the desired results.

**[Is this the best model to generate +18 Anime/***? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m37z0j/is_this_the_best_model_to_generate_18_animehentai/)
*   **Summary:** The thread asks for the best model to generate +18 Anime. The answers point out that there is no "best" model, but suggest some popular ones like Illustrious, Noobai, Pony, Wai, and Chroma.
*   **Emotion:** The overall emotional tone is neutral and informative.
*   **Top 3 Points of View:**
    *   There is no single "best" model for generating +18 anime.
    *   Several models are popular and perform well for this purpose, including Illustrious, Noobai, Pony, Wai, and Chroma.
    *   Personal preference plays a significant role in choosing the right model.

**[SD 1.5 Are Tan Lines (or Tan Skin) Even Possible? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m3aieg/sd_15_are_tan_lines_or_tan_skin_even_possible/)**
*   **Summary:** The thread questions if it's possible to generate tan lines or tan skin using Stable Diffusion 1.5. The comments suggest using danbooru-tag based checkpoints and searching for existing models specifically trained for tan lines on Civitai.
*   **Emotion:** The overall emotional tone is neutral, with a hint of frustration in one of the responses due to the perceived lack of prior research.
*   **Top 3 Points of View:**
    *   Tan lines and tan skin are definitely possible in SD 1.5.
    *   Using danbooru-tag based checkpoints can help.
    *   Searching for specific models on Civitai is recommended.

**[Which ai model does this creator use? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m3ak7j/which_ai_model_does_this_creator_use/)**
*   **Summary:** This thread asks which AI model a specific creator uses. The comments suggest it could be FLUX with LORAs, or a combination of SDXL generations with FLUX inpainting.
*   **Emotion:** The overall emotional tone is neutral.
*   **Top 3 Points of View:**
    *   FLUX model is a likely candidate, possibly with LORAs.
    *   The creator may be using a combination of SDXL for initial generation and FLUX for inpainting.

**[So I started studying/taking courses for 3D animation a few months ago, and I would like this community's opinion on the future. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m3chl3/so_i_started_studyingtaking_courses_for_3d/)**
*   **Summary:** This thread expresses concern about the future of 3D animation in the face of advancing AI technology. The commenter suggests that AI models will eventually automate most, if not all, aspects of 3D animation, potentially making a career in the field unsustainable.
*   **Emotion:** The overall emotional tone is neutral but leaning towards pessimistic, reflecting anxiety about the impact of AI on the 3D animation industry.
*   **Top 3 Points of View:**
    *   AI models are rapidly improving in their capacity for animation tasks.
    *   AI will likely automate many aspects of 3D animation in the future.
    *   A traditional career in 3D animation may become difficult or impossible to sustain.
