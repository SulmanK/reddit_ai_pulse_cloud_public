---
title: "Machine Learning Subreddit"
date: "2025-07-16"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "NLP"]
---

# Overall Ranking and Top Discussions
1.  [[R][D] Interpretability as a Side Effect? Are Activation Functions Biasing Your Models?](https://www.reddit.com/r/MachineLearning/comments/1m18mn3/rd_interpretability_as_a_side_effect_are/) (Score: 32)
    *   This thread discusses whether activation functions in machine learning models are causing bias and affecting interpretability.
2.  [P] LSTM to recognize baseball players based on their swing keypoint data](https://www.reddit.com/r/MachineLearning/comments/1m123zn/p_lstm_to_recognize_baseball_players_based_on/) (Score: 7)
    *   The thread discusses using LSTM (Long Short-Term Memory) networks to identify baseball players based on their swing keypoint data.
3.  [D] Changing values in difficult to predict range](https://www.reddit.com/r/MachineLearning/comments/1m1ec4f/d_changing_values_in_difficult_to_predict_range/) (Score: 6)
    *   The thread is about whether or not changing values in a difficult to predict range is standard practice, and how models are underperforming for those data points.
4.  [P] Human Activity Recognition on STM32 Nucleo](https://www.reddit.com/r/MachineLearning/comments/1m1dmur/p_human_activity_recognition_on_stm32_nucleo/) (Score: 5)
    *   The thread features someone asking if it can be trained to remind the user to flush the toilet and put on a car seatbelt.
5.  [[R] Is the Two-Tower Model Hitting Its Limits for RecSys Retrieval?](https://www.reddit.com/r/MachineLearning/comments/1m1fb37/r_is_the_twotower_model_hitting_its_limits_for/) (Score: 5)
    *   The discussion centers on whether the two-tower model is reaching its limitations in recommendation systems retrieval and mentions a promising alternative.
6.  [ICML 2025, can a workshop registration access poster sessions and/or socials? [D]](https://www.reddit.com/r/MachineLearning/comments/1m0vu90/icml_2025_can_a_workshop_registration_access/) (Score: 4)
    *   This thread discusses whether a workshop registration for ICML 2025 will allow access to poster sessions and/or social events.
7.  [[R] Interactive Probabilistic Neural Network Decision Matrix Model](https://www.reddit.com/r/MachineLearning/comments/1m11bog/r_interactive_probabilistic_neural_network/) (Score: 4)
    *   The discussion is about an Interactive Probabilistic Neural Network Decision Matrix Model, with requests for more background information.
8.  [D] EMNLP 2025 Meta-reviews](https://www.reddit.com/r/MachineLearning/comments/1m1in5r/d_emnlp_2025_metareviews/) (Score: 3)
    *   The thread discusses the availability and delays of meta-reviews for papers submitted to EMNLP 2025.
9.  [Should a large enough network be able to learn random noise? [D]](https://www.reddit.com/r/MachineLearning/comments/1m1jh78/should_a_large_enough_network_be_able_to_learn/) (Score: 1)
    *   This thread explores the possibility of a large neural network learning random noise, discussing local minima and potential ways to debug the process.
10. [How to find a relevant PhD topic in computer vision? Industry problem vs trendy topics [D]](https://www.reddit.com/r/MachineLearning/comments/1m0w8n1/how_to_find_a_relevant_phd_topic_in_computer/) (Score: 0)
    *   The thread discusses the process of finding a relevant PhD topic in computer vision, focusing on the options between industry problems and trendy topics.
11. [D] Guys i just got interviewed, can you help me if i was cooked ?](https://www.reddit.com/r/MachineLearning/comments/1m1dymr/d_guys_i_just_got_interviewed_can_you_help_me_if/) (Score: 0)
    *   The discussion thread focuses on the experience of a job interview where the candidate was asked to code a CNN (Convolutional Neural Network) from scratch in one hour.
12. [[D] With renewed interest in chain of thought is creative prompt engineering actually underrated as a new layer in LLM progress?](https://www.reddit.com/r/MachineLearning/comments/1m1itr0/d_with_renewed_interest_in_chain_of_thought_is/) (Score: 0)
    *   The discussion thread explores the idea that creative prompt engineering is an underrated aspect of progress in Large Language Models (LLMs), especially with the renewed interest in chain-of-thought prompting.

# Detailed Analysis by Thread
**[[R][D] Interpretability as a Side Effect? Are Activation Functions Biasing Your Models? (Score: 32)](https://www.reddit.com/r/MachineLearning/comments/1m18mn3/rd_interpretability_as_a_side_effect_are/)**
*  **Summary:**  This thread discusses whether activation functions in machine learning models are causing bias and affecting interpretability. Users are exploring how activation functions may fragment the latent space and how alternative primitives to the classical weighted edge could support the paper.
*  **Emotion:** The emotional tone of the thread is predominantly Neutral, with some instances of Positive sentiment related to answering questions and finding the topic interesting.
*  **Top 3 Points of View:**
    *   Activation functions may discretize data, fragmenting the latent space.
    *   Replacing activation functions could yield better performance by avoiding data loss.
    *   Alternative primitives to the classical weighted edge might provide supporting evidence.

**[P] LSTM to recognize baseball players based on their swing keypoint data (Score: 7)](https://www.reddit.com/r/MachineLearning/comments/1m123zn/p_lstm_to_recognize_baseball_players_based_on/)**
*  **Summary:** The thread discusses using LSTM (Long Short-Term Memory) networks to identify baseball players based on their swing keypoint data. Users are questioning the number of data points and time sequences per prediction, as LSTMs are subject to the gradient vanishing problem.
*  **Emotion:** The emotional tone is Neutral, focusing on technical questions.
*  **Top 3 Points of View:**
    *   LSTMs are being used to recognize baseball players based on swing data.
    *   There are questions about the quantity of data points and time sequences.
    *   LSTMs may struggle to capture long-term time series input due to the gradient vanishing problem.

**[D] Changing values in difficult to predict range (Score: 6)](https://www.reddit.com/r/MachineLearning/comments/1m1ec4f/d_changing_values_in_difficult_to_predict_range/)**
*  **Summary:** The thread is about whether or not changing values in a difficult to predict range is standard practice, and how models are underperforming for those data points.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Artificially changing values to fit model predictions is not standard practice.
    *   Models consistently underperforming for certain data points suggests a need to take a closer look at the sample.
    *   If the domain is understood so well that they know they can do this and still train a good model, then simple heuristics would probably work so well that a machine learning model is not needed.

**[P] Human Activity Recognition on STM32 Nucleo (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1m1dmur/p_human_activity_recognition_on_stm32_nucleo/)**
*  **Summary:** The thread features someone asking if it can be trained to remind the user to flush the toilet and put on a car seatbelt.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   It can be trained to remind to flush toilets after use.
    *   I need an AI that reminds me to flush toilet and put on car seatbelt.
    *   No other real points of view.

**[[R] Is the Two-Tower Model Hitting Its Limits for RecSys Retrieval? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1m1fb37/r_is_the_twotower_model_hitting_its_limits_for/)**
*  **Summary:** The discussion centers on whether the two-tower model is reaching its limitations in recommendation systems retrieval and mentions a promising alternative.
*  **Emotion:** The emotional tone is Positive and Neutral.
*  **Top 3 Points of View:**
    *   Two towers is such a standard I doubt it’ll change soon.
    *   The big companies will start testing this one out, if they aren’t already.
    *   Neat, this is the first I’d heard of it, but sounds very promising.

**[ICML 2025, can a workshop registration access poster sessions and/or socials? [D] (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1m0vu90/icml_2025_can_a_workshop_registration_access/)**
*  **Summary:** This thread discusses whether a workshop registration for ICML 2025 will allow access to poster sessions and/or social events.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   I am not able to access poster sessions without a main conference registration.
    *   I am able to attend socials.
    *   No other points of view.

**[[R] Interactive Probabilistic Neural Network Decision Matrix Model (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1m11bog/r_interactive_probabilistic_neural_network/)**
*  **Summary:** The discussion is about an Interactive Probabilistic Neural Network Decision Matrix Model, with requests for more background information.
*  **Emotion:** The emotional tone is Positive and Neutral.
*  **Top 3 Points of View:**
    *   a background about the work/tool/whatever it is would help
    *   I like
    *   Procastinating and lot of effort in one sentence?

**[D] EMNLP 2025 Meta-reviews (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1m1in5r/d_emnlp_2025_metareviews/)**
*  **Summary:** The thread discusses the availability and delays of meta-reviews for papers submitted to EMNLP 2025.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Anyone has meta score ??
    *   I see meta reviews for the papers that I reviewed but not for my authored papers.
    *   A SAC told me a lot of ACs are late in giving MRs this round so they’re delaying it a bit.

**[Should a large enough network be able to learn random noise? [D] (Score: 1)](https://www.reddit.com/r/MachineLearning/comments/1m1jh78/should_a_large_enough_network_be_able_to_learn/)**
*  **Summary:** This thread explores the possibility of a large neural network learning random noise, discussing local minima and potential ways to debug the process.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   A model can only learn in a correlational fashion. True randomness cannot be learned.
    *   What we need is the input to the network, the desired output, the training method and the actual observed output.
    *   what you're seeing is referred to as a 'local minimum'.

**[How to find a relevant PhD topic in computer vision? Industry problem vs trendy topics [D] (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1m0w8n1/how_to_find_a_relevant_phd_topic_in_computer/)**
*  **Summary:** The thread discusses the process of finding a relevant PhD topic in computer vision, focusing on the options between industry problems and trendy topics.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The goal of the PhD is to demonstrate independent research abilities and transferable skills.
    *   The top labs nowadays require incoming PhD candidates to already have first authorships in top conferences.
    *   No other points of view.

**[D] Guys i just got interviewed, can you help me if i was cooked ? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1m1dymr/d_guys_i_just_got_interviewed_can_you_help_me_if/)**
*  **Summary:** The discussion thread focuses on the experience of a job interview where the candidate was asked to code a CNN (Convolutional Neural Network) from scratch in one hour.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   That's a ridiculous ask. 1 hour? Lol.
    *   He wanted you to create a neural network manually. He probably wanted to see your thought process on how you'd build such a model and gauge your people skills.
    *   lol, what a bad CTO.

**[[D] With renewed interest in chain of thought is creative prompt engineering actually underrated as a new layer in LLM progress? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1m1itr0/d_with_renewed_interest_in_chain_of_thought_is/)**
*  **Summary:** The discussion thread explores the idea that creative prompt engineering is an underrated aspect of progress in Large Language Models (LLMs), especially with the renewed interest in chain-of-thought prompting.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The prompts are the only way data can be generated.
    *   It's context engineering.
    *   I'm increasingly of the mindset that there's more performance to be gained right now from improved prompting than there is from actual foundational model improvements
