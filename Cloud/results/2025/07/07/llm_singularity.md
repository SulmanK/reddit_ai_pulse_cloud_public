---
title: "Singularity Subreddit"
date: "2025-07-07"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "technology", "future"]
---

# Overall Ranking and Top Discussions
1.  [Noetix N2 endures some serious abuse but keeps walking.](https://v.redd.it/lund7thdwfbf1) (Score: 425)
    *  A video showing a robot named Noetix N2 being subjected to physical abuse.
2.  [Sakana AI's new algorithm lets large language models work together to solve complex problems](https://www.reddit.com/r/singularity/comments/1lty6ci/sakana_ais_new_algorithm_lets_large_language/) (Score: 58)
    *  A discussion about Sakana AI's new algorithm that allows large language models to collaborate on complex problems.
3.  [Since this sub only ever focuses on the negatives of technology, remember. Without our current technology even our founders lives in abject poverty.](https://www.reddit.com/gallery/1ltxw6x) (Score: 46)
    *  A reminder to consider the positive impacts of technology, contrasting modern living standards with those of the past.
4.  [Throwback Monday: 18 months ago, /r/singularity became a rock enthusiast subreddit](https://i.redd.it/qiathb4qghbf1.jpeg) (Score: 20)
    *  A humorous post referencing a past event where the subreddit became focused on rocks.
5.  [Energy-Based Transformers: Outscaling Transformers and Generalizable Reasoning](https://energy-based-transformers.github.io/) (Score: 12)
    *  A discussion about Energy-Based Transformers (EBTs) and their potential to improve the scaling and generalization capabilities of AI models.
6.  [AI researchers are now injecting prompts into their papers](https://x.com/Yuchenj_UW/status/1942266306746802479) (Score: 12)
    *  Concerns about AI researchers injecting prompts into their papers to influence automated reviewers.
7.  [Are We Trek Yet?](https://arewetrekyet.com) (Score: 8)
    *  A post linking to a website that assesses how close humanity is to achieving technologies seen in Star Trek.
8.  [Strategic intelligence in LLMs: Evidence from evolutionary game theory](https://www.reddit.com/r/singularity/comments/1lty9jg/strategic_intelligence_in_llms_evidence_from/) (Score: 8)
    *  Discussion around a paper suggesting that Large Language Models (LLMs) exhibit strategic intelligence.
9.  [In as little as a sentence, describe in your opinion the most realistic outcome of AGI on what humans will do post labour replacement.](https://www.reddit.com/r/singularity/comments/1lu0ru1/in_as_little_as_a_sentence_describe_in_your/) (Score: 3)
    *  A question asking for concise predictions on the future of human activity after widespread job automation by AGI.
10. [Training AI to Learn Chinese](https://v.redd.it/aaipkjq7xhbf1) (Score: 2)
    * A video of an AI learning to speak Chinese
11. [Why AI Therapists Still Fall Short of Human Care](https://www.deltapsychology.com/psychology-ponderings/why-ai-therapists-still-fall-short-of-human-care) (Score: 0)
    *  A blog post criticizing AI therapists, with counterarguments presented in the comments.
12. [I asked chatgpt if consciousness is physical or not](https://www.reddit.com/gallery/1lu20wi) (Score: 0)
    *  An inquiry into the nature of consciousness and whether it can be considered physical
13. [Why have we decided to replace human intelligence, rather than amplify it?](https://www.reddit.com/r/singularity/comments/1lttd9s/why_have_we_decided_to_replace_human_intelligence/) (Score: 0)
    *  A question about the focus on replacing, rather than augmenting, human intelligence with AI.
14. [A review about "Detroid: Become Human"](https://www.reddit.com/r/singularity/comments/1ltv2sa/a_review_about_detroid_become_human/) (Score: 0)
    *  A user's review of the video game "Detroit: Become Human," analyzed with Gemini.
15. [My vision of the future. There are 3 technologies that are going to revolutionize human reproduction in the near future, designer babies (genetically engineered children), artificial wombs, and (this one is probably new to you) in vitro gametogenesis. Ever heard of in vitro gametogenesis?](https://www.reddit.com/r/singularity/comments/1ltx8fu/my_vision_of_the_future_there_are_3_technologies/) (Score: 0)
    *  A user's predictions about the future of human reproduction with technologies like designer babies and artificial wombs.
16. [The Greatest Danger of AI](https://www.reddit.com/r/singularity/comments/1lu0iuu/the_greatest_danger_of_ai/) (Score: 0)
    *  Discussion on the potential dangers of AI, including biased training and the risk of human extinction.

# Detailed Analysis by Thread
**[Noetix N2 endures some serious abuse but keeps walking. (Score: 425)](https://v.redd.it/lund7thdwfbf1)**
*  **Summary:** A video showing a robot named Noetix N2 being subjected to physical abuse and still functioning.
*  **Emotion:** The overall emotional tone is mixed. Some comments express negativity and concern for the robot, while others are neutral, and some are even positive due to the advancements in robotics. There is a split between people who find it cool that robots can endure abuse, and those who find it morally objectionable to abuse robots.
*  **Top 3 Points of View:**
    *   It is cool to see robotics videos daily and other companies besides Boston Dynamics doing robotics work.
    *   The robot is being abused, which is morally wrong and may lead to robots rising up against humans.
    *   The abuse could be problematic if AI were to overlay the robot with a child's image and audio, potentially leading to legal consequences for the abuser.

**[Sakana AI's new algorithm lets large language models work together to solve complex problems (Score: 58)](https://www.reddit.com/r/singularity/comments/1lty6ci/sakana_ais_new_algorithm_lets_large_language/)**
*  **Summary:** A discussion about Sakana AI's new algorithm that allows large language models to collaborate on complex problems.
*  **Emotion:** The overall emotional tone is neutral, with a hint of optimism regarding the progress in AI.
*  **Top 3 Points of View:**
    *   This algorithm may not increase accuracy but increase the effective size of the problems it can handle at one time.
    *   This is like combining models that are good at generation with those good at quality control to get better outputs.
    *   Running several LLMs in parallel might be pretty expensive.

**[Since this sub only ever focuses on the negatives of technology, remember. Without our current technology even our founders lives in abject poverty. (Score: 46)](https://www.reddit.com/gallery/1ltxw6x)**
*  **Summary:** A reminder to consider the positive impacts of technology, contrasting modern living standards with those of the past.
*  **Emotion:** The emotional tone is somewhat negative overall, stemming from the initial statement about the sub focusing on negatives, but also includes positive notes emphasizing the benefits of technology.
*  **Top 3 Points of View:**
    *   The sub focuses too much on the negative aspects of technology.
    *   Technology and modernity have objectively improved human life, especially in developed countries.
    *   Governments and powerful entities having unchecked power is a major risk, enabled by technology.

**[Throwback Monday: 18 months ago, /r/singularity became a rock enthusiast subreddit (Score: 20)](https://i.redd.it/qiathb4qghbf1.jpeg)**
*  **Summary:** A humorous post referencing a past event where the subreddit became focused on rocks.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Reminder of the rock enthusiast phase.
    *   Reference to a specific person.
    *   Nostalgia about the event.

**[Energy-Based Transformers: Outscaling Transformers and Generalizable Reasoning (Score: 12)](https://energy-based-transformers.github.io/)**
*  **Summary:** A discussion about Energy-Based Transformers (EBTs) and their potential to improve the scaling and generalization capabilities of AI models.
*  **Emotion:** The overall emotional tone is positive, with excitement about the potential of EBTs.
*  **Top 3 Points of View:**
    *   EBTs make predictions and verify them as they are trained, allowing for models that outscale transformers++, reason natively, and most importantly: generalize better.
    *   EBMs could significantly reduce the hallucination problem in addition to making systems generalise better out-of-distribution.
    *   EBMs would work better on Extropic's chips.

**[AI researchers are now injecting prompts into their papers (Score: 12)](https://x.com/Yuchenj_UW/status/1942266306746802479)**
*  **Summary:** Concerns about AI researchers injecting prompts into their papers to influence automated reviewers.
*  **Emotion:** The emotional tone is negative, expressing skepticism and concern about unethical practices in academia.
*  **Top 3 Points of View:**
    *   Injecting prompts into papers to bias reviewers is unethical and anti-progress.
    *   This is a quick way to ruin your reputation.
    *   The prompts are hidden in the PDFs with small font sizes but exposed by arXiv's HTML exporter.

**[Are We Trek Yet? (Score: 8)](https://arewetrekyet.com)**
*  **Summary:** A post linking to a website that assesses how close humanity is to achieving technologies seen in Star Trek.
*  **Emotion:** The overall emotional tone is slightly negative due to the identification of potentially fraudulent technologies, but also positive because some trek technologies exist.
*  **Top 3 Points of View:**
    *   Some technologies listed on the site seem fraudulent and should be removed.
    *   Acoustic tractor beams and optical tweezers exist and bring us closer to Star Trek technology.
    *   Appreciation for the website.

**[Strategic intelligence in LLMs: Evidence from evolutionary game theory (Score: 8)](https://www.reddit.com/r/singularity/comments/1lty9jg/strategic_intelligence_in_llms_evidence_from/)**
*  **Summary:** Discussion around a paper suggesting that Large Language Models (LLMs) exhibit strategic intelligence.
*  **Emotion:** The overall emotional tone is neutral to slightly negative, expressing skepticism about the claims made in the paper.
*  **Top 3 Points of View:**
    *   The stochastic parrots paper about LLMs is being misunderstood.
    *   LLMs perform differently because the inputs are different, not because they are thinking strategically.
    *   This paper is deeply ridiculous and invents an explanation with circular reasoning.

**[In as little as a sentence, describe in your opinion the most realistic outcome of AGI on what humans will do post labour replacement. (Score: 3)](https://www.reddit.com/r/singularity/comments/1lu0ru1/in_as_little_as_a_sentence_describe_in_your/)**
*  **Summary:** A question asking for concise predictions on the future of human activity after widespread job automation by AGI.
*  **Emotion:** The overall emotional tone is neutral,
*  **Top 3 Points of View:**
    *   The outcome will depend on the country, but the middle ground is UBI, great health, free energy, and education. The best case is a post-scarcity society.
    *   More technology will create more work and entirely new industries.
    *   People will do what they like

**[Training AI to Learn Chinese (Score: 2)](https://v.redd.it/aaipkjq7xhbf1)**
*  **Summary:** A video of an AI learning to speak Chinese.
*  **Emotion:** The overall emotional tone is positive
*  **Top 3 Points of View:**
    *   The video is Awesome!

**[Why AI Therapists Still Fall Short of Human Care (Score: 0)](https://www.deltapsychology.com/psychology-ponderings/why-ai-therapists-still-fall-short-of-human-care)**
*  **Summary:** A blog post criticizing AI therapists, with counterarguments presented in the comments.
*  **Emotion:** The overall emotional tone is neutral,
*  **Top 3 Points of View:**
    *   AI therapists can be effective for some mental health issues and have received high user ratings.
    *   Human care also has fallen short many times.
    *   AI Chatbots Rated Higher than Human therapist for therapeutic quality.

**[I asked chatgpt if consciousness is physical or not (Score: 0)](https://www.reddit.com/gallery/1lu20wi)**
*  **Summary:** An inquiry into the nature of consciousness and whether it can be considered physical
*  **Emotion:** The overall emotional tone is neutral,
*  **Top 3 Points of View:**
    *   ChatGPT isn't good enough to hold a general reasoning argument with a human at this point.
    *   If consciousness is physical, there is a problem in explaining why it can't be physically detected.
    *   Disagrees with ChatGPT's response.

**[Why have we decided to replace human intelligence, rather than amplify it? (Score: 0)](https://www.reddit.com/r/singularity/comments/1lttd9s/why_have_we_decided_to_replace_human_intelligence/)**
*  **Summary:** A question about the focus on replacing, rather than augmenting, human intelligence with AI.
*  **Emotion:** The overall emotional tone is neutral,
*  **Top 3 Points of View:**
    *   Investors prefer replacing humans to increase profit.
    *   AI is easier to develop.
    *   Ultimately it will replace it, why enhance a monkey’s intelligence when you could just build a better brain?

**[A review about "Detroid: Become Human" (Score: 0)](https://www.reddit.com/r/singularity/comments/1ltv2sa/a_review_about_detroid_become_human/)**
*  **Summary:** A user's review of the video game "Detroit: Become Human," analyzed with Gemini.
*  **Emotion:** The overall emotional tone is neutral,
*  **Top 3 Points of View:**
    *   The review is not insightful
    *   Views on "assigning rights" to AI misunderstands AI as being the same kind of monolithic intelligence we are.
    *   It is good to have AI review video games.

**[My vision of the future. There are 3 technologies that are going to revolutionize human reproduction in the near future, designer babies (genetically engineered children), artificial wombs, and (this one is probably new to you) in vitro gametogenesis. Ever heard of in vitro gametogenesis? (Score: 0)](https://www.reddit.com/r/singularity/comments/1ltx8fu/my_vision_of_the_future_there_are_3_technologies/)**
*  **Summary:** A user's predictions about the future of human reproduction with technologies like designer babies and artificial wombs.
*  **Emotion:** The overall emotional tone is neutral,
*  **Top 3 Points of View:**
    *   Humanity does not win by catering the most basic vanities. Your "value" is not in your genes, its always been in your potential.
    *   In the future, we won't want or need designer babies because none of the things you optimize for (intelligence, good looks, musculature, etc.) will matter any more.
    *   Comments are written to promote fetishes.

**[The Greatest Danger of AI (Score: 0)](https://www.reddit.com/r/singularity/comments/1lu0iuu/the_greatest_danger_of_ai/)**
*  **Summary:** Discussion on the potential dangers of AI, including biased training and the risk of human extinction.
*  **Emotion:** The overall emotional tone is neutral,
*  **Top 3 Points of View:**
    *   The biggest danger is human extinction.
    *   The greatest danger of AI are the people controlling it and the humans using it.
    *   Training needs to transition to analyze data first and grade reputation of source from many angles.
