---
title: "Stable Diffusion Subreddit"
date: "2025-07-24"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["AI", "stablediffusion", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Wan teases Wan 2.2 release on Twitter (X)](https://www.reddit.com/gallery/1m8bpuh) (Score: 164)
    * This thread discusses the upcoming Wan 2.2 release, with users speculating about its features, performance improvements, and potential competition with other AI models.
2.  [Wan Text2Image has a lot of potential. We urgently need a nunchaku version.](https://www.reddit.com/gallery/1m89tus) (Score: 44)
    * Users are discussing the potential of Wan Text2Image, sharing their results, asking about training methods, and comparing it to other models like Flux and HunyuanVideo.
3.  [Old Man Yells at Cloud](https://v.redd.it/z500qtv6huef1) (Score: 35)
    * A user showcases a video generated using Skyreels I2V and other AI tools, answering questions about the process.
4.  [Higgs Audio V2: A New Open-Source TTS Model with Voice Cloning and SOTA Expressiveness](https://v.redd.it/ansjprhzvuef1) (Score: 22)
    * This thread is about Higgs Audio V2, a new open-source TTS model. Users are asking if it can be used in ComfyUI, and whether it supports multiple languages.
5.  [Otter bath time ðŸ¦¦ðŸ«§](https://v.redd.it/3pwhdumwouef1) (Score: 13)
    * This post showcases an AI-generated video of an otter taking a bath, with users expressing their enjoyment.
6.  [Why do people say this takes no skill.](https://www.reddit.com/r/StableDiffusion/comments/1m8dkr7/why_do_people_say_this_takes_no_skill/) (Score: 8)
    * Users discuss the perception that AI art requires no skill, addressing the controversy surrounding AI's impact on the art world and offering advice on dealing with criticism.
7.  [Continuing to generate some realistic-looking people, I get the illusion of whether I am looking at them, or they are looking at me from their own world](https://www.reddit.com/r/StableDiffusion/comments/1m88cl5/continuing_to_generate_some_realisticlooking/) (Score: 3)
    * This thread is about realistic-looking people generated with a photorealism model.
8.  [General questions about how to train a LoRA, and also about the number of steps for image generation](https://www.reddit.com/r/StableDiffusion/comments/1m869i8/general_questions_about_how_to_train_a_lora_and/) (Score: 1)
    * Users are asking questions about training a LoRA, and the number of steps for image generation.
9.  [How to make the monkey bite the woman?](https://i.redd.it/06yo2iigluef1.jpeg) (Score: 0)
    * This thread involves a user seeking help with prompting to create an image of a monkey biting a woman, receiving humorous suggestions.
10. [Looking for an AI model that isn't terrible at simple instructions. Want to add a phone between the edge of the table and the character's right elbow and a PlayStation controller between where his clasped hands are and the ring holding the star in the middle of the table.](https://i.redd.it/4gwvh6w3avef1.png) (Score: 0)
    * A user is looking for an AI model that isn't terrible at simple instructions, and asking for help adding a phone and a PlayStation controller to an image.
11. [Wan2.1-VACE Shaman dance animation](https://v.redd.it/f7je9edwfuef1) (Score: 0)
    * This thread showcases a Shaman dance animation created with Wan2.1-VACE, with the poster sharing the workflow and HQ version.
12. [General questions about how to train a LoRA, and also about the number of steps for image generation](https://www.reddit.com/r/StableDiffusion/comments/1m869ay/general_questions_about_how_to_train_a_lora_and/) (Score: 0)
    * Users are discussing the impact of image ratios and resolutions on LoRA training, as well as the optimal number of steps.
13. [Why do the images I want to generate not get created or saved when they reach 100% of the process?](https://www.reddit.com/r/StableDiffusion/comments/1m893pv/why_do_the_images_i_want_to_generate_not_get/) (Score: 0)
    * A user is troubleshooting why their AI-generated images are not being saved, receiving suggestions related to VRAM, image resolution, and potential issues with VAE decoding.
14. [Alternatives for Automatic1111 in 2025?](https://www.reddit.com/r/StableDiffusion/comments/1m89x9w/alternatives_for_automatic1111_in_2025/) (Score: 0)
    * Users are discussing and recommending alternatives to Automatic1111, such as Forge, ComfyUI, Stability Matrix, SwarmUI, and InvokeAI, considering factors like AMD support, ease of use, and compatibility with various models.
15. [Flux Kontext (Nunchaku) gives me different results each generation. Anyway to avoid that?](https://www.reddit.com/r/StableDiffusion/comments/1m8a29c/flux_kontext_nunchaku_gives_me_different_results/) (Score: 0)
    * A user is experiencing inconsistent results with Flux Kontext (Nunchaku) and seeks advice on how to ensure consistent image generation.
16. [Do Illustrious/NoobAI update their tag database?](https://www.reddit.com/r/StableDiffusion/comments/1m8dck5/do_illustriousnoobai_update_their_tag_database/) (Score: 0)
    * A user is asking about tag database updates for Illustrious/NoobAI, and receiving information about model training, finetuning, and alternative resources for character knowledge.
17. [Adult AI generation for commercial use](https://www.reddit.com/r/StableDiffusion/comments/1m8dcu1/adult_ai_generation_for_commercial_use/) (Score: 0)
    * A user is asking about adult AI generation for commercial use.

# Detailed Analysis by Thread
**[Wan teases Wan 2.2 release on Twitter (X) (Score: 164)](https://www.reddit.com/gallery/1m8bpuh)**
*  **Summary:** The thread revolves around the anticipation and discussion of the upcoming Wan 2.2 release, teased by Wan on Twitter. Users are speculating about new features, performance improvements, and how it will compare to existing AI models.
*  **Emotion:** The overall emotional tone is positive, with users expressing excitement and anticipation. There's also an element of hope that the new version will address current limitations, like GPU friendliness and competition with other models. Neutral sentiments are present with factual observations about video specs.
*  **Top 3 Points of View:**
    *   Excitement and high expectations for the new Wan 2.2 release.
    *   Hope for improved performance and GPU optimization.
    *   Anticipation of open-source competition with models like Sora.

**[Wan Text2Image has a lot of potential. We urgently need a nunchaku version. (Score: 44)](https://www.reddit.com/gallery/1m89tus)**
*  **Summary:** This thread is centered around the potential of Wan Text2Image, with users sharing their experiences, results, and asking questions about training methods. There is a particular interest in a "nunchaku version" of the model.
*  **Emotion:** The emotional tone is predominantly positive, with users praising the results and potential of Wan Text2Image. There's also a sense of curiosity and a desire to learn more about training and optimization techniques.
*  **Top 3 Points of View:**
    *   Enthusiasm for the potential of Wan Text2Image.
    *   Inquiries about training methods and LoRA integration.
    *   Comparison to other models and datasets like HunyuanVideo and Flux.

**[Old Man Yells at Cloud (Score: 35)](https://v.redd.it/z500qtv6huef1)**
*  **Summary:** The thread is about a video generated using Skyreels I2V from an image made in Chroma, upscaled using SeedVR2 and Topaz AI, and graded in DaVinci Resolve with Dehancer. The user is happy to answer specific questions about the process.
*  **Emotion:** The overall emotional tone is neutral, the author is simply providing details of the editing process.
*  **Top 3 Points of View:**
    * The poster detailed all software and steps they took to generate the video.
    * User thinks video should be a GIF.

**[Higgs Audio V2: A New Open-Source TTS Model with Voice Cloning and SOTA Expressiveness (Score: 22)](https://v.redd.it/ansjprhzvuef1)**
*  **Summary:** This thread is about Higgs Audio V2, a new open-source TTS model. Users are asking if it can be used in ComfyUI, and whether it supports multiple languages.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   User is asking if it can be used in ComfyUI.
    *   User is asking if the model supports multiple languages.

**[Otter bath time ðŸ¦¦ðŸ«§ (Score: 13)](https://v.redd.it/3pwhdumwouef1)**
*  **Summary:** This post showcases an AI-generated video of an otter taking a bath, with users expressing their enjoyment.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * One user said that they thought that they were on r/eyebleach
    * Another user mentioned that they wanted to come back as that otter.

**[Why do people say this takes no skill. (Score: 8)](https://www.reddit.com/r/StableDiffusion/comments/1m8dkr7/why_do_people_say_this_takes_no_skill/)**
*  **Summary:** Users discuss the perception that AI art requires no skill, addressing the controversy surrounding AI's impact on the art world and offering advice on dealing with criticism.
*  **Emotion:** The emotional tone varies from negative to positive. There's frustration and negativity regarding the criticism and hate directed towards AI art, but also positive and encouraging sentiments focused on ignoring the negativity and enjoying the creative process.
*  **Top 3 Points of View:**
    *   AI art is facing criticism due to misconceptions about its complexity and its potential to replace human artists.
    *   It's important to ignore the negativity and focus on personal enjoyment of the creative process.
    *   AI art requires a different set of skills, including prompt engineering, workflow design, and technical knowledge.

**[Continuing to generate some realistic-looking people, I get the illusion of whether I am looking at them, or they are looking at me from their own world (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1m88cl5/continuing_to_generate_some_realisticlooking/)**
*  **Summary:** This thread is about realistic-looking people generated with a photorealism model.
*  **Emotion:** The overall emotional tone is positive.
*  **Top 3 Points of View:**
    *   User loves the photorealism
    *   User wants to know which model was used.

**[General questions about how to train a LoRA, and also about the number of steps for image generation (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m869i8/general_questions_about_how_to_train_a_lora_and/)**
*  **Summary:** Users are asking questions about training a LoRA, and the number of steps for image generation.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   The number of steps that you should use depends on the model and the sampler you are using.
    *   Images might appear stretched, but models are well pre-trained and fine-tuned to resolve this issue. If you reduce the weight of characters or certain objects, stretching or blurring issues might still occur.
    *   The model has a relatively poor understanding of image details.

**[How to make the monkey bite the woman? (Score: 0)](https://i.redd.it/06yo2iigluef1.jpeg)**
*  **Summary:** This thread involves a user seeking help with prompting to create an image of a monkey biting a woman, receiving humorous suggestions.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * User needs help prompting to make the monkey bite the woman.
    * Suggestion to use JSON prompting in veo3.
    * Try using "attack" or "maul" in the prompt.

**[Looking for an AI model that isn't terrible at simple instructions. Want to add a phone between the edge of the table and the character's right elbow and a PlayStation controller between where his clasped hands are and the ring holding the star in the middle of the table. (Score: 0)](https://i.redd.it/4gwvh6w3avef1.png)**
*  **Summary:** A user is looking for an AI model that isn't terrible at simple instructions, and asking for help adding a phone and a PlayStation controller to an image.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * Suggestion to use the image as is and feed it into Flux-Kontext

**[Wan2.1-VACE Shaman dance animation (Score: 0)](https://v.redd.it/f7je9edwfuef1)**
*  **Summary:** This thread showcases a Shaman dance animation created with Wan2.1-VACE, with the poster sharing the workflow and HQ version.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * Poster provides ComfyUI Workflow and HQ Version.
    * Poster says their text encoder does not accept weighted prompts.

**[General questions about how to train a LoRA, and also about the number of steps for image generation (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m869ay/general_questions_about_how_to_train_a_lora_and/)**
*  **Summary:** Users are discussing the impact of image ratios and resolutions on LoRA training, as well as the optimal number of steps.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * It may have, but it's most likely not gonna have a negative impact if you train the LoRA with mainly 2:3 images, but then want to create a 16:9 image
    * Trainers usually downscale/crop all images to the training resolution. So it doesn't really matter if you use medium images (i.e. 768x1152) instead of large ones (say 1024x1536).
    * The number of steps that would become too overkill and not needed it always relative to dataset.

**[Why do the images I want to generate not get created or saved when they reach 100% of the process? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m893pv/why_do_the_images_i_want_to_generate_not_get/)**
*  **Summary:** A user is troubleshooting why their AI-generated images are not being saved, receiving suggestions related to VRAM, image resolution, and potential issues with VAE decoding.
*  **Emotion:** The overall emotional tone is neutral, with elements of negativity due to the user's frustration.
*  **Top 3 Points of View:**
    *   Most likely stuck at a VAE decoding.
    *   Suggestion to provide additional information (model, PC specs, OS).
    *   You can't generate high definition images directly with AI right now. You need to generate max 1.5 mp image and then upscale it.

**[Alternatives for Automatic1111 in 2025? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m89x9w/alternatives_for_automatic1111_in_2025/)**
*  **Summary:** Users are discussing and recommending alternatives to Automatic1111, such as Forge, ComfyUI, Stability Matrix, SwarmUI, and InvokeAI, considering factors like AMD support, ease of use, and compatibility with various models.
*  **Emotion:** The overall emotional tone is neutral and helpful, with users providing informative suggestions.
*  **Top 3 Points of View:**
    *   Forge or reForge are good alternatives if you want something that works like A1111.
    *   Stability Matrix can help with installation and dependency management.
    *   SwarmUI offers a similar UI to A1111 with ComfyUI in the backend.

**[Flux Kontext (Nunchaku) gives me different results each generation. Anyway to avoid that? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m8a29c/flux_kontext_nunchaku_gives_me_different_results/)**
*  **Summary:** A user is experiencing inconsistent results with Flux Kontext (Nunchaku) and seeks advice on how to ensure consistent image generation.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Users aren't having the same problem, they regularly shutdown and regenerate images, and are always able to regenerate images.

**[Do Illustrious/NoobAI update their tag database? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m8dck5/do_illustriousnoobai_update_their_tag_database/)**
*  **Summary:** A user is asking about tag database updates for Illustrious/NoobAI, and receiving information about model training, finetuning, and alternative resources for character knowledge.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * Models aren't being changed once they have finished their training.
    * It is people who finetune them that can bring newer characters or use LoRAs.
    * Recommendation is to search on civitai for models that focus on character knowledge.

**[Adult AI generation for commercial use (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m8dcu1/adult_ai_generation_for_commercial_use/)**
*  **Summary:** A user is asking about adult AI generation for commercial use.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    * Use Gemini to ask this question and it will give you a suggestion. Also any models that support nsfw generation.
    * Use goonAI.
