---
title: "Stable Diffusion Subreddit"
date: "2025-07-13"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Still in love with SD1.5 - even in 2025](https://www.reddit.com/gallery/1lyw8rm) (Score: 92)
    * Discussing the continued relevance and usefulness of Stable Diffusion 1.5 in 2025, highlighting its speed, control net capabilities and low memory requirements.
2.  [Loras for WAN in text2image mode are amazing at capturing likeness](https://imgur.com/a/K0e4Mzk) (Score: 43)
    *  Showcasing the capabilities of Loras with WAN in text2image mode for capturing likeness, and discussing workflow.
3.  [CLIP-KO: Knocking out the text obsession (typographic attack vulnerability) in CLIP. New Model, Text Encoder, Code, Dataset.](https://www.reddit.com/gallery/1lyzjkh) (Score: 32)
    * Introducing CLIP-KO, a new model and dataset aimed at addressing typographic attack vulnerabilities in CLIP.
4.  [Using ComfyUI with Perplexity Comet](https://i.redd.it/rs5od0oayocf1.jpeg) (Score: 4)
    *  A post about using ComfyUI with Perplexity Comet.
5.  [Been trying to generate buildings, but it always adds this "Courtyard". Anyone has an idea how to stop that from happening?](https://i.redd.it/tp0d474u4pcf1.png) (Score: 3)
    * Seeking advice on how to prevent the generation of "courtyards" when creating images of buildings.
6.  [How one website gets around the payment processor issue CivitAI is having](https://www.reddit.com/r/StableDiffusion/comments/1lywr2n/how_one_website_gets_around_the_payment_processor/) (Score: 2)
    * Discussing methods used by websites to bypass payment processor issues.
7.  [Training LORA, learning the wrong stuff](https://www.reddit.com/r/StableDiffusion/comments/1lyxm1m/training_lora_learning_the_wrong_stuff/) (Score: 2)
    *  A question about how to prevent loras from learning the wrong thing.
8.  [I’m looking for a simple WF to do V2V with OpenPose in WAN 2.1 that preserves the input image exactly](https://www.reddit.com/r/StableDiffusion/comments/1lz1lc0/im_looking_for_a_simple_wf_to_do_v2v_with/) (Score: 2)
    * Seeking a simple workflow for video-to-video conversion using OpenPose in WAN 2.1.
9.  [Checkpoint Help](https://www.reddit.com/r/StableDiffusion/comments/1lyaygx/checkpoint_help/) (Score: 1)
    * Seeking help understanding different checkpoint architectures and their compatibility with LoRAs.
10. [Local training... noob q's](https://www.reddit.com/r/StableDiffusion/comments/1lyy7xp/local_training_noob_qs/) (Score: 1)
    * Asking newbie questions about local training, specifically regarding file security, copying scenes, and training specific items.
11. [As a beginner I have no idea what's the issue?](https://i.redd.it/lxuubsohqocf1.png) (Score: 0)
    * A beginner seeks help identifying the issue with their image generation.
12. [Comparison video Wan 2.1 vs Veo 2. Woman performing a wheelie on a 10 speed bicycle. I used Flashback Screen Recorder.](https://v.redd.it/yfq8gg6i6ocf1) (Score: 0)
    * A comparison video of Wan 2.1 vs Veo 2 is shared, showing a woman performing a wheelie on a bicycle.
13. [Supir upscaling for photography rules. No need for bigger lens](https://www.reddit.com/gallery/1lyyjkb) (Score: 0)
    * Showcasing the effectiveness of Supir upscaling for photography.
14. [What's the easiest way to run Flux and/or Chroma?](https://www.reddit.com/r/StableDiffusion/comments/1lywmw1/whats_the_easiest_way_to_run_flux_andor_chroma/) (Score: 0)
    * Asking about the easiest way to run Flux and/or Chroma.
15. [Step by Step Beginners Guide for An Idiot like Me?](https://www.reddit.com/r/StableDiffusion/comments/1lyzw0h/step_by_step_beginners_guide_for_an_idiot_like_me/) (Score: 0)
    * Seeking a step-by-step beginner's guide for Stable Diffusion.

# Detailed Analysis by Thread
**[Still in love with SD1.5 - even in 2025 (Score: 92)](https://www.reddit.com/gallery/1lyw8rm)**
*  **Summary:** The thread discusses the continued relevance of Stable Diffusion 1.5 (SD1.5) in 2025. Users are sharing their experiences, tips, and reasons for still using the older model. The discussion covers topics like generation speed, memory usage, control net capabilities, and comparisons with newer models like SDXL and Cosmos 2b.
*  **Emotion:** The overall emotional tone is Neutral, with slight variations. While some comments express positive sentiments about SD1.5 and its capabilities, others are more critical or neutral, focusing on comparisons and technical aspects.
*  **Top 3 Points of View:**
    *   SD1.5 is still a viable option due to its speed and low memory requirements.
    *   Newer models like SDXL offer better prompt adherence and understanding, making them more efficient for some users.
    *   SD1.5 remains useful for specific applications like control net and certain types of models (e.g., furry models).

**[Loras for WAN in text2image mode are amazing at capturing likeness (Score: 43)](https://imgur.com/a/K0e4Mzk)**
*  **Summary:** This thread discusses the effectiveness of using Loras with WAN in text2image mode for capturing likeness. Users share workflows, compare WAN to other tools like Flux, and troubleshoot technical issues.
*  **Emotion:** The overall emotional tone is Positive. Users express excitement and satisfaction with the performance of Loras in conjunction with WAN. However, there are some Negative sentiments when users have technical issues.
*  **Top 3 Points of View:**
    *   WAN 2.1 is excellent for text-to-image generation with Loras, particularly for capturing likeness.
    *   WAN is considered a powerful tool, possibly better than Flux for some applications.
    *   Users are encountering technical issues, particularly with PyTorch versions and missing LoRAs.

**[CLIP-KO: Knocking out the text obsession (typographic attack vulnerability) in CLIP. New Model, Text Encoder, Code, Dataset. (Score: 32)](https://www.reddit.com/gallery/1lyzjkh)**
*  **Summary:** This thread announces the release of CLIP-KO, a new model and dataset designed to address typographic attack vulnerabilities in CLIP. Users express interest in testing the new tool and ask about its compatibility with SDXL.
*  **Emotion:** The overall emotional tone is Positive to Neutral. Users are curious and express interest in trying out the new model. There's also a hint of confusion or lack of understanding about the technical details.
*  **Top 3 Points of View:**
    *   Users are eager to test CLIP-KO and see how it improves text handling in image generation.
    *   There's a desire to understand how to integrate CLIP-KO with existing workflows, particularly with SDXL.
    *   Some users may not fully grasp the technical implications of CLIP-KO but are still willing to try it out.

**[Using ComfyUI with Perplexity Comet (Score: 4)](https://i.redd.it/rs5od0oayocf1.jpeg)**
*  **Summary:** This thread features a user showcasing the integration of ComfyUI with Perplexity Comet.
*  **Emotion:** The emotional tone is Negative due to skepticism about the AI's ability to understand node connections.
*  **Top 3 Points of View:**
    *   A user doubts the AI's understanding of node connections.

**[Been trying to generate buildings, but it always adds this "Courtyard". Anyone has an idea how to stop that from happening? (Score: 3)](https://i.redd.it/tp0d474u4pcf1.png)**
*  **Summary:** A user is seeking help to prevent the generation of courtyards when creating images of buildings. The thread provides several suggestions and workarounds.
*  **Emotion:** The emotional tone is Neutral, as users are offering technical advice and solutions.
*  **Top 3 Points of View:**
    *   Inpainting can be used to remove unwanted courtyards after generation.
    *   Using a control net image with a depth map can help guide the generation process.
    *   Alternative methods like nag custom nodes or Chroma may help avoid the issue.

**[How one website gets around the payment processor issue CivitAI is having (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1lywr2n/how_one_website_gets_around_the_payment_processor/)**
*  **Summary:** This thread discusses how some websites bypass payment processor restrictions, possibly relating to the issues faced by CivitAI.
*  **Emotion:** The emotional tone is Positive, with curiosity about methods used to circumvent payment processors.
*  **Top 3 Points of View:**
    * Setting up a fake website to get approved to process payments, but using the gateway on a non conforming site.
    * Fraud can be committed or alternatives are offered for no one.

**[Training LORA, learning the wrong stuff (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1lyxm1m/training_lora_learning_the_wrong_stuff/)**
*  **Summary:** A user is asking about how to prevent LoRAs from learning the wrong details during training, specifically concerning faces.
*  **Emotion:** The overall emotional tone is Positive, focused on offering practical advice and solutions.
*  **Top 3 Points of View:**
    *   Masking can be used to prevent LoRAs from learning unwanted facial details.
    *   Tagging should focus on elements relevant to the LoRA, excluding irrelevant details.
    *   Using a relative high learning rate, keeps you away from learning the details.

**[I’m looking for a simple WF to do V2V with OpenPose in WAN 2.1 that preserves the input image exactly (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1lz1lc0/im_looking_for_a_simple_wf_to_do_v2v_with/)**
*  **Summary:** A user is seeking a straightforward workflow for video-to-video conversion using OpenPose in WAN 2.1 that preserves the input image.
*  **Emotion:** The emotional tone is Neutral, as the user is simply requesting information and others are offering suggestions.
*  **Top 3 Points of View:**
    *   Phantom is a suggestion to resolve the user's problem.

**[Checkpoint Help (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1lyaygx/checkpoint_help/)**
*  **Summary:** A user needs help understanding different checkpoint architectures and their compatibility with LoRAs. The thread provides a detailed overview of various model families and their characteristics.
*  **Emotion:** The emotional tone is Neutral, focused on providing informative and helpful advice.
*  **Top 3 Points of View:**
    *   Different checkpoint architectures (SD 1.5, FLUX, SDXL, Pony, Illustrious) have varying strengths and weaknesses.
    *   LoRAs need to match the architecture of the checkpoints for optimal results.
    *   Experimentation is key to finding the best models for specific needs.

**[Local training... noob q's (Score: 1)](https://www.reddit.com/r/StableDiffusion/com/1lyy7xp/local_training_noob_qs/)**
*  **Summary:** A new user is asking basic questions about local training, covering topics like file security, copying scenes, and training specific items.
*  **Emotion:** The overall emotional tone is Neutral, focused on providing guidance and resources for beginners.
*  **Top 3 Points of View:**
    *   Files from reputable sources like Hugging Face and Civitai are generally safe.
    *   ControlNet can be used to copy the geometry and placement of scenes.
    *   LoRAs are needed for training specific items.

**[As a beginner I have no idea what's the issue? (Score: 0)](https://i.redd.it/lxuubsohqocf1.png)**
*  **Summary:** A beginner is seeking help in identifying the cause of a problem they are encountering with image generation, without providing sufficient context.
*  **Emotion:** The emotional tone is Neutral, as users are trying to assist but need more information.
*  **Top 3 Points of View:**
    *   Need to see the user's settings.
    *   The issue may be related to LORA strength settings.
    *   The user may be using LORA instead of the model.

**[Comparison video Wan 2.1 vs Veo 2. Woman performing a wheelie on a 10 speed bicycle. I used Flashback Screen Recorder. (Score: 0)](https://v.redd.it/yfq8gg6i6ocf1)**
*  **Summary:** A comparison video between Wan 2.1 and Veo 2 is presented, depicting a woman performing a wheelie on a bicycle.
*  **Emotion:** The emotional tone is Positive, with varying degrees of endorsement for each model.
*  **Top 3 Points of View:**
    *   Wan 2.1 produced a more impressive wheelie.
    *   Veo is inferior to Wan 2.1.
    *   Veo 2 may be using prompt enhancements.

**[Supir upscaling for photography rules. No need for bigger lens (Score: 0)](https://www.reddit.com/gallery/1lyyjkb)**
*  **Summary:** This thread showcases the results of Supir upscaling for photography and the need for bigger lens.
*  **Emotion:** The emotional tone is Positive.
*  **Top 3 Points of View:**
    *   Upscaling of photographs, no need to buy new lens.
    *   Another workflow is to become a patreon member to unlock.
    *   Photography is excellent.

**[What's the easiest way to run Flux and/or Chroma? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lywmw1/whats_the_easiest_way_to_run_flux_andor_chroma/)**
*  **Summary:** The thread discusses the easiest ways to run Flux and/or Chroma.
*  **Emotion:** The emotional tone is Positive and informative, providing suggestions and highlighting the ease of use of specific tools.
*  **Top 3 Points of View:**
    *   ComfyUI/SwarmUI or Forge support Chroma.
    *   SwarmUI is the easiest to use because it uses comfy as a backend.

**[Step by Step Beginners Guide for An Idiot like Me? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lyzw0h/step_by_step_beginners_guide_for_an_idiot_like_me/)**
*  **Summary:** A user seeks a step-by-step beginner's guide to Stable Diffusion.
*  **Emotion:** The emotional tone is Positive, with users offering suggestions and resources to help beginners.
*  **Top 3 Points of View:**
    *   The subreddit wiki may contain useful resources.
    *   Youtube tutorials provide easy ways to get started.
    *   Try to get started with Think Diffusion.
