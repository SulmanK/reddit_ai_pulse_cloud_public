---
title: "Machine Learning Subreddit"
date: "2025-07-04"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "reddit", "analysis"]
---

# Overall Ranking and Top Discussions
1.  [[D] A Serious Concern on the ACL Rolling Review System](https://www.reddit.com/r/MachineLearning/comments/1lr15dk/d_a_serious_concern_on_the_acl_rolling_review/) (Score: 32)
    *   This thread discusses concerns about the ACL Rolling Review system, including reviewer behavior and potential conflicts of interest.
2.  [[D] Understanding Optimal Batch Size Calculation - Arithmetic Intensity](https://www.reddit.com/r/MachineLearning/comments/1lrc7vh/d_understanding_optimal_batch_size_calculation/) (Score: 13)
    *   This thread explores the calculation of optimal batch size, particularly in relation to arithmetic intensity.
3.  [[D] Is MBZUAI a reputable institution?](https://www.reddit.com/r/MachineLearning/comments/1lr7sur/d_is_mbzuai_a_reputable_institution/) (Score: 12)
    *   This thread discusses the reputation of the Mohamed bin Zayed University of Artificial Intelligence (MBZUAI), considering factors like funding, faculty, research output, and location.
4.  [[D] Sampling technique for imbalanced dataset of a OOS prediction model](https://www.reddit.com/r/MachineLearning/comments/1lraj3z/d_sampling_technique_for_imbalanced_dataset_of_a/) (Score: 8)
    *   The thread is about determining which sampling technique should be used for an imbalanced dataset.
5.  [[D] Is Kaggle Ranking Easier Than It Should Be?](https://www.reddit.com/r/MachineLearning/comments/1lrqett/d_is_kaggle_ranking_easier_than_it_should_be/) (Score: 5)
    *   This thread discusses whether the Kaggle ranking system is too easy, particularly for non-competition aspects like notebooks and discussions.
6.  [[D] Combining box and point prompts with SAM 2.1 for more consistent segmentation — best practices?](https://www.reddit.com/gallery/1lrjvbf) (Score: 5)
    *   The thread discusses how to combine box and point prompts with SAM 2.1 for consistent segmentation.
7.  [[D] Did anyone receive this from NIPS?](https://www.reddit.com/r/MachineLearning/comments/1lrr5yy/d_did_anyone_receive_this_from_nips/) (Score: 4)
    *   This thread discusses the issue of a co-author agreeing to review for NIPS but not fulfilling the commitment.
8.  [[R]Group Recommendation Systems — Looking for Baselines, Any Suggestions?](https://www.reddit.com/r/MachineLearning/comments/1lr934p/rgroup_recommendation_systems_looking_for/) (Score: 4)
    *   This thread is asking for baseline suggestions for Group Recommendation Systems
9.  [[R] kappaTune: a PyTorch-based optimizer wrapper for continual learning via selective fine-tuning](https://www.reddit.com/r/MachineLearning/comments/1lrnibz/r_kappatune_a_pytorchbased_optimizer_wrapper_for/) (Score: 3)
    *   This thread discusses a PyTorch-based optimizer wrapper for continual learning via selective fine-tuning.
10. [[P] Why am I getting poor performance with GNNs for edge prediction from node features only?](https://www.reddit.com/r/MachineLearning/comments/1lrcwk1/p_why_am_i_getting_poor_performance_with_gnns_for/) (Score: 2)
    *   This thread discusses the challenges of achieving good performance with Graph Neural Networks (GNNs) for edge prediction when only node features are used.
11. [[D] How trustworthy are benchmarks of new proprietary LLMs?](https://www.reddit.com/r/MachineLearning/comments/1lrnruz/d_how_trustworthy_are_benchmarks_of_new/) (Score: 2)
    *   The thread explores how trustworthy benchmarks are for the new proprietary LLMs.
12. [[D] OpenAI Board Member on ML Research in Industry vs. Academia](https://www.reddit.com/r/MachineLearning/comments/1lrdpvy/d_openai_board_member_on_ml_research_in_industry/) (Score: 0)
    *   The thread is about the point of view of an OpenAI board member on Machine Learning research in industry compared to academia.
13. [[D] Can Tesla FSD be fooled?](https://www.reddit.com/r/MachineLearning/comments/1lrq5lt/d_can_tesla_fsd_be_fooled/) (Score: 0)
    *   The thread is about whether a Tesla FSD can be fooled.

# Detailed Analysis by Thread
**[[D] A Serious Concern on the ACL Rolling Review System (Score: 32)](https://www.reddit.com/r/MachineLearning/comments/1lr15dk/d_a_serious_concern_on_the_acl_rolling_review/)**
*  **Summary:** The thread discusses concerns about the ACL Rolling Review system, with users expressing frustration over reviewer behavior, lack of engagement after rebuttals, and potential conflicts of interest. Suggestions include raising concerns at the ACL Business Meeting and focusing on improving the work based on feedback.
*  **Emotion:** The dominant emotion is positive, likely reflecting a desire for constructive change, though negative sentiment is also present due to frustrations with the review process.
*  **Top 3 Points of View:**
    *   Reviewers are sometimes uncooperative and do not engage meaningfully after rebuttals.
    *   Reviewers with submissions in the same cycle may have a conflict of interest.
    *   Researchers should focus on improving their work based on reviewer feedback, regardless of acceptance.

**[[D] Understanding Optimal Batch Size Calculation - Arithmetic Intensity (Score: 13)](https://www.reddit.com/r/MachineLearning/comments/1lrc7vh/d_understanding_optimal_batch_size_calculation/)**
*  **Summary:** The thread explores the concept of arithmetic intensity and its relationship to determining the optimal batch size for machine learning models. Users discuss how to estimate batch size, the interpretation of dividing FLOPs by Bytes, and the impact of batch size on generalization.
*  **Emotion:** The emotional tone is largely neutral, reflecting a technical discussion and exchange of information.
*  **Top 3 Points of View:**
    *   Batch size can be estimated by iteratively doubling it until the time to run an epoch no longer decreases.
    *   Dividing FLOPs by Bytes provides a measure of compute intensity versus data movement intensity.
    *   Smaller batch sizes can sometimes lead to better generalization.

**[[D] Is MBZUAI a reputable institution? (Score: 12)](https://www.reddit.com/r/MachineLearning/comments/1lr7sur/d_is_mbzuai_a_reputable_institution/)**
*  **Summary:** The thread discusses the reputation of MBZUAI, focusing on its funding, faculty, research output, and the quality of students. Opinions are generally positive, acknowledging its newness but highlighting its resources and talent. Concerns are also raised about the climate and legal system in Abu Dhabi.
*  **Emotion:** The dominant emotion is positive, reflecting favorable impressions of the institution. Neutral sentiment is also present, considering the pros and cons.
*  **Top 3 Points of View:**
    *   MBZUAI has significant financial resources and is hiring top researchers, making it a potentially good opportunity.
    *   While new, MBZUAI is producing high-quality research and has a good reputation in ML/AI circles.
    *   The climate and legal system in Abu Dhabi may be a drawback for some individuals.

**[[D] Sampling technique for imbalanced dataset of a OOS prediction model (Score: 8)](https://www.reddit.com/r/MachineLearning/comments/1lraj3z/d_sampling_technique_for_imbalanced_dataset_of_a/)**
*  **Summary:** The thread discusses the best sampling techniques to use with imbalanced datasets. Several different methods, like oversampling, undersampling, SMOTE, and loss-based learning were suggested.
*  **Emotion:** The emotional tone of the thread is neutral, with most comments providing technical advice with little to no emotional inflection.
*  **Top 3 Points of View:**
    *   Oversampling is a useful technique with imbalanced datasets.
    *   SMOTE is a recommended sampling technique.
    *   The thread suggests using a retrieval setting with memory.

**[[D] Combining box and point prompts with SAM 2.1 for more consistent segmentation — best practices? (Score: 5)](https://www.reddit.com/gallery/1lrjvbf)**
*  **Summary:** This thread discusses how to combine different prompting methods such as box prompts and point prompts to improve image segmentation results using SAM 2.1.
*  **Emotion:** The thread has a neutral tone as it offers technical advice.
*  **Top 3 Points of View:**
    *   Box prompts are converted to points, and combining boxes and points is possible.
    *   Text prompts can be combined with SAM2.1, for example by using florence2 or CLIP.
    *   Real-time semantic segmentation models like Unet or DeepLabV3 can be trained using SAM 2.1 to annotate data.

**[[D] Is Kaggle Ranking Easier Than It Should Be? (Score: 5)](https://www.reddit.com/r/MachineLearning/comments/1lrqett/d_is_kaggle_ranking_easier_than_it_should_be/)**
*  **Summary:** The thread explores how easy or difficult it is to get a high rank on Kaggle. The consensus is that earning the title of "grandmaster" is easy through discussions or notebook grinding, but obtaining "competition master" requires a lot of skill.
*  **Emotion:** The overall tone is neutral because it is a discussion about a system.
*  **Top 3 Points of View:**
    *   Earning "grandmaster" status is easy by exploiting the system.
    *   Competition master status requires skill.
    *   Kaggle rank is similar to Reddit karma.

**[[D] Did anyone receive this from NIPS? (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1lrr5yy/d_did_anyone_receive_this_from_nips/)**
*  **Summary:** This thread discusses how a co-author volunteered to review for NIPS but did not complete the task.
*  **Emotion:** The emotional tone of the thread is negative.
*  **Top 3 Points of View:**
    *   The co-author should not have volunteered to review if they weren't going to do it.
    *   The co-author is the one who is wrong, not the conference.
    *   Asking the co-author to hand over their review login.

**[[R]Group Recommendation Systems — Looking for Baselines, Any Suggestions? (Score: 4)](https://www.reddit.com/r/MachineLearning/comments/1lr934p/rgroup_recommendation_systems_looking_for/)**
*  **Summary:** This thread recommends matrix factorization and tensor models for recommendation systems.
*  **Emotion:** The emotional tone of this thread is neutral.
*  **Top 3 Points of View:**
    *   Tensor/Matrix factorization models are good baseline models.
    *   More recent GNN-based models are recommended.

**[[R] kappaTune: a PyTorch-based optimizer wrapper for continual learning via selective fine-tuning (Score: 3)](https://www.reddit.com/r/MachineLearning/comments/1lrnibz/r_kappatune_a_pytorchbased_optimizer_wrapper_for/)**
*  **Summary:** This thread is about a Pytorch optimizer and whether it eliminates the need to manually freeze layers.
*  **Emotion:** The emotional tone of the thread is neutral.
*  **Top 3 Points of View:**
    *   The user wants to know if they will need to manually freeze layers.
    *   The user is asking if the condition number should be recomputed periodically.
    *   The user is asking if they have tried this method with CIFAR-10 or CIFAR-100.

**[[P] Why am I getting poor performance with GNNs for edge prediction from node features only? (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1lrcwk1/p_why_am_i_getting_poor_performance_with_gnns_for/)**
*  **Summary:** This thread is about the user getting bad performance on GNNs for edge prediction.
*  **Emotion:** The emotional tone is negative.
*  **Top 3 Points of View:**
    *   The user is trying to determine why they are getting poor performance with GNNs for edge prediction from node features.
    *   Link prediction works better on larger graphs.

**[[D] How trustworthy are benchmarks of new proprietary LLMs? (Score: 2)](https://www.reddit.com/r/MachineLearning/comments/1lrnruz/d_how_trustworthy_are_benchmarks_of_new/)**
*  **Summary:** This thread is about how trustworthy benchmarks are for the new proprietary LLMs.
*  **Emotion:** The emotional tone of the thread is negative.
*  **Top 3 Points of View:**
    *   Create a user-friendly app for non-technical people to evaluate LLMs.

**[[D] OpenAI Board Member on ML Research in Industry vs. Academia (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1lrdpvy/d_openai_board_member_on_ml_research_in_industry/)**
*  **Summary:** This thread is about the point of view of an OpenAI board member on Machine Learning research in industry compared to academia.
*  **Emotion:** The emotional tone of the thread is positive.
*  **Top 3 Points of View:**
    *   The viewpoint of an OpenAI board member is likely biased.

**[[D] Can Tesla FSD be fooled? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1lrq5lt/d_can_tesla_fsd_be_fooled/)**
*  **Summary:** This thread is asking whether Tesla's FSD (Full Self-Driving) can be fooled.
*  **Emotion:** The emotional tone of the thread is positive and neutral.
*  **Top 3 Points of View:**
    *   Adversarial attacks and data poisoning can fool a FSD.
    *   It is easier to fool an FSD using things that humans can see and interpret.
    *   Yes, here is an example.
