---
title: "Stable Diffusion Subreddit"
date: "2025-07-04"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["stablediffusion", "AI", "image generation"]
---

# Overall Ranking and Top Discussions
1.  [Simpletuner creator is reporting N S F W loras on huggingface and they are being removed. The community needs to look elsewhere to post controversial loras](https://i.redd.it/cefqbeb79waf1.png) (Score: 147)
    *   The discussion revolves around the removal of N S F W LoRAs (models) from Hugging Face by the Simpletuner creator, leading to a debate about censorship and alternative hosting options, such as torrents.
2.  [My first try at making an autoregressive colorizer model](https://v.redd.it/lv57osd2awaf1) (Score: 67)
    *   Users are discussing the creator's autoregressive colorizer model, offering advice on validation techniques, suggesting alternative approaches like diffusion models, and requesting more details about the model's implementation.
3.  [Hitem3D currently best mesh generator? Three img2mesh generation examples](https://www.reddit.com/gallery/1lrpvoq) (Score: 28)
    *   The thread discusses the capabilities of Hitem3D for generating 3D meshes from images, with some users questioning whether it is open source and requesting to see the unexposed sides of the generated meshes. There's also a mention of "hunyuan 3d" as a potentially superior alternative.
4.  [I built a GUI tool for FLUX LoRA manipulation - advanced layer merging, face and style pre-sets, subtraction, layer zeroing, metadata editing and more. Tried to build what I wanted, something easy.](https://www.reddit.com/gallery/1lrmnfj) (Score: 20)
    *   The discussion centers around a new GUI tool for manipulating FLUX LoRAs. Users are expressing interest in the tool, asking about its capabilities with different models (Illustrious, Pony), requesting a demonstration video, and thanking the creator for explaining block and layer architecture.
5.  [Trying to use an upscaling workflow using a nunchaku based FLUX model (Works great on low vram and it outputs 4K images + Workflow included)](https://www.reddit.com/gallery/1lrngyp) (Score: 9)
    *   The conversation focuses on an upscaling workflow using a nunchaku-based FLUX model, particularly its performance on low VRAM systems. Users are asking about the definition of "low RAM" and inquiring about compatibility with other upscaling methods.
6.  [Can we take a moment to appreciate how insane Flux Kontext dev is?](https://www.reddit.com/r/StableDiffusion/comments/1lrrdyi/can_we_take_a_moment_to_appreciate_how_insane/) (Score: 9)
    *   Users are discussing Flux Kontext dev, with mixed opinions on its performance. Some find it disappointing due to blurriness and inconsistent results, while others acknowledge its potential, particularly for watermark removal, but note issues with face swapping and auto-colorizing.
7.  [Ovis-U1-3B small yet capable all to all free model](https://www.reddit.com/gallery/1lrrrdp) (Score: 5)
    *   The thread is about the Ovis-U1-3B model, with users sharing links to download it and try it out.
8.  [How come openpose always generates black images for me?](https://i.redd.it/nnjroq6ukwaf1.png) (Score: 3)
    *   A user is seeking help with Openpose generating black images, and others are offering suggestions, such as using AIO Aux preprocessor node or acknowledging that the issue sometimes occurs randomly.
9. [How to set up Wan2.1 with ComfyUI and Loras? 3080 8GB | 64 GB Ram](https://www.reddit.com/r/StableDiffusion/comments/1lrr9d1/how_to_set_up_wan21_with_comfyui_and_loras_3080/) (Score: 1)
    * A user is asking how to setup Wan2.1 with ComfyUI and Loras, and another user provided custom nodes and workflows.
10. [Ignorant question: how Flix Kontext Lora are trained ?](https://www.reddit.com/r/StableDiffusion/comments/1lrl7ht/ignorant_question_how_flix_kontext_lora_are/) (Score: 0)
    * A user is asking how Flix Kontext Lora are trained, and another user provided video tutorials for training.
11. [Loading time - SD vs. ComfyUI](https://www.reddit.com/r/StableDiffusion/comments/1lrm8j0/loading_time_sd_vs_comfyui/) (Score: 0)
    * A user is comparing loading times between SD and ComfyUI.
12. [Krita AI results looks too similar](https://www.reddit.com/r/StableDiffusion/comments/1lrno3b/krita_ai_results_looks_too_similar/) (Score: 0)
    * A user is asking why Krita AI results looks too similar, and another user suggested using wildcards to randomize the details about prompts.
13. [Flux Kontext is not working for this image](https://www.reddit.com/r/StableDiffusion/comments/1lrnt9h/flux_kontext_is_not_working_for_this_image/) (Score: 0)
    * A user is complaining about Flux Kontext not working for a specific image.
14. [Is VACE continue video using WAN better at using the context of the video than I2V or is it the same thing just automatically extracting the last frame?](https://www.reddit.com/r/StableDiffusion/comments/1lrnwgv/is_vace_continue_video_using_wan_better_at_using/) (Score: 0)
    * A user is asking if VACE continue video using WAN is better at using context of video than I2V.
15. [What is her name?](https://www.reddit.com/r/StableDiffusion/comments/1lrobrd/what_is_her_name/) (Score: 0)
    * A user is asking what is the name of a person.
16. [How to use ai to add to a video?](https://www.reddit.com/r/StableDiffusion/comments/1lrop5e/how_to_use_ai_to_add_to_a_video/) (Score: 0)
    * A user is asking how to use AI to add to a video.
17. [Why is no one talking about the ai studio/Instagram collective Slop shop](https://www.reddit.com/r/StableDiffusion/comments/1lroxex/why_is_no_one_talking_about_the_ai/) (Score: 0)
    * A user is asking why no one is talking about the AI studio/Instagram collective Slop shop.
18. [How Can I Swap My Face Into an AI Image Accurately?](https://www.reddit.com/r/StableDiffusion/comments/1lrplle/how_can_i_swap_my_face_into_an_ai_image_accurately/) (Score: 0)
    * A user is asking how they can swap their face into an AI image accurately.

# Detailed Analysis by Thread
**[Simpletuner creator is reporting N S F W loras on huggingface and they are being removed. The community needs to look elsewhere to post controversial loras (Score: 147)](https://i.redd.it/cefqbeb79waf1.png)**
*  **Summary:**  The thread discusses the removal of N S F W LoRAs (models) from Hugging Face by the Simpletuner creator, leading to a debate about censorship and alternative hosting options, such as torrents.
*  **Emotion:** The emotional tone is mixed, with Neutral being the most frequent, alongside some Negative and Positive sentiment depending on user opinions regarding the creator's actions and the censorship.
*  **Top 3 Points of View:**
    *   The Simpletuner creator is justified in removing N S F W content.
    *   The community needs to find alternative, uncensored hosting solutions, such as torrents.
    *   The actions are nonsensical, especially for an open-source tool.

**[My first try at making an autoregressive colorizer model (Score: 67)](https://v.redd.it/lv57osd2awaf1)**
*  **Summary:** Users are discussing the creator's autoregressive colorizer model, offering advice on validation techniques, suggesting alternative approaches like diffusion models, and requesting more details about the model's implementation.
*  **Emotion:** Primarily Neutral, focusing on technical aspects, with some Positive sentiment towards the project's value as a learning experience.
*  **Top 3 Points of View:**
    *   The model should be validated using images not used in training.
    *   Diffusion models might be a faster alternative to autoregressive models.
    *   More details about the model's implementation are needed.

**[Hitem3D currently best mesh generator? Three img2mesh generation examples (Score: 28)](https://www.reddit.com/gallery/1lrpvoq)**
*  **Summary:** The thread discusses the capabilities of Hitem3D for generating 3D meshes from images, with some users questioning whether it is open source and requesting to see the unexposed sides of the generated meshes. There's also a mention of "hunyuan 3d" as a potentially superior alternative.
*  **Emotion:** Mostly Neutral, with a slight leaning towards Positive sentiment expressing amazement and interest.
*  **Top 3 Points of View:**
    *   Hitem3D is a high-quality mesh generator.
    *   It's important to know if Hitem3D is open or closed source.
    *   It would be helpful to see the full 3D mesh, not just the side visible in the input image.

**[I built a GUI tool for FLUX LoRA manipulation - advanced layer merging, face and style pre-sets, subtraction, layer zeroing, metadata editing and more. Tried to build what I wanted, something easy. (Score: 20)](https://www.reddit.com/gallery/1lrmnfj)**
*  **Summary:** The discussion centers around a new GUI tool for manipulating FLUX LoRAs. Users are expressing interest in the tool, asking about its capabilities with different models (Illustrious, Pony), requesting a demonstration video, and thanking the creator for explaining block and layer architecture.
*  **Emotion:** Mostly Neutral, with a noticeable Positive sentiment reflecting excitement and appreciation for the tool and its creator.
*  **Top 3 Points of View:**
    *   The GUI tool is a valuable contribution.
    *   It would be beneficial if the tool supported other models like Illustrious or Pony.
    *   A demonstration video would be helpful in understanding the tool's functionality.

**[Trying to use an upscaling workflow using a nunchaku based FLUX model (Works great on low vram and it outputs 4K images + Workflow included) (Score: 9)](https://www.reddit.com/gallery/1lrngyp)**
*  **Summary:** The conversation focuses on an upscaling workflow using a nunchaku-based FLUX model, particularly its performance on low VRAM systems. Users are asking about the definition of "low RAM" and inquiring about compatibility with other upscaling methods.
*  **Emotion:** Primarily Neutral, with some Positive feedback regarding the workflow's effectiveness.
*  **Top 3 Points of View:**
    *   The workflow is effective for upscaling images with low VRAM.
    *   The term "low RAM" needs clarification.
    *   The workflow is appreciated.

**[Can we take a moment to appreciate how insane Flux Kontext dev is? (Score: 9)](https://www.reddit.com/r/StableDiffusion/comments/1lrrdyi/can_we_take_a_moment_to_appreciate_how_insane/)**
*  **Summary:** Users are discussing Flux Kontext dev, with mixed opinions on its performance. Some find it disappointing due to blurriness and inconsistent results, while others acknowledge its potential, particularly for watermark removal, but note issues with face swapping and auto-colorizing.
*  **Emotion:** Mixed, leaning towards Negative, with disappointment being a recurring theme despite some appreciation for specific features.
*  **Top 3 Points of View:**
    *   Flux Kontext dev is currently disappointing due to blurriness and inconsistent results.
    *   It has potential, especially for watermark removal.
    *   Proper prompting is crucial for achieving good results.

**[Ovis-U1-3B small yet capable all to all free model (Score: 5)](https://www.reddit.com/gallery/1lrrrdp)**
*  **Summary:** The thread is about the Ovis-U1-3B model, with users sharing links to download it and try it out.
*  **Emotion:** The sentiment is overwhelmingly Neutral, simply sharing information about the model.
*  **Top 3 Points of View:**
    *   The Ovis-U1-3B model is available for download.
    *   The Ovis-U1-3B model has an Apache License 2.0
    *   The poster isn't the owner of the model

**[How come openpose always generates black images for me? (Score: 3)](https://i.redd.it/nnjroq6ukwaf1.png)**
*  **Summary:** A user is seeking help with Openpose generating black images, and others are offering suggestions, such as using AIO Aux preprocessor node or acknowledging that the issue sometimes occurs randomly.
*  **Emotion:** The emotional tone is Neutral as users are trying to help each other with technical issues.
*  **Top 3 Points of View:**
    *   AIO Aux preprocessor node might resolve the issue.
    *   The issue might be due to Openpose not detecting the pose correctly.
    *   User is trying to recreate a pose from pixiv.net

**[How to set up Wan2.1 with ComfyUI and Loras? 3080 8GB | 64 GB Ram (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1lrr9d1/how_to_set_up_wan21_with_comfyui_and_loras_3080/)**
*  **Summary:** A user is asking how to setup Wan2.1 with ComfyUI and Loras, and another user provided custom nodes and workflows.
*  **Emotion:** The emotional tone is Neutral as users are trying to help each other with technical issues.
*  **Top 3 Points of View:**
    *   GGUF and DisTorch nodes from here work for my 10GB VRAM
    *   Just use a workflow from here and replace the loaders with loaders from the custom node.
    *   There are also some ways to speed up generation itself, but that's a separate thing.

**[Ignorant question: how Flix Kontext Lora are trained ? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrl7ht/ignorant_question_how_flix_kontext_lora_are/)**
*  **Summary:** A user is asking how Flix Kontext Lora are trained, and another user provided video tutorials for training.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   A control image and target image with a prompt
    *   from the maker of ai toolkit himself https://www.youtube.com/watch?v=WSWubJ4eFqI
    *   First test using Kontext Dev Lora trainer : r/FluxAI

**[Loading time - SD vs. ComfyUI (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrm8j0/loading_time_sd_vs_comfyui/)**
*  **Summary:** A user is comparing loading times between SD and ComfyUI.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Not sure what the problem is. It's been the opposite for me, mainly because of GGUF that Forge loads longer for some reason.
    *   There might me something wrong with your setup.
    *   I would reinstall a fresh Comfy.

**[Krita AI results looks too similar (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrno3b/krita_ai_results_looks_too_similar/)**
*  **Summary:** A user is asking why Krita AI results looks too similar, and another user suggested using wildcards to randomize the details about prompts.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Write longer prompts.
    *   Flowmatching models like flux converge to pretty much the same result if you use short ones or use something like chroma with a low CFG.
    *   You could use wildcards and similar to randomize some details about prompts.

**[Flux Kontext is not working for this image (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrnt9h/flux_kontext_is_not_working_for_this_image/)**
*  **Summary:** A user is complaining about Flux Kontext not working for a specific image.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Kontext is absolutely unpredictable.
    *   Kontext is not something predictable.
    *   Try: Remove the person on the left from the photo while maintaining the original composition.

**[Is VACE continue video using WAN better at using the context of the video than I2V or is it the same thing just automatically extracting the last frame? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrnwgv/is_vace_continue_video_using_wan_better_at_using/)**
*  **Summary:** A user is asking if VACE continue video using WAN is better at using context of video than I2V.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   I2v doesn’t use context as I understand it for continue video workflows you can have several frames of context to help with flow
    *   Vace can use more than a single frame and thus have better coherence in the continuation as opposed to single frame which would lose all momentum

**[What is her name? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrobrd/what_is_her_name/)**
*  **Summary:** A user is asking what is the name of a person.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Hi, my name is, what? My name is, who?
    *   AND HER NAME IS JOOOOOHN CEEEEENAAAA !!!!!!
    *   darude sandstorm

**[How to use ai to add to a video? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrop5e/how_to_use_ai_to_add_to_a_video/)**
*  **Summary:** A user is asking how to use AI to add to a video.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   Try searching for video to video or v2v workflows
    *   you can probably get away with a still image or a start/stop image and an i2v workflow
    *   You're on the bleeding edge to do 5 secs of 720p on a 5090.

**[Why is no one talking about the ai studio/Instagram collective Slop shop (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lroxex/why_is_no_one_talking_about_the_ai/)**
*  **Summary:** A user is asking why no one is talking about the AI studio/Instagram collective Slop shop.
*  **Emotion:** Mixed, with Neutral and Negative sentiment present.
*  **Top 3 Points of View:**
    *   Not sure why we should talk about it.
    *   Please don't give influencers free advertising.
    *   I think this is just an ad for your Instagram handle.

**[How Can I Swap My Face Into an AI Image Accurately? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1lrplle/how_can_i_swap_my_face_into_an_ai_image_accurately/)**
*  **Summary:** A user is asking how they can swap their face into an AI image accurately.
*  **Emotion:** The emotional tone is Neutral.
*  **Top 3 Points of View:**
    *   The best way is to create or pay someone to create a LORA of you from 20 or so photos of you.
    *   If you don't have a powerful PC to do it yourself you can use online services like CivitAI to have the LORA made
    *   A less accurate option is to use faceswappers
