---
title: "Stable Diffusion Subreddit"
date: "2025-07-23"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["Stable Diffusion", "AI", "Image Generation"]
---

# Overall Ranking and Top Discussions
1.  [IDK about you all, but im pretty sure illustrious is still the best looking model :3](https://i.redd.it/mozwjubm1mef1.png) (Score: 126)
    * This thread discusses the best looking stable diffusion models, with a focus on the Illustrious model.
2.  [Best Illustrious finetune?](https://www.reddit.com/r/StableDiffusion/comments/1m78bsd/best_illustrious_finetune/) (Score: 22)
    *  This thread asks for recommendations for the best fine-tuned versions of the Illustrious model.
3.  ['Repeat After Me' - July 2025. Generative](https://v.redd.it/nnuv4bhpenef1) (Score: 20)
    *  This thread features a generative video and encourages discussion on its potential, including ideas about NFTs and automating creativity.
4.  [Anyone training loras text2IMAGE for Wan 14 B? Have people discovered any guidelines? For example - dim/alpha value, does training at 512 or 728 resolution make much difference? The number of images?](https://www.reddit.com/r/StableDiffusion/comments/1m7bjph/anyone_training_loras_text2image_for_wan_14_b/) (Score: 6)
    *  Users are discussing the training of LoRAs (Low-Rank Adaptation) for the Wan 14 B model, seeking guidelines on parameters like dim/alpha value, resolution, and the number of images needed.
5.  [Don't you love it when the AI recognizes an obscure prompt?](https://i.redd.it/zkddbj3wjnef1.png) (Score: 5)
    *  This thread marvels at AI's ability to recognize and generate images based on obscure prompts, even from relatively unknown books.
6.  [How do you use Chroma v45 in the official workflow?](https://www.reddit.com/r/StableDiffusion/comments/1m7apy1/how_do_you_use_chroma_v45_in_the_official_workflow/) (Score: 5)
    *  This thread discusses the installation and usage of Chroma v45 within a specific workflow.
7.  [Is it natural for ComfyUI to run super slowly (img2vid gen)?](https://www.reddit.com/r/StableDiffusion/comments/1m76xls/is_it_natural_for_comfyui_to_run_super_slowly/) (Score: 1)
    *  This thread discusses the performance of ComfyUI for image-to-video generation, with users offering suggestions to improve speed and efficiency.
8.  [Wan text2IMAGE incredibly slow. 3 to 4 minutes to generate a single image. Am I doing something wrong ?](https://www.reddit.com/r/StableDiffusion/comments/1m78zeo/wan_text2image_incredibly_slow_3_to_4_minutes_to/) (Score: 1)
    *  Users are troubleshooting slow image generation times with the Wan text2image model, discussing potential causes and solutions.
9.  [Hot take on video models and the future being 3d art](https://www.reddit.com/r/StableDiffusion/comments/1m79zc4/hot_take_on_video_models_and_the_future_being_3d/) (Score: 0)
    *  This thread discusses the future of video models, specifically whether smaller, more specialized models are more beneficial than giant all-encompassing ones.
10. [Any Suggestions for High-Fidelity Inpainting of Jewels on Images](https://www.reddit.com/r/StableDiffusion/comments/1m7bui2/any_suggestions_for_highfidelity_inpainting_of/) (Score: 0)
    *  This thread seeks suggestions for high-fidelity inpainting of jewels onto images using Stable Diffusion.
11. [Trying to Start an AI Content Business… But Can’t Find the Right Partner](https://www.reddit.com/r/StableDiffusion/comments/1m7c5qf/trying_to_start_an_ai_content_business_but_cant/) (Score: 0)
    *  The thread is about finding a partner to start an AI content business.
12. [Any Flux/Flux Kontext Loras that "de-fluxifies" outputs?](https://www.reddit.com/r/StableDiffusion/comments/1m7crux/any_fluxflux_kontext_loras_that_defluxifies/) (Score: 0)
    *  This thread asks for recommendations on LoRAs that can improve image quality when using the Flux/Flux Kontext models.
13. [Flux + light-peach lipstick, in Comfyui](https://www.reddit.com/r/StableDiffusion/comments/1m7fykw/flux_lightpeach_lipstick_in_comfyui/) (Score: 0)
    *  This thread discusses how to fix light-peach lipstick in ComfyUI.

# Detailed Analysis by Thread
**[[D] IDK about you all, but im pretty sure illustrious is still the best looking model :3 (Score: 126)](https://i.redd.it/mozwjubm1mef1.png)**
*  **Summary:** The thread revolves around users sharing their opinions on the best-looking stable diffusion models, with a particular emphasis on the Illustrious model. Various models are compared, with discussions on anime vs. photorealistic capabilities and the presence of watermarks.
*  **Emotion:** The overall emotional tone is neutral, with a mix of positive and negative sentiments depending on the specific model being discussed. Some comments express enthusiasm for the Illustrious model, while others suggest alternatives or point out its limitations.
*  **Top 3 Points of View:**
    *   Illustrious is considered the best-looking model by the original poster and some commenters.
    *   Other models like NoobAI, NovelAI, and Wan T2I are suggested as superior alternatives.
    *   The best model depends on the specific use case, such as anime vs. photorealistic images.

**[Best Illustrious finetune? (Score: 22)](https://www.reddit.com/r/StableDiffusion/comments/1m78bsd/best_illustrious_finetune/)**
*  **Summary:** The thread is a request for recommendations on the best fine-tuned versions of the Illustrious stable diffusion model. Users share their preferred fine-tunes, along with their reasons for liking them.
*  **Emotion:** The emotional tone is generally positive, with users enthusiastically sharing their favorite models and providing helpful suggestions.
*  **Top 3 Points of View:**
    *   Aesthetic preferences are highly subjective, making it difficult to definitively recommend one "best" finetune.
    *   Several specific finetunes are recommended, including JANKU, miaomiao vpred, Plant Milk Walnut, and WAI.
    *   LoRA compatibility is an important factor for some users when choosing a finetune.

**['Repeat After Me' - July 2025. Generative (Score: 20)](https://v.redd.it/nnuv4bhpenef1)**
*  **Summary:** A user shares a generative video titled "Repeat After Me" and prompts discussion around its potential.
*  **Emotion:** The overall emotion is positive, with users expressing appreciation for the video and sharing ideas about its future applications.
*  **Top 3 Points of View:**
    *   The video is considered a great example of generative AI.
    *   NFTs and their role in preserving early AI art are discussed.
    *   The concept of automating creativity through a "telephone game" approach is explored.

**[Anyone training loras text2IMAGE for Wan 14 B? Have people discovered any guidelines? For example - dim/alpha value, does training at 512 or 728 resolution make much difference? The number of images? (Score: 6)](https://www.reddit.com/r/StableDiffusion/comments/1m7bjph/anyone_training_loras_text2image_for_wan_14_b/)**
*  **Summary:** The thread is a discussion about training LoRAs for the Wan 14 B model, with users seeking guidance on various training parameters.
*  **Emotion:** The overall emotional tone is neutral and informative, with users sharing their experiences and advice.
*  **Top 3 Points of View:**
    *   LoRA can be used to generate both images and videos.
    *   A specific YouTube tutorial is recommended for creating Wan Loras.
    *   The resolution of training images is important, with higher resolution generally preferred when VRAM allows.

**[Don't you love it when the AI recognizes an obscure prompt? (Score: 5)](https://i.redd.it/zkddbj3wjnef1.png)**
*  **Summary:** A user expresses amazement at the AI's capacity to generate images based on even the most obscure prompts, highlighting its knowledge and capabilities.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   AI can recognize an obscure prompt
    *   Pick your favorite scene from a book written 50 years that was never popular. It still knows. =)
    *   No other points of view available in this thread.

**[How do you use Chroma v45 in the official workflow? (Score: 5)](https://www.reddit.com/r/StableDiffusion/comments/1m7apy1/how_do_you_use_chroma_v45_in_the_official_workflow/)**
*  **Summary:** The thread discusses how to use Chroma v45.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Have you reloaded nodes? Either refresh or press "r".
    *   The file goes into the "diffusion_models" folder. (V46 is the latest.) Edit to add: If it's the safetensors-version. GGUF goes into the unet-folder, I think, don't use it myself. GGUF also uses a different loader.
    *   No other points of view available in this thread.

**[Is it natural for ComfyUI to run super slowly (img2vid gen)? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m76xls/is_it_natural_for_comfyui_to_run_super_slowly/)**
*  **Summary:** The thread discusses the performance of ComfyUI for image-to-video generation, with users offering suggestions to improve speed and efficiency.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Make sure your VRAM usage isn't reaching >95%.
    *   Try using the web ui of comfy, if you haven't already.
    *   Try using the Wan 720p Q8 GGUF model.

**[Wan text2IMAGE incredibly slow. 3 to 4 minutes to generate a single image. Am I doing something wrong ? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m78zeo/wan_text2image_incredibly_slow_3_to_4_minutes_to/)**
*  **Summary:** Users are troubleshooting slow image generation times with the Wan text2image model, discussing potential causes and solutions.
*  **Emotion:** The emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Check if Lightx2v or similar speed-enhancing techniques are being used.
    *   System specifications are necessary to provide accurate troubleshooting advice.
    *   Verify if the user is attempting to use Wan (designed for video) for still image generation.

**[Hot take on video models and the future being 3d art (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m79zc4/hot_take_on_video_models_and_the_future_being_3d/)**
*  **Summary:** This thread discusses the future of video models.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Giant all encompassing AI models are not the direction we should be going.
    *   Crazy good vfx artists are using AI for vfx.
    *   Generative world stuff is being worked on.

**[Any Suggestions for High-Fidelity Inpainting of Jewels on Images (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m7bui2/any_suggestions_for_highfidelity_inpainting_of/)**
*  **Summary:** This thread seeks suggestions for high-fidelity inpainting of jewels onto images using Stable Diffusion.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   There are two types of inpainting: one attempts to repaint the entire image and the other only focuses on the masked area to inpaint.
    *   No other points of view available in this thread.
    *   No other points of view available in this thread.

**[Trying to Start an AI Content Business… But Can’t Find the Right Partner (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m7c5qf/trying_to_start_an_ai_content_business_but_cant/)**
*  **Summary:** The thread is about finding a partner to start an AI content business.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Dont start with a text made by chatgpt.
    *   Nobody will let you rip them off.
    *   It's a slow process to produce a character lora which is flexible, high quality and consistent.

**[Any Flux/Flux Kontext Loras that "de-fluxifies" outputs? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m7crux/any_fluxflux_kontext_loras_that_defluxifies/)**
*  **Summary:** This thread asks for recommendations on LoRAs that can improve image quality when using the Flux/Flux Kontext models.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Try the clown shark nodes.
    *   Unflux for Kontext?
    *   There's one from fofr.

**[Flux + light-peach lipstick, in Comfyui (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m7fykw/flux_lightpeach_lipstick_in_comfyui/)**
*  **Summary:** This thread discusses how to fix light-peach lipstick in ComfyUI.
*  **Emotion:** The overall emotional tone is neutral.
*  **Top 3 Points of View:**
    *   Have you tried the Kontext Place It LoRA?
    *   Yeah, learn to fix it manually and run it through again.
    *   No other points of view available in this thread.
