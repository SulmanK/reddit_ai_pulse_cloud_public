---
title: "Machine Learning Subreddit"
date: "2025-07-02"
description: "Analysis of top discussions and trends in the machinelearning subreddit"
tags: ["machinelearning", "AI", "LLM"]
---

# Overall Ranking and Top Discussions
1.  [[D] How will LLM companies deal with CloudFlare's anti-crawler protections, now turned on by default (opt-out)?](https://www.reddit.com/r/MachineLearning/comments/1lppvk8/d_how_will_llm_companies_deal_with_cloudflares/) (Score: 62)
    * Discussion on how Large Language Model (LLM) companies will handle CloudFlare's new anti-crawler protections.
2.  [[D] Request for Career Advice ‚Äì ML PhD non hot topic](https://www.reddit.com/r/MachineLearning/comments/1lphfhf/d_request_for_career_advice_ml_phd_non_hot_topic/) (Score: 45)
    *  Career advice for an ML PhD graduate whose research area is not currently a hot topic.
3.  [[D] How to become fluent at modifying/designing/improving models?](https://www.reddit.com/r/MachineLearning/comments/1lppyht/d_how_to_become_fluent_at/) (Score: 17)
    *  Discussion on how to improve skills in modifying, designing, and improving machine learning models.
4.  [[D] Will the relationship between Meta's FAIR and Super Intelligence Labs be like that of Google Brain and DeepMind previously?](https://www.reddit.com/r/MachineLearning/comments/1lplwz3/d_will_the_relationship_between_metas_fair_and/) (Score: 9)
    *  Speculation on the future relationship between Meta's FAIR and Super Intelligence Labs, drawing parallels with Google Brain and DeepMind.
5.  [[D] Classical ML prediction - preventing data leakage from time series process data üôè](https://www.reddit.com/r/MachineLearning/comments/1lpjc4n/d_classical_ml_prediction_preventing_data_leakage/) (Score: 8)
    *  Seeking advice on preventing data leakage in classical ML prediction, specifically with time-series data.
6.  [[D] Tips / Hints for scaling agents and ML/AI Ops?](https://www.reddit.com/r/MachineLearning/comments/1lpxgsj/d_tips_hints_for_scaling_agents_and_mlai_ops/) (Score: 0)
    *  A query regarding tips and hints for scaling agents and ML/AI Operations.
7.  [[D] Do LLMs need experience?](https://www.reddit.com/r/MachineLearning/comments/1lq0sgn/d_do_llms_need_experience/) (Score: 0)
    *  Discussion on whether Large Language Models (LLMs) need "experience" to improve, potentially through continuous fine-tuning.
8.  [[D] Jupyternaut is anyone using it on their notebooks ?](https://www.reddit.com/r/MachineLearning/comments/1lq1hel/d_jupyternaut_is_anyone_using_it_on_their/) (Score: 0)
    *  A question about whether anyone is using Jupyternaut on their notebooks.

# Detailed Analysis by Thread
**[[D] How will LLM companies deal with CloudFlare's anti-crawler protections, now turned on by default (opt-out)? (Score: 62)](https://www.reddit.com/r/MachineLearning/comments/1lppvk8/d_how_will_llm_companies_deal_with_cloudflares/)**
*   **Summary:** This thread discusses the challenges that Large Language Model (LLM) companies face with CloudFlare's anti-crawler protections being enabled by default. Users suggest various strategies, including paying CloudFlare, improving sample efficiency, and using browser extensions to scrape data.
*   **Emotion:** The overall emotional tone is neutral, with users mainly discussing technical and strategic aspects of the issue.
*   **Top 3 Points of View:**
    *   LLM companies might end up paying CloudFlare for access.
    *   Scrapers will always find a way to bypass the protections because the content needs to be accessible to humans.
    *   Improving sample efficiency in LLMs can help reduce the need for extensive crawling.

**[[D] Request for Career Advice ‚Äì ML PhD non hot topic (Score: 45)](https://www.reddit.com/r/MachineLearning/comments/1lphfhf/d_request_for_career_advice_ml_phd_non_hot_topic/)**
*   **Summary:** This thread focuses on providing career advice to a Machine Learning PhD graduate whose research area is not currently considered a "hot topic." Users share their experiences and suggest strategies for finding jobs in both industry and academia.
*   **Emotion:** The overall emotional tone is neutral, focusing on practical advice and career strategies.
*   **Top 3 Points of View:**
    *   Networking and internships are crucial for securing research scientist positions.
    *   It's important to showcase your work through code, demos, and presentations.
    *   Even with a "non-hot" topic, it's possible to transition into relevant areas like LLM applied research.

**[[D] How to become fluent at modifying/designing/improving models? (Score: 17)](https://www.reddit.com/r/MachineLearning/comments/1lppyht/d_how_to_become_fluent_at/)**
*   **Summary:** The thread explores methods for becoming proficient in modifying, designing, and improving machine learning models. The main suggestion is to practice by building, implementing, and tweaking models, with a focus on learning from failures.
*   **Emotion:** The overall emotional tone is slightly positive, encouraging practice and hands-on experience.
*   **Top 3 Points of View:**
    *   Building and experimenting with models is more effective than passively reading.
    *   Digging into the layers and modules causing issues is where the real learning happens.
    *   Tweaking existing architectures and observing the results is a good way to gain confidence.

**[[D] Will the relationship between Meta's FAIR and Super Intelligence Labs be like that of Google Brain and DeepMind previously? (Score: 9)](https://www.reddit.com/r/MachineLearning/comments/1lplwz3/d_will_the_relationship_between_metas_fair_and/)**
*   **Summary:** Users are speculating on the relationship between Meta's FAIR and Super Intelligence Labs, wondering if it will resemble the relationship between Google Brain and DeepMind. The discussion touches on potential competition for resources and differing research directions.
*   **Emotion:** Neutral, with a speculative and analytical tone.
*   **Top 3 Points of View:**
    *   FAIR may be consumed by the GenAI and super intelligence labs.
    *   There might be a "turf war" over computational resources.
    *   The two labs might pursue different research directions, with FAIR focusing on architectures other than scaled-up autoregressive models.

**[[D] Classical ML prediction - preventing data leakage from time series process data üôè (Score: 8)](https://www.reddit.com/r/MachineLearning/comments/1lpjc4n/d_classical_ml_prediction_preventing_data_leakage/)**
*   **Summary:** This thread addresses the problem of preventing data leakage in classical ML prediction, specifically for time-series data. Users provide advice on proper data splitting and cross-validation techniques.
*   **Emotion:** The thread maintains a neutral and helpful tone, with users offering practical solutions.
*   **Top 3 Points of View:**
    *   Using step-forward cross-validation is crucial for time-series data to avoid data leakage.
    *   Model development should simulate the way the model will be handled in production.
    *   Out-of-sample testing with a temporally held-out test set is necessary to assess true model performance.

**[[D] Tips / Hints for scaling agents and ML/AI Ops? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1lpxgsj/d_tips_hints_for_scaling_agents_and_mlai_ops/)**
*   **Summary:** This thread is asking for tips on how to scale agents and ML/AI Operations.
*   **Emotion:** Neutral.
*   **Top 3 Points of View:**
    *   A question regarding simulating a social environment with interacting agents or doing normal enterprise agent work with RAGs.
    *   A question about what the original poster wants to scale.
    *   Not enough information provided to understand what kind of tips are needed.

**[[D] Do LLMs need experience? (Score: 0)](https://www.reddit.com/r/MachineLearning/comments/1lq0sgn/d_do_llms_need_experience/)**
*   **Summary:** The discussion revolves around whether LLMs benefit from "experience," potentially through continuous fine-tuning or by incorporating mechanisms similar to human memory.
*   **Emotion:** Mostly neutral, with some skepticism expressed regarding the practicality of continuous fine-tuning.
*   **Top 3 Points of View:**
    *   Continuous fine-tuning might lead to overfitting and deterioration of the model's overall performance.
    *   Experience is useful because it attaches sensations other than just mere words to the neural network and experience also translates knowledge into first person perspective.
    *   LLMs do not need these memories, they model language statistics. Chatbots, agents and so on are composite models that use at their core LLMs, plus other things.

**[[D] Jupyternaut is anyone using it on their notebooks ? (Score: 0)](https://www.reddit.com/r/MachineLearning/com/1lq1hel/d_jupyternaut_is_anyone_using_it_on_their/)**
*   **Summary:** Question asking if anyone is using Jupyternaut on their notebooks.
*   **Emotion:** Mostly positive.
*   **Top 3 Points of View:**
    *   I've gotten good results from using Claude Code's built-in notebook support. One tip is to tell it in \`CLAUDE.md\` to check its work by running the notebook using papermill or nbconvert.

