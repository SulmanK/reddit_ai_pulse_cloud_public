---
title: "Stable Diffusion Subreddit"
date: "2025-07-25"
description: "Analysis of top discussions and trends in the stablediffusion subreddit"
tags: ["AI", "Stable Diffusion", "Image Generation"]
---

# Overall Ranking and Top Discussions
1.  [Day off work, went to see what models are on civitai (tensor art is now defunct, no adult content at all allowed)](https://i.redd.it/t8tq5fib52ff1.png) (Score: 196)
    * This thread discusses the shift from Tensor Art to Civitai for models and the increasing restrictions on adult content, and the effect of The Online Safety Act in the UK.
2.  [Wan releases new video previews for the imminent launch of Wan 2.2.](https://www.reddit.com/r/StableDiffusion/comments/1m96f4y/wan_releases_new_video_previews_for_the_imminent/) (Score: 58)
    *  This thread covers the new video previews for Wan 2.2 and discusses features such as T2I and I2V.
3.  [Arbitrary finding: CLIP ViT-L/14@336 has just a normal ViT-L/14 text encoder (a "CLIP-L"). But what it learned from the larger dim ViT makes it superior (detail guidance).](https://www.reddit.com/gallery/1m950l2) (Score: 35)
    * This post highlights an observation about CLIP ViT-L/14@336 and its text encoder.
4.  [CivitAI Bans UK Users](https://mobinetai.com/civitai-bans-uk-users/) (Score: 14)
    * The post is about CivitAI banning UK users due to new regulations.
5.  [Realtime Brush - TouchDesigner + StreamDiffusionTD](https://v.redd.it/vxvfjuphv1ff1) (Score: 12)
    * This thread features a real-time brush tool using TouchDesigner and StreamDiffusionTD.
6.  [Wan text2image + ControlNet ?](https://www.reddit.com/r/StableDiffusion/comments/1m92obe/wan_text2image_controlnet/) (Score: 3)
    * This post discusses using Wan text2image with ControlNet.
7.  [What's the Best NoobAI-based Model?](https://www.reddit.com/r/StableDiffusion/comments/1m9284z/whats_the_best_noobaibased_model/) (Score: 2)
    * This thread asks for recommendations on the best NoobAI-based model.
8.  [Has anyone managed to use Stable Diffusion (or similar) to get around the new UK face verification requirements?](https://www.reddit.com/r/StableDiffusion/comments/1m97lbz/has_anyone_managed_to_use_stable_diffusion_or/) (Score: 2)
    * This post explores methods to bypass the new UK face verification requirements using Stable Diffusion.
9.  [What's the best image to 3d model for images of real humans that can be run locally?](https://www.reddit.com/r/StableDiffusion/comments/1m947rb/whats_the_best_image_to_3d_model_for_images_of/) (Score: 1)
    * The discussion focuses on finding the best local image-to-3D model for realistic humans.
10. [Wan VACE 2.1 for image editing?](https://www.reddit.com/r/StableDiffusion/comments/1m98w0w/wan_vace_21_for_image_editing/) (Score: 1)
    * This post asks about using Wan VACE 2.1 for image editing.
11. [Best Way to replicate Product Photographs using AI ?](https://www.reddit.com/gallery/1m9499y) (Score: 0)
    * A discussion on the best methods for replicating product photographs using AI.
12. [SeedVR2 vs SUPIR (most of the community SUPIR tests are wrong we used SECourses App) - 1024px to 2048px - imgsli link provided](https://www.reddit.com/gallery/1m96saa) (Score: 0)
    *  This post compares SeedVR2 and SUPIR upscalers, claiming that most community tests are incorrect.
13. [Recruiting interview participants on how AI is impacting freelance digital artists in the video game industry.](https://www.reddit.com/r/StableDiffusion/comments/1m94c08/recruiting_interview_participants_on_how_ai_is/) (Score: 0)
    * This post is a recruitment call for interview participants discussing the impact of AI on freelance digital artists in the video game industry.
14. [Is it possible to use references when generating?](https://www.reddit.com/r/StableDiffusion/comments/1m94kqt/is_it_possible_to_use_references_when_generating/) (Score: 0)
    * The post is about using references when generating images with AI
15. [Help AI Influencer willing to Pay](https://www.reddit.com/r/StableDiffusion/comments/1m951zj/help_ai_influencer_willing_to_pay/) (Score: 0)
    * This post is seeking assistance for an AI influencer.
16. [Has anyone actually nailed real-time face + voice swap for live calls in 2025?](https://www.reddit.com/r/StableDiffusion/comments/1m996a4/has_anyone_actually_nailed_realtime_face_voice/) (Score: 0)
    * This post inquires about real-time face and voice swapping technology for live calls.

# Detailed Analysis by Thread
**[Day off work, went to see what models are on civitai (tensor art is now defunct, no adult content at all allowed) (Score: 196)](https://i.redd.it/t8tq5fib52ff1.png)**
*  **Summary:** The discussion revolves around the shift from Tensor Art to Civitai due to content restrictions, the impact of the UK's Online Safety Act, and methods to bypass these restrictions using VPNs.
*  **Emotion:** The overall emotional tone is mixed, with positive sentiments expressed towards supporting Civitai and negative sentiments regarding government regulations. The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   The UK's Online Safety Act is an overreach that stifles small businesses and cuts the UK off from the global internet.
    *   Using VPNs is a viable solution to bypass content restrictions imposed by the Online Safety Act.
    *   The Online Safety Act represents a concerning trend toward mass surveillance and erodes privacy.

**[Wan releases new video previews for the imminent launch of Wan 2.2. (Score: 58)](https://www.reddit.com/r/StableDiffusion/comments/1m96f4y/wan_releases_new_video_previews_for_the_imminent/)**
*  **Summary:**  The thread discusses the imminent launch of Wan 2.2, with users expressing excitement and anticipation for new features, including T2I, I2V, and Lora compatibility.
*  **Emotion:** The dominant emotion is Positive, with users expressing excitement and anticipation.
*  **Top 3 Points of View:**
    *   Users are excited about the upcoming release of Wan 2.2 and its potential new features.
    *   There is a hope that Wan 2.2 will be compatible with Lora.
    *   The lack of integrated sound is a significant drawback compared to other models like Veo3.

**[Arbitrary finding: CLIP ViT-L/14@336 has just a normal ViT-L/14 text encoder (a "CLIP-L"). But what it learned from the larger dim ViT makes it superior (detail guidance). (Score: 35)](https://www.reddit.com/gallery/1m950l2)**
*  **Summary:**  The thread highlights the superior detail guidance of CLIP ViT-L/14@336 due to its training.
*  **Emotion:** The overall emotional tone is Neutral, with comments mainly providing observations and related links.
*  **Top 3 Points of View:**
    *   CLIP ViT-L/14@336's superiority is due to its training.
    *   The fast pace of the AI industry leads to overlooking potentially valuable improvements.
    *   The image resembles a Thargoid from the Elite Dangerous game.

**[CivitAI Bans UK Users (Score: 14)](https://mobinetai.com/civitai-bans-uk-users/)**
*  **Summary:**  This post reports that CivitAI is banning UK users.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   VPNs are a necessary tool to circumvent the ban.

**[Realtime Brush - TouchDesigner + StreamDiffusionTD (Score: 12)](https://v.redd.it/vxvfjuphv1ff1)**
*  **Summary:**  The post showcases a real-time brush tool using TouchDesigner and StreamDiffusionTD.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   The approach of gatekeeping information behind a workshop is frowned upon.
    *   Users are interested in learning how the tool was made and accessing the code.
    *   Specifying the timezone for the workshop is important for international participants.

**[Wan text2image + ControlNet ? (Score: 3)](https://www.reddit.com/r/StableDiffusion/comments/1m92obe/wan_text2image_controlnet/)**
*  **Summary:**  The thread discusses the use of Wan text2image with ControlNet and seeks advice on improving results.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   Mixing Canny and Depth control types can yield good results.
    *   Duplicating the image multiple times might be a temporary solution, although overkill.
    *   The strength of Canny and Depth can be adjusted to achieve the desired outcome.

**[What's the Best NoobAI-based Model? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1m9284z/whats_the_best_noobaibased_model/)**
*  **Summary:**  This thread is a request for recommendations on the best NoobAI-based models for various purposes such as realistic, anime, furry, and NSFW content.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   The choice of model depends on the desired output (realistic, anime, furry, etc.).
    *   Noob and Illustrious finetunes and merges are largely interchangeable.
    *   VPred models, often based on Noob, excel at understanding lighting and taking prompts literally.

**[Has anyone managed to use Stable Diffusion (or similar) to get around the new UK face verification requirements? (Score: 2)](https://www.reddit.com/r/StableDiffusion/comments/1m97lbz/has_anyone_managed_to_use_stable_diffusion_or/)**
*  **Summary:**  The thread explores methods to bypass the new UK face verification requirements using Stable Diffusion or similar technologies.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   AI is generally poor at determining age or profiling.
    *   Using a virtual camera with a pre-recorded video of an older person is a possible workaround.
    *   Using a VPN is a straightforward solution.

**[What's the best image to 3d model for images of real humans that can be run locally? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m947rb/whats_the_best_image_to_3d_model_for_images_of/)**
*  **Summary:** The discussion centers around finding the best local image-to-3D model solution for generating realistic human models.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    * There is no currently available 3D AI generator capable of creating realistic-looking humans.
    * Realistic human models are difficult to create in Blender.
    * Training LoRAs and generating images of characters in different poses and settings is a more effective approach.

**[Wan VACE 2.1 for image editing? (Score: 1)](https://www.reddit.com/r/StableDiffusion/comments/1m98w0w/wan_vace_21_for_image_editing/)**
*  **Summary:**  This post inquires about the capabilities of Wan VACE 2.1 for image editing.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   Kontext is context-aware, while Wan is not.
    *   Fine-tuning Wan could make it context-aware.

**[Best Way to replicate Product Photographs using AI ? (Score: 0)](https://www.reddit.com/gallery/1m9499y)**
*  **Summary:**  This thread seeks advice on the best methods for replicating product photographs using AI.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   Flux Kontext is a viable solution for replicating product photos.

**[SeedVR2 vs SUPIR (most of the community SUPIR tests are wrong we used SECourses App) - 1024px to 2048px - imgsli link provided (Score: 0)](https://www.reddit.com/gallery/1m96saa)**
*  **Summary:** This post compares SeedVR2 and SUPIR upscalers.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   4x LexicaDAT2\_otf is a preferred upscaler for photos.
    *   There's a disagreement on the correct testing methodology for upscalers.

**[Recruiting interview participants on how AI is impacting freelance digital artists in the video game industry. (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m94c08/recruiting_interview_participants_on_how_ai_is/)**
*  **Summary:**  This post seeks participants for interviews on the impact of AI on freelance digital artists in the video game industry.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    * The RPG Community has its own AI division and is vocal on Reddit and X.

**[Is it possible to use references when generating? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m94kqt/is_it_possible_to_use_references_when_generating/)**
*  **Summary:**  The post asks about using references when generating images with AI.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    *   Flux Kontext or OmniGen2 can be used.
    *   Reference videos can provide helpful ideas.

**[Help AI Influencer willing to Pay (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m951zj/help_ai_influencer_willing_to_pay/)**
*  **Summary:** This post is seeking assistance for an AI influencer.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    * Offering services for free to those needing an AI influencer.
    * Interest in the amount spent and expected recoup on the investment.

**[Has anyone actually nailed real-time face + voice swap for live calls in 2025? (Score: 0)](https://www.reddit.com/r/StableDiffusion/comments/1m996a4/has_anyone_actually_nailed_realtime_face_voice/)**
*  **Summary:** This post inquires about real-time face and voice swapping technology for live calls.
*  **Emotion:** The dominant emotion is Neutral.
*  **Top 3 Points of View:**
    * The primary use case for this technology is seen as scamming.
