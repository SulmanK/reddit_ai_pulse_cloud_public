---
title: "Data Science Subreddit"
date: "2026-02-12"
description: "Analysis of top discussions and trends in the datascience subreddit"
tags: ["data science", "AI", "career", "machine learning", "workplace"]
---

# Overall Ranking and Top Discussions
*   1. [How I scraped 5.3 million jobs (including 5,335 data science jobs)](https://www.reddit.com/r/datascience/comments/1qy7a89/how_i_scraped_53_million_jobs_including_5335_data/) (Score: 701)
    * How I scraped 5.3 million jobs (including 5,335 data science jobs). Discussion points include: I've been using your site ever since i graduated with my psych bachelor last year. Haven't gotten a job offer yet, but i've notice that interviews are just more frequent when the job is from your site. Thank you for making it, I hope you don't sell out lol; Site looks great! What were some unexpected challenges putting this together? What were some surprising insights?; So it‚Äôs you that made this website that‚Äôs amazing! I used it last week and now I have an interview with this company I like. Thanks for making it for all of us üëå; I have been sharing this site with everyone I know non-stop for last 3 months. Super helpful tbh; Love HiringCafe is looking for trends over time. He would like to see changes in desired skills and qualifications and compensation.; The dataset is interesting less for counts and more for longitudinal signals. The data can say a lot about how the market digests new ideas rather than reacting to hype.; I'd love to know what the LLM costs are of this? Sounds expensive; that's what every smart engineer does, automates stuff lol !; ***, in all my years of job searching I've never saw a job platform with such granular filters.


Fantastic work with the UX, will definitely be recommending to others!; Maybe some topic modeling for job descriptions across different roles to see what sort of latent or non-obvious themes emerge.
*   2. [An easy process to make sure your executive team understands the data](https://www.reddit.com/r/datascience/comments/1r0dvmw/an_easy_process_to_make_sure_your_executive_team/) (Score: 344)
    * An easy process to make sure your executive team understands the data. Discussion points include: Too bad that's impossible and you would be on the chopping block before them; lol this is funny but also a little too real. actually, the problem is rarely exec iq. it is that they want a decision, not a methods lecture. if the takeaway is clear and the tradeoffs are explicit, most leadership teams do fine. when it breaks is when data work never connects back to an actual decision they own.; As someone who‚Äôs done analytics + reporting‚Ä¶ yup. Execs say they want data-driven decisions but only if it fits on 1 slide w no nuance lol.; HAHAHAHAHAHAHA this made my day! Thanks for posting¬†; I'm literally having to spoon feed execs with screenshots of dashboards in PowerPoint with annotations and big text explaining the numbers they demanded we produce. I cba with this *** as a career üòÑ; Yea I‚Äôm tired of dumbing it down. I could maybe understand if you were presenting to leaders on another team.

But leaders that I report up to? Not understanding the function they are managing. It‚Äôs insanity and on top of it they act high and mighty as if they are doing such important work.; If you think about it, data illiterate execs are the bottleneck to making the most out of data. To me, this speaks volumes. You say it in a humorous way, but sadly I think there is some truth to it.; In a good organization there is a tension between the execs who want only the infomation they need in digestable format and the smes who want to give enough detail. In my experience it always gets dumbed down as the exec are not from the same background as the; I use Reddit to make the cranky LinkedIn posts I don't have the guts to attach my real name to.; Yep, it's crazy to me how much of industry data analysis is just [Potemkin Data Science](https://mcorrell.medium.com/potemkin-data-science-fba2b5ba5cc6).
*   3. [New Study Finds AI May Be Leading to ‚ÄúWorkload Creep‚Äù in Tech](https://www.interviewquery.com/p/ai-workload-creep-tech-workers-study) (Score: 319)
    * New Study Finds AI May Be Leading to ‚ÄúWorkload Creep‚Äù in Tech. Discussion points include: New tech doesn't mean less time for humans to work, it means the market expects more in the time you do work. The top 1% will capture any gains.; Even if AI does save time, it won't be passed on to the actual workers.; Of course, cuz every advancement in technology has been the same. Increase productivity, continue to work the same amount, or more, because if you don't do it your competitor will. So what we're left with is a foot on the gas pedal instead of a smooth cruise control; Can we acknowledge that despite the MASSIVE advancements in software and AI over the last decade, the working conditions of tech employees have gotten WORSE instead of better?

You really need to understand that is not a technology problem.; Just a moment, changing my resume skills to add: Untangling AI spaghetti code.; Doesn‚Äôt take a study to realize that.; This was happening well before AI ***; No surprises there. Any automation benefits the factory owner, not the worker.; Guess who is now a full stack software engineer instead of a data scientist due to company needs? This guy. Guess who doesn‚Äôt know JavaScript like at all, this guy; Anyone have a link or citation to the ‚Äúmulti-month field study by UC Berkeley researchers‚Äù they‚Äôre referring to?.
*   4. [Is Gen AI the only way forward?](https://www.reddit.com/r/datascience/comments/1qxf2xt/is_gen_ai_the_only_way_forward/) (Score: 269)
    * Is Gen AI the only way forward?. Discussion points include: Everyone wants Gen AI now.....even though they have absolutely no clue what use case it's gonna solve for their business .....; This happened when analytics moved to ‚Äúdata science‚Äù and now data science becomes ‚ÄúAI‚Äù.; AI is probably worth learning for product development at my company. I usually code statistical and data engineering engines myself and create a UI with a CharGPT chat bot.; Par for the course. I‚Äôm an ML engineer (some DS some SWE) and every remotely interesting posting turns out to actually want sometime to help them generate slop at max speed.; I'm an NLP data scientist and I spend so much time fighting people using Gen AI where traditional methodologies are faster, more deterministic and computationally cheaper.; Everyone used to want ‚Äòdata science‚Äô even when they had little/no data. Now they want AI because they need to be using AI. The more things change, the more they stay the same. I think in the long run, I think it‚Äôll just keep coming back to domain knowledge and communications skills; Just lie? You'll probably get hired and then you'll end up working on everything but what they hired you for.; Every company has a mid-level manager who is keen to "implement AI" because it will look great on their performance review/CV. And every company has execs who are terrified of having their "Kodak moment" by pushing back on "AI", only for their competitors to use it and outperform them.; As a data scientist in a fintech startup whose leadership is heavily invested in LLM/agentic tooling, understanding how LLMs work and their strengths and weaknesses is a crucial part of learning in the current state of the industry.; >¬†require heavily technical and training of LLM models. Oh, these are all API calling companies, not R&D.

That‚Äôs super obnoxious. I don‚Äôt mind fiddling with prompts and sending it to an API, but your *** tier generic b2b saas company is not going to invent a new llm.
*   5. [AI isn‚Äôt making data science interviews easier.](https://www.reddit.com/r/datascience/comments/1r16y9s/ai_isnt_making_data_science_interviews_easier/) (Score: 184)
    * AI isn‚Äôt making data science interviews easier.. Discussion points include: Leetcode tests and sql puzzles is a smooth brained process that anyone can game. Data scientists deal in ideas not memorized code snippets. The highest impact ideas are synthesized using available tools and existing literature, not rote memorization.; The most tedious part of interview prep was memorizing Python and SQL syntax for specific libraries and such. To me that isn't the value of a Data Scientist. The real value is understanding of models and how to interpret data and results.; The cheaters are so obvious, it‚Äôs sad.  One followup question shows they aren‚Äôt thinking, just reading.  At the end of the day, we all know syntax can be looked up, but a good thought process is the what an interview still needs to reveal.; That's the kind of shift I'd want.

I'm a much better "thinker" than I am a straight up coder.; It's not clear why we're asking candidates questions that can be easily generated by AI. I'm usually more interested in how candidates approach difficult problems and break them down into sub problems.; I'm hiring for my first remote DS since the recent AI boom. I don't want to take up a lot of time and do Leetcode-style tests. I worry that if I get specific like logistic regression on this, I'll just get a bunch of; i is a tool that simulates an interview with a real-time to help candidates prepare for interviews.; The interview is more critical than ever. Interviewers are looking for people who fit between industry DS/statisticians and academic DS/Statisticians to develop methods and methodologies.; As someone who hires it‚Äôs very obvious when someone is cheating during interviews with AI so in that sense it makes my job easier

(It‚Äôs cheating because we ask you at the start not to in order to get a sense of your true skillset); I *** at coding interviews, I always freeze up even after coding for over 20 years. I can do thinking and reasoning interviews, so this is good news to me!.
*   6. [Finding myself disillusioned with the quality of discussion in this sub](https://www.reddit.com/r/datascience/comments/1qxltyk/finding_myself_disillusioned_with_the_quality_of/) (Score: 173)
    * Finding myself disillusioned with the quality of discussion in this sub. Discussion points include: All of Reddit is midwit town square. Just average people who think they're smarter than they really are. It's a shame really.; In linguistics, if a word is widely used and understood to mean something, then that's what it means now.

Deep down, I hate that - it's how we end up with 'literally' meaning 'figuratively' and similar abominations, but that's how it is.; The difficulty is that there is a gap between the technical definition of AI and the current marketing-driven layperson definition of AI.  I think many of these comments are due to people mixing those two up without clarification.; Back before gpt-3 came out this sub was a goldmine of smart people sharing code snippets, approaches, and knowledge.

Now it‚Äôs filled with slop and h1bs desperately trying to get jobs; In 2019 I was building models with gradient boosting and random forest regression. It was called machine learning.

Now I‚Äôm building models with gradient boosting and random forest regression. That‚Äôs called AI now.; Does the technical or widely used definitions of AI even important? Why would it be an indicator of quality of discussion. You seem a bit full of yourself; I'm surprised you are getting so much hate.

For what it's worth, I see what you're saying and agree.

There have just been so many strange comments that seem to lack a basic understanding of data science, and they are often the most upvoted comment.

Which is unfortunate, because it just spreads misinformation and further confuses people.; The quality of new grads has decreased. Some people chatgpt their degree.; This sub had definitely devolved over the decade. I keep it because there are gems here and there, but the stats subreddit may be more to your liking. It‚Äôs not perfect but it has more technical posts imo; I mean isn‚Äôt this why professionals say machine learning instead of AI?.
*   7. [Thoughts about going from Senior data scientist at company A to Senior Data Analyst at Company B](https://www.reddit.com/r/datascience/comments/1qytqug/thoughts_about_going_from_senior_data_scientist/) (Score: 85)
    * Thoughts about going from Senior data scientist at company A to Senior Data Analyst at Company B. Discussion points include: I switched from DS to analytics and it‚Äôs been absolutely fine, it‚Äôs not the title it‚Äôs the work, scope, and ownership for me.; Pay and what you work on are so much more important than title.; You can change the job title on your CV as long as it matches the work you are doing. HR departments don't check this stuff until you've passed the interview and accepted the offer. You can request a change in your job title when signing the contract.; You could always list your title as Sr. Data Analyst (Machine Learning) or Sr. Data Analyst (Data Science) or something along those lines; There was a time where previous job title mattered.

These days? Not so much.

But, it has always been the case that your salary matters the most when negotiating new salaries.; It doesn't matter. How much are you getting paid and what type of work will you do?; If you want to become a data scientist, negotiate the title. Recruiting for a DS role with analyst title on the resume might be problematic in the future.; Title matters when applying for a job as a data scientist. If the term data scientist isn't in your resume, you might get rejected.; Title does not equal job. Just tell people you're a data scientist; title is fake prestige anyway, especially across companies. scope and money matter more. recruiter noise maybe, but they‚Äôll still call. honestly lucky with how *** hiring is now
actually the problem is bots scan for words, not talent. i only started getting interviews when i used software to tailor my resume to each listing..
jobowl.co, that‚Äôs the tool.
*   8. [[Advice/Vent] How to coach an insular and combative science team](https://www.reddit.com/r/datascience/comments/1r1qo10/advicevent_how_to_coach_an_insular_and_combative/) (Score: 69)
    * [Advice/Vent] How to coach an insular and combative science team. Discussion points include: If this is causing real friction, make it visible to them. Take them to a stakeholder connect and put them on a spot -"Hey, where in documentation can we find this?"

This will solve the insular part. Combative is something you fix with regular catch-ups over tea.; this sounds more like an incentive and ownership issue than pure skill. if there are no hard constraints around latency, reliability, or business impact, they can ignore feedback. sometimes things only change when slas and deployment gates are enforced by leadership. without that backing, coaching alone rarely fixes behavior.; *** Id *** to have you on our team :/; If latency, deployment safety, and documentation standards are optional, they will continue to be deprioritized. I would make production constraints explicit and structural, require latency targets, define inference inputs, and clear ownership for sign off.; Clarifying question here - what authority comes(to you) with this ask to up-level this team?; Sometimes you just have to clean house. Especially when dealing with a toxic culture. If you are in charge of these people and they are flat out ignoring you that's completely unacceptable, especially with the lengths you have gone to try to guide them.

It sucks but often you can't cure a toxic culture without a full reset.¬†; In the end, if you get them to push their code into GIT nightly, the problem is largely mitigated. This isn't about teambuilding, it's about the business owning the property they paid to develop.; If you are a leader, you consult your subordinates when making decisions, but in the end you postulate the correct decision/standard and start prosecuting those not following orders.; At high level there are only a few options: do it yourself to show the example, upskill, hire, or fire. Some people are incompetent but they do not know it. Some lack even the humility to listen to others.; A senior IC is in a quasi-management role and controls jobs, titles and titles. They need to understand that something is going to happen to them if they don't listen to him. Middle-ground solution is to set up some challenge projects with clear goals that meet clear.
*   9. [Meta ds - interview](https://www.reddit.com/r/datascience/comments/1r2flqg/meta_ds_interview/) (Score: 41)
    * Meta ds - interview. Discussion points include: Some teams/orgs are more toxic than others, with people working 60 hour weeks. That doesn't make sense given they do a lot of deep dives and analyze trade-offs for product decisions.; DS at Meta have more influence over strategy than any other big place I've worked.; I work in tech (not Meta but similar-scale), and these rumors pop up every quarter. Yes, data teams get pressure to automate repetitive tasks, but that doesn‚Äôt mean analysts get fired. It usually means the job evolves, not disappears.; I would pay money to watch them try to do this.; well.. thanks for the replies. i got humbled quite a bit here. leaving the post here in case anyone hears similar rumors; It‚Äôs not true, but you are expected to use AI heavily to automate workflows.; And you just believe that? Lol.
*   10. [Retraining strategy with evolving classes + imbalanced labels?](https://www.reddit.com/r/datascience/comments/1qyhmtx/retraining_strategy_with_evolving_classes/) (Score: 20)
    * Retraining strategy with evolving classes + imbalanced labels?. Discussion points include: For unbalanced classes you could use the SMOTE library or another Python library to balance the classes (I don't know if this is possible with a single piece of data).; Full retrains with all clean human labeled data tend to be safer than online updates here. A replay buffer for rare classes helps.; You have so little data I dont think you should make it more complicated that fresh retains whenever the label space changes.

Work on your imbalance with weighting, focal loss, etc.; retrain periodically, use weighted loss for rare classes. good luck.; i would do periodic full retrains on all human-labeled data, plus a replay buffer or class-balanced sampling for the rare labels, keep a fixed ‚Äúgolden‚Äù set for regression checks and track rolling per-class metrics with macro-f1.
*   11. [This was posted by a guy who "helps people get hired", so take it with a grain of salt - "Which companies hire the most first-time Data Analysts?"](https://imgur.com/3v39lf4) (Score: 14)
    * This was posted by a guy who "helps people get hired", so take it with a grain of salt - "Which companies hire the most first-time Data Analysts?". Discussion points include: To be honest, I don't think this is really worth anything. Some of those companies hiring more DAs may have stricter standards and it may be harder to get in.

Most companies need DAs, just look everywhere. Cast a wide net and see what you get.; Error generating reply.; Anyone had experience with accenture as a strategist?; Would be easier for me to get a job if I had been a business major. Finance, accounting, supply chain, etc. RIP.
*   12. [Data cleaning survival guide](https://www.reddit.com/r/datascience/comments/1qxjifc/data_cleaning_survival_guide/) (Score: 14)
    * Data cleaning survival guide. Discussion points include: Error generating reply.; Great post!
Its a "obvious that must be said" post and I love it. Plus, Its not just a data science solution for those problem, but a data engineering.

My team simply doesnt work this way and we see a lot of technical debt..
*   13. [Rescaling logistic regression predictions for under-sampled data?](https://www.reddit.com/r/datascience/comments/1r24okt/rescaling_logistic_regression_predictions_for/) (Score: 13)
    * Rescaling logistic regression predictions for under-sampled data?. Discussion points include: You should never undersample unless you've run into compute/memory limitations. If you did undersample, you only need to tweak the intercept term.; With xgboost and similar for binary classification problems, sampling is only necessary if you've got a billion or so observations and/or hundreds of features.; Doesn‚Äôt matter what the scaling is if you only care about the predictions. It will move the probabilities around but ultimately the order of your observations from a predicted probability standpoint is not changed. If you actually use probabilities you will need to calibrate with something like betacal or other technique.; It really depends more on what the decision boundary looks like‚Ä¶ I would start by doing some plotting and looking at precision and recall for the underrepresented class and go from there.; Model calibration; There are two approaches to solve the problem: resampling and working with the imbalance.; if u under sample, the predicted probabilities won‚Äôt reflect the true base rate. the ranking may still work, but calibration will be off unless u correct for the original class prior. using class weights is often cleaner if memory allows.; In my field we deal with less than a 1% bad rate of data sampling. Usually the approach is to build the model on the original data, generate a precision recall curve and choose a probability threshold..
*   14. [Anyone ever work with Meta data?](https://www.reddit.com/r/datascience/comments/1r2argg/anyone_ever_work_with_meta_data/) (Score: 8)
    * Anyone ever work with Meta data?. Discussion points include: Pretty sure Cambridge Analytica wrote the handbook on working with Meta data. Unbeatable attribution, terrible exit strategy.; I'm pretty sure there are some research papers from professors that worked with Meta. I'd start there and maybe they have replication data without identifiers.; I worked there for a few months. Don't want to dox myself but it was pretty horrible and sick place. The data depends on the project but it's all about eye balls and young kids'eye balls.....
*   15. [Weekly Entering & Transitioning - Thread 09 Feb, 2026 - 16 Feb, 2026](https://www.reddit.com/r/datascience/comments/1qzv8yw/weekly_entering_transitioning_thread_09_feb_2026/) (Score: 4)
    * Weekly Entering & Transitioning - Thread 09 Feb, 2026 - 16 Feb, 2026. Discussion points include: Part of a severance pay is 5k towards education. He has an Masters in DS but doesn't enjoy it and wants to stay in the insights/business analyst realm. He would like to learn more data engineering or Tableau.; In the current job market, the vast majority of open positions are at the senior level. Most of the struggles are happening for people landing their first ds job.; I cannot post to the community as I do not have enough of reputation. What is the threshold for comments and comment karma? How to achieve it? I am a senior person, not junior, Fortune 500 experience.; Anyway, I wanted to ask how often you are asked pandas by heart no external documentation allowed, no jupyter, in whiteboarding plain editor style? Senior+ role, big tech. And pandas is not supposed to be used in production, at large companies at least, only in prototypes or small scale solutions at best. So why bother with such a gate-keeping?; been lurking these threads for months and finally ready to jump in üî• honestly the FAQ saved my life when I was drowning in all the "learn python vs R" debates, definitely worth checking out first before posting the same questions everyone asks üòÇ.
*   16. [easy_sm - A Unix-style CLI for AWS SageMaker that lets you prototype locally before deploying](https://www.reddit.com/r/datascience/comments/1qxo3le/easy_sm_a_unixstyle_cli_for_aws_sagemaker_that/) (Score: 3)
    * easy_sm - A Unix-style CLI for AWS SageMaker that lets you prototype locally before deploying. Discussion points include: i was just messing around with sagemaker last week and the feedback loop was killing me, so this tool sounds like a total lifesaver.
*   17. [Memory exhaustion errors (crosspost from snowflake forum)](/r/snowflake/comments/1r07w5u/memory_exhaustion_errors/) (Score: 1)
    * Memory exhaustion errors (crosspost from snowflake forum). Discussion points include: Snowflake doesn't operate on a 900+ col, 30m row matrix in one go. Try reducing columns first, sample or chunk for fit, and consider running the pca on a snowpark-optimized warehouse..

# Detailed Analysis by Thread
**[How I scraped 5.3 million jobs (including 5,335 data science jobs)](https://www.reddit.com/r/datascience/comments/1qy7a89/how_i_scraped_53_million_jobs_including_5335_data/) (Score: 701)**
*  **Summary:** The post details a project involving the scraping of 5.3 million job listings, including a significant number of data science roles. Discussion points include: Users appreciate the site, finding it very helpful and effective for job searching. Others suggest further data analysis possibilities like topic modeling, longitudinal trend analysis of skills, and spatial analysis of job markets. There are also inquiries about the technical implementation, such as LLM costs and unexpected challenges during development.
*  **Emotion:** The overall emotional tone is Predominantly Positive, showing general approval and optimism. (Average Sentiment Score: 0.70).
*  **Top 3 Points of View:**
    * Users express strong appreciation and positive experiences with the job scraping tool/website, finding it very helpful for job searching.
    * Suggestions are made for further data analysis/features, such as topic modeling, longitudinal trend analysis of skills, and spatial analysis of job markets.
    * Inquiries are raised about the technical details of the project, including LLM costs and unexpected challenges.

**[An easy process to make sure your executive team understands the data](https://www.reddit.com/r/datascience/comments/1r0dvmw/an_easy_process_to_make_sure_your_executive_team/) (Score: 344)**
*  **Summary:** The thread discusses the challenge of ensuring executive teams comprehend data insights. Comments reveal widespread frustration among data professionals regarding executives' data literacy and the demand for oversimplified information. While some acknowledge this as a common career frustration, others suggest it stems from a desire for quick decisions or misaligned organizational incentives.
*  **Emotion:** The overall emotional tone is Predominantly Negative, indicating general dissatisfaction. (Average Sentiment Score: 0.65).
*  **Top 3 Points of View:**
    * Widespread frustration among data professionals due to executives' lack of data literacy and the need to oversimplify complex data insights.
    * The problem is seen as systemic, with some arguing that executives prioritize quick decisions over detailed understanding, or that organizational incentives are misaligned.
    * Some comments reflect a sense of resignation, viewing the situation as a common and frustrating aspect of a data career.

**[New Study Finds AI May Be Leading to ‚ÄúWorkload Creep‚Äù in Tech](https://www.interviewquery.com/p/ai-workload-creep-tech-workers-study) (Score: 319)**
*  **Summary:** This discussion centers on a study suggesting AI might be increasing workloads for tech professionals. Many users agree that automation benefits companies more than workers, leading to increased tasks or reduced headcount. Some also argue that this "workload creep" predates AI, being a continuous issue driven by market expectations for higher productivity.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.63).
*  **Top 3 Points of View:**
    * AI and automation primarily benefit company owners (factory owners), leading to increased workload for employees or reduced headcounts, rather than improving worker conditions.
    * Many believe that 'workload creep' is not a new phenomenon caused by AI, but rather a long-standing issue in tech driven by market expectations for ever-increasing productivity.
    * There is a cynical view that technological advancements consistently lead to more demands on workers without commensurate benefits for them.

**[Is Gen AI the only way forward?](https://www.reddit.com/r/datascience/comments/1qxf2xt/is_gen_ai_the_only_way_forward/) (Score: 269)**
*  **Summary:** The thread questions the pervasive notion that Generative AI is the sole path forward for data science. Discussions highlight intense corporate pressure to adopt AI, even when its practical applications or ROI are unclear. Many observe that current AI implementations are often superficial, frequently rebranding existing machine learning efforts. There's significant skepticism about Gen AI's true value, with some advocating for traditional methods.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.60).
*  **Top 3 Points of View:**
    * There's significant corporate pressure from management/CEOs to adopt Gen AI, sometimes requiring its use despite questionable ROI or actual business need.
    * Many companies are focused on superficial AI integration (e.g., API calls, chatbots) rather than deep R&D, often rebranding existing ML as AI.
    * Skepticism about Gen AI's true value, with some arguing traditional methods are often superior, more deterministic, and computationally cheaper.

**[AI isn‚Äôt making data science interviews easier.](https://www.reddit.com/r/datascience/comments/1r16y9s/ai_isnt_making_data_science_interviews_easier/) (Score: 184)**
*  **Summary:** This thread discusses the impact of AI on data science interview processes. Many users believe AI will shift interviews from testing rote coding to assessing critical thinking and problem-solving skills. Interviewers also note that AI-assisted cheating is often detectable through follow-up questions, making the human interaction even more crucial. There's a shared frustration with traditional, memorization-based technical rounds.
*  **Emotion:** The overall emotional tone is Neutral, with practical discussions and some critical viewpoints. (Average Sentiment Score: 0.58).
*  **Top 3 Points of View:**
    * AI's presence shifts the focus of data science interviews away from rote coding and memorization (which AI can assist with) towards critical thinking, problem-solving, and conceptual understanding.
    * Interviewers note that candidates attempting to use AI to cheat are often easily identified through follow-up questions, making the human element of the interview more crucial.
    * Frustration with outdated interview practices like Leetcode and SQL puzzles, advocating for more open-ended data exploration or case study questions that assess true data scientist value.

**[Finding myself disillusioned with the quality of discussion in this sub](https://www.reddit.com/r/datascience/comments/1qxltyk/finding_myself_disillusioned_with_the_quality_of/) (Score: 173)**
*  **Summary:** The original poster expresses disillusionment with the declining quality of discussions in the subreddit. Commenters largely agree, attributing it to a general drop in technical depth, an influx of misinformation, and the imprecise use of terms like "AI" which are often conflated with "Machine Learning." Concerns about the competence of new data science graduates, potentially due to over-reliance on tools like ChatGPT, are also raised.
*  **Emotion:** The overall emotional tone is Neutral but leans Negative, with practical discussions and some critical viewpoints. (Average Sentiment Score: 0.56).
*  **Top 3 Points of View:**
    * The overall quality and technical depth of discussions in the subreddit have declined, with more superficial posts and a perceived increase in misinformation.
    * The broad and often imprecise use of the term 'AI' (conflated with 'Machine Learning') is contributing to confusion and diluted discussions.
    * Concerns are raised about the declining quality of new data science graduates, suggesting an over-reliance on tools like ChatGPT for their education rather than genuine understanding.

**[Thoughts about going from Senior data scientist at company A to Senior Data Analyst at Company B](https://www.reddit.com/r/datascience/comments/1qytqug/thoughts_about_going_from_senior_data_scientist/) (Score: 85)**
*  **Summary:** This thread discusses the implications of transitioning from a Senior Data Scientist role to a Senior Data Analyst position. The central debate revolves around whether job titles truly matter, or if scope of work and compensation are more important. Many users offer advice on how to navigate this, including negotiating titles, or adjusting resume descriptions to better reflect experience, especially given AI-powered screening tools.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.73).
*  **Top 3 Points of View:**
    * The actual scope of work, responsibilities, and compensation are considered more important than the specific job title for career satisfaction and progression.
    * Job titles, particularly 'Data Scientist,' are important for resume screening (especially with AI tools) and future job applications, making title negotiation or strategic resume modification valuable.
    * It is generally acceptable to represent one's title on a resume as a more accurate reflection of work performed (e.g., 'Data Scientist' if the role's duties align), even if the official company title differs.

**[[Advice/Vent] How to coach an insular and combative science team](https://www.reddit.com/r/datascience/comments/1r1qo10/advicevent_how_to_coach_an_insular_and_combative/) (Score: 69)**
*  **Summary:** The original poster seeks advice on managing a difficult, insular, and combative science team. Responses largely focus on leadership strategies, suggesting that the issue is often structural, related to incentives, accountability, and clear policy enforcement rather than a lack of skill. Suggestions range from direct enforcement and making non-compliance visible to stakeholders, to more drastic measures like "cleaning house" if the culture is truly toxic.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.67).
*  **Top 3 Points of View:**
    * The core issue likely stems from unclear incentives, lack of accountability, and insufficient enforcement of standards (e.g., for latency, documentation, deployment), requiring clear leadership and policy implementation.
    * Direct and firm leadership is needed, potentially involving setting explicit production constraints, requiring adherence, and making consequences clear for non-compliance.
    * Suggestions include 'cleaning house' (firing) if the team is genuinely toxic and resistant, or making their non-compliance visible to stakeholders to drive change.

**[Meta ds - interview](https://www.reddit.com/r/datascience/comments/1r2flqg/meta_ds_interview/) (Score: 41)**
*  **Summary:** This thread addresses a job seeker's inquiries about Meta's Data Scientist roles, specifically rumors about automation and potential layoffs. Most comments dismiss these rumors as exaggerated, asserting that Meta's DS professionals still hold significant strategic influence, focusing on deep analytical dives and product decisions. While automation of repetitive tasks is expected, it's generally seen as leading to job evolution rather than disappearance.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.75).
*  **Top 3 Points of View:**
    * Rumors about Meta significantly automating Data Scientist roles or reducing headcount are widely dismissed as exaggerated or untrue.
    * Data Scientists at Meta are seen as having substantial strategic influence, performing deep analytical dives and contributing to product decisions, functioning more akin to quantitative analysts.
    * While automation of repetitive tasks is expected across tech, it typically leads to job evolution and allows DS professionals to focus on higher-value work, rather than job elimination.

**[Retraining strategy with evolving classes + imbalanced labels?](https://www.reddit.com/r/datascience/comments/1qyhmtx/retraining_strategy_with_evolving_classes/) (Score: 20)**
*  **Summary:** This technical discussion focuses on strategies for retraining machine learning models when dealing with evolving classes and imbalanced labels. Key advice includes favoring periodic full retrains on human-labeled data, utilizing techniques like replay buffers for rare classes, and addressing class imbalance through methods like weighting, focal loss, or SMOTE. Proper evaluation with fixed validation sets and appropriate metrics is also emphasized.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.75).
*  **Top 3 Points of View:**
    * Advocacy for periodic full retrains using all human-labeled data, potentially incorporating techniques like replay buffers or class-balanced sampling for rare classes, to maintain model robustness and prevent bias.
    * Emphasis on proper evaluation with a fixed 'golden' validation set to track metrics accurately, and using appropriate metrics like macro-F1 or balanced accuracy for imbalanced datasets.
    * Recommendations to address class imbalance directly through techniques like weighting, focal loss, or libraries like SMOTE, rather than undersampling, which should only be a last resort for computational limits.

**[This was posted by a guy who "helps people get hired", so take it with a grain of salt - "Which companies hire the most first-time Data Analysts?"](https://imgur.com/3v39lf4) (Score: 14)**
*  **Summary:** The thread discusses a list, shared by a "career helper," of companies supposedly hiring the most first-time Data Analysts. The general sentiment among commenters is skepticism, suggesting the information is unreliable and not particularly useful. Advice centers on casting a wide net in job applications rather than relying on such specific lists.
*  **Emotion:** The overall emotional tone is Neutral but leans Negative, with practical discussions and some critical viewpoints. (Average Sentiment Score: 0.58).
*  **Top 3 Points of View:**
    * Skepticism about the value of lists purporting to show 'which companies hire the most first-time Data Analysts,' suggesting such information is often unreliable or misleading.
    * Advice to job seekers to broaden their search and 'cast a wide net' for Data Analyst positions, as many companies need DAs regardless of their 'first-time hiring' reputation.
    * The sentiment that company-specific hiring lists can be misleading because some companies, despite high volume, might have very stringent hiring standards.

**[Data cleaning survival guide](https://www.reddit.com/r/datascience/comments/1qxjifc/data_cleaning_survival_guide/) (Score: 14)**
*  **Summary:** This discussion revolves around a "Data cleaning survival guide" post. Commenters express strong appreciation for the guide, highlighting its value in promoting essential data quality practices for both data science and data engineering. The consensus is that such foundational guidance is crucial for preventing technical debt and ensuring reliable outcomes.
*  **Emotion:** The overall emotional tone is Predominantly Positive, showing general approval and optimism. (Average Sentiment Score: 0.64).
*  **Top 3 Points of View:**
    * Strong appreciation for the 'Data cleaning survival guide' post, recognizing it as a valuable resource for best practices in data quality.
    * Acknowledgement that robust data cleaning and quality practices are essential for both data science and data engineering, preventing technical debt and ensuring reliable outcomes.
    * A positive sentiment towards sharing foundational, 'obvious but must be said' guidance that can significantly improve team processes.

**[Rescaling logistic regression predictions for under-sampled data?](https://www.reddit.com/r/datascience/comments/1r24okt/rescaling_logistic_regression_predictions_for/) (Score: 13)**
*  **Summary:** This technical thread addresses how to rescale logistic regression predictions when data has been undersampled. Expert advice generally discourages undersampling unless strictly necessary due to resource constraints, favoring class weighting instead. If undersampling is used, calibration of model probabilities is crucial to ensure predictions reflect true base rates. The discussion also covers evaluating models based on practical trade-offs of false positives/negatives.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.77).
*  **Top 3 Points of View:**
    * General advice to avoid undersampling unless strictly necessary due to memory/compute constraints, preferring class weighting or building models on the full dataset instead.
    * If undersampling is used, calibration of model probabilities (e.g., adjusting the intercept, using isotonic regression or Platt scaling) is crucial to ensure predictions reflect true base rates.
    * Focus on the practical application and trade-offs of false positives/negatives, and evaluate models using appropriate metrics and probability thresholds rather than just default 0.5.

**[Anyone ever work with Meta data?](https://www.reddit.com/r/datascience/comments/1r2argg/anyone_ever_work_with_meta_data/) (Score: 8)**
*  **Summary:** The thread asks for experiences working with Meta data. Responses include suggestions to look for academic research on the topic and strong negative comments about working at Meta, citing a "horrible and sick" environment and ethical concerns related to data usage, particularly concerning younger users. Historical references like Cambridge Analytica are also brought up, hinting at past controversies.
*  **Emotion:** The overall emotional tone is Neutral but leans Negative, with practical discussions and some critical viewpoints. (Average Sentiment Score: 0.49).
*  **Top 3 Points of View:**
    * Suggestions to look for academic research papers involving Meta data for insights or replication data.
    * Negative experiences reported about working at Meta, describing the environment as 'horrible and sick' and raising concerns about data usage (e.g., 'eye balls and young kids' eye balls').
    * Historical reference to Cambridge Analytica, hinting at ethical concerns and privacy implications associated with Meta's data practices.

**[Weekly Entering & Transitioning - Thread 09 Feb, 2026 - 16 Feb, 2026](https://www.reddit.com/r/datascience/comments/1qzv8yw/weekly_entering_transitioning_thread_09_feb_2026/) (Score: 4)**
*  **Summary:** This weekly thread serves as a forum for individuals entering or transitioning into data science. Discussions highlight challenges in the current job market, particularly the prevalence of senior-level roles and difficulties for newcomers. Users express frustration with certain interview practices and seek advice on valuable courses for career transitions, while also appreciating existing community resources like FAQs.
*  **Emotion:** The overall emotional tone is Neutral, with practical discussions and some critical viewpoints. (Average Sentiment Score: 0.57).
*  **Top 3 Points of View:**
    * Challenges in the current data science job market, with a perception of slow hiring, a prevalence of senior-level roles, and difficulties for those transitioning or seeking their first job.
    * Frustration with common, potentially 'gate-keeping' interview practices, such as whiteboard coding for Pandas in plain editors, which may not reflect real-world DS work.
    * Seeking guidance on valuable paid courses/certifications for career transitions (e.g., from DS to analytics/DE) and appreciation for helpful community FAQs addressing common beginner questions.

**[easy_sm - A Unix-style CLI for AWS SageMaker that lets you prototype locally before deploying](https://www.reddit.com/r/datascience/comments/1qxo3le/easy_sm_a_unixstyle_cli_for_aws_sagemaker_that/) (Score: 3)**
*  **Summary:** The post introduces `easy_sm`, a Unix-style CLI tool designed to simplify local prototyping before deploying to AWS SageMaker. The sole comment enthusiastically suggests the tool is a "lifesaver" due to its ability to improve the feedback loop in SageMaker development.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.31).
*  **Top 3 Points of View:**
    * The tool `easy_sm` is seen as a valuable solution for improving the developer experience with AWS SageMaker, specifically by streamlining the feedback loop during prototyping.

**[Memory exhaustion errors (crosspost from snowflake forum)](/r/snowflake/comments/1r07w5u/memory_exhaustion_errors/) (Score: 1)**
*  **Summary:** This thread discusses strategies for addressing memory exhaustion errors encountered when working with large datasets in Snowflake. The primary advice emphasizes optimizing data handling through reducing column count, sampling or chunking data for model fitting, or leveraging Snowpark-optimized warehouses to avoid operating on massive matrices in a single go.
*  **Emotion:** The overall emotional tone is Neutral, characterized by practical discussions and objective observations. (Average Sentiment Score: 0.63).
*  **Top 3 Points of View:**
    * Addressing memory exhaustion in Snowflake requires strategic data handling, such as reducing column count, using sampling/chunking for model fitting, or leveraging Snowpark-optimized warehouses.
    * The core problem lies in trying to operate on very large data matrices (e.g., 900+ columns, 30M rows) in a single operation within Snowflake.
    * Recommendations focus on optimizing data processing by fitting on representative samples and only transforming the full set, or using incremental approaches.
