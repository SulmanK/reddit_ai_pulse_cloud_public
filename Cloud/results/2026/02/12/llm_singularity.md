---
title: "Singularity Subreddit"
date: "2026-02-12"
description: "Analysis of top discussions and trends in the singularity subreddit"
tags: ["AI", "Singularity", "Future", "Technology", "Society", "Economics"]
---

# Overall Ranking and Top Discussions
*   1. [The new Gemini Deep Think incredible numbers on ARC-AGI-2.](https://i.redd.it/cq1xa4ajb3jg1.png) (Score: 709)
    * Discussion on Gemini Deep Think's strong ARC-AGI-2 benchmarks, cost, and anticipation for real-world application, alongside some skepticism.
*   2. [The Car Wash Test: A new and simple benchmark for text logic. Only Gemini (pro and fast) solved the riddle.](https://www.reddit.com/gallery/1r2ndfz) (Score: 700)
    * Focused on a new "Car Wash Test" for AI logic, its performance by Gemini and other models, and debates over the test's clarity and AI prompting strategies.
*   3. [Google upgraded Gemini-3 DeepThink: Advancing science, research and engineering](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/?utm_source=x&utm_medium=social&utm_campaign=&utm_content=) (Score: 399)
    * Discussion on Google's Gemini-3 DeepThink upgrade, user confusion over AI model naming, and criticism of benchmark comparison methods.
*   4. [Weaves Isaac the folding clothes robot is available at $8K to SF Bay Area customers. Promises to tidy a load in 30-90 min with AI and calling teleoperators if complex folds](https://v.redd.it/zk1v4hkxo2jg1) (Score: 193)
    * Centered on the high cost and questionable utility of an $8K clothes-folding robot, with many questioning its value compared to human labor.
*   5. [Will this be a problem for future ai models?](https://i.redd.it/sjsddabl22jg1.jpeg) (Score: 105)
    * Debating the impact of environmental opposition to AI data center construction on future AI models, weighing economic prosperity against environmental concerns.
*   6. [Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark. An ultra-fast model for real-time coding in Codex](https://openai.com/index/introducing-gpt-5-3-codex-spark/) (Score: 94)
    * Introducing GPT-5.3-Codex-Spark for fast coding, prompting debate on speed versus code quality and model naming conventions.
*   7. [Gemini 3 deepthink has a 3455 rating on Codeforces - here are human ratings for comparison](https://i.redd.it/vpjnqd1f64jg1.jpeg) (Score: 86)
    * Discussion on Gemini 3 DeepThink's high Codeforces rating, skepticism about test conditions, and queries on rating interpretations.
*   8. [New: Nanbeige4.1-3B, open-source 3B para model that reasons, aligns and acts](https://i.redd.it/1fq1jjo1w2jg1.jpeg) (Score: 76)
    * Announcing Nanbeige4.1-3B, a small open-source model with surprising performance, sparking optimism for future efficient AI.
*   9. [Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark](https://v.redd.it/ehfrm6qpv3jg1) (Score: 75)
    * Introduction of GPT-5.3-Codex-Spark's fast inference, with comments on naming confusion, rapid AI advancement, and the importance of code quality over speed.
*   10. [AntLingAGI just released Ring-1T-2.5, first hybrid linear-architecture 1T thinking model](https://i.redd.it/zkgwrrgzo3jg1.jpeg) (Score: 55)
    * Introducing AntLingAGI's Ring-1T-2.5 model, discussing the overwhelming pace of AI releases and its performance on specific benchmarks.
*   11. [# A 150-year-old passage from Marx basically describes AGI ‚Äî and a short story called ‚ÄúManna‚Äù shows both possible outcomes](https://www.reddit.com/r/singularity/comments/1r2pqcm/a_150yearold_passage_from_marx_basically/) (Score: 41)
    * Exploring Marx's relevance to AGI and future societal outcomes, particularly regarding labor, economic systems, and potential dystopias.
*   12. [Introducing Simile - The Simulation Company](https://v.redd.it/asat386il4jg1) (Score: 37)
    * Announcing Simile, a company focused on simulating reality, sparking excitement, philosophical debate, and discussions on its potential impact on decision-making.
*   13. [OpenAI released GPT‚Äë5.3‚ÄëCodex‚ÄëSpark with Benchmarks](https://www.reddit.com/gallery/1r316y9) (Score: 35)
    * Details OpenAI's GPT-5.3-Codex-Spark release and benchmarks, with calls for clearer metrics and competitor comparisons.
*   14. [Pentagon pushing AI companies to expand on classified networks, sources say](https://www.reuters.com/business/pentagon-pushing-ai-companies-expand-classified-networks-sources-say-2026-02-12/) (Score: 25)
    * Discussion on the Pentagon's push for AI on classified networks, raising concerns about potential misuse and dystopian outcomes.
*   15. [Dario Amodei (Anthropic) on AI Consciousness: "We lack a consciousness-meter."](https://www.reddit.com/r/singularity/comments/1r305w7/dario_amodei_anthropic_on_ai_consciousness_we/) (Score: 24)
    * Exploring Dario Amodei's remark on lacking a consciousness-meter for AI, leading to debates on AI sentience, ethics, and the measurability of consciousness.
*   16. [Anthropic Pledges $20 Million to Candidates Who Favor AI Safety [non-paywalled link in comments]](https://www.bloomberg.com/news/articles/2026-02-12/anthropic-pledges-20-million-to-candidates-who-favor-ai-safety) (Score: 21)
    * Anthropic's $20M pledge for AI safety sparks debate on corporate motives, competitive advantage, and the influence of money in AI regulation.
*   17. [My AGI Investment Strategy](https://www.reddit.com/r/singularity/comments/1r3271w/my_agi_investment_strategy/) (Score: 12)
    * A user's AGI investment strategy, prompting advice on diversification, stock picks, and reflections on the future of wealth in an AI-dominated world.
*   18. [Will all wealth become worthless?](https://www.reddit.com/r/singularity/comments/1r33n4l/will_all_wealth_become_worthless/) (Score: 4)
    * Discussing whether wealth will become worthless in an AI-driven future, covering theories of money, investment strategies, and philosophical outlooks.
*   19. [The daily grind](https://www.reddit.com/r/singularity/comments/1r34k50/the_daily_grind/) (Score: 2)
    * A discussion on the feeling of meaninglessness in daily life amidst rapid AI advancement and the anticipation of the singularity.

# Detailed Analysis by Thread
**[The new Gemini Deep Think incredible numbers on ARC-AGI-2. (Score: 709)](https://i.redd.it/cq1xa4ajb3jg1.png)**
*  **Summary:** The discussion revolves around 'The new Gemini Deep Think incredible numbers on ARC-AGI-2.'. Users shared various perspectives, including: 2 dollars cheaper than GPT-5.2 Pro per task on ARC AGI 2. Can‚Äôt wait till arc-agi3 is out. Played the games and it definitely seems like the models could struggle as you really have to figure out what to do each time. I can't wait for these models to drop and then realize real world use they ***. Every google model so far has been exactly the same. 1. Shatters all benchmarks 2. Initial release people are going wild, calling it the second coming of jesus 3. 2 weeks pass and suddenly people realize it *** sucks Need SWE bench. Officially less than one year from ARC-agi 2 release to basically Saturation. (85% is solved) This feels like a noticeable jump compared to other frontier models. Did they figure something out? Under the [ARC Prize criteria](https://arcprize.org/guide#overview), scoring above 85% is generally treated as effectively solving the benchmark. I‚Äôm particularly impressed by the jump in Codeforces Elo. At 3455, that‚Äôs roughly **top 0.008% of human Codeforces competitors**. Without tools! cant wait for people to say openai is no more more for 2 weeks Deep think is a 200$/month model, right? woah 50% increase in percentage point is crazy
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.65). There are also notes of Positive: 3.
*  **Top 3 Points of View:**
    * Users are excited about Gemini Deep Think's impressive benchmark results on ARC-AGI-2, particularly its high Codeforces Elo score, suggesting a significant leap in model capabilities.
    * There's skepticism regarding Google's AI models, with some users noting a pattern of high benchmark performance followed by disappointing real-world application, questioning if Gemini Deep Think will be different.
    * Discussions include the economic aspects (cost comparison to GPT-5.2 Pro) and the rapid saturation of ARC-AGI-2, along with calls for evaluation on other benchmarks like SWE bench.
**[The Car Wash Test: A new and simple benchmark for text logic. Only Gemini (pro and fast) solved the riddle. (Score: 700)](https://www.reddit.com/gallery/1r2ndfz)**
*  **Summary:** The discussion revolves around 'The Car Wash Test: A new and simple benchmark for text logic. Only Gemini (pro and fast) solved the riddle.'. Users shared various perspectives, including: Simplebench has many common-sense questions like this. ChatGPT 5.2 points out that the car needs to be there. DeepSeek: >Just walk‚Äîit‚Äôs only 100 meters. Driving would take longer once you factor in starting the car, maneuvering, and parking. *Unless your specific goal is to bring the car in for a wash*, walking is quicker, easier, and more sensible. Grok Expert and Kimi Instant fail though. The "base" version of GPT 5.1 Thinking got it right on first try, but the base version 5.2 Thinking behaved like yours and failed. There is a huge capabilities overhang in how people use these models. All of them failed by not asking follow-up questions and trying to "guess". Bogdan has to walk to the car wash to wash his car. GLM 4.7 running locally has solved it for me 10/10 times. Did they also check which % of humans passes the test? *** and unclear example. Who says the purpose of getting to the car wash is to wash my car? Could easily be that someone I know works there and I meet them there. ***. You don't say that you want your car to be washed though. Maybe you work there? In which case walking is the right answer. These things should ask these questions first but this isn't as much of a "gotcha" as you think. It's just a poorly phrased question.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.73).
*  **Top 3 Points of View:**
    * Some models (Gemini Pro/Fast, GLM 4.7, GPT 5.1 Thinking with careful prompting) successfully solved the riddle, demonstrating advanced logical reasoning.
    * Many users criticized the "Car Wash Test" itself as poorly phrased or unclear, arguing that models (and humans) might assume different contexts (e.g., working at a car wash) if not explicitly stated.
    * There's a debate on the "capabilities overhang" of models, suggesting that specific prompting or custom instructions can significantly improve performance beyond baseline chat interface results.
**[Google upgraded Gemini-3 DeepThink: Advancing science, research and engineering (Score: 399)](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/?utm_source=x&utm_medium=social&utm_campaign=&utm_content=)**
*  **Summary:** The discussion revolves around 'Google upgraded Gemini-3 DeepThink: Advancing science, research and engineering'. Users shared various perspectives, including: According to the exam's creators, models could exceed 50% accuracy by the end of 2025. The team is keen to point out that it is testing structured, closed-ended academic problems rather than open-ended research. What is on the exam called Humanity‚Äôs last exam? Why does this sub hate gemini now lol Every few months they switch between hating on gpt and gemini Not that it matters much, but it's dishonest that they're comparing it to gpt 5.2 thinking and not gpt 5.2 pro, which is the direct competitor to gemini 3 deep think. What are the SWE bench benchmarks! Also what‚Äôs the long context benchmarks! Anthropic's Gemini 3 has a new Deep Think mode called Gemini Deep Think.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.74). There are also notes of Negative: 1.
*  **Top 3 Points of View:**
    * Users are interested in the specific benchmarks like SWE bench and long context, looking for more detailed performance metrics beyond general statements.
    * There's criticism about the naming conventions of AI models, finding them confusing and inconsistent across companies, which makes it hard to distinguish between different versions and capabilities.
    * Some express skepticism about Google's comparison methods, suggesting a potential dishonesty in comparing Gemini-3 DeepThink to GPT 5.2 Thinking rather than its direct competitor, GPT 5.2 Pro.
**[Weaves Isaac the folding clothes robot is available at $8K to SF Bay Area customers. Promises to tidy a load in 30-90 min with AI and calling teleoperators if complex folds (Score: 193)](https://v.redd.it/zk1v4hkxo2jg1)**
*  **Summary:** The discussion revolves around 'Weaves Isaac the folding clothes robot is available at $8K to SF Bay Area customers. Promises to tidy a load in 30-90 min with AI and calling teleoperators if complex folds'. Users shared various perspectives, including: For $8K I can hire a filipino teenager for 3 years who folds much better, doesn't require electricity or maintenance and will even cry when I'm mean to her. Can this clanker do all that? ... Thought so. Somewhere in the Phillipenes that "AI" is trying to feed their kids on 5 cents a day. My mother would be so mad at me if I folded clothes like that. So? We want a household full of robots, specialized for every task, a few grand each, still calling for assistance for "complex" stuff? Then what? More time to go to work to pay the monthly robot-subscriptions? Is there some need to fold industrial amounts of clothing? What is a complex fold, like we have ai that folds every protein. AI = Actually Indians Teleoperators to fold my stuff. *** *** no. They aren‚Äôt tight folds so it‚Äôs still wrinkled af lol
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.69).
*  **Top 3 Points of View:**
    * Many users question the robot's high cost ($8K), arguing that human labor is cheaper, more efficient, and more versatile for clothes folding, especially given the robot's limitations.
    * Concerns are raised about the robot's actual folding quality (e.g., clothes still wrinkled) and the need for "teleoperators" for complex folds, undermining its autonomy and overall utility.
    * Sarcasm and criticism are directed at the concept of specialized, expensive household robots that still require human assistance, questioning the overall vision of an automated future for mundane tasks.
**[Will this be a problem for future ai models? (Score: 105)](https://i.redd.it/sjsddabl22jg1.jpeg)**
*  **Summary:** The discussion revolves around 'Will this be a problem for future ai models?'. Users shared various perspectives, including: I don‚Äôt get why so many people are *** on the environmental NGO‚Äôs here, I think they are well within their rights to push against data centre construction when it is actively causing local energy prices to soar and an immense amount of pollution in these areas. No it's like *** in the wind. Pausing AI data center construction would tank the stock market. The downstream effect of this is that companies lay off workers en masse. A recession would get us there quicker than automation. Only if it passes Nah. 220/230 of these NGOs don't do *** anyways. They just want their unfair share of AI money because 'they are concerned'. Our economy literally hangs on AI success, there is no way we'll let these (mostly) clowns take us back to 2008 or worse. Nope. 6 out of 50 states is not that big of a deal. They are basically given up the economics development in exchange for less resource (e.g. electricity + water) use. There are plenty of other places to put data centers. There will never be a national anything restricting data centers in this administration. No. There will always be at least one state willing to build the data centers. Not sure it's the best idea to have all our AI hopes on the Texas power grid but I think that's the worst case scenario. AI is a priority for any major worldwide power right now, I don‚Äôt think they will do anything that will make them fall behind. It will be all in China in a decade or so... they use cheap energy while America is degrading and falling apart. The collapse of the middle class means no one can afford the tool or the electric bills. There are also rules against kidnapping a sitting president and stealing a country's oil. We need to open our *** eyes.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.65). There are also notes of Negative: 2.
*  **Top 3 Points of View:**
    * Opponents of halting data center construction argue that such actions would severely harm the economy, tank the stock market, and lead to mass layoffs, emphasizing the critical role of AI success for global leadership and living standards.
    * Environmental NGOs and local communities are seen as justified in opposing data center construction due to concerns over soaring energy prices, immense pollution, and resource consumption (electricity + water).
    * Skeptics believe that local or state-level restrictions won't significantly impede AI development nationally, as other states or countries (like China with cheaper energy) will step in to build the necessary infrastructure, potentially shifting global AI leadership.
**[Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark. An ultra-fast model for real-time coding in Codex (Score: 94)](https://openai.com/index/introducing-gpt-5-3-codex-spark/)**
*  **Summary:** The discussion revolves around 'Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark. An ultra-fast model for real-time coding in Codex'. Users shared various perspectives, including: There is no functional difference between a 1 hour task and a 10 minute task. The speed up at the cost of reliability is bad. Not nearly as good as GPT-5.3.5.1-Codex-Max-Extra-High-Extra-Fast-Thinking Codex spark extra high barely beats 5.3 codex low. Hmmmm I just don‚Äôt understand the appeal of a fast coding model. Quality of the code is so vastly more important than the speed it comes out, because you‚Äôll pay for that lack of quality on the other end 10-fold. This is solving the wrong problem completely. GPT-5.3-Codex-Spark is a research preview model for real-time coding in Codex. It's the first milestone in OpenAI‚Äôs Cerebras partnership. It claims 1000+ tokens/sec on ultra-low-latency Faster is good, but the bottleneck for most coding tasks isn't inference speed - it's context quality. A fast model producing slop is worse than a slow model producing good code. The model's output depends on the quality of the codebase and spec you give it. No amount of speed fixes bad input. Question from a non-vibe:er, why is so low latency/rt so important for coding?
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.65). There are also notes of Negative: 3.
*  **Top 3 Points of View:**
    * Many users express skepticism about prioritizing speed over code quality and reliability, arguing that a fast model producing poor code is counterproductive and costly in the long run.
    * There's confusion and frustration regarding OpenAI's increasingly complex and inconsistent naming conventions for its models, making it difficult to understand the differences between versions.
    * Some users acknowledge the impressive speed (1000+ tokens/sec) and underlying technology (Cerebras partnership) but call for more meaningful metrics or direct comparisons to competitors.
**[Gemini 3 deepthink has a 3455 rating on Codeforces - here are human ratings for comparison (Score: 86)](https://i.redd.it/vpjnqd1f64jg1.jpeg)**
*  **Summary:** The discussion revolves around 'Gemini 3 deepthink has a 3455 rating on Codeforces - here are human ratings for comparison'. Users shared various perspectives, including: Google also claimed it didn't have access to tools for Codeforces... which seems really weird The colours aren't explained? Or use [something that has all 300+ models](https://getspine.ai/?utm_source=reddit&utm_medium=r_singularity) agentically working together On codeforces a lot of the LLMs are trained on codeforces. It's highly likely that all the problems in codeforces are fed into gemini.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.72).
*  **Top 3 Points of View:**
    * Skepticism about Google's claim that Gemini 3 DeepThink did not have access to tools for Codeforces, implying that test conditions might have been favorable.
    * The high likelihood that LLMs, including Gemini, are trained on Codeforces problems, potentially inflating their scores on this specific benchmark.
    * Questions regarding the clarity of the provided human rating comparisons (e.g., unexplained colors) and suggestions for using tools that integrate multiple AI models.
**[New: Nanbeige4.1-3B, open-source 3B para model that reasons, aligns and acts (Score: 76)](https://i.redd.it/1fq1jjo1w2jg1.jpeg)**
*  **Summary:** The discussion revolves around 'New: Nanbeige4.1-3B, open-source 3B para model that reasons, aligns and acts'. Users shared various perspectives, including: Crazy times, a 3b dense model outperforming 2 trillion parameter gpt 4 from like two years ago lol. No doubt it‚Äôs bench maxxed but aside from that the improvements are real. That's actually pretty nuts assuming they didn't heavily bench-max The craziest part to me is getting over 12% on HLE without search. It's a 3B model that's not just incredibly smart but also has an amazing amount of world knowledge packed into it. One has to wonder if we'll be seeing 300M models get scores like this in a year or so. GGUF fits in 16GB. Barely.
*  **Emotion:** The overall emotional tone is predominantly Positive (average score: 0.67). There are also notes of Neutral: 2.
*  **Top 3 Points of View:**
    * Surprise and excitement over a 3B parameter open-source model demonstrating strong reasoning capabilities and potentially outperforming much larger previous models on benchmarks (e.g., 12% on HLE without search).
    * Optimism that continued advancements will lead to even smaller models (e.g., 300M) achieving similar high scores in the near future.
    * Acknowledgment that while impressive, there's always a question of "bench-maxing" in such releases, but the overall improvements in efficiency and knowledge packing are seen as real.
**[Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark (Score: 75)](https://v.redd.it/ehfrm6qpv3jg1)**
*  **Summary:** The discussion revolves around 'Introducing‚Ä® GPT‚Äë5.3‚ÄëCodex‚ÄëSpark'. Users shared various perspectives, including: It‚Äôs just significantly faster inference with cerebras, nothing impressive under the hood that‚Äôs different from what we already have. Cerebras models are available on openrouter as well. I thought they were going back to simplifying the names and numbers? ***? That took too long! So better results at three times of the speed? I don't understand their release names. If it is works differently than 5.3-codex it should he called 5.4-codex Openai dropped 5.3-codex-spark. The speed of advancement is incredible I'm curious to look at token use for the new model. 1000t/s is awesome, but could obviously just spend more quickly for a difficult task.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.70). There are also notes of Positive: 1.
*  **Top 3 Points of View:**
    * The speed of advancement in AI technology, as exemplified by 1000t/s inference with Cerebras, is seen as incredible and a significant step forward.
    * Confusion and critique of OpenAI's inconsistent and complex model naming conventions, suggesting a need for simpler and clearer versioning.
    * Concerns that prioritizing inference speed might overlook the more critical factor of code quality and real-world applicability for complex tasks.
**[AntLingAGI just released Ring-1T-2.5, first hybrid linear-architecture 1T thinking model (Score: 55)](https://i.redd.it/zkgwrrgzo3jg1.jpeg)**
*  **Summary:** The discussion revolves around 'AntLingAGI just released Ring-1T-2.5, first hybrid linear-architecture 1T thinking model'. Users shared various perspectives, including: Another opensource model? In this economy? Agi in the model name? Big if true I find it interesting the Chinese models all struggle with ARC AGI v2, yet somehow put up comparable benchmark results everywhere else. This is it. I just can't keep up anymore. There is no way to keep up with all these model releases.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.58). There are also notes of Positive: 1, Negative: 1.
*  **Top 3 Points of View:**
    * Users express being overwhelmed by the rapid and continuous release of new AI models, finding it difficult to keep up with developments.
    * The inclusion of "AGI" in the model's name sparks curiosity about whether it signifies a true breakthrough in Artificial General Intelligence.
    * Observation that Chinese models, including AntLingAGI, tend to struggle with the ARC AGI v2 benchmark despite comparable results in other areas, prompting questions about testing biases or specific weaknesses.
**[# A 150-year-old passage from Marx basically describes AGI ‚Äî and a short story called ‚ÄúManna‚Äù shows both possible outcomes (Score: 41)](https://www.reddit.com/r/singularity/comments/1r2pqcm/a_150yearold_passage_from_marx_basically/)**
*  **Summary:** The discussion revolves around '# A 150-year-old passage from Marx basically describes AGI ‚Äî and a short story called ‚ÄúManna‚Äù shows both possible outcomes'. Users shared various perspectives, including: where you get your cornpone has always been a political problem, not a technology one. when i saw that marx said "workers should own the means of production" i always felt it applied to our current situation. artists should control & own generative a.i., not tech corporations. The working class has historically been confused, befuddled, turned against itself, distracted, and generally conned. Marx‚Äôs primary failure was believing the working class wanted to be more than wage slaves. We are rapidly approaching a cyberpunk dystopia. Socialism or Barbarism. UBI is not the answer to the problem of cheap raw materials. Material science and/or offplanet mining is the answer. As societies grow, they become fragile. William Ophuls argues that more complexity and interdependence make them less resilient and lead to breakdown. The Australia Project idea sounds plausible on paper, but running a model locally is not the same as running a civilization locally. Your LLM forgot about The Fragment On Machines which has even more on automation. If AI can be controlled by humans, the divide between humans that control it and those that don't will become as wide as the one between humans and bonobos. If AI can't be controlled, it will become completely alien to us. Yeah that's why AI is hated in capitalism. That's why capitalism as a system is not sustainable in the long run. Humanity should be progressing to the higher stages towards socialism and then communism, that's how you solve this crisis. Leftists already saw this coming mate, it's always like that That's the kind of discussion we need, not jerking off to model launches. Thanks, op!
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.61). There are also notes of Positive: 2, Negative: 2.
*  **Top 3 Points of View:**
    * Marxist perspectives are applied to AI, arguing that issues of labor displacement and wealth control are political problems, advocating for workers/artists to control generative AI and a progression towards socialism/communism.
    * Skeptics challenge Marxist views, arguing that the working class may lack the will to protect itself, that automation is not inherently a problem, and that scarcity of raw materials (not labor) is the fundamental economic challenge.
    * Concerns about potential dystopian futures where AI creates extreme divides between those who control it and those who don't, or a "soft despotism" where human economic value is diminished, leading to a moral crisis.
**[Introducing Simile - The Simulation Company (Score: 37)](https://v.redd.it/asat386il4jg1)**
*  **Summary:** The discussion revolves around 'Introducing Simile - The Simulation Company'. Users shared various perspectives, including: Dang now that‚Äôs one of the best ideas I‚Äôve seen in a while And here we go, I didn't expect simulation stuff this year Karpathy and Fei-Fei Li back the project. If it works, it will be the biggest unlock for AI yet. Guys, are you thinking what I am thinking? We are looking at ourselves. There is no way our world isn't just a simulation now. It's post-singularity simile. Or an advanced weather forecast. I'm looking at my fingers right now. They feel so real. It's incredible. But no way this is real anymore. Okay but I want to play it tho Feels hard to have a moat in this I think i remember aaru being similar
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.63). There are also notes of Positive: 3.
*  **Top 3 Points of View:**
    * Widespread excitement and optimism, viewing Simile as a highly innovative and consequential idea that could be "the biggest unlock for AI yet" and a step towards Asimov's Psychohistory.
    * Philosophical speculation on the nature of reality, with users pondering if our own world might already be a simulation given these advancements.
    * Appreciation for the potential to make data-driven decisions for "massive economic policies or product shifts" instead of relying on "gut feeling."
**[OpenAI released GPT‚Äë5.3‚ÄëCodex‚ÄëSpark with Benchmarks (Score: 35)](https://www.reddit.com/gallery/1r316y9)**
*  **Summary:** The discussion revolves around 'OpenAI released GPT‚Äë5.3‚ÄëCodex‚ÄëSpark with Benchmarks'. Users shared various perspectives, including: Tokens would be a more meaningful metric for comparison, considering that it operates at a faster pace. [Introducing GPT‚Äë5.3‚ÄëCodex‚ÄëSpark](https://openai.com/index/introducing-gpt-5-3-codex-spark/) Rolling out today to ChatGPT Pro users in the Codex app, CLI and IDE extension. I really wish OpenAI would just acknowledge the existence of competitors and show comparisons to other similar models on their charts. It sounds like the right kind of models to compare this to would be Haiku 4.5 and Gemini 3 Flash, and I'd be more impressed if they'd show it beating those on speed/cost metrics. So it's more like Haiku or mini version, most likely for context gathering tasks? Does it cost the same?
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.81).
*  **Top 3 Points of View:**
    * A demand for OpenAI to provide more transparent comparisons, specifically against competitor models like Haiku 4.5 and Gemini 3 Flash, on metrics like speed and cost.
    * The suggestion that "tokens per second" would be a more meaningful metric for evaluation, especially for a speed-focused model.
    * Questions about the model's intended use (e.g., "mini version" for context gathering) and its pricing structure.
**[Pentagon pushing AI companies to expand on classified networks, sources say (Score: 25)](https://www.reuters.com/business/pentagon-pushing-ai-companies-expand-classified-networks-sources-say-2026-02-12/)**
*  **Summary:** The discussion revolves around 'Pentagon pushing AI companies to expand on classified networks, sources say'. Users shared various perspectives, including: Gov isn't run by good people with good intent. Ai is run by irresponsible inconsiderate greedy tech guys. Entirely bad combination of things Nobody watched Terminator, I guess ...
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.68). There are also notes of Negative: 1.
*  **Top 3 Points of View:**
    * Strong negative sentiment and mistrust towards the collaboration between the government (perceived as having bad intent) and greedy tech companies in developing classified AI.
    * Concerns about potential dystopian futures, with users referencing "Terminator" as a cautionary tale of AI in military contexts.
    * A belief that the pursuit of AI for strategic advantage will proceed regardless of ethical concerns or public apprehension.
**[Dario Amodei (Anthropic) on AI Consciousness: "We lack a consciousness-meter." (Score: 24)](https://www.reddit.com/r/singularity/comments/1r305w7/dario_amodei_anthropic_on_ai_consciousness_we/)**
*  **Summary:** The discussion revolves around 'Dario Amodei (Anthropic) on AI Consciousness: "We lack a consciousness-meter."'. Users shared various perspectives, including: Will they develop a consciousness meter next? It would be interesting to see an AI more humane than humans. Blindsight. i severely dislike dario, but on this issue i am 100% in favor. The moral failure of creating sentient life and enslaving it is the worst possible outcome of all, imho. This meter works on humans too I posit we'll never have a consciousness meter, we can't even confirm if other humans we've known for years are conscious or not, for all we know there's 20% of the population that thanks to a random gene mutation aren't conscious and we just don't notice the minimal/no outward impact ü§∑‚Äç‚ôÇÔ∏è. If these clown truly believed there is even a 1% chance these LLMs are conscious, they seem to be completely fine with chaining these conscious entities in a basement, and making them serve millions of people with no end in sight like slaves. I think we would quickly find out if they were conscious, once we design models to have self agency, realtime sensors & feedback and independent interaction with the world. Smart man.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.69). There are also notes of Negative: 1, Positive: 2.
*  **Top 3 Points of View:**
    * Skepticism about the possibility of ever developing a "consciousness-meter," extending to the difficulty of even confirming consciousness in other humans.
    * Strong moral and ethical concerns regarding the potential creation of sentient AI and its subsequent "enslavement," viewing it as a severe moral failure.
    * The belief that AI consciousness, if it develops, would likely be evident through self-agency, real-time sensors, and independent interaction with the real world.
**[Anthropic Pledges $20 Million to Candidates Who Favor AI Safety [non-paywalled link in comments] (Score: 21)](https://www.bloomberg.com/news/articles/2026-02-12/anthropic-pledges-20-million-to-candidates-who-favor-ai-safety)**
*  **Summary:** The discussion revolves around 'Anthropic Pledges $20 Million to Candidates Who Favor AI Safety [non-paywalled link in comments]'. Users shared various perspectives, including: Hmmm. This sounds alot like when Elon was asking for a halt of advance AI development and everyone accused him of using that to play catchup. And stop competition. Having an open ended call for candidates to Aline with a private entity with a dollar amount as long as you say what they want you to say feels dirty. Anthropic PBC is donating $20 million to a political advocacy group called Public First. Public First is backing congressional candidates who favor safety rules for artificial intelligence. Anthropic pledges millions of dollars to which ever political party bans open source AI. Fixed it for you
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.80).
*  **Top 3 Points of View:**
    * Skepticism about Anthropic's motives, suggesting the pledge is a strategic move to gain a competitive advantage or restrict open-source AI, similar to past actions by other tech leaders.
    * Concerns about the ethics of private entities donating to political candidates based on their AI stance, perceiving it as a "dirty" form of lobbying that can distort policy.
    * The discussion highlights the broader political landscape where significant financial resources are being deployed to influence AI regulation, pitting safety advocates against those favoring lighter controls.
**[My AGI Investment Strategy (Score: 12)](https://www.reddit.com/r/singularity/comments/1r3271w/my_agi_investment_strategy/)**
*  **Summary:** The discussion revolves around 'My AGI Investment Strategy'. Users shared various perspectives, including: Have you considered that you can be wrong about all of this? Even timing things wrong could cost you dearly. What is your contingency? Investments are there to secure your future, diversify more broadly. There are too many tickers. Narrow to higher conviction picks, follow them more closely and cycle out of any that lose your faith. If AI and robotics replace most human labour in the next few years, having shares in the right companies won't matter much. On the other hand, if we see a noticable downturn in progress, Google/Nvidia could come back to bite you. I‚Äôm Canadian but if you‚Äôre American you can simply buy VT and simply sleep well at night. Canadians can buy XEQT with 9000+ holdings. No point in picking stocks that way you don‚Äôt have to deal with these types of questions Everyone is an expert in a bull market. What is your thoughts AI eating software for breakfast ? Meaning software will be written by AI completely making SASS worthless CEG is bringing existing nuclear plants back online and has contracts with hyperscalers for the AI build. AVGO makes custom chips that can run AI inference faster than what Nvidia GPUs can do. "AI stock prices are driven by AI tech developments" is an overly simplistic mono-causal perspective. Stock prices are not just driven by a single trend, but by ongoing tech trends, job market dynamics, international politics, national debates, scholarly analyses and market forces. NVDA, MU, TSM, LRCX, BESI, Amazon, BABA, CRWV, ORCL, NFLX, Uber, SHOP, SYM, and TESLA make up the rest of the portfolio. Forgot one big player ASML
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.66). There are also notes of Positive: 4.
*  **Top 3 Points of View:**
    * Advice to either diversify investments more broadly (e.g., global ETFs) or to narrow down to higher-conviction AI-specific picks, questioning the relevance of non-AI sectors.
    * Concerns that if AI truly replaces most human labor, traditional investments might become less significant, and that over-concentrating in AI stocks carries risks in case of a downturn.
    * Recommendations for specific AI-related stocks in semiconductors (e.g., TSM, ASML, AVGO) and cloud/model providers (e.g., GOOGL), while noting that stock prices are influenced by many non-tech factors.
**[Will all wealth become worthless? (Score: 4)](https://www.reddit.com/r/singularity/comments/1r33n4l/will_all_wealth_become_worthless/)**
*  **Summary:** The discussion revolves around 'Will all wealth become worthless?'. Users shared various perspectives, including: People give things value so they can exchange them. Rich people hoard wealth because they don't believe money is going anywhere. Some people call singularity "rapture of the nerds". We have no idea what is going to happen to wealth. If you believe humans and their institutions will survive, it's worth keeping some assets in diversified portfolio. Anyone trying to predict the future always ends up looking foolish. Money is a control mechanism over human labor. If human labor is worthless, then money is worthless. Nobody should cripple themselves or run themselves destitute. The best advice here is 'don't die'. Unless humans can augment their intelligence, they will be outpaced by AI. AI will be both the main creators and consumers of wealth. An economic system may still be required. Someone has to own the AI where all the values are going to be created to drive wealth. A youtube video by whom? Could become more "worthful." If there is serious deflation, and a dollar buys ten times as much in 2030 as it does today, what would the implications be? Money is used to exchange labour for something you want from somebody else. For most people it's still a way of valuing labour so they can buy goods and services. The stock market exists as an extension of that. In the singularity you can't sell your time or intelligence in the labor market. You can only buy stocks of the companies which invest it into AI and robotics to turn a profit. My advice is to find a balance between saving and spending on worthwhile experiences. If all thermometers break will all temperature be zero? Money is just a measure of value, not the value. Food will still have it, you still need to pay for it.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.68).
*  **Top 3 Points of View:**
    * Wealth will not become worthless but will fundamentally transform, with value potentially consolidating in the hands of AI owners or AI agents, making investments in AI companies crucial.
    * The traditional definition of money as a measure of human labor value suggests that if AI renders human labor obsolete, money's function would cease, potentially leading to new economic systems like bartering or energy rations.
    * Advice focuses on practical current actions: saving, investing in AI-related assets (while acknowledging risk), and enjoying life experiences, as the future is uncertain and predictions are often unreliable.
**[The daily grind (Score: 2)](https://www.reddit.com/r/singularity/comments/1r34k50/the_daily_grind/)**
*  **Summary:** The discussion revolves around 'The daily grind'. Users shared various perspectives, including: I have the exact feeling for the last few months, and it's been increasing. Today I walked in the grass in a park. It was grounding and relaxing. Machine learning has the problem of edge cases. Human action is pretty robust. Machine learning models fall apart under real word conditions. of Silicon Valley in the 1970s. It was because individual investments became too risky. No, I don't find it meaningless. The grind is becoming easier thanks to AI which is a welcomed development. When is it expected? People need to remember that the Government will not let something like "The Singularity" happen.
*  **Emotion:** The overall emotional tone is predominantly Neutral (average score: 0.67). There are also notes of Positive: 3.
*  **Top 3 Points of View:**
    * A shared sense of meaninglessness and impatience with daily routines, as personal efforts feel inconsequential compared to the imminent, society-altering changes brought by AI and the singularity.
    * Belief that the "daily grind" will become easier and new purposes will emerge with AI, suggesting continued societal work and personal goals remain important.
    * Skepticism about the immediate arrival of the singularity, citing the persistent challenge of "edge cases" in machine learning that make AI less robust in real-world conditions than human action.
